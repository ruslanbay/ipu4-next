From 7ebebd0ca5801ec6503f858dcdd90ce58010c748 Mon Sep 17 00:00:00 2001
From: ruslanbay <67730802+ruslanbay@users.noreply.github.com>
Date: Fri, 21 Nov 2025 14:43:50 +0100
Subject: [PATCH 2/9] IPU4: replace /drivers/media/pci/intel/ with
 https://github.com/intel/linux-intel-lts/tree/lts-v5.15.195-android_t-251103T063840Z/drivers/media/pci/intel

---
 drivers/media/pci/intel/Kconfig               |   64 +-
 drivers/media/pci/intel/Makefile              |   16 +-
 drivers/media/pci/intel/ipu-bus.c             |  210 ++-
 drivers/media/pci/intel/ipu-bus.h             |    9 +-
 drivers/media/pci/intel/ipu-buttress.c        | 1080 ++++++++++----
 drivers/media/pci/intel/ipu-buttress.h        |   25 +-
 drivers/media/pci/intel/ipu-cpd.c             |  167 ++-
 drivers/media/pci/intel/ipu-cpd.h             |   38 +-
 drivers/media/pci/intel/ipu-dma.c             |  252 ++--
 drivers/media/pci/intel/ipu-dma.h             |    2 +-
 drivers/media/pci/intel/ipu-fw-com.c          |   98 +-
 drivers/media/pci/intel/ipu-fw-com.h          |    7 +-
 drivers/media/pci/intel/ipu-fw-isys.c         |  458 +-----
 drivers/media/pci/intel/ipu-fw-isys.h         |  319 ++--
 drivers/media/pci/intel/ipu-fw-psys.c         |  272 +---
 drivers/media/pci/intel/ipu-fw-psys.h         |  102 +-
 .../media/pci/intel/ipu-isys-csi2-be-soc.c    |  309 ++--
 drivers/media/pci/intel/ipu-isys-csi2-be.c    |   79 +-
 drivers/media/pci/intel/ipu-isys-csi2-be.h    |   27 +-
 drivers/media/pci/intel/ipu-isys-csi2.c       |  454 +++++-
 drivers/media/pci/intel/ipu-isys-csi2.h       |   35 +-
 drivers/media/pci/intel/ipu-isys-media.h      |  101 +-
 drivers/media/pci/intel/ipu-isys-queue.c      |  595 +++++++-
 drivers/media/pci/intel/ipu-isys-queue.h      |   60 +-
 drivers/media/pci/intel/ipu-isys-subdev.c     |  593 ++++++--
 drivers/media/pci/intel/ipu-isys-subdev.h     |  117 +-
 drivers/media/pci/intel/ipu-isys-tpg.c        |  100 +-
 drivers/media/pci/intel/ipu-isys-tpg.h        |    8 +-
 drivers/media/pci/intel/ipu-isys-video.c      |  765 ++++++----
 drivers/media/pci/intel/ipu-isys-video.h      |   49 +-
 drivers/media/pci/intel/ipu-isys.c            | 1278 +++++++++--------
 drivers/media/pci/intel/ipu-isys.h            |   79 +-
 drivers/media/pci/intel/ipu-mmu.c             |  883 ++++++------
 drivers/media/pci/intel/ipu-mmu.h             |   42 +-
 drivers/media/pci/intel/ipu-pdata.h           |   51 +-
 drivers/media/pci/intel/ipu-psys-compat32.c   |   80 +-
 drivers/media/pci/intel/ipu-psys.c            |  624 ++++----
 drivers/media/pci/intel/ipu-psys.h            |   48 +-
 drivers/media/pci/intel/ipu-trace-event.h     |   99 ++
 drivers/media/pci/intel/ipu-trace.c           |  522 ++++---
 drivers/media/pci/intel/ipu-trace.h           |  168 ++-
 drivers/media/pci/intel/ipu-wrapper.c         |  547 +++++++
 drivers/media/pci/intel/ipu-wrapper.h         |   16 +
 drivers/media/pci/intel/ipu.c                 |  363 ++---
 drivers/media/pci/intel/ipu.h                 |   40 +-
 drivers/media/pci/intel/ipu3/ipu3-cio2-main.c |    2 +-
 drivers/media/pci/intel/ipu6/Makefile         |   58 -
 .../media/pci/intel/ipu6/ipu-fw-resources.c   |  103 --
 .../intel/ipu6/ipu-platform-buttress-regs.h   |  318 ----
 .../intel/ipu6/ipu-platform-isys-csi2-reg.h   |  277 ----
 .../media/pci/intel/ipu6/ipu-platform-isys.h  |   26 -
 .../media/pci/intel/ipu6/ipu-platform-psys.h  |   78 -
 .../media/pci/intel/ipu6/ipu-platform-regs.h  |  333 -----
 .../pci/intel/ipu6/ipu-platform-resources.h   |  103 --
 drivers/media/pci/intel/ipu6/ipu-platform.h   |   35 -
 drivers/media/pci/intel/ipu6/ipu-resources.c  |  860 -----------
 .../media/pci/intel/ipu6/ipu6-fw-resources.c  |  608 --------
 drivers/media/pci/intel/ipu6/ipu6-isys-csi2.c |  513 -------
 drivers/media/pci/intel/ipu6/ipu6-isys-csi2.h |   14 -
 drivers/media/pci/intel/ipu6/ipu6-isys-gpc.c  |  203 ---
 drivers/media/pci/intel/ipu6/ipu6-isys-phy.c  |  595 --------
 drivers/media/pci/intel/ipu6/ipu6-isys-phy.h  |  159 --
 drivers/media/pci/intel/ipu6/ipu6-isys.c      |  174 ---
 .../media/pci/intel/ipu6/ipu6-l-scheduler.c   |  615 --------
 .../pci/intel/ipu6/ipu6-platform-resources.h  |  196 ---
 drivers/media/pci/intel/ipu6/ipu6-ppg.c       |  560 --------
 drivers/media/pci/intel/ipu6/ipu6-ppg.h       |   38 -
 drivers/media/pci/intel/ipu6/ipu6-psys-gpc.c  |  210 ---
 drivers/media/pci/intel/ipu6/ipu6-psys.c      | 1032 -------------
 drivers/media/pci/intel/ipu6/ipu6.c           |  333 -----
 .../pci/intel/ipu6/ipu6ep-fw-resources.c      |  393 -----
 .../intel/ipu6/ipu6ep-platform-resources.h    |   42 -
 .../pci/intel/ipu6/ipu6se-fw-resources.c      |  194 ---
 .../intel/ipu6/ipu6se-platform-resources.h    |  103 --
 74 files changed, 7061 insertions(+), 12365 deletions(-)
 create mode 100644 drivers/media/pci/intel/ipu-trace-event.h
 create mode 100644 drivers/media/pci/intel/ipu-wrapper.c
 create mode 100644 drivers/media/pci/intel/ipu-wrapper.h
 delete mode 100644 drivers/media/pci/intel/ipu6/Makefile
 delete mode 100644 drivers/media/pci/intel/ipu6/ipu-fw-resources.c
 delete mode 100644 drivers/media/pci/intel/ipu6/ipu-platform-buttress-regs.h
 delete mode 100644 drivers/media/pci/intel/ipu6/ipu-platform-isys-csi2-reg.h
 delete mode 100644 drivers/media/pci/intel/ipu6/ipu-platform-isys.h
 delete mode 100644 drivers/media/pci/intel/ipu6/ipu-platform-psys.h
 delete mode 100644 drivers/media/pci/intel/ipu6/ipu-platform-regs.h
 delete mode 100644 drivers/media/pci/intel/ipu6/ipu-platform-resources.h
 delete mode 100644 drivers/media/pci/intel/ipu6/ipu-platform.h
 delete mode 100644 drivers/media/pci/intel/ipu6/ipu-resources.c
 delete mode 100644 drivers/media/pci/intel/ipu6/ipu6-fw-resources.c
 delete mode 100644 drivers/media/pci/intel/ipu6/ipu6-isys-csi2.c
 delete mode 100644 drivers/media/pci/intel/ipu6/ipu6-isys-csi2.h
 delete mode 100644 drivers/media/pci/intel/ipu6/ipu6-isys-gpc.c
 delete mode 100644 drivers/media/pci/intel/ipu6/ipu6-isys-phy.c
 delete mode 100644 drivers/media/pci/intel/ipu6/ipu6-isys-phy.h
 delete mode 100644 drivers/media/pci/intel/ipu6/ipu6-isys.c
 delete mode 100644 drivers/media/pci/intel/ipu6/ipu6-l-scheduler.c
 delete mode 100644 drivers/media/pci/intel/ipu6/ipu6-platform-resources.h
 delete mode 100644 drivers/media/pci/intel/ipu6/ipu6-ppg.c
 delete mode 100644 drivers/media/pci/intel/ipu6/ipu6-ppg.h
 delete mode 100644 drivers/media/pci/intel/ipu6/ipu6-psys-gpc.c
 delete mode 100644 drivers/media/pci/intel/ipu6/ipu6-psys.c
 delete mode 100644 drivers/media/pci/intel/ipu6/ipu6.c
 delete mode 100644 drivers/media/pci/intel/ipu6/ipu6ep-fw-resources.c
 delete mode 100644 drivers/media/pci/intel/ipu6/ipu6ep-platform-resources.h
 delete mode 100644 drivers/media/pci/intel/ipu6/ipu6se-fw-resources.c
 delete mode 100644 drivers/media/pci/intel/ipu6/ipu6se-platform-resources.h

diff --git a/drivers/media/pci/intel/Kconfig b/drivers/media/pci/intel/Kconfig
index ee4a77acb66f..01418fce13be 100644
--- a/drivers/media/pci/intel/Kconfig
+++ b/drivers/media/pci/intel/Kconfig
@@ -1,20 +1,66 @@
-config VIDEO_INTEL_IPU6
+config VIDEO_INTEL_IPU
 	tristate "Intel IPU driver"
 	depends on ACPI
-	depends on MEDIA_SUPPORT
-	depends on MEDIA_PCI_SUPPORT
 	select IOMMU_API
 	select IOMMU_IOVA
 	select X86_DEV_DMA_OPS if X86
 	select VIDEOBUF2_DMA_CONTIG
-	select V4L2_FWNODE
 	select PHYS_ADDR_T_64BIT
 	select COMMON_CLK
 	help
-	  This is the Intel imaging processing unit, found in Intel SoCs and
-	  used for capturing images and video from a camera sensor.
+		Say Y here!
 
-	  To compile this driver, say Y here! It contains 3 modules -
-	  intel_ipu6, intel_ipu6_isys and intel_ipu6_psys.
+choice
+	prompt "intel ipu generation type"
+	depends on VIDEO_INTEL_IPU
+	default VIDEO_INTEL_IPU4
+
+config VIDEO_INTEL_IPU4
+	bool "Compile for IPU4 driver"
+	help
+		Say Y here!
+
+config VIDEO_INTEL_IPU4P
+	bool "Compile for IPU4P driver"
+	help
+		Say Y here!
+
+endchoice
+
+choice
+	prompt "intel ipu hardware platform type"
+	depends on VIDEO_INTEL_IPU
+	default VIDEO_INTEL_IPU_SOC
+
+config VIDEO_INTEL_IPU_SOC
+	bool "Compile for SOC"
+	help
+		Select for SOC platform
+
+endchoice
+
+config VIDEO_INTEL_IPU_FW_LIB
+	bool "Compile firmware library"
+	default y
+	help
+		If selected, the firmware hostlib css would be compiled
+
+config VIDEO_INTEL_IPU_WERROR
+	bool "Force GCC to throw an error instead of a warning when compiling"
+	depends on VIDEO_INTEL_IPU
+	depends on EXPERT
+	depends on !COMPILE_TEST
+	default n
+	help
+	  Add -Werror to the build flags for (and only for) intel ipu module.
+	  Do not enable this unless you are writing code for the ipu module.
+
+	  Recommended for driver developers only.
+
+	  If in doubt, say "N".
+
+config VIDEO_INTEL_UOS
+        bool "Compile driver per UOS"
+        help
+	        If selected UOS driver components will be compiled
 
-source "drivers/media/pci/intel/ipu3/Kconfig"
diff --git a/drivers/media/pci/intel/Makefile b/drivers/media/pci/intel/Makefile
index 6e1b92ef63d4..6955385d34ec 100644
--- a/drivers/media/pci/intel/Makefile
+++ b/drivers/media/pci/intel/Makefile
@@ -3,5 +3,17 @@
 # Makefile for the IPU3 cio2 and ImGU drivers
 #
 
-obj-$(CONFIG_VIDEO_IPU3_CIO2)   += ipu3/
-obj-$(CONFIG_VIDEO_INTEL_IPU6)	+= ipu6/
+obj-y	+= ipu3/
+# force check the compile warning to make sure zero warnings
+# note we may have build issue when gcc upgraded.
+ccflags-y := -Wno-error=uninitialized
+subdir-ccflags-y += $(call cc-disable-warning, unused-parameter)
+subdir-ccflags-y += $(call cc-disable-warning, implicit-fallthrough)
+subdir-ccflags-y += $(call cc-disable-warning, missing-field-initializers)
+subdir-ccflags-y += $(call cc-disable-warning, int-conversion)
+subdir-ccflags-y += $(call cc-disable-warning, enum-conversion)
+subdir-ccflags-y += $(call cc-disable-warning, uninitialized)
+subdir-ccflags-$(CONFIG_VIDEO_INTEL_IPU_WERROR) += -Werror
+
+obj-$(CONFIG_VIDEO_INTEL_IPU4)  += ipu4/
+obj-$(CONFIG_VIDEO_INTEL_IPU4P)	+= ipu4/
diff --git a/drivers/media/pci/intel/ipu-bus.c b/drivers/media/pci/intel/ipu-bus.c
index d3b7f44c0e8a..03cf1cb0d918 100644
--- a/drivers/media/pci/intel/ipu-bus.c
+++ b/drivers/media/pci/intel/ipu-bus.c
@@ -1,5 +1,5 @@
 // SPDX-License-Identifier: GPL-2.0
-// Copyright (C) 2013 - 2020 Intel Corporation
+// Copyright (C) 2013 - 2018 Intel Corporation
 
 #include <linux/delay.h>
 #include <linux/device.h>
@@ -14,15 +14,41 @@
 #include "ipu.h"
 #include "ipu-platform.h"
 #include "ipu-dma.h"
+#include "ipu-mmu.h"
 
 #ifdef CONFIG_PM
 static struct bus_type ipu_bus;
 
+static int bus_pm_suspend_child_dev(struct device *dev, void *p)
+{
+	struct ipu_bus_device *adev = to_ipu_bus_device(dev);
+	struct device *parent = (struct device *)p;
+
+	if (!ipu_bus_get_drvdata(adev))
+		return 0;	/* Device not attached to any driver yet */
+
+	if (dev->parent != parent || adev->ctrl)
+		return 0;
+
+	return pm_generic_runtime_suspend(dev);
+}
+
 static int bus_pm_runtime_suspend(struct device *dev)
 {
 	struct ipu_bus_device *adev = to_ipu_bus_device(dev);
 	int rval;
 
+	if (!adev->ctrl) {
+		dev_dbg(dev, "has no buttress control info, bailing out\n");
+		return 0;
+	}
+
+	rval = bus_for_each_dev(&ipu_bus, NULL, dev, bus_pm_suspend_child_dev);
+	if (rval) {
+		dev_err(dev, "failed to suspend child device\n");
+		return rval;
+	}
+
 	rval = pm_generic_runtime_suspend(dev);
 	if (rval)
 		return rval;
@@ -42,11 +68,34 @@ static int bus_pm_runtime_suspend(struct device *dev)
 	return -EIO;
 }
 
+static int bus_pm_resume_child_dev(struct device *dev, void *p)
+{
+	struct ipu_bus_device *adev = to_ipu_bus_device(dev);
+	struct device *parent = (struct device *)p;
+	int r;
+
+	if (!ipu_bus_get_drvdata(adev))
+		return 0;	/* Device not attached to any driver yet */
+
+	if (dev->parent != parent || adev->ctrl)
+		return 0;
+
+	mutex_lock(&adev->resume_lock);
+	r = pm_generic_runtime_resume(dev);
+	mutex_unlock(&adev->resume_lock);
+	return r;
+}
+
 static int bus_pm_runtime_resume(struct device *dev)
 {
 	struct ipu_bus_device *adev = to_ipu_bus_device(dev);
 	int rval;
 
+	if (!adev->ctrl) {
+		dev_dbg(dev, "has no buttress control info, bailing out\n");
+		return 0;
+	}
+
 	rval = ipu_buttress_power(dev, adev->ctrl, true);
 	dev_dbg(dev, "%s: buttress power up %d\n", __func__, rval);
 	if (rval)
@@ -57,10 +106,50 @@ static int bus_pm_runtime_resume(struct device *dev)
 	if (rval)
 		goto out_err;
 
+	/*
+	 * It needs to be ensured that IPU child devices' resume/suspend are
+	 * called only when the child devices' power is turned on/off by the
+	 * parent device here. Therefore, children's suspend/resume are called
+	 * from here, because that is the only way to guarantee it.
+	 */
+	rval = bus_for_each_dev(&ipu_bus, NULL, dev, bus_pm_resume_child_dev);
+	if (rval) {
+		dev_err(dev, "failed to resume child device - reset it\n");
+
+		rval = pm_generic_runtime_suspend(dev);
+		dev_dbg(dev, "%s: suspend %d\n", __func__, rval);
+
+		rval = ipu_buttress_power(dev, adev->ctrl, false);
+		dev_dbg(dev, "%s: buttress power down %d\n", __func__, rval);
+		if (rval)
+			return rval;
+
+		usleep_range(1000, 1100);
+
+		rval = ipu_buttress_power(dev, adev->ctrl, true);
+		dev_dbg(dev, "%s: buttress power up %d\n", __func__, rval);
+		if (rval)
+			return rval;
+
+		rval = pm_generic_runtime_resume(dev);
+		dev_dbg(dev, "%s: re-resume %d\n", __func__, rval);
+		if (rval)
+			goto out_err;
+
+		rval = bus_for_each_dev(&ipu_bus, NULL, dev,
+					bus_pm_resume_child_dev);
+
+		if (rval) {
+			dev_err(dev, "resume retry failed\n");
+			goto out_err;
+		}
+	}
+
 	return 0;
 
 out_err:
-	ipu_buttress_power(dev, adev->ctrl, false);
+	if (adev->ctrl)
+		ipu_buttress_power(dev, adev->ctrl, false);
 
 	return -EBUSY;
 }
@@ -85,28 +174,100 @@ static int ipu_bus_match(struct device *dev, struct device_driver *drv)
 	return !strncmp(dev_name(dev), adrv->wanted, strlen(adrv->wanted));
 }
 
+static struct ipu_dma_mapping *alloc_dma_mapping(struct device *dev)
+{
+	struct ipu_dma_mapping *dmap;
+
+	dmap = kzalloc(sizeof(*dmap), GFP_KERNEL);
+	if (!dmap)
+		return NULL;
+
+	dmap->mmu_info = ipu_mmu_alloc();
+	if (!dmap->mmu_info) {
+		kfree(dmap);
+		return NULL;
+	}
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 0, 0)
+	init_iova_domain(&dmap->iovad, dma_get_mask(dev) >> PAGE_SHIFT);
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(4, 15, 0)
+	init_iova_domain(&dmap->iovad, SZ_4K, 1,
+			 dma_get_mask(dev) >> PAGE_SHIFT);
+#else
+	init_iova_domain(&dmap->iovad, SZ_4K, 1);
+#endif
+	dmap->mmu_info->dmap = dmap;
+
+	kref_init(&dmap->ref);
+
+	pr_debug("alloc mapping\n");
+
+	iova_cache_get();
+
+	return dmap;
+}
+
+static void free_dma_mapping(struct ipu_mmu *mmu)
+{
+	struct ipu_dma_mapping *dmap = mmu->dmap;
+
+	ipu_mmu_destroy(dmap->mmu_info);
+	mmu->set_mapping(mmu, NULL);
+	iova_cache_put();
+	put_iova_domain(&dmap->iovad);
+	kfree(dmap);
+}
+
 static int ipu_bus_probe(struct device *dev)
 {
 	struct ipu_bus_device *adev = to_ipu_bus_device(dev);
 	struct ipu_bus_driver *adrv = to_ipu_bus_driver(dev->driver);
+	struct ipu_mmu *mmu;
+	struct ipu_dma_mapping *dmap;
 	int rval;
 
 	dev_dbg(dev, "bus probe dev %s\n", dev_name(dev));
 
+	if (adev->iommu) {
+		dev_dbg(dev, "alloc dma mapping\n");
+		mmu = ipu_bus_get_drvdata(to_ipu_bus_device(adev->iommu));
+
+		dmap = alloc_dma_mapping(dev);
+		if (!dmap) {
+			dev_err(dev, "%s: can't alloc dma mapping\n", __func__);
+			rval = -ENOMEM;
+			goto out_err;
+		}
+
+		/*
+		 * Turn mmu on and off synchronously. Otherwise it may still
+		 * be on at psys / isys probing phase and that may cause
+		 * problems on development environments.
+		 */
+		pm_runtime_get_sync(dev);
+		mmu->set_mapping(mmu, dmap);
+		pm_runtime_put_sync(dev);
+	}
+
 	adev->adrv = adrv;
-	if (!adrv->probe) {
+	if (adrv->probe) {
+		rval = adrv->probe(adev);
+		if (!rval) {
+			/*
+			 * If the device power, after probe, is enabled
+			 * (from the parent device), its resume needs to
+			 * be called to initialize the device properly.
+			 */
+			if (!adev->ctrl &&
+			    !pm_runtime_status_suspended(dev->parent)) {
+				mutex_lock(&adev->resume_lock);
+				pm_generic_runtime_resume(dev);
+				mutex_unlock(&adev->resume_lock);
+			}
+		}
+	} else {
 		rval = -ENODEV;
-		goto out_err;
-	}
-	rval = pm_runtime_get_sync(&adev->dev);
-	if (rval < 0) {
-		dev_err(&adev->dev, "Failed to get runtime PM\n");
-		goto out_err;
 	}
 
-	rval = adrv->probe(adev);
-	pm_runtime_put(&adev->dev);
-
 	if (rval)
 		goto out_err;
 
@@ -115,7 +276,6 @@ static int ipu_bus_probe(struct device *dev)
 out_err:
 	ipu_bus_set_drvdata(adev, NULL);
 	adev->adrv = NULL;
-
 	return rval;
 }
 
@@ -123,9 +283,14 @@ static void ipu_bus_remove(struct device *dev)
 {
 	struct ipu_bus_device *adev = to_ipu_bus_device(dev);
 	struct ipu_bus_driver *adrv = to_ipu_bus_driver(dev->driver);
+	struct ipu_bus_device *adev_iommu = to_ipu_bus_device(adev->iommu);
+	struct ipu_mmu *mmu = ipu_bus_get_drvdata(adev_iommu);
 
 	if (adrv->remove)
 		adrv->remove(adev);
+
+	if (adev->iommu)
+		free_dma_mapping(mmu);
 }
 
 static struct bus_type ipu_bus = {
@@ -140,10 +305,14 @@ static struct mutex ipu_bus_mutex;
 
 static void ipu_bus_release(struct device *dev)
 {
+	struct ipu_bus_device *adev = to_ipu_bus_device(dev);
+
+	kfree(adev);
 }
 
 struct ipu_bus_device *ipu_bus_add_device(struct pci_dev *pdev,
 					  struct device *parent, void *pdata,
+					  struct device *iommu,
 					  struct ipu_buttress_ctrl *ctrl,
 					  char *name, unsigned int nr)
 {
@@ -151,20 +320,24 @@ struct ipu_bus_device *ipu_bus_add_device(struct pci_dev *pdev,
 	struct ipu_device *isp = pci_get_drvdata(pdev);
 	int rval;
 
-	adev = devm_kzalloc(&pdev->dev, sizeof(*adev), GFP_KERNEL);
+	adev = kzalloc(sizeof(*adev), GFP_KERNEL);
 	if (!adev)
 		return ERR_PTR(-ENOMEM);
 
 	adev->dev.parent = parent;
 	adev->dev.bus = &ipu_bus;
 	adev->dev.release = ipu_bus_release;
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 13, 16)
 	adev->dev.dma_ops = &ipu_dma_ops;
+#else
+	adev->dev.archdata.dma_ops = &ipu_dma_ops;
+#endif
 	adev->dma_mask = DMA_BIT_MASK(isp->secure_mode ?
 				      IPU_MMU_ADDRESS_BITS :
 				      IPU_MMU_ADDRESS_BITS_NON_SECURE);
 	adev->dev.dma_mask = &adev->dma_mask;
-	adev->dev.dma_parms = pdev->dev.dma_parms;
 	adev->dev.coherent_dma_mask = adev->dma_mask;
+	adev->iommu = iommu;
 	adev->ctrl = ctrl;
 	adev->pdata = pdata;
 	adev->isp = isp;
@@ -181,9 +354,6 @@ struct ipu_bus_device *ipu_bus_add_device(struct pci_dev *pdev,
 	list_add(&adev->list, &isp->devices);
 	mutex_unlock(&ipu_bus_mutex);
 
-	pm_runtime_allow(&adev->dev);
-	pm_runtime_enable(&adev->dev);
-
 	return adev;
 }
 
@@ -195,7 +365,6 @@ void ipu_bus_del_devices(struct pci_dev *pdev)
 	mutex_lock(&ipu_bus_mutex);
 
 	list_for_each_entry_safe(adev, save, &isp->devices, list) {
-		pm_runtime_disable(&adev->dev);
 		list_del(&adev->list);
 		device_unregister(&adev->dev);
 	}
@@ -222,12 +391,14 @@ int ipu_bus_register(void)
 	mutex_init(&ipu_bus_mutex);
 	return bus_register(&ipu_bus);
 }
+EXPORT_SYMBOL(ipu_bus_register);
 
 void ipu_bus_unregister(void)
 {
 	mutex_destroy(&ipu_bus_mutex);
 	return bus_unregister(&ipu_bus);
 }
+EXPORT_SYMBOL(ipu_bus_unregister);
 
 static int flr_rpm_recovery(struct device *dev, void *p)
 {
@@ -252,3 +423,4 @@ int ipu_bus_flr_recovery(void)
 	bus_for_each_dev(&ipu_bus, NULL, NULL, flr_rpm_recovery);
 	return 0;
 }
+EXPORT_SYMBOL(ipu_bus_flr_recovery);
diff --git a/drivers/media/pci/intel/ipu-bus.h b/drivers/media/pci/intel/ipu-bus.h
index 1108cd377705..5d47d03b06c4 100644
--- a/drivers/media/pci/intel/ipu-bus.h
+++ b/drivers/media/pci/intel/ipu-bus.h
@@ -1,5 +1,5 @@
 /* SPDX-License-Identifier: GPL-2.0 */
-/* Copyright (C) 2013 - 2020 Intel Corporation */
+/* Copyright (C) 2013 - 2018 Intel Corporation */
 
 #ifndef IPU_BUS_H
 #define IPU_BUS_H
@@ -9,6 +9,7 @@
 #include <linux/list.h>
 #include <linux/mm.h>
 #include <linux/pci.h>
+#include <linux/iommu.h>
 
 #define IPU_BUS_NAME	IPU_NAME "-bus"
 
@@ -20,7 +21,8 @@ struct ipu_bus_device {
 	struct list_head list;
 	void *pdata;
 	struct ipu_bus_driver *adrv;
-	struct ipu_mmu *mmu;
+	struct device *iommu;
+	struct iommu_device iommu_dev;
 	struct ipu_device *isp;
 	struct ipu_subsystem_trace_config *trace_cfg;
 	struct ipu_buttress_ctrl *ctrl;
@@ -33,7 +35,7 @@ struct ipu_bus_device {
 
 struct ipu_bus_driver {
 	struct device_driver drv;
-	const char *wanted;
+	char wanted[20];
 	int (*probe)(struct ipu_bus_device *adev);
 	void (*remove)(struct ipu_bus_device *adev);
 	irqreturn_t (*isr)(struct ipu_bus_device *adev);
@@ -45,6 +47,7 @@ struct ipu_bus_driver {
 
 struct ipu_bus_device *ipu_bus_add_device(struct pci_dev *pdev,
 					  struct device *parent, void *pdata,
+					  struct device *iommu,
 					  struct ipu_buttress_ctrl *ctrl,
 					  char *name, unsigned int nr);
 void ipu_bus_del_devices(struct pci_dev *pdev);
diff --git a/drivers/media/pci/intel/ipu-buttress.c b/drivers/media/pci/intel/ipu-buttress.c
index 41d484d6c5e2..7967fe5410d3 100644
--- a/drivers/media/pci/intel/ipu-buttress.c
+++ b/drivers/media/pci/intel/ipu-buttress.c
@@ -1,5 +1,5 @@
 // SPDX-License-Identifier: GPL-2.0
-// Copyright (C) 2013 - 2020 Intel Corporation
+// Copyright (C) 2013 - 2018 Intel Corporation
 
 #include <linux/clk.h>
 #include <linux/clkdev.h>
@@ -11,7 +11,6 @@
 #include <linux/elf.h>
 #include <linux/errno.h>
 #include <linux/firmware.h>
-#include <linux/iopoll.h>
 #include <linux/module.h>
 #include <linux/pci.h>
 #include <linux/pm_runtime.h>
@@ -23,9 +22,11 @@
 #include "ipu-buttress.h"
 #include "ipu-platform-buttress-regs.h"
 #include "ipu-cpd.h"
+#define CREATE_TRACE_POINTS
+#define IPU_PERF_REG_TRACE
+#include "ipu-trace-event.h"
 
-#define BOOTLOADER_STATUS_OFFSET       0x15c
-
+#define BOOTLOADER_STATUS_OFFSET	0x8000
 #define BOOTLOADER_MAGIC_KEY		0xb00710ad
 
 #define ENTRY	BUTTRESS_IU2CSECSR_IPC_PEER_COMP_ACTIONS_RST_PHASE1
@@ -34,15 +35,13 @@
 
 #define BUTTRESS_TSC_SYNC_RESET_TRIAL_MAX	10
 
-#define BUTTRESS_CSE_BOOTLOAD_TIMEOUT		5000000
-#define BUTTRESS_CSE_AUTHENTICATE_TIMEOUT	10000000
-#define BUTTRESS_CSE_FWRESET_TIMEOUT		100000
+#define BUTTRESS_CSE_BOOTLOAD_TIMEOUT		5000
+#define BUTTRESS_CSE_AUTHENTICATE_TIMEOUT	10000
+#define BUTTRESS_CSE_FWRESET_TIMEOUT		100
 
 #define BUTTRESS_IPC_TX_TIMEOUT			1000
-#define BUTTRESS_IPC_RESET_TIMEOUT		2000
 #define BUTTRESS_IPC_RX_TIMEOUT			1000
-#define BUTTRESS_IPC_VALIDITY_TIMEOUT		1000000
-#define BUTTRESS_TSC_SYNC_TIMEOUT		5000
+#define BUTTRESS_IPC_VALIDITY_TIMEOUT		1000
 
 #define IPU_BUTTRESS_TSC_LIMIT	500	/* 26 us @ 19.2 MHz */
 #define IPU_BUTTRESS_TSC_RETRY	10
@@ -51,6 +50,23 @@
 
 #define BUTTRESS_IPC_CMD_SEND_RETRY	1
 
+static const struct ipu_buttress_sensor_clk_freq sensor_clk_freqs[] = {
+	{6750000, BUTTRESS_SENSOR_CLK_FREQ_6P75MHZ},
+	{8000000, BUTTRESS_SENSOR_CLK_FREQ_8MHZ},
+	{9600000, BUTTRESS_SENSOR_CLK_FREQ_9P6MHZ},
+	{12000000, BUTTRESS_SENSOR_CLK_FREQ_12MHZ},
+	{13600000, BUTTRESS_SENSOR_CLK_FREQ_13P6MHZ},
+	{14400000, BUTTRESS_SENSOR_CLK_FREQ_14P4MHZ},
+	{15800000, BUTTRESS_SENSOR_CLK_FREQ_15P8MHZ},
+	{16200000, BUTTRESS_SENSOR_CLK_FREQ_16P2MHZ},
+	{17300000, BUTTRESS_SENSOR_CLK_FREQ_17P3MHZ},
+	{18600000, BUTTRESS_SENSOR_CLK_FREQ_18P6MHZ},
+	{19200000, BUTTRESS_SENSOR_CLK_FREQ_19P2MHZ},
+	{24000000, BUTTRESS_SENSOR_CLK_FREQ_24MHZ},
+	{26000000, BUTTRESS_SENSOR_CLK_FREQ_26MHZ},
+	{27000000, BUTTRESS_SENSOR_CLK_FREQ_27MHZ}
+};
+
 static const u32 ipu_adev_irq_mask[] = {
 	BUTTRESS_ISR_IS_IRQ, BUTTRESS_ISR_PS_IRQ
 };
@@ -58,14 +74,10 @@ static const u32 ipu_adev_irq_mask[] = {
 int ipu_buttress_ipc_reset(struct ipu_device *isp, struct ipu_buttress_ipc *ipc)
 {
 	struct ipu_buttress *b = &isp->buttress;
-	unsigned int retries = BUTTRESS_IPC_RESET_TIMEOUT;
+	unsigned long tout_jfs;
+	unsigned int tout = 500;
 	u32 val = 0, csr_in_clr;
 
-	if (!isp->secure_mode) {
-		dev_info(&isp->pdev->dev, "Skip ipc reset for non-secure mode");
-		return 0;
-	}
-
 	mutex_lock(&b->ipc_mutex);
 
 	/* Clear-by-1 CSR (all bits), corresponding internal states. */
@@ -74,6 +86,7 @@ int ipu_buttress_ipc_reset(struct ipu_device *isp, struct ipu_buttress_ipc *ipc)
 
 	/* Set peer CSR bit IPC_PEER_COMP_ACTIONS_RST_PHASE1 */
 	writel(ENTRY, isp->base + ipc->csr_out);
+
 	/*
 	 * Clear-by-1 all CSR bits EXCEPT following
 	 * bits:
@@ -83,46 +96,57 @@ int ipu_buttress_ipc_reset(struct ipu_device *isp, struct ipu_buttress_ipc *ipc)
 	 * their role.
 	 */
 	csr_in_clr = BUTTRESS_IU2CSECSR_IPC_PEER_DEASSERTED_REG_VALID_REQ |
-		BUTTRESS_IU2CSECSR_IPC_PEER_ACKED_REG_VALID |
-		BUTTRESS_IU2CSECSR_IPC_PEER_ASSERTED_REG_VALID_REQ | QUERY;
+	    BUTTRESS_IU2CSECSR_IPC_PEER_ACKED_REG_VALID |
+	    BUTTRESS_IU2CSECSR_IPC_PEER_ASSERTED_REG_VALID_REQ | QUERY;
 
-	while (retries--) {
-		usleep_range(400, 500);
+	/*
+	 * How long we should wait here?
+	 */
+	tout_jfs = jiffies + msecs_to_jiffies(tout);
+	do {
 		val = readl(isp->base + ipc->csr_in);
-		switch (val) {
-		case (ENTRY | EXIT):
-		case (ENTRY | EXIT | QUERY):
-			dev_dbg(&isp->pdev->dev,
-				"%s:%s & %s\n", __func__,
-				"IPC_PEER_COMP_ACTIONS_RST_PHASE1",
-				"IPC_PEER_COMP_ACTIONS_RST_PHASE2");
-			/*
-			 * 1) Clear-by-1 CSR bits
-			 * (IPC_PEER_COMP_ACTIONS_RST_PHASE1,
-			 * IPC_PEER_COMP_ACTIONS_RST_PHASE2).
-			 * 2) Set peer CSR bit
-			 * IPC_PEER_QUERIED_IP_COMP_ACTIONS_RST_PHASE.
-			 */
-			writel(ENTRY | EXIT, isp->base + ipc->csr_in);
-			writel(QUERY, isp->base + ipc->csr_out);
-			break;
-		case ENTRY:
-		case (ENTRY | QUERY):
-			dev_dbg(&isp->pdev->dev,
-				"%s:IPC_PEER_COMP_ACTIONS_RST_PHASE1\n",
-				__func__);
-			/*
-			 * 1) Clear-by-1 CSR bits
-			 * (IPC_PEER_COMP_ACTIONS_RST_PHASE1,
-			 * IPC_PEER_QUERIED_IP_COMP_ACTIONS_RST_PHASE).
-			 * 2) Set peer CSR bit
-			 * IPC_PEER_COMP_ACTIONS_RST_PHASE1.
-			 */
-			writel(ENTRY | QUERY, isp->base + ipc->csr_in);
-			writel(ENTRY, isp->base + ipc->csr_out);
-			break;
-		case EXIT:
-		case (EXIT | QUERY):
+		dev_dbg(&isp->pdev->dev, "%s: csr_in = %x\n", __func__, val);
+		if (val & ENTRY) {
+			if (val & EXIT) {
+				dev_dbg(&isp->pdev->dev,
+					"%s:%s & %s\n",
+					__func__,
+					"IPC_PEER_COMP_ACTIONS_RST_PHASE1",
+					"IPC_PEER_COMP_ACTIONS_RST_PHASE2");
+				/*
+				 * 1) Clear-by-1 CSR bits
+				 * (IPC_PEER_COMP_ACTIONS_RST_PHASE1,
+				 * IPC_PEER_COMP_ACTIONS_RST_PHASE2).
+				 * 2) Set peer CSR bit
+				 * IPC_PEER_QUERIED_IP_COMP_ACTIONS_RST_PHASE.
+				 */
+				writel(ENTRY | EXIT,
+					   isp->base + ipc->csr_in);
+
+				writel(QUERY, isp->base + ipc->csr_out);
+
+				tout_jfs = jiffies + msecs_to_jiffies(tout);
+				continue;
+			} else {
+				dev_dbg(&isp->pdev->dev,
+					"%s:IPC_PEER_COMP_ACTIONS_RST_PHASE1\n",
+					__func__);
+				/*
+				 * 1) Clear-by-1 CSR bits
+				 * (IPC_PEER_COMP_ACTIONS_RST_PHASE1,
+				 * IPC_PEER_QUERIED_IP_COMP_ACTIONS_RST_PHASE).
+				 * 2) Set peer CSR bit
+				 * IPC_PEER_COMP_ACTIONS_RST_PHASE1.
+				 */
+				writel(ENTRY | QUERY,
+					   isp->base + ipc->csr_in);
+
+				writel(ENTRY, isp->base + ipc->csr_out);
+
+				tout_jfs = jiffies + msecs_to_jiffies(tout);
+				continue;
+			}
+		} else if (val & EXIT) {
 			dev_dbg(&isp->pdev->dev,
 				"%s: IPC_PEER_COMP_ACTIONS_RST_PHASE2\n",
 				__func__);
@@ -140,27 +164,34 @@ int ipu_buttress_ipc_reset(struct ipu_device *isp, struct ipu_buttress_ipc *ipc)
 			 * IPC_PEER_COMP_ACTIONS_RST_PHASE2.
 			 */
 			writel(EXIT, isp->base + ipc->csr_in);
-			writel(0, isp->base + ipc->db0_in);
+
+			writel(0 << BUTTRESS_IU2CSEDB0_BUSY_SHIFT,
+				   isp->base + ipc->db0_in);
+
 			writel(csr_in_clr, isp->base + ipc->csr_in);
+
 			writel(EXIT, isp->base + ipc->csr_out);
 
 			/*
 			 * Read csr_in again to make sure if RST_PHASE2 is done.
 			 * If csr_in is QUERY, it should be handled again.
 			 */
-			usleep_range(200, 300);
+			usleep_range(100, 500);
 			val = readl(isp->base + ipc->csr_in);
 			if (val & QUERY) {
 				dev_dbg(&isp->pdev->dev,
 					"%s: RST_PHASE2 retry csr_in = %x\n",
 					__func__, val);
-				break;
+				continue;
 			}
+
 			mutex_unlock(&b->ipc_mutex);
+
 			return 0;
-		case QUERY:
+		} else if (val & QUERY) {
 			dev_dbg(&isp->pdev->dev,
-				"%s: %s\n", __func__,
+				"%s: %s\n",
+				__func__,
 				"IPC_PEER_QUERIED_IP_COMP_ACTIONS_RST_PHASE");
 			/*
 			 * 1) Clear-by-1 CSR bit
@@ -169,18 +200,17 @@ int ipu_buttress_ipc_reset(struct ipu_device *isp, struct ipu_buttress_ipc *ipc)
 			 * IPC_PEER_COMP_ACTIONS_RST_PHASE1
 			 */
 			writel(QUERY, isp->base + ipc->csr_in);
+
 			writel(ENTRY, isp->base + ipc->csr_out);
-			break;
-		default:
-			dev_dbg_ratelimited(&isp->pdev->dev,
-					    "%s: unexpected CSR 0x%x\n",
-					    __func__, val);
-			break;
+
+			tout_jfs = jiffies + msecs_to_jiffies(tout);
 		}
-	}
+		usleep_range(100, 500);
+	} while (!time_after(jiffies, tout_jfs));
 
 	mutex_unlock(&b->ipc_mutex);
-	dev_err(&isp->pdev->dev, "Timed out while waiting for CSE\n");
+
+	dev_err(&isp->pdev->dev, "Timed out while waiting for CSE!\n");
 
 	return -ETIMEDOUT;
 }
@@ -191,32 +221,44 @@ ipu_buttress_ipc_validity_close(struct ipu_device *isp,
 {
 	/* Set bit 5 in CSE CSR */
 	writel(BUTTRESS_IU2CSECSR_IPC_PEER_DEASSERTED_REG_VALID_REQ,
-	       isp->base + ipc->csr_out);
+		   isp->base + ipc->csr_out);
 }
 
 static int
 ipu_buttress_ipc_validity_open(struct ipu_device *isp,
 			       struct ipu_buttress_ipc *ipc)
 {
-	unsigned int mask = BUTTRESS_IU2CSECSR_IPC_PEER_ACKED_REG_VALID;
+	unsigned long tout_jfs;
 	unsigned int tout = BUTTRESS_IPC_VALIDITY_TIMEOUT;
-	void __iomem *addr;
-	int ret;
 	u32 val;
 
 	/* Set bit 3 in CSE CSR */
 	writel(BUTTRESS_IU2CSECSR_IPC_PEER_ASSERTED_REG_VALID_REQ,
-	       isp->base + ipc->csr_out);
+		   isp->base + ipc->csr_out);
 
-	addr = isp->base + ipc->csr_in;
-	ret = readl_poll_timeout(addr, val, val & mask, 200, tout);
-	if (ret) {
-		val = readl(addr);
-		dev_err(&isp->pdev->dev, "CSE validity timeout 0x%x\n", val);
-		ipu_buttress_ipc_validity_close(isp, ipc);
-	}
+	/*
+	 * How long we should wait here?
+	 */
+	tout_jfs = jiffies + msecs_to_jiffies(tout);
+	do {
+		val = readl(isp->base + ipc->csr_in);
+		dev_dbg(&isp->pdev->dev, "%s: CSE/ISH2IUCSR = %x\n",
+			__func__, val);
 
-	return ret;
+		if (val & BUTTRESS_IU2CSECSR_IPC_PEER_ACKED_REG_VALID) {
+			dev_dbg(&isp->pdev->dev,
+				"%s: Validity ack received from peer\n",
+				__func__);
+			return 0;
+		}
+		usleep_range(100, 1000);
+	} while (!time_after(jiffies, tout_jfs));
+
+	dev_err(&isp->pdev->dev, "Timed out while waiting for CSE!\n");
+
+	ipu_buttress_ipc_validity_close(isp, ipc);
+
+	return -ETIMEDOUT;
 }
 
 static void ipu_buttress_ipc_recv(struct ipu_device *isp,
@@ -227,10 +269,10 @@ static void ipu_buttress_ipc_recv(struct ipu_device *isp,
 	writel(0, isp->base + ipc->db0_in);
 }
 
-static int ipu_buttress_ipc_send_bulk(struct ipu_device *isp,
-				      enum ipu_buttress_ipc_domain ipc_domain,
-				      struct ipu_ipc_buttress_bulk_msg *msgs,
-				      u32 size)
+int
+ipu_buttress_ipc_send_bulk(struct ipu_device *isp,
+			   enum ipu_buttress_ipc_domain ipc_domain,
+			   struct ipu_ipc_buttress_bulk_msg *msgs, u32 size)
 {
 	struct ipu_buttress *b = &isp->buttress;
 	struct ipu_buttress_ipc *ipc;
@@ -262,7 +304,7 @@ static int ipu_buttress_ipc_send_bulk(struct ipu_device *isp,
 			msgs[i].cmd);
 		writel(msgs[i].cmd, isp->base + ipc->data0_out);
 
-		val = BUTTRESS_IU2CSEDB0_BUSY | msgs[i].cmd_size;
+		val = 1 << BUTTRESS_IU2CSEDB0_BUSY_SHIFT | msgs[i].cmd_size;
 
 		writel(val, isp->base + ipc->db0_out);
 
@@ -314,13 +356,14 @@ static int ipu_buttress_ipc_send_bulk(struct ipu_device *isp,
 		}
 	}
 
-	dev_dbg(&isp->pdev->dev, "bulk IPC commands done\n");
+	dev_dbg(&isp->pdev->dev, "bulk IPC commands completed\n");
 
 out:
 	ipu_buttress_ipc_validity_close(isp, ipc);
 	mutex_unlock(&b->ipc_mutex);
 	return ret;
 }
+EXPORT_SYMBOL_GPL(ipu_buttress_ipc_send_bulk);
 
 static int
 ipu_buttress_ipc_send(struct ipu_device *isp,
@@ -364,9 +407,15 @@ irqreturn_t ipu_buttress_isr(int irq, void *isp_ptr)
 	irqreturn_t ret = IRQ_NONE;
 	u32 disable_irqs = 0;
 	u32 irq_status;
+#ifdef CONFIG_VIDEO_INTEL_IPU4
+	u32 reg_irq_sts = BUTTRESS_REG_ISR_ENABLED_STATUS;
+#else
 	u32 reg_irq_sts = BUTTRESS_REG_ISR_STATUS;
+#endif
 	unsigned int i;
 
+	dev_dbg(&isp->pdev->dev, "isr: Buttress interrupt handler\n");
+
 	pm_runtime_get(&isp->pdev->dev);
 
 	if (!pm_runtime_active(&isp->pdev->dev)) {
@@ -376,6 +425,11 @@ irqreturn_t ipu_buttress_isr(int irq, void *isp_ptr)
 		return IRQ_HANDLED;
 	}
 
+	trace_ipu_perf_reg(BUTTRESS_REG_IS_FREQ_CTL,
+			   readl(isp->base + BUTTRESS_REG_IS_FREQ_CTL));
+	trace_ipu_perf_reg(BUTTRESS_REG_PS_FREQ_CTL,
+			   readl(isp->base + BUTTRESS_REG_PS_FREQ_CTL));
+
 	irq_status = readl(isp->base + reg_irq_sts);
 	if (!irq_status) {
 		pm_runtime_put(&isp->pdev->dev);
@@ -392,8 +446,7 @@ irqreturn_t ipu_buttress_isr(int irq, void *isp_ptr)
 				if (r == IRQ_WAKE_THREAD) {
 					ret = IRQ_WAKE_THREAD;
 					disable_irqs |= ipu_adev_irq_mask[i];
-				} else if (ret == IRQ_NONE &&
-					   r == IRQ_HANDLED) {
+				} else if (ret == IRQ_NONE && r == IRQ_HANDLED) {
 					ret = IRQ_HANDLED;
 				}
 			}
@@ -433,8 +486,7 @@ irqreturn_t ipu_buttress_isr(int irq, void *isp_ptr)
 			complete(&b->ish.send_complete);
 		}
 
-		if (irq_status & BUTTRESS_ISR_SAI_VIOLATION &&
-		    ipu_buttress_get_secure_mode(isp)) {
+		if (irq_status & BUTTRESS_ISR_SAI_VIOLATION) {
 			dev_err(&isp->pdev->dev,
 				"BUTTRESS_ISR_SAI_VIOLATION\n");
 			WARN_ON(1);
@@ -445,7 +497,7 @@ irqreturn_t ipu_buttress_isr(int irq, void *isp_ptr)
 
 	if (disable_irqs)
 		writel(BUTTRESS_IRQS & ~disable_irqs,
-		       isp->base + BUTTRESS_REG_ISR_ENABLE);
+			   isp->base + BUTTRESS_REG_ISR_ENABLE);
 
 	pm_runtime_put(&isp->pdev->dev);
 
@@ -477,6 +529,7 @@ int ipu_buttress_power(struct device *dev,
 		       struct ipu_buttress_ctrl *ctrl, bool on)
 {
 	struct ipu_device *isp = to_ipu_bus_device(dev)->isp;
+	unsigned long tout_jfs;
 	u32 pwr_sts, val;
 	int ret = 0;
 
@@ -493,25 +546,40 @@ int ipu_buttress_power(struct device *dev,
 		val = 0;
 		pwr_sts = ctrl->pwr_sts_off << ctrl->pwr_sts_shift;
 	} else {
-		val = BUTTRESS_FREQ_CTL_START |
-			ctrl->divisor << ctrl->divisor_shift |
-			ctrl->qos_floor << BUTTRESS_FREQ_CTL_QOS_FLOOR_SHIFT |
-			BUTTRESS_FREQ_CTL_ICCMAX_LEVEL;
+		val = 1 << BUTTRESS_FREQ_CTL_START_SHIFT
+		    | ctrl->divisor << ctrl->divisor_shift
+		    | ctrl->qos_floor << BUTTRESS_FREQ_CTL_QOS_FLOOR_SHIFT;
 
 		pwr_sts = ctrl->pwr_sts_on << ctrl->pwr_sts_shift;
 	}
 
+	val |= ctrl->ovrd << ctrl->ovrd_shift;
 	writel(val, isp->base + ctrl->freq_ctl);
 
-	ret = readl_poll_timeout(isp->base + BUTTRESS_REG_PWR_STATE,
-				 val, ((val & ctrl->pwr_sts_mask) == pwr_sts),
-				 100, BUTTRESS_POWER_TIMEOUT);
-	if (ret)
-		dev_err(&isp->pdev->dev,
-			"Change power status timeout with 0x%x\n", val);
+	tout_jfs = jiffies + msecs_to_jiffies(BUTTRESS_POWER_TIMEOUT);
+	do {
+		usleep_range(10, 40);
+		val = readl(isp->base + BUTTRESS_REG_PWR_STATE);
+		if ((val & ctrl->pwr_sts_mask) == pwr_sts) {
+			dev_dbg(&isp->pdev->dev,
+				"Rail state successfully changed\n");
+			goto out;
+		}
+	} while (!time_after(jiffies, tout_jfs));
+
+	dev_err(&isp->pdev->dev,
+		"Timeout when trying to change state of the rail 0x%x\n", val);
+
+	ret = -ETIMEDOUT;
 
+out:
 	ctrl->started = !ret && on;
 
+	trace_ipu_perf_reg(BUTTRESS_REG_IS_FREQ_CTL,
+			   readl(isp->base + BUTTRESS_REG_IS_FREQ_CTL));
+	trace_ipu_perf_reg(BUTTRESS_REG_PS_FREQ_CTL,
+			   readl(isp->base + BUTTRESS_REG_PS_FREQ_CTL));
+
 	mutex_unlock(&isp->buttress.power_mutex);
 
 	return ret;
@@ -533,9 +601,9 @@ void ipu_buttress_set_secure_mode(struct ipu_device *isp)
 	read = readl(isp->base + BUTTRESS_REG_SECURITY_CTL);
 
 	if (secure_mode_enable)
-		val = read |= BUTTRESS_SECURITY_CTL_FW_SECURE_MODE;
+		val = read |= 1 << BUTTRESS_SECURITY_CTL_FW_SECURE_MODE_SHIFT;
 	else
-		val = read & ~BUTTRESS_SECURITY_CTL_FW_SECURE_MODE;
+		val = read & ~(1 << BUTTRESS_SECURITY_CTL_FW_SECURE_MODE_SHIFT);
 
 	if (val == read)
 		return;
@@ -560,6 +628,7 @@ void ipu_buttress_set_secure_mode(struct ipu_device *isp)
 				"update security control register failed\n");
 	}
 }
+EXPORT_SYMBOL_GPL(ipu_buttress_set_secure_mode);
 
 bool ipu_buttress_get_secure_mode(struct ipu_device *isp)
 {
@@ -567,7 +636,7 @@ bool ipu_buttress_get_secure_mode(struct ipu_device *isp)
 
 	val = readl(isp->base + BUTTRESS_REG_SECURITY_CTL);
 
-	return val & BUTTRESS_SECURITY_CTL_FW_SECURE_MODE;
+	return val & (1 << BUTTRESS_SECURITY_CTL_FW_SECURE_MODE_SHIFT);
 }
 
 bool ipu_buttress_auth_done(struct ipu_device *isp)
@@ -588,7 +657,7 @@ static void ipu_buttress_set_psys_ratio(struct ipu_device *isp,
 					unsigned int psys_divisor,
 					unsigned int psys_qos_floor)
 {
-	struct ipu_buttress_ctrl *ctrl = isp->psys->ctrl;
+	struct ipu_buttress_ctrl *ctrl = isp->psys_iommu->ctrl;
 
 	mutex_lock(&isp->buttress.power_mutex);
 
@@ -604,31 +673,10 @@ static void ipu_buttress_set_psys_ratio(struct ipu_device *isp,
 		 * transition by writing wanted ratio, floor ratio and start
 		 * bit. No need to stop PS first
 		 */
-		writel(BUTTRESS_FREQ_CTL_START |
-		       ctrl->qos_floor << BUTTRESS_FREQ_CTL_QOS_FLOOR_SHIFT |
-		       psys_divisor, isp->base + BUTTRESS_REG_PS_FREQ_CTL);
-	}
-
-out_mutex_unlock:
-	mutex_unlock(&isp->buttress.power_mutex);
-}
-
-static void ipu_buttress_set_isys_ratio(struct ipu_device *isp,
-					unsigned int isys_divisor)
-{
-	struct ipu_buttress_ctrl *ctrl = isp->isys->ctrl;
-
-	mutex_lock(&isp->buttress.power_mutex);
-
-	if (ctrl->divisor == isys_divisor)
-		goto out_mutex_unlock;
-
-	ctrl->divisor = isys_divisor;
-
-	if (ctrl->started) {
-		writel(BUTTRESS_FREQ_CTL_START |
-		       ctrl->qos_floor << BUTTRESS_FREQ_CTL_QOS_FLOOR_SHIFT |
-		       isys_divisor, isp->base + BUTTRESS_REG_IS_FREQ_CTL);
+		writel(1 << BUTTRESS_FREQ_CTL_START_SHIFT |
+			   ctrl->
+			   qos_floor << BUTTRESS_FREQ_CTL_QOS_FLOOR_SHIFT |
+			   psys_divisor, isp->base + BUTTRESS_REG_PS_FREQ_CTL);
 	}
 
 out_mutex_unlock:
@@ -660,7 +708,7 @@ ipu_buttress_add_psys_constraint(struct ipu_device *isp,
 						  b->psys_fused_freqs.max_freq);
 		ipu_buttress_set_psys_freq(isp, b->psys_min_freq);
 	}
-	mutex_unlock(&b->cons_mutex);
+	mutex_unlock(&isp->buttress.cons_mutex);
 }
 EXPORT_SYMBOL_GPL(ipu_buttress_add_psys_constraint);
 
@@ -691,7 +739,7 @@ EXPORT_SYMBOL_GPL(ipu_buttress_remove_psys_constraint);
 
 int ipu_buttress_reset_authentication(struct ipu_device *isp)
 {
-	int ret;
+	unsigned long tout_jfs;
 	u32 val;
 
 	if (!isp->secure_mode) {
@@ -700,24 +748,29 @@ int ipu_buttress_reset_authentication(struct ipu_device *isp)
 		return 0;
 	}
 
-	writel(BUTTRESS_FW_RESET_CTL_START, isp->base +
-	       BUTTRESS_REG_FW_RESET_CTL);
+	writel(1 << BUTTRESS_FW_RESET_CTL_START_SHIFT, isp->base +
+		   BUTTRESS_REG_FW_RESET_CTL);
 
-	ret = readl_poll_timeout(isp->base + BUTTRESS_REG_FW_RESET_CTL, val,
-				 val & BUTTRESS_FW_RESET_CTL_DONE, 500,
-				 BUTTRESS_CSE_FWRESET_TIMEOUT);
-	if (ret) {
-		dev_err(&isp->pdev->dev,
-			"Time out while resetting authentication state\n");
-	} else {
-		dev_info(&isp->pdev->dev,
-			 "FW reset for authentication done\n");
-		writel(0, isp->base + BUTTRESS_REG_FW_RESET_CTL);
-		/* leave some time for HW restore */
-		usleep_range(800, 1000);
-	}
+	tout_jfs = jiffies + msecs_to_jiffies(BUTTRESS_CSE_FWRESET_TIMEOUT);
+	do {
+		val = readl(isp->base + BUTTRESS_REG_FW_RESET_CTL);
+		if (val & 1 << BUTTRESS_FW_RESET_CTL_DONE_SHIFT) {
+			dev_info(&isp->pdev->dev,
+				 "FW reset for authentication done!\n");
+			writel(0, isp->base + BUTTRESS_REG_FW_RESET_CTL);
+			/*
+			 * Leave some time for HW restore.
+			 */
+			usleep_range(100, 1000);
+			return 0;
+		}
+		usleep_range(100, 1000);
+	} while (!time_after(jiffies, tout_jfs));
 
-	return ret;
+	dev_err(&isp->pdev->dev,
+		"Timed out while resetting authentication state!\n");
+
+	return -ETIMEDOUT;
 }
 
 int ipu_buttress_map_fw_image(struct ipu_bus_device *sys,
@@ -783,8 +836,9 @@ int ipu_buttress_authenticate(struct ipu_device *isp)
 {
 	struct ipu_psys_pdata *psys_pdata;
 	struct ipu_buttress *b = &isp->buttress;
-	u32 data, mask, done, fail;
+	u32 data;
 	int rval;
+	unsigned long tout_jfs;
 
 	if (!isp->secure_mode) {
 		dev_dbg(&isp->pdev->dev,
@@ -796,6 +850,12 @@ int ipu_buttress_authenticate(struct ipu_device *isp)
 
 	mutex_lock(&b->auth_mutex);
 
+	rval = pm_runtime_get_sync(&isp->psys_iommu->dev);
+	if (rval < 0) {
+		dev_err(&isp->pdev->dev, "Runtime PM failed (%d)\n", rval);
+		goto iunit_power_off;
+	}
+
 	if (ipu_buttress_auth_done(isp)) {
 		rval = 0;
 		goto iunit_power_off;
@@ -826,31 +886,45 @@ int ipu_buttress_authenticate(struct ipu_device *isp)
 		goto iunit_power_off;
 	}
 
-	mask = BUTTRESS_SECURITY_CTL_FW_SETUP_MASK;
-	done = BUTTRESS_SECURITY_CTL_FW_SETUP_DONE;
-	fail = BUTTRESS_SECURITY_CTL_AUTH_FAILED;
-	rval = readl_poll_timeout(isp->base + BUTTRESS_REG_SECURITY_CTL, data,
-				  ((data & mask) == done ||
-				   (data & mask) == fail), 500,
-				  BUTTRESS_CSE_BOOTLOAD_TIMEOUT);
-	if (rval) {
-		dev_err(&isp->pdev->dev, "CSE boot_load timeout\n");
-		goto iunit_power_off;
-	}
+	tout_jfs = jiffies + msecs_to_jiffies(BUTTRESS_CSE_BOOTLOAD_TIMEOUT);
+	do {
+		data = readl(isp->base + BUTTRESS_REG_SECURITY_CTL);
+		data &= BUTTRESS_SECURITY_CTL_FW_SETUP_MASK;
+		if (data == BUTTRESS_SECURITY_CTL_FW_SETUP_DONE) {
+			dev_dbg(&isp->pdev->dev, "CSE boot_load done\n");
+			break;
+		} else if (data == BUTTRESS_SECURITY_CTL_AUTH_FAILED) {
+			dev_err(&isp->pdev->dev, "CSE boot_load failed\n");
+			rval = -EINVAL;
+			goto iunit_power_off;
+		}
+		usleep_range(500, 1000);
+	} while (!time_after(jiffies, tout_jfs));
 
-	data = readl(isp->base + BUTTRESS_REG_SECURITY_CTL) & mask;
-	if (data == fail) {
-		dev_err(&isp->pdev->dev, "CSE auth failed\n");
-		rval = -EINVAL;
+	if (data != BUTTRESS_SECURITY_CTL_FW_SETUP_DONE) {
+		dev_err(&isp->pdev->dev, "CSE boot_load timed out\n");
+		rval = -ETIMEDOUT;
 		goto iunit_power_off;
 	}
 
-	rval = readl_poll_timeout(psys_pdata->base + BOOTLOADER_STATUS_OFFSET,
-				  data, data == BOOTLOADER_MAGIC_KEY, 500,
-				  BUTTRESS_CSE_BOOTLOAD_TIMEOUT);
-	if (rval) {
-		dev_err(&isp->pdev->dev, "Expect magic number timeout 0x%x\n",
-			data);
+	tout_jfs = jiffies + msecs_to_jiffies(BUTTRESS_CSE_BOOTLOAD_TIMEOUT);
+	do {
+		data = readl(psys_pdata->base + BOOTLOADER_STATUS_OFFSET);
+		dev_dbg(&isp->pdev->dev, "%s: BOOTLOADER_STATUS 0x%x",
+			__func__, data);
+		if (data == BOOTLOADER_MAGIC_KEY) {
+			dev_dbg(&isp->pdev->dev,
+				"%s: Expected magic number found, breaking...",
+				__func__);
+			break;
+		}
+		usleep_range(500, 1000);
+	} while (!time_after(jiffies, tout_jfs));
+
+	if (data != BOOTLOADER_MAGIC_KEY) {
+		dev_dbg(&isp->pdev->dev,
+			"%s: CSE boot_load timed out...\n", __func__);
+		rval = -ETIMEDOUT;
 		goto iunit_power_off;
 	}
 
@@ -869,57 +943,67 @@ int ipu_buttress_authenticate(struct ipu_device *isp)
 		goto iunit_power_off;
 	}
 
-	done = BUTTRESS_SECURITY_CTL_AUTH_DONE;
-	rval = readl_poll_timeout(isp->base + BUTTRESS_REG_SECURITY_CTL, data,
-				  ((data & mask) == done ||
-				   (data & mask) == fail), 500,
-				  BUTTRESS_CSE_AUTHENTICATE_TIMEOUT);
-	if (rval) {
-		dev_err(&isp->pdev->dev, "CSE authenticate timeout\n");
-		goto iunit_power_off;
-	}
+	tout_jfs = jiffies;
+	tout_jfs += msecs_to_jiffies(BUTTRESS_CSE_AUTHENTICATE_TIMEOUT);
+	do {
+		data = readl(isp->base + BUTTRESS_REG_SECURITY_CTL);
+		data &= BUTTRESS_SECURITY_CTL_FW_SETUP_MASK;
+		if (data == BUTTRESS_SECURITY_CTL_AUTH_DONE) {
+			dev_dbg(&isp->pdev->dev, "CSE authenticate_run done\n");
+			break;
+		} else if (data == BUTTRESS_SECURITY_CTL_AUTH_FAILED) {
+			dev_err(&isp->pdev->dev,
+				"CSE authenticate_run failed\n");
+			rval = -EINVAL;
+			goto iunit_power_off;
+		}
+		usleep_range(500, 1000);
+	} while (!time_after(jiffies, tout_jfs));
 
-	data = readl(isp->base + BUTTRESS_REG_SECURITY_CTL) & mask;
-	if (data == fail) {
-		dev_err(&isp->pdev->dev, "CSE boot_load failed\n");
-		rval = -EINVAL;
+	if (data != BUTTRESS_SECURITY_CTL_AUTH_DONE) {
+		dev_err(&isp->pdev->dev, "CSE authenticate_run timed out\n");
+		rval = -ETIMEDOUT;
 		goto iunit_power_off;
 	}
 
-	dev_info(&isp->pdev->dev, "CSE authenticate_run done\n");
-
 iunit_power_off:
+	pm_runtime_put(&isp->psys_iommu->dev);
+
 	mutex_unlock(&b->auth_mutex);
 
 	return rval;
 }
+EXPORT_SYMBOL(ipu_buttress_authenticate);
 
 static int ipu_buttress_send_tsc_request(struct ipu_device *isp)
 {
-	u32 val, mask, shift, done;
-	int ret;
-
-	mask = BUTTRESS_PWR_STATE_HH_STATUS_MASK;
-	shift = BUTTRESS_PWR_STATE_HH_STATUS_SHIFT;
+	unsigned long tout_jfs = msecs_to_jiffies(5);
 
 	writel(BUTTRESS_FABRIC_CMD_START_TSC_SYNC,
-	       isp->base + BUTTRESS_REG_FABRIC_CMD);
+		   isp->base + BUTTRESS_REG_FABRIC_CMD);
 
-	val = readl(isp->base + BUTTRESS_REG_PWR_STATE);
-	val = (val & mask) >> shift;
-	if (val == BUTTRESS_PWR_STATE_HH_STATE_ERR) {
-		dev_err(&isp->pdev->dev, "Start tsc sync failed\n");
-		return -EINVAL;
-	}
+	tout_jfs += jiffies;
+	do {
+		u32 val;
 
-	done = BUTTRESS_PWR_STATE_HH_STATE_DONE;
-	ret = readl_poll_timeout(isp->base + BUTTRESS_REG_PWR_STATE, val,
-				 ((val & mask) >> shift == done), 500,
-				 BUTTRESS_TSC_SYNC_TIMEOUT);
-	if (ret)
-		dev_err(&isp->pdev->dev, "Start tsc sync timeout\n");
+		val = readl(isp->base + BUTTRESS_REG_PWR_STATE);
+		val = (val & BUTTRESS_PWR_STATE_HH_STATUS_MASK) >>
+		    BUTTRESS_PWR_STATE_HH_STATUS_SHIFT;
 
-	return ret;
+		switch (val) {
+		case BUTTRESS_PWR_STATE_HH_STATE_DONE:
+			dev_dbg(&isp->pdev->dev, "Start tsc sync completed!\n");
+			return 0;
+		case BUTTRESS_PWR_STATE_HH_STATE_ERR:
+			dev_err(&isp->pdev->dev, "Start tsc sync failed!\n");
+			return -EINVAL;
+		default:
+			usleep_range(500, 1000);
+			break;
+		}
+	} while (!time_after(jiffies, tout_jfs));
+
+	return -ETIMEDOUT;
 }
 
 int ipu_buttress_start_tsc_sync(struct ipu_device *isp)
@@ -945,7 +1029,7 @@ int ipu_buttress_start_tsc_sync(struct ipu_device *isp)
 		return ret;
 	}
 
-	dev_err(&isp->pdev->dev, "TSC sync failed(timeout)\n");
+	dev_err(&isp->pdev->dev, "TSC sync failed(timeout).\n");
 
 	return -ETIMEDOUT;
 }
@@ -960,28 +1044,441 @@ struct clk_ipu_sensor {
 
 #define to_clk_ipu_sensor(_hw) container_of(_hw, struct clk_ipu_sensor, hw)
 
-int ipu_buttress_tsc_read(struct ipu_device *isp, u64 *val)
+static int ipu_buttress_clk_pll_prepare(struct clk_hw *hw)
 {
-	u32 tsc_hi_1, tsc_hi_2, tsc_lo;
-	unsigned long flags;
+	struct clk_ipu_sensor *ck = to_clk_ipu_sensor(hw);
+	int ret;
 
-	local_irq_save(flags);
-	tsc_hi_1 = readl(isp->base + BUTTRESS_REG_TSC_HI);
-	tsc_lo = readl(isp->base + BUTTRESS_REG_TSC_LO);
-	tsc_hi_2 = readl(isp->base + BUTTRESS_REG_TSC_HI);
-	if (tsc_hi_1 == tsc_hi_2) {
-		*val = (u64)tsc_hi_1 << 32 | tsc_lo;
-	} else {
-		/* Check if TSC has rolled over */
-		if (tsc_lo & BIT(31))
-			*val = (u64)tsc_hi_1 << 32 | tsc_lo;
-		else
-			*val = (u64)tsc_hi_2 << 32 | tsc_lo;
+	/* Workaround needed to get sensor clock running in some cases */
+	ret = pm_runtime_get_sync(&ck->isp->isys->dev);
+	return ret >= 0 ? 0 : ret;
+}
+
+static void ipu_buttress_clk_pll_unprepare(struct clk_hw *hw)
+{
+	struct clk_ipu_sensor *ck = to_clk_ipu_sensor(hw);
+
+	/* Workaround needed to get sensor clock stopped in some cases */
+	pm_runtime_put(&ck->isp->isys->dev);
+}
+
+static int ipu_buttress_clk_pll_enable(struct clk_hw *hw)
+{
+	struct clk_ipu_sensor *ck = to_clk_ipu_sensor(hw);
+	u32 val;
+	unsigned int i;
+
+	/*
+	 * Start bit behaves like master clock request towards ICLK.
+	 * It is needed regardless of the 24 MHz or per clock out pll
+	 * setting.
+	 */
+	val = readl(ck->isp->base + BUTTRESS_REG_SENSOR_FREQ_CTL);
+	val |= 1 << BUTTRESS_FREQ_CTL_START_SHIFT;
+	val &= ~BUTTRESS_SENSOR_FREQ_CTL_OSC_OUT_FREQ_MASK(ck->id);
+	for (i = 0; i < ARRAY_SIZE(sensor_clk_freqs); i++)
+		if (sensor_clk_freqs[i].rate == ck->rate)
+			break;
+
+	if (i < ARRAY_SIZE(sensor_clk_freqs))
+		val |= sensor_clk_freqs[i].val <<
+		    BUTTRESS_SENSOR_FREQ_CTL_OSC_OUT_FREQ_SHIFT(ck->id);
+	else
+		val |= BUTTRESS_SENSOR_FREQ_CTL_OSC_OUT_FREQ_DEFAULT(ck->id);
+
+	writel(val, ck->isp->base + BUTTRESS_REG_SENSOR_FREQ_CTL);
+
+	return 0;
+}
+
+static void ipu_buttress_clk_pll_disable(struct clk_hw *hw)
+{
+	struct clk_ipu_sensor *ck = to_clk_ipu_sensor(hw);
+	u32 val;
+	int i;
+
+	val = readl(ck->isp->base + BUTTRESS_REG_SENSOR_CLK_CTL);
+	for (i = 0; i < IPU_BUTTRESS_NUM_OF_SENS_CKS; i++) {
+		if (val &
+		    (1 << BUTTRESS_SENSOR_CLK_CTL_OSC_CLK_OUT_EN_SHIFT(i)))
+			return;
 	}
-	local_irq_restore(flags);
+
+	/* See enable control above */
+	val = readl(ck->isp->base + BUTTRESS_REG_SENSOR_FREQ_CTL);
+	val &= ~(1 << BUTTRESS_FREQ_CTL_START_SHIFT);
+	writel(val, ck->isp->base + BUTTRESS_REG_SENSOR_FREQ_CTL);
+}
+
+static int ipu_buttress_clk_enable(struct clk_hw *hw)
+{
+	struct clk_ipu_sensor *ck = to_clk_ipu_sensor(hw);
+	u32 val;
+
+	val = readl(ck->isp->base + BUTTRESS_REG_SENSOR_CLK_CTL);
+	val |= 1 << BUTTRESS_SENSOR_CLK_CTL_OSC_CLK_OUT_EN_SHIFT(ck->id);
+
+	/* Enable dynamic sensor clock */
+	val |= 1 << BUTTRESS_SENSOR_CLK_CTL_OSC_CLK_OUT_SEL_SHIFT(ck->id);
+	writel(val, ck->isp->base + BUTTRESS_REG_SENSOR_CLK_CTL);
+
+	return 0;
+}
+
+static void ipu_buttress_clk_disable(struct clk_hw *hw)
+{
+	struct clk_ipu_sensor *ck = to_clk_ipu_sensor(hw);
+	u32 val;
+
+	val = readl(ck->isp->base + BUTTRESS_REG_SENSOR_CLK_CTL);
+	val &= ~(1 << BUTTRESS_SENSOR_CLK_CTL_OSC_CLK_OUT_EN_SHIFT(ck->id));
+	writel(val, ck->isp->base + BUTTRESS_REG_SENSOR_CLK_CTL);
+}
+
+static long ipu_buttress_clk_round_rate(struct clk_hw *hw,
+					unsigned long rate,
+					unsigned long *parent_rate)
+{
+	unsigned long best = ULONG_MAX;
+	unsigned long round_rate = 0;
+	int i;
+
+	for (i = 0; i < ARRAY_SIZE(sensor_clk_freqs); i++) {
+		long diff = sensor_clk_freqs[i].rate - rate;
+
+		if (diff == 0)
+			return rate;
+
+		diff = abs(diff);
+		if (diff < best) {
+			best = diff;
+			round_rate = sensor_clk_freqs[i].rate;
+		}
+	}
+
+	return round_rate;
+}
+
+static unsigned long
+ipu_buttress_clk_recalc_rate(struct clk_hw *hw, unsigned long parent_rate)
+{
+	struct clk_ipu_sensor *ck = to_clk_ipu_sensor(hw);
+
+	return ck->rate;
+}
+
+static int ipu_buttress_clk_set_rate(struct clk_hw *hw,
+				     unsigned long rate,
+				     unsigned long parent_rate)
+{
+	struct clk_ipu_sensor *ck = to_clk_ipu_sensor(hw);
+
+	/*
+	 * R    N       P       PVD     PLLout
+	 * 1    45      128     2       6.75
+	 * 1    40      96      2       8
+	 * 1    40      80      2       9.6
+	 * 1    15      20      4       14.4
+	 * 1    40      32      2       24
+	 * 1    65      48      1       26
+	 *
+	 */
+	ck->rate = rate;
 
 	return 0;
 }
+
+static const struct clk_ops ipu_buttress_clk_sensor_ops = {
+	.enable = ipu_buttress_clk_enable,
+	.disable = ipu_buttress_clk_disable,
+};
+
+static const struct clk_ops ipu_buttress_clk_sensor_ops_parent = {
+	.enable = ipu_buttress_clk_pll_enable,
+	.disable = ipu_buttress_clk_pll_disable,
+	.prepare = ipu_buttress_clk_pll_prepare,
+	.unprepare = ipu_buttress_clk_pll_unprepare,
+	.round_rate = ipu_buttress_clk_round_rate,
+	.recalc_rate = ipu_buttress_clk_recalc_rate,
+	.set_rate = ipu_buttress_clk_set_rate,
+};
+
+static struct clk_init_data ipu_buttress_sensor_clk_data[] = {
+	{
+	 .name = "OSC_CLK_OUT0",
+	 .ops = &ipu_buttress_clk_sensor_ops,
+	 .parent_names = (const char *[]){"ipu_sensor_pll0"},
+	 .num_parents = 1,
+	 .flags = CLK_SET_RATE_PARENT,
+	},
+	{
+	 .name = "OSC_CLK_OUT1",
+	 .ops = &ipu_buttress_clk_sensor_ops,
+	 .parent_names = (const char *[]){"ipu_sensor_pll1"},
+	 .num_parents = 1,
+	 .flags = CLK_SET_RATE_PARENT,
+	},
+	{
+	 .name = "OSC_CLK_OUT2",
+	 .ops = &ipu_buttress_clk_sensor_ops,
+	 .parent_names = (const char *[]){"ipu_sensor_pll2"},
+	 .num_parents = 1,
+	 .flags = CLK_SET_RATE_PARENT,
+	},
+};
+
+static struct clk_init_data ipu_buttress_sensor_pll_data[] = {
+	{
+	 .name = "ipu_sensor_pll0",
+	 .ops = &ipu_buttress_clk_sensor_ops_parent,
+	},
+	{
+	 .name = "ipu_sensor_pll1",
+	 .ops = &ipu_buttress_clk_sensor_ops_parent,
+	},
+	{
+	 .name = "ipu_sensor_pll2",
+	 .ops = &ipu_buttress_clk_sensor_ops_parent,
+	},
+};
+
+static void ipu_buttress_read_psys_fused_freqs(struct ipu_device *isp)
+{
+	struct ipu_buttress_fused_freqs *fused_freq =
+	    &isp->buttress.psys_fused_freqs;
+	u32 reg_val, max_ratio, min_ratio, efficient_ratio;
+
+	reg_val = readl(isp->base + BUTTRESS_REG_PS_FREQ_CAPABILITIES);
+
+	min_ratio = (reg_val &
+		     BUTTRESS_PS_FREQ_CAPABILITIES_MIN_RATIO_MASK) >>
+		     BUTTRESS_PS_FREQ_CAPABILITIES_MIN_RATIO_SHIFT;
+	max_ratio = (reg_val &
+		     BUTTRESS_PS_FREQ_CAPABILITIES_MAX_RATIO_MASK) >>
+		     BUTTRESS_PS_FREQ_CAPABILITIES_MAX_RATIO_SHIFT;
+	efficient_ratio =
+	    (reg_val &
+	     BUTTRESS_PS_FREQ_CAPABILITIES_EFFICIENT_RATIO_MASK) >>
+	     BUTTRESS_PS_FREQ_CAPABILITIES_EFFICIENT_RATIO_SHIFT;
+
+	fused_freq->min_freq = min_ratio * BUTTRESS_PS_FREQ_STEP;
+	fused_freq->max_freq = max_ratio * BUTTRESS_PS_FREQ_STEP;
+	fused_freq->efficient_freq = efficient_ratio * BUTTRESS_PS_FREQ_STEP;
+}
+
+#ifdef I2C_WA
+/*
+ * The dev_id was hard code in platform data, as i2c bus number
+ * may change dynamiclly, we need to update this bus id
+ * accordingly.
+ *
+ * @adapter_id: hardware i2c adapter id, this was fixed in platform data
+ * return: i2c bus id registered in system
+ */
+int ipu_get_i2c_bus_id(int adapter_id)
+{
+	struct i2c_adapter *adapter;
+	char name[32];
+	int i = 0;
+
+	snprintf(name, sizeof(name), "i2c_designware.%d", adapter_id);
+	while ((adapter = i2c_get_adapter(i)) != NULL) {
+		struct device *parent = adapter->dev.parent;
+
+		if (parent && !strncmp(name, dev_name(parent), sizeof(name)))
+			return i;
+		i++;
+	}
+
+	/* Not found, should never happen! */
+	WARN_ON_ONCE(1);
+	return -1;
+}
+EXPORT_SYMBOL_GPL(ipu_get_i2c_bus_id);
+#endif
+
+static int ipu_buttress_clk_init(struct ipu_device *isp)
+{
+	struct ipu_buttress *b = &isp->buttress;
+	struct ipu_isys_subdev_pdata *pdata = isp->pdev->dev.platform_data;
+	struct ipu_isys_clk_mapping *clkmap = pdata ? pdata->clk_map : NULL;
+	struct clk_init_data *clk_data_parent;
+	struct clk_init_data *clk_data;
+	int i, rval;
+	unsigned int num_plls;
+
+	ipu_buttress_read_psys_fused_freqs(isp);
+	isp->buttress.psys_min_freq = b->psys_fused_freqs.efficient_freq;
+
+	clk_data_parent = ipu_buttress_sensor_pll_data;
+
+	num_plls = ARRAY_SIZE(ipu_buttress_sensor_pll_data);
+
+	for (i = 0; i < num_plls; i++) {
+		struct clk_ipu_sensor *parent_clk =
+		    devm_kzalloc(&isp->pdev->dev,
+				 sizeof(*parent_clk), GFP_KERNEL);
+
+		if (!parent_clk) {
+			rval = -ENOMEM;
+			goto err;
+		}
+
+		parent_clk->hw.init = &clk_data_parent[i];
+		parent_clk->isp = isp;
+		parent_clk->id = i;
+
+		b->pll_sensor[i] = clk_register(NULL, &parent_clk->hw);
+		if (IS_ERR(b->pll_sensor[i])) {
+			rval = PTR_ERR(b->pll_sensor[i]);
+			goto err;
+		}
+	}
+
+	clk_data = ipu_buttress_sensor_clk_data;
+
+	for (i = 0; i < IPU_BUTTRESS_NUM_OF_SENS_CKS; i++) {
+		char buffer[16];	/* max for clk_register_clkdev */
+		unsigned int parent_index = 0;
+		struct clk_ipu_sensor *my_clk =
+		    devm_kzalloc(&isp->pdev->dev, sizeof(*my_clk),
+				 GFP_KERNEL);
+
+		if (!my_clk) {
+			rval = -ENOMEM;
+			goto err;
+		}
+
+		if (i < num_plls)
+			parent_index = i;
+
+		my_clk->hw.init = &clk_data[i];
+
+		my_clk->id = i;
+		my_clk->isp = isp;
+
+		b->clk_sensor[i] = clk_register(NULL, &my_clk->hw);
+		if (IS_ERR(b->clk_sensor[i])) {
+			rval = PTR_ERR(b->clk_sensor[i]);
+			goto err;
+		}
+		rval = clk_set_parent(b->clk_sensor[i],
+				      b->pll_sensor[parent_index]);
+		if (rval)
+			goto err;
+
+		/* Register generic clocks for sensor driver */
+		snprintf(buffer, sizeof(buffer), "ipu_cam_clk%d", i);
+		rval = clk_register_clkdev(b->clk_sensor[i], buffer, NULL);
+		if (rval)
+			goto err;
+	}
+
+	/* Now map sensor clocks */
+	if (!clkmap)
+		return 0;
+
+	while (clkmap->clkdev_data.dev_id) {
+#ifdef I2C_WA
+		char *dev_id = kstrdup(clkmap->clkdev_data.dev_id, GFP_KERNEL);
+		int adapter_id = clkmap->clkdev_data.dev_id[0] - '0';
+		char *addr = strpbrk(clkmap->clkdev_data.dev_id, "-");
+		int bus_id = ipu_get_i2c_bus_id(adapter_id);
+
+		snprintf(dev_id, PAGE_SIZE, "%d-%s", bus_id, addr + 1);
+#endif
+
+		/*
+		 * Lookup table must be NULL terminated
+		 * CLKDEV_INIT(NULL, NULL, NULL)
+		 */
+		for (i = 0; i < IPU_BUTTRESS_NUM_OF_SENS_CKS; i++) {
+			if (!strcmp(clkmap->platform_clock_name,
+				    clk_data[i].name)) {
+				clkmap->clkdev_data.clk = b->clk_sensor[i];
+#ifdef I2C_WA
+				clkmap->clkdev_data.dev_id = dev_id;
+#endif
+				clkdev_add(&clkmap->clkdev_data);
+				break;
+			}
+		}
+		clkmap++;
+	}
+
+	return 0;
+
+err:
+	/* It is safe to call clk_unregister with null pointer */
+	for (i = IPU_BUTTRESS_NUM_OF_SENS_CKS - 1; i >= 0; i--)
+		clk_unregister(b->clk_sensor[i]);
+
+	for (i = num_plls - 1; i >= 0; i--)
+		clk_unregister(b->pll_sensor[i]);
+
+	return rval;
+}
+
+static void ipu_buttress_clk_exit(struct ipu_device *isp)
+{
+	struct ipu_buttress *b = &isp->buttress;
+	int i;
+
+	/* It is safe to call clk_unregister with null pointer */
+	for (i = 0; i < IPU_BUTTRESS_NUM_OF_SENS_CKS; i++)
+		clk_unregister(b->clk_sensor[i]);
+
+	for (i = 0; i < ARRAY_SIZE(ipu_buttress_sensor_pll_data); i++)
+		clk_unregister(b->pll_sensor[i]);
+}
+
+int ipu_buttress_tsc_read(struct ipu_device *isp, u64 *val)
+{
+	struct ipu_buttress *b = &isp->buttress;
+	u32 tsc_hi, tsc_lo_1, tsc_lo_2, tsc_lo_3, tsc_chk = 0;
+	unsigned long flags;
+	short retry = IPU_BUTTRESS_TSC_RETRY;
+
+	do {
+		spin_lock_irqsave(&b->tsc_lock, flags);
+		tsc_hi = readl(isp->base + BUTTRESS_REG_TSC_HI);
+
+		/*
+		 * We are occasionally getting broken values from
+		 * HH. Reading 3 times and doing sanity check as a WA
+		 */
+		tsc_lo_1 = readl(isp->base + BUTTRESS_REG_TSC_LO);
+		tsc_lo_2 = readl(isp->base + BUTTRESS_REG_TSC_LO);
+		tsc_lo_3 = readl(isp->base + BUTTRESS_REG_TSC_LO);
+		tsc_chk = readl(isp->base + BUTTRESS_REG_TSC_HI);
+		spin_unlock_irqrestore(&b->tsc_lock, flags);
+		if (tsc_chk == tsc_hi && tsc_lo_2 &&
+		    tsc_lo_2 - tsc_lo_1 <= IPU_BUTTRESS_TSC_LIMIT &&
+		    tsc_lo_3 - tsc_lo_2 <= IPU_BUTTRESS_TSC_LIMIT) {
+			*val = (u64)tsc_hi << 32 | tsc_lo_2;
+			return 0;
+		}
+
+		/*
+		 * Trace error only if limit checkings fails at least
+		 *  by two consecutive readings.
+		 */
+		if (retry < IPU_BUTTRESS_TSC_RETRY - 1 && tsc_lo_2)
+			dev_err(&isp->pdev->dev,
+				"%s = %u, %s = %u, %s = %u, %s = %u, %s = %u",
+				"failure: tsc_hi", tsc_hi,
+				"tsc_chk", tsc_chk,
+				"tsc_lo_1", tsc_lo_1,
+				"tsc_lo_2", tsc_lo_2, "tsc_lo_3", tsc_lo_3);
+	} while (retry--);
+
+	if (!tsc_chk && !tsc_lo_2)
+		return -EIO;
+
+	WARN_ON_ONCE(1);
+
+	return -EINVAL;
+}
 EXPORT_SYMBOL_GPL(ipu_buttress_tsc_read);
 
 #ifdef CONFIG_DEBUG_FS
@@ -1086,54 +1583,6 @@ static int ipu_buttress_psys_force_freq_set(void *data, u64 val)
 	return 0;
 }
 
-static int ipu_buttress_isys_freq_get(void *data, u64 *val)
-{
-	struct ipu_device *isp = data;
-	u32 reg_val;
-	int rval;
-
-	rval = pm_runtime_get_sync(&isp->isys->dev);
-	if (rval < 0) {
-		pm_runtime_put(&isp->isys->dev);
-		dev_err(&isp->pdev->dev, "Runtime PM failed (%d)\n", rval);
-		return rval;
-	}
-
-	reg_val = readl(isp->base + BUTTRESS_REG_IS_FREQ_CTL);
-
-	pm_runtime_put(&isp->isys->dev);
-
-	*val = IPU_IS_FREQ_RATIO_BASE *
-	    (reg_val & IPU_BUTTRESS_IS_FREQ_CTL_DIVISOR_MASK);
-
-	return 0;
-}
-
-static int ipu_buttress_isys_freq_set(void *data, u64 val)
-{
-	struct ipu_device *isp = data;
-	int rval;
-
-	if (val < BUTTRESS_MIN_FORCE_IS_FREQ ||
-	    val > BUTTRESS_MAX_FORCE_IS_FREQ)
-		return -EINVAL;
-
-	rval = pm_runtime_get_sync(&isp->isys->dev);
-	if (rval < 0) {
-		pm_runtime_put(&isp->isys->dev);
-		dev_err(&isp->pdev->dev, "Runtime PM failed (%d)\n", rval);
-		return rval;
-	}
-
-	do_div(val, BUTTRESS_IS_FREQ_STEP);
-	if (val)
-		ipu_buttress_set_isys_ratio(isp, val);
-
-	pm_runtime_put(&isp->isys->dev);
-
-	return 0;
-}
-
 DEFINE_SIMPLE_ATTRIBUTE(ipu_buttress_psys_force_freq_fops,
 			ipu_buttress_psys_force_freq_get,
 			ipu_buttress_psys_force_freq_set, "%llu\n");
@@ -1142,8 +1591,7 @@ DEFINE_SIMPLE_ATTRIBUTE(ipu_buttress_psys_freq_fops,
 			ipu_buttress_psys_freq_get, NULL, "%llu\n");
 
 DEFINE_SIMPLE_ATTRIBUTE(ipu_buttress_isys_freq_fops,
-			ipu_buttress_isys_freq_get,
-			ipu_buttress_isys_freq_set, "%llu\n");
+			ipu_buttress_isys_freq_get, NULL, "%llu\n");
 
 int ipu_buttress_debugfs_init(struct ipu_device *isp)
 {
@@ -1188,7 +1636,7 @@ int ipu_buttress_debugfs_init(struct ipu_device *isp)
 	if (!file)
 		goto err;
 
-	file = debugfs_create_file("isys_freq", 0700, dir, isp,
+	file = debugfs_create_file("isys_freq", 0400, dir, isp,
 				   &ipu_buttress_isys_freq_fops);
 	if (!file)
 		goto err;
@@ -1201,26 +1649,25 @@ int ipu_buttress_debugfs_init(struct ipu_device *isp)
 
 #endif /* CONFIG_DEBUG_FS */
 
-u64 ipu_buttress_tsc_ticks_to_ns(u64 ticks, const struct ipu_device *isp)
+u64 ipu_buttress_tsc_ticks_to_ns(u64 ticks)
 {
 	u64 ns = ticks * 10000;
-
 	/*
+	 * TSC clock frequency is 19.2MHz,
 	 * converting TSC tick count to ns is calculated by:
-	 * Example (TSC clock frequency is 19.2MHz):
 	 * ns = ticks * 1000 000 000 / 19.2Mhz
 	 *    = ticks * 1000 000 000 / 19200000Hz
 	 *    = ticks * 10000 / 192 ns
 	 */
-	do_div(ns, isp->buttress.ref_clk);
+	do_div(ns, 192);
 
 	return ns;
 }
 EXPORT_SYMBOL_GPL(ipu_buttress_tsc_ticks_to_ns);
 
-static ssize_t psys_fused_min_freq_show(struct device *dev,
-					struct device_attribute *attr,
-					char *buf)
+static ssize_t
+ipu_buttress_psys_fused_min_freq_get(struct device *dev,
+				     struct device_attribute *attr, char *buf)
 {
 	struct ipu_device *isp = pci_get_drvdata(to_pci_dev(dev));
 
@@ -1228,11 +1675,12 @@ static ssize_t psys_fused_min_freq_show(struct device *dev,
 			isp->buttress.psys_fused_freqs.min_freq);
 }
 
-static DEVICE_ATTR_RO(psys_fused_min_freq);
+static DEVICE_ATTR(psys_fused_min_freq, 0444,
+		   ipu_buttress_psys_fused_min_freq_get, NULL);
 
-static ssize_t psys_fused_max_freq_show(struct device *dev,
-					struct device_attribute *attr,
-					char *buf)
+static ssize_t
+ipu_buttress_psys_fused_max_freq_get(struct device *dev,
+				     struct device_attribute *attr, char *buf)
 {
 	struct ipu_device *isp = pci_get_drvdata(to_pci_dev(dev));
 
@@ -1240,11 +1688,13 @@ static ssize_t psys_fused_max_freq_show(struct device *dev,
 			isp->buttress.psys_fused_freqs.max_freq);
 }
 
-static DEVICE_ATTR_RO(psys_fused_max_freq);
+static DEVICE_ATTR(psys_fused_max_freq, 0444,
+		   ipu_buttress_psys_fused_max_freq_get, NULL);
 
-static ssize_t psys_fused_efficient_freq_show(struct device *dev,
-					      struct device_attribute *attr,
-					      char *buf)
+static ssize_t
+ipu_buttress_psys_fused_efficient_freq_get(struct device *dev,
+					   struct device_attribute *attr,
+					   char *buf)
 {
 	struct ipu_device *isp = pci_get_drvdata(to_pci_dev(dev));
 
@@ -1252,7 +1702,8 @@ static ssize_t psys_fused_efficient_freq_show(struct device *dev,
 			isp->buttress.psys_fused_freqs.efficient_freq);
 }
 
-static DEVICE_ATTR_RO(psys_fused_efficient_freq);
+static DEVICE_ATTR(psys_fused_efficient_freq, 0444,
+		   ipu_buttress_psys_fused_efficient_freq_get, NULL);
 
 int ipu_buttress_restore(struct ipu_device *isp)
 {
@@ -1264,17 +1715,18 @@ int ipu_buttress_restore(struct ipu_device *isp)
 
 	return 0;
 }
+EXPORT_SYMBOL(ipu_buttress_restore);
 
 int ipu_buttress_init(struct ipu_device *isp)
 {
 	struct ipu_buttress *b = &isp->buttress;
-	u32 val;
 	int rval, ipc_reset_retry = BUTTRESS_CSE_IPC_RESET_RETRY;
 
 	mutex_init(&b->power_mutex);
 	mutex_init(&b->auth_mutex);
 	mutex_init(&b->cons_mutex);
 	mutex_init(&b->ipc_mutex);
+	spin_lock_init(&b->tsc_lock);
 	init_completion(&b->ish.send_complete);
 	init_completion(&b->cse.send_complete);
 	init_completion(&b->ish.recv_complete);
@@ -1289,14 +1741,24 @@ int ipu_buttress_init(struct ipu_device *isp)
 	b->cse.data0_in = BUTTRESS_REG_CSE2IUDATA0;
 	b->cse.data0_out = BUTTRESS_REG_IU2CSEDATA0;
 
-	/* no ISH on IPU6 */
-	memset(&b->ish, 0, sizeof(b->ish));
+	b->ish.csr_in = BUTTRESS_REG_ISH2IUCSR;
+	b->ish.csr_out = BUTTRESS_REG_IU2ISHCSR;
+	b->ish.db0_in = BUTTRESS_REG_ISH2IUDB0;
+	b->ish.db0_out = BUTTRESS_REG_IU2ISHDB0;
+	b->ish.data0_in = BUTTRESS_REG_ISH2IUDATA0;
+	b->ish.data0_out = BUTTRESS_REG_IU2ISHDATA0;
 	INIT_LIST_HEAD(&b->constraints);
 
+	rval = ipu_buttress_clk_init(isp);
+	if (rval) {
+		dev_err(&isp->pdev->dev, "Clock init failed\n");
+		goto err_mutex_destroy;
+	}
+
 	ipu_buttress_set_secure_mode(isp);
 	isp->secure_mode = ipu_buttress_get_secure_mode(isp);
 	if (isp->secure_mode != secure_mode_enable)
-		dev_warn(&isp->pdev->dev, "Unable to set secure mode\n");
+		dev_warn(&isp->pdev->dev, "Unable to set secure mode!\n");
 
 	dev_info(&isp->pdev->dev, "IPU in %s mode\n",
 		 isp->secure_mode ? "secure" : "non-secure");
@@ -1305,33 +1767,11 @@ int ipu_buttress_init(struct ipu_device *isp)
 	writel(BUTTRESS_IRQS, isp->base + BUTTRESS_REG_ISR_CLEAR);
 	writel(BUTTRESS_IRQS, isp->base + BUTTRESS_REG_ISR_ENABLE);
 
-	/* get ref_clk frequency by reading the indication in btrs control */
-	val = readl(isp->base + BUTTRESS_REG_BTRS_CTRL);
-	val &= BUTTRESS_REG_BTRS_CTRL_REF_CLK_IND;
-	val >>= 8;
-
-	switch (val) {
-	case 0x0:
-		b->ref_clk = 240;
-		break;
-	case 0x1:
-		b->ref_clk = 192;
-		break;
-	case 0x2:
-		b->ref_clk = 384;
-		break;
-	default:
-		dev_warn(&isp->pdev->dev,
-			 "Unsupported ref clock, use 19.2Mhz by default.\n");
-		b->ref_clk = 192;
-		break;
-	}
-
 	rval = device_create_file(&isp->pdev->dev,
 				  &dev_attr_psys_fused_min_freq);
 	if (rval) {
 		dev_err(&isp->pdev->dev, "Create min freq file failed\n");
-		goto err_mutex_destroy;
+		goto err_clk_unregister;
 	}
 
 	rval = device_create_file(&isp->pdev->dev,
@@ -1355,10 +1795,10 @@ int ipu_buttress_init(struct ipu_device *isp)
 	do {
 		rval = ipu_buttress_ipc_reset(isp, &b->cse);
 		if (rval) {
-			dev_warn(&isp->pdev->dev,
-				 "IPC reset protocol failed, retrying\n");
+			dev_err(&isp->pdev->dev,
+				"IPC reset protocol failed, retry!\n");
 		} else {
-			dev_info(&isp->pdev->dev, "IPC reset done\n");
+			dev_dbg(&isp->pdev->dev, "IPC reset completed!\n");
 			return 0;
 		}
 	} while (ipc_reset_retry--);
@@ -1369,6 +1809,8 @@ int ipu_buttress_init(struct ipu_device *isp)
 	device_remove_file(&isp->pdev->dev, &dev_attr_psys_fused_max_freq);
 err_remove_min_freq_file:
 	device_remove_file(&isp->pdev->dev, &dev_attr_psys_fused_min_freq);
+err_clk_unregister:
+	ipu_buttress_clk_exit(isp);
 err_mutex_destroy:
 	mutex_destroy(&b->power_mutex);
 	mutex_destroy(&b->auth_mutex);
@@ -1389,6 +1831,8 @@ void ipu_buttress_exit(struct ipu_device *isp)
 	device_remove_file(&isp->pdev->dev, &dev_attr_psys_fused_max_freq);
 	device_remove_file(&isp->pdev->dev, &dev_attr_psys_fused_min_freq);
 
+	ipu_buttress_clk_exit(isp);
+
 	mutex_destroy(&b->power_mutex);
 	mutex_destroy(&b->auth_mutex);
 	mutex_destroy(&b->cons_mutex);
diff --git a/drivers/media/pci/intel/ipu-buttress.h b/drivers/media/pci/intel/ipu-buttress.h
index 4b2bf974858e..2c5e93af6d54 100644
--- a/drivers/media/pci/intel/ipu-buttress.h
+++ b/drivers/media/pci/intel/ipu-buttress.h
@@ -1,5 +1,5 @@
 /* SPDX-License-Identifier: GPL-2.0 */
-/* Copyright (C) 2013 - 2020 Intel Corporation */
+/* Copyright (C) 2013 - 2018 Intel Corporation */
 
 #ifndef IPU_BUTTRESS_H
 #define IPU_BUTTRESS_H
@@ -12,16 +12,12 @@
 #define IPU_BUTTRESS_NUM_OF_PLL_CKS	3
 #define IPU_BUTTRESS_TSC_CLK		19200000
 
-#define BUTTRESS_POWER_TIMEOUT			200000
+#define BUTTRESS_POWER_TIMEOUT			200
 
 #define BUTTRESS_PS_FREQ_STEP		25U
 #define BUTTRESS_MIN_FORCE_PS_FREQ	(BUTTRESS_PS_FREQ_STEP * 8)
 #define BUTTRESS_MAX_FORCE_PS_FREQ	(BUTTRESS_PS_FREQ_STEP * 32)
 
-#define BUTTRESS_IS_FREQ_STEP		25U
-#define BUTTRESS_MIN_FORCE_IS_FREQ	(BUTTRESS_IS_FREQ_STEP * 8)
-#define BUTTRESS_MAX_FORCE_IS_FREQ	(BUTTRESS_IS_FREQ_STEP * 16)
-
 struct ipu_buttress_ctrl {
 	u32 freq_ctl, pwr_sts_shift, pwr_sts_mask, pwr_sts_on, pwr_sts_off;
 	union {
@@ -32,6 +28,8 @@ struct ipu_buttress_ctrl {
 		unsigned int divisor_shift;
 		unsigned int ratio_shift;
 	};
+	unsigned int ovrd;
+	u32 ovrd_shift;
 	unsigned int qos_floor;
 	bool started;
 };
@@ -58,6 +56,9 @@ struct ipu_buttress_ipc {
 
 struct ipu_buttress {
 	struct mutex power_mutex, auth_mutex, cons_mutex, ipc_mutex;
+	spinlock_t tsc_lock;	/* tsc lock */
+	struct clk *clk_sensor[IPU_BUTTRESS_NUM_OF_SENS_CKS];
+	struct clk *pll_sensor[IPU_BUTTRESS_NUM_OF_PLL_CKS];
 	struct ipu_buttress_ipc cse;
 	struct ipu_buttress_ipc ish;
 	struct list_head constraints;
@@ -66,7 +67,7 @@ struct ipu_buttress {
 	u32 wdt_cached_value;
 	u8 psys_force_ratio;
 	bool force_suspend;
-	u32 ref_clk;
+	bool ps_started;
 };
 
 struct ipu_buttress_sensor_clk_freq {
@@ -114,7 +115,7 @@ int ipu_buttress_reset_authentication(struct ipu_device *isp);
 bool ipu_buttress_auth_done(struct ipu_device *isp);
 int ipu_buttress_start_tsc_sync(struct ipu_device *isp);
 int ipu_buttress_tsc_read(struct ipu_device *isp, u64 *val);
-u64 ipu_buttress_tsc_ticks_to_ns(u64 ticks, const struct ipu_device *isp);
+u64 ipu_buttress_tsc_ticks_to_ns(u64 ticks);
 
 irqreturn_t ipu_buttress_isr(int irq, void *isp_ptr);
 irqreturn_t ipu_buttress_isr_threaded(int irq, void *isp_ptr);
@@ -125,5 +126,13 @@ void ipu_buttress_csi_port_config(struct ipu_device *isp,
 				  u32 legacy, u32 combo);
 int ipu_buttress_restore(struct ipu_device *isp);
 
+int
+ipu_buttress_ipc_send_bulk(struct ipu_device *isp,
+			   enum ipu_buttress_ipc_domain ipc_domain,
+			   struct ipu_ipc_buttress_bulk_msg *msgs, u32 size);
 int ipu_buttress_psys_freq_get(void *data, u64 *val);
+int ipu_buttress_isys_freq_get(void *data, u64 *val);
+#ifdef I2C_WA
+int ipu_get_i2c_bus_id(int adapter_id);
+#endif /* I2C_WA */
 #endif /* IPU_BUTTRESS_H */
diff --git a/drivers/media/pci/intel/ipu-cpd.c b/drivers/media/pci/intel/ipu-cpd.c
index 3833f3f0bd8d..3833ce1b7519 100644
--- a/drivers/media/pci/intel/ipu-cpd.c
+++ b/drivers/media/pci/intel/ipu-cpd.c
@@ -1,5 +1,5 @@
 // SPDX-License-Identifier: GPL-2.0
-// Copyright (C) 2015 - 2020 Intel Corporation
+// Copyright (C) 2015 - 2018 Intel Corporation
 
 #include <linux/dma-mapping.h>
 #include <linux/module.h>
@@ -7,6 +7,8 @@
 #include "ipu.h"
 #include "ipu-cpd.h"
 
+#include "ipu4-css/ia_css_fw_pkg_release.h"
+
 /* 15 entries + header*/
 #define MAX_PKG_DIR_ENT_CNT		16
 /* 2 qword per entry/header */
@@ -37,18 +39,17 @@
 #define CPD_METADATA_IDX	1
 #define CPD_MODULEDATA_IDX	2
 
-static inline struct ipu_cpd_ent *ipu_cpd_get_entries(const void *cpd)
-{
-	const struct ipu_cpd_hdr *cpd_hdr = cpd;
-
-	return (struct ipu_cpd_ent *)((u8 *)cpd + cpd_hdr->hdr_len);
-}
-
+#define ipu_cpd_get_entries(cpd) ((struct ipu_cpd_ent *) \
+				  ((struct ipu_cpd_hdr *)cpd + 1))
 #define ipu_cpd_get_entry(cpd, idx) (&ipu_cpd_get_entries(cpd)[idx])
 #define ipu_cpd_get_manifest(cpd) ipu_cpd_get_entry(cpd, CPD_MANIFEST_IDX)
 #define ipu_cpd_get_metadata(cpd) ipu_cpd_get_entry(cpd, CPD_METADATA_IDX)
 #define ipu_cpd_get_moduledata(cpd) ipu_cpd_get_entry(cpd, CPD_MODULEDATA_IDX)
 
+static bool fw_version_check = true;
+module_param(fw_version_check, bool, 0444);
+MODULE_PARM_DESC(fw_version_check, "enable/disable checking firmware version");
+
 static const struct ipu_cpd_metadata_cmpnt *
 ipu_cpd_metadata_get_cmpnt(struct ipu_device *isp,
 			   const void *metadata,
@@ -100,52 +101,34 @@ static int ipu_cpd_metadata_get_cmpnt_id(struct ipu_device *isp,
 	return cmpnt->id;
 }
 
-static const struct ipu6_cpd_metadata_cmpnt *
-ipu6_cpd_metadata_get_cmpnt(struct ipu_device *isp,
-			    const void *metadata,
-			    unsigned int metadata_size,
-			    u8 idx)
+static u32
+ipu_cpd_metadata_get_cmpnt_icache_base_offs(struct ipu_device *isp,
+					    const void *metadata,
+					    unsigned int metadata_size, u8 idx)
 {
-	const struct ipu_cpd_metadata_extn *extn = metadata;
-	const struct ipu6_cpd_metadata_cmpnt *cmpnts = metadata + sizeof(*extn);
-	int cmpnt_count;
-
-	cmpnt_count = (metadata_size - sizeof(*extn)) / sizeof(*cmpnts);
-	if (idx > MAX_COMPONENT_ID || idx >= cmpnt_count) {
-		dev_err(&isp->pdev->dev, "Component index out of range (%d)\n",
-			idx);
-		return ERR_PTR(-EINVAL);
-	}
-
-	return &cmpnts[idx];
-}
-
-static u32 ipu6_cpd_metadata_cmpnt_version(struct ipu_device *isp,
-					   const void *metadata,
-					   unsigned int metadata_size, u8 idx)
-{
-	const struct ipu6_cpd_metadata_cmpnt *cmpnt =
-	    ipu6_cpd_metadata_get_cmpnt(isp, metadata,
-					metadata_size, idx);
+	const struct ipu_cpd_metadata_cmpnt *cmpnt =
+	    ipu_cpd_metadata_get_cmpnt(isp, metadata,
+				       metadata_size, idx);
 
 	if (IS_ERR(cmpnt))
 		return PTR_ERR(cmpnt);
 
-	return cmpnt->ver;
+	return cmpnt->icache_base_offs;
 }
 
-static int ipu6_cpd_metadata_get_cmpnt_id(struct ipu_device *isp,
-					  const void *metadata,
-					  unsigned int metadata_size, u8 idx)
+static u32
+ipu_cpd_metadata_get_cmpnt_entry_point(struct ipu_device *isp,
+				       const void *metadata,
+				       unsigned int metadata_size, u8 idx)
 {
-	const struct ipu6_cpd_metadata_cmpnt *cmpnt =
-	    ipu6_cpd_metadata_get_cmpnt(isp, metadata,
-					metadata_size, idx);
+	const struct ipu_cpd_metadata_cmpnt *cmpnt =
+	    ipu_cpd_metadata_get_cmpnt(isp, metadata,
+				       metadata_size, idx);
 
 	if (IS_ERR(cmpnt))
 		return PTR_ERR(cmpnt);
 
-	return cmpnt->id;
+	return cmpnt->entry_point;
 }
 
 static int ipu_cpd_parse_module_data(struct ipu_device *isp,
@@ -160,15 +143,13 @@ static int ipu_cpd_parse_module_data(struct ipu_device *isp,
 	const struct ipu_cpd_hdr *dir_hdr;
 	const struct ipu_cpd_ent *dir_ent;
 	int i;
-	u8 len;
 
 	if (!module_data)
 		return -EINVAL;
 
 	module_data_hdr = module_data;
 	dir_hdr = module_data + module_data_hdr->hdr_len;
-	len = dir_hdr->hdr_len;
-	dir_ent = (struct ipu_cpd_ent *)(((u8 *)dir_hdr) + len);
+	dir_ent = (struct ipu_cpd_ent *)(dir_hdr + 1);
 
 	pkg_dir[0] = PKG_DIR_HDR_MARK;
 	/* pkg_dir entry count = component count + pkg_dir header */
@@ -180,26 +161,15 @@ static int ipu_cpd_parse_module_data(struct ipu_device *isp,
 
 		*p++ = dma_addr_module_data + dir_ent->offset;
 
-		if (ipu_ver == IPU_VER_6 || ipu_ver == IPU_VER_6EP)
-			id = ipu6_cpd_metadata_get_cmpnt_id(isp, metadata,
-							    metadata_size, i);
-		else
-			id = ipu_cpd_metadata_get_cmpnt_id(isp, metadata,
-							   metadata_size, i);
-
+		id = ipu_cpd_metadata_get_cmpnt_id(isp, metadata,
+						   metadata_size, i);
 		if (id < 0 || id > MAX_COMPONENT_ID) {
 			dev_err(&isp->pdev->dev,
 				"Failed to parse component id\n");
 			return -EINVAL;
 		}
-
-		if (ipu_ver == IPU_VER_6 || ipu_ver == IPU_VER_6EP)
-			ver = ipu6_cpd_metadata_cmpnt_version(isp, metadata,
-							      metadata_size, i);
-		else
-			ver = ipu_cpd_metadata_cmpnt_version(isp, metadata,
-							     metadata_size, i);
-
+		ver = ipu_cpd_metadata_cmpnt_version(isp, metadata,
+						     metadata_size, i);
 		if (ver < 0 || ver > MAX_COMPONENT_VERSION) {
 			dev_err(&isp->pdev->dev,
 				"Failed to parse component version\n");
@@ -211,7 +181,7 @@ static int ipu_cpd_parse_module_data(struct ipu_device *isp,
 		 * 63:56        55      54:48   47:32   31:24   23:0
 		 * Rsvd         Rsvd    Type    Version Rsvd    Size
 		 */
-		*p = dir_ent->len | (u64)id << PKG_DIR_ID_SHIFT |
+		*p = dir_ent->len | (u64) id << PKG_DIR_ID_SHIFT |
 		    (u64)ver << PKG_DIR_VERSION_SHIFT;
 	}
 
@@ -239,7 +209,12 @@ void *ipu_cpd_create_pkg_dir(struct ipu_bus_device *adev,
 	*pkg_dir_size = PKG_DIR_SIZE + man_sz + met_sz;
 	pkg_dir = dma_alloc_attrs(&adev->dev, *pkg_dir_size, dma_addr,
 				  GFP_KERNEL,
-				  0);
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0)
+				  NULL
+#else
+				  0
+#endif
+	    );
 	if (!pkg_dir)
 		return pkg_dir;
 
@@ -265,7 +240,12 @@ void *ipu_cpd_create_pkg_dir(struct ipu_bus_device *adev,
 			"Unable to parse module data section!\n");
 		dma_free_attrs(&isp->psys->dev, *pkg_dir_size, pkg_dir,
 			       *dma_addr,
-			       0);
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0)
+			       NULL
+#else
+			       0
+#endif
+		    );
 		return NULL;
 	}
 
@@ -288,10 +268,40 @@ void ipu_cpd_free_pkg_dir(struct ipu_bus_device *adev,
 			  u64 *pkg_dir,
 			  dma_addr_t dma_addr, unsigned int pkg_dir_size)
 {
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0)
+	dma_free_attrs(&adev->dev, pkg_dir_size, pkg_dir, dma_addr, NULL);
+#else
 	dma_free_attrs(&adev->dev, pkg_dir_size, pkg_dir, dma_addr, 0);
+#endif
 }
 EXPORT_SYMBOL_GPL(ipu_cpd_free_pkg_dir);
 
+u32 ipu_cpd_get_pg_icache_base(struct ipu_device *isp,
+			       u8 idx,
+			       const void *cpd_file, unsigned int cpd_file_size)
+{
+	const struct ipu_cpd_ent *metadata = ipu_cpd_get_metadata(cpd_file);
+	const void *metadata_addr = cpd_file + metadata->offset;
+
+	return ipu_cpd_metadata_get_cmpnt_icache_base_offs(isp,
+							   metadata_addr,
+							   metadata->len, idx);
+}
+EXPORT_SYMBOL_GPL(ipu_cpd_get_pg_icache_base);
+
+u32 ipu_cpd_get_pg_entry_point(struct ipu_device *isp,
+			       u8 idx,
+			       const void *cpd_file, unsigned int cpd_file_size)
+{
+	const struct ipu_cpd_ent *metadata = ipu_cpd_get_metadata(cpd_file);
+	const void *metadata_addr = cpd_file + metadata->offset;
+
+	return ipu_cpd_metadata_get_cmpnt_entry_point(isp,
+						      metadata_addr,
+						      metadata->len, idx);
+}
+EXPORT_SYMBOL_GPL(ipu_cpd_get_pg_entry_point);
+
 static int ipu_cpd_validate_cpd(struct ipu_device *isp,
 				const void *cpd,
 				unsigned long cpd_size, unsigned long data_size)
@@ -299,24 +309,21 @@ static int ipu_cpd_validate_cpd(struct ipu_device *isp,
 	const struct ipu_cpd_hdr *cpd_hdr = cpd;
 	struct ipu_cpd_ent *ent;
 	unsigned int i;
-	u8 len;
-
-	len = cpd_hdr->hdr_len;
 
 	/* Ensure cpd hdr is within moduledata */
-	if (cpd_size < len) {
+	if (cpd_size < sizeof(*cpd_hdr)) {
 		dev_err(&isp->pdev->dev, "Invalid CPD moduledata size\n");
 		return -EINVAL;
 	}
 
 	/* Sanity check for CPD header */
-	if ((cpd_size - len) / sizeof(*ent) < cpd_hdr->ent_cnt) {
+	if ((cpd_size - sizeof(*cpd_hdr)) / sizeof(*ent) < cpd_hdr->ent_cnt) {
 		dev_err(&isp->pdev->dev, "Invalid CPD header\n");
 		return -EINVAL;
 	}
 
 	/* Ensure that all entries are within moduledata */
-	ent = (struct ipu_cpd_ent *)(((u8 *)cpd_hdr) + len);
+	ent = (struct ipu_cpd_ent *)(cpd_hdr + 1);
 	for (i = 0; i < cpd_hdr->ent_cnt; i++, ent++) {
 		if (data_size < ent->offset ||
 		    data_size - ent->offset < ent->len) {
@@ -342,7 +349,18 @@ static int ipu_cpd_validate_moduledata(struct ipu_device *isp,
 		return -EINVAL;
 	}
 
-	dev_info(&isp->pdev->dev, "FW version: %x\n", mod_hdr->fw_pkg_date);
+	if (fw_version_check && mod_hdr->fw_pkg_date != IA_CSS_FW_PKG_RELEASE) {
+		dev_err(&isp->pdev->dev,
+			"Moduledata and library version mismatch (%x != %x)\n",
+			mod_hdr->fw_pkg_date, IA_CSS_FW_PKG_RELEASE);
+		return -EINVAL;
+	}
+
+	dev_warn(&isp->pdev->dev,
+		 "Moduledata version: %x, library version: %x\n",
+		 mod_hdr->fw_pkg_date, IA_CSS_FW_PKG_RELEASE);
+
+	dev_info(&isp->pdev->dev, "CSS release: %x\n", IA_CSS_FW_PKG_RELEASE);
 	rval = ipu_cpd_validate_cpd(isp, moduledata +
 				    mod_hdr->hdr_len,
 				    moduledata_size -
@@ -359,7 +377,6 @@ static int ipu_cpd_validate_metadata(struct ipu_device *isp,
 				     const void *metadata, u32 meta_size)
 {
 	const struct ipu_cpd_metadata_extn *extn = metadata;
-	unsigned int size;
 
 	/* Sanity check for metadata size */
 	if (meta_size < sizeof(*extn) || meta_size > MAX_METADATA_SIZE) {
@@ -377,12 +394,8 @@ static int ipu_cpd_validate_metadata(struct ipu_device *isp,
 	}
 
 	/* Validate metadata size multiple of metadata components */
-	if (ipu_ver == IPU_VER_6 || ipu_ver == IPU_VER_6EP)
-		size = sizeof(struct ipu6_cpd_metadata_cmpnt);
-	else
-		size = sizeof(struct ipu_cpd_metadata_cmpnt);
-
-	if ((meta_size - sizeof(*extn)) % size) {
+	if ((meta_size - sizeof(*extn)) %
+	    sizeof(struct ipu_cpd_metadata_cmpnt)) {
 		dev_err(&isp->pdev->dev, "%s: Invalid metadata size\n",
 			__func__);
 		return -EINVAL;
diff --git a/drivers/media/pci/intel/ipu-cpd.h b/drivers/media/pci/intel/ipu-cpd.h
index 6e8fd5a9e51f..7033e90e135f 100644
--- a/drivers/media/pci/intel/ipu-cpd.h
+++ b/drivers/media/pci/intel/ipu-cpd.h
@@ -1,5 +1,5 @@
 /* SPDX-License-Identifier: GPL-2.0 */
-/* Copyright (C) 2015 - 2020 Intel Corporation */
+/* Copyright (C) 2015 - 2018 Intel Corporation */
 
 #ifndef IPU_CPD_H
 #define IPU_CPD_H
@@ -19,9 +19,6 @@
 
 #define IPU_CPD_PKG_DIR_CLIENT_PG_TYPE	3
 
-#define IPU6_CPD_METADATA_HASH_KEY_SIZE          48
-#define IPU_CPD_METADATA_HASH_KEY_SIZE           32
-
 struct __packed ipu_cpd_module_data_hdr {
 	u32 hdr_len;
 	u32 endian;
@@ -34,17 +31,20 @@ struct __packed ipu_cpd_module_data_hdr {
 	u8 rsvd[2];
 };
 
-/* ipu_cpd_hdr structure updated as the chksum and
- * sub_partition_name is unused on host side
- * CSE layout version 1.6 for ipu6se (hdr_len = 0x10)
- * CSE layout version 1.7 for ipu6 (hdr_len = 0x14)
- */
 struct __packed ipu_cpd_hdr {
 	u32 hdr_mark;
 	u32 ent_cnt;
 	u8 hdr_ver;
 	u8 ent_ver;
 	u8 hdr_len;
+#if defined(CONFIG_VIDEO_INTEL_IPU4) || defined(CONFIG_VIDEO_INTEL_IPU4P)
+	u8 chksm;
+	u32 name;
+#else
+	u8 rsvd;
+	u32 sub_partition_name;
+	u32 chksm;
+#endif
 };
 
 struct __packed ipu_cpd_ent {
@@ -58,17 +58,7 @@ struct __packed ipu_cpd_metadata_cmpnt {
 	u32 id;
 	u32 size;
 	u32 ver;
-	u8 sha2_hash[IPU_CPD_METADATA_HASH_KEY_SIZE];
-	u32 entry_point;
-	u32 icache_base_offs;
-	u8 attrs[16];
-};
-
-struct __packed ipu6_cpd_metadata_cmpnt {
-	u32 id;
-	u32 size;
-	u32 ver;
-	u8 sha2_hash[IPU6_CPD_METADATA_HASH_KEY_SIZE];
+	u8 sha2_hash[32];
 	u32 entry_point;
 	u32 icache_base_offs;
 	u8 attrs[16];
@@ -99,6 +89,14 @@ void *ipu_cpd_create_pkg_dir(struct ipu_bus_device *adev,
 void ipu_cpd_free_pkg_dir(struct ipu_bus_device *adev,
 			  u64 *pkg_dir,
 			  dma_addr_t dma_addr, unsigned int pkg_dir_size);
+u32 ipu_cpd_get_pg_icache_base(struct ipu_device *isp,
+			       u8 idx,
+			       const void *cpd_file,
+			       unsigned int cpd_file_size);
+u32 ipu_cpd_get_pg_entry_point(struct ipu_device *isp,
+			       u8 idx,
+			       const void *cpd_file,
+			       unsigned int cpd_file_size);
 int ipu_cpd_validate_cpd_file(struct ipu_device *isp,
 			      const void *cpd_file,
 			      unsigned long cpd_file_size);
diff --git a/drivers/media/pci/intel/ipu-dma.c b/drivers/media/pci/intel/ipu-dma.c
index a661257a30de..96ce50571434 100644
--- a/drivers/media/pci/intel/ipu-dma.c
+++ b/drivers/media/pci/intel/ipu-dma.c
@@ -1,68 +1,82 @@
 // SPDX-License-Identifier: GPL-2.0
-// Copyright (C) 2013 - 2021 Intel Corporation
+// Copyright (C) 2013 - 2018 Intel Corporation
 
 #include <asm/cacheflush.h>
 
 #include <linux/slab.h>
 #include <linux/device.h>
 #include <linux/dma-mapping.h>
+#include <linux/dma-map-ops.h>
 #include <linux/gfp.h>
 #include <linux/highmem.h>
 #include <linux/iova.h>
 #include <linux/module.h>
 #include <linux/scatterlist.h>
-#include <linux/version.h>
 #include <linux/vmalloc.h>
-#include <linux/dma-map-ops.h>
 
 #include "ipu-dma.h"
 #include "ipu-bus.h"
 #include "ipu-mmu.h"
 
-struct vm_info {
-	struct list_head list;
-	struct page **pages;
-	void *vaddr;
-	unsigned long size;
-};
-
-static struct vm_info *get_vm_info(struct ipu_mmu *mmu, void *vaddr)
-{
-	struct vm_info *info, *save;
-
-	list_for_each_entry_safe(info, save, &mmu->vma_list, list) {
-		if (info->vaddr == vaddr)
-			return info;
-	}
-
-	return NULL;
-}
-
 /* Begin of things adapted from arch/arm/mm/dma-mapping.c */
 static void __dma_clear_buffer(struct page *page, size_t size,
-			       unsigned long attrs)
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0)
+			       struct dma_attrs *attrs
+#else
+			       unsigned long attrs
+#endif
+				)
 {
 	/*
 	 * Ensure that the allocated pages are zeroed, and that any data
 	 * lurking in the kernel direct-mapped region is invalidated.
 	 */
-	void *ptr = page_address(page);
-
-	memset(ptr, 0, size);
-	if ((attrs & DMA_ATTR_SKIP_CPU_SYNC) == 0)
-		clflush_cache_range(ptr, size);
+	if (PageHighMem(page)) {
+		while (size > 0) {
+			void *ptr = kmap_atomic(page);
+
+			memset(ptr, 0, PAGE_SIZE);
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0)
+			if (!dma_get_attr(DMA_ATTR_SKIP_CPU_SYNC, attrs))
+#else
+			if ((attrs & DMA_ATTR_SKIP_CPU_SYNC) == 0)
+#endif
+				clflush_cache_range(ptr, PAGE_SIZE);
+			kunmap_atomic(ptr);
+			page++;
+			size -= PAGE_SIZE;
+		}
+	} else {
+		void *ptr = page_address(page);
+
+		memset(ptr, 0, size);
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0)
+		if (!dma_get_attr(DMA_ATTR_SKIP_CPU_SYNC, attrs))
+#else
+		if ((attrs & DMA_ATTR_SKIP_CPU_SYNC) == 0)
+#endif
+			clflush_cache_range(ptr, size);
+	}
 }
 
 static struct page **__dma_alloc_buffer(struct device *dev, size_t size,
-					gfp_t gfp,
-					unsigned long attrs)
+					  gfp_t gfp,
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0)
+					  struct dma_attrs *attrs
+#else
+					  unsigned long attrs
+#endif
+					)
 {
 	struct page **pages;
 	int count = size >> PAGE_SHIFT;
 	int array_size = count * sizeof(struct page *);
 	int i = 0;
 
-	pages = kvzalloc(array_size, GFP_KERNEL);
+	if (array_size <= PAGE_SIZE)
+		pages = kzalloc(array_size, GFP_KERNEL);
+	else
+		pages = vzalloc(array_size);
 	if (!pages)
 		return NULL;
 
@@ -94,15 +108,24 @@ static struct page **__dma_alloc_buffer(struct device *dev, size_t size,
 	while (i--)
 		if (pages[i])
 			__free_pages(pages[i], 0);
-	kvfree(pages);
+	if (array_size <= PAGE_SIZE)
+		kfree(pages);
+	else
+		vfree(pages);
 	return NULL;
 }
 
 static int __dma_free_buffer(struct device *dev, struct page **pages,
-			     size_t size,
-			     unsigned long attrs)
+			       size_t size,
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0)
+			       struct dma_attrs *attrs
+#else
+			       unsigned long attrs
+#endif
+				)
 {
 	int count = size >> PAGE_SHIFT;
+	int array_size = count * sizeof(struct page *);
 	int i;
 
 	for (i = 0; i < count; i++) {
@@ -112,7 +135,10 @@ static int __dma_free_buffer(struct device *dev, struct page **pages,
 		}
 	}
 
-	kvfree(pages);
+	if (array_size <= PAGE_SIZE)
+		kfree(pages);
+	else
+		vfree(pages);
 	return 0;
 }
 
@@ -123,7 +149,8 @@ static void ipu_dma_sync_single_for_cpu(struct device *dev,
 					size_t size,
 					enum dma_data_direction dir)
 {
-	struct ipu_mmu *mmu = to_ipu_bus_device(dev)->mmu;
+	struct device *aiommu = to_ipu_bus_device(dev)->iommu;
+	struct ipu_mmu *mmu = dev_get_drvdata(aiommu);
 	unsigned long pa = ipu_mmu_iova_to_phys(mmu->dmap->mmu_info,
 						dma_handle);
 
@@ -143,27 +170,28 @@ static void ipu_dma_sync_sg_for_cpu(struct device *dev,
 
 static void *ipu_dma_alloc(struct device *dev, size_t size,
 			   dma_addr_t *dma_handle, gfp_t gfp,
-			   unsigned long attrs)
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0)
+			   struct dma_attrs *attrs
+#else
+			   unsigned long attrs
+#endif
+			)
 {
-	struct ipu_mmu *mmu = to_ipu_bus_device(dev)->mmu;
+	struct device *aiommu = to_ipu_bus_device(dev)->iommu;
+	struct ipu_mmu *mmu = dev_get_drvdata(aiommu);
 	struct page **pages;
 	struct iova *iova;
-	struct vm_info *info;
 	int i;
 	int rval;
-	unsigned long count;
-
-	info = kzalloc(sizeof(*info), GFP_KERNEL);
-	if (!info)
-		return NULL;
+	unsigned int count;
+	void *addr;
 
 	size = PAGE_ALIGN(size);
-	count = size >> PAGE_SHIFT;
 
-	iova = alloc_iova(&mmu->dmap->iovad, count,
+	iova = alloc_iova(&mmu->dmap->iovad, size >> PAGE_SHIFT,
 			  dma_get_mask(dev) >> PAGE_SHIFT, 0);
 	if (!iova)
-		goto out_kfree;
+		return NULL;
 
 	pages = __dma_alloc_buffer(dev, size, gfp, attrs);
 	if (!pages)
@@ -171,107 +199,105 @@ static void *ipu_dma_alloc(struct device *dev, size_t size,
 
 	for (i = 0; iova->pfn_lo + i <= iova->pfn_hi; i++) {
 		rval = ipu_mmu_map(mmu->dmap->mmu_info,
-				   (iova->pfn_lo + i) << PAGE_SHIFT,
-				   page_to_phys(pages[i]), PAGE_SIZE);
+				 (iova->pfn_lo + i) << PAGE_SHIFT,
+				 page_to_phys(pages[i]), PAGE_SIZE);
 		if (rval)
 			goto out_unmap;
 	}
 
-	info->vaddr = vmap(pages, count, VM_USERMAP, PAGE_KERNEL);
-	if (!info->vaddr)
+	count = iova->pfn_hi - iova->pfn_lo + 1;
+
+	addr = vmap(pages, count, VM_MAP_PUT_PAGES, PAGE_KERNEL);
+	if (!addr)
 		goto out_unmap;
 
+
 	*dma_handle = iova->pfn_lo << PAGE_SHIFT;
 
-	info->pages = pages;
-	info->size = size;
-	list_add(&info->list, &mmu->vma_list);
+	mmu->tlb_invalidate(mmu);
 
-	return info->vaddr;
+	return addr;
 
 out_unmap:
 	for (i--; i >= 0; i--) {
 		ipu_mmu_unmap(mmu->dmap->mmu_info,
-			      (iova->pfn_lo + i) << PAGE_SHIFT, PAGE_SIZE);
+			(iova->pfn_lo + i) << PAGE_SHIFT,
+			PAGE_SIZE);
 	}
 	__dma_free_buffer(dev, pages, size, attrs);
 
 out_free_iova:
 	__free_iova(&mmu->dmap->iovad, iova);
-out_kfree:
-	kfree(info);
 
 	return NULL;
 }
 
 static void ipu_dma_free(struct device *dev, size_t size, void *vaddr,
 			 dma_addr_t dma_handle,
-			 unsigned long attrs)
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0)
+			 struct dma_attrs *attrs
+#else
+			 unsigned long attrs
+#endif
+			)
 {
-	struct ipu_mmu *mmu = to_ipu_bus_device(dev)->mmu;
+	struct device *aiommu = to_ipu_bus_device(dev)->iommu;
+	struct ipu_mmu *mmu = dev_get_drvdata(aiommu);
+	struct vm_struct *area = find_vm_area(vaddr);
 	struct page **pages;
-	struct vm_info *info;
 	struct iova *iova = find_iova(&mmu->dmap->iovad,
 				      dma_handle >> PAGE_SHIFT);
 
-	if (WARN_ON(!iova))
+	if (WARN_ON(!area))
 		return;
 
-	info = get_vm_info(mmu, vaddr);
-	if (WARN_ON(!info))
+	if (WARN_ON(!area->pages))
 		return;
 
-	if (WARN_ON(!info->vaddr))
-		return;
-
-	if (WARN_ON(!info->pages))
+	if (WARN_ON(!iova))
 		return;
 
-	list_del(&info->list);
-
 	size = PAGE_ALIGN(size);
 
-	pages = info->pages;
+	pages = area->pages;
 
 	vunmap(vaddr);
 
 	ipu_mmu_unmap(mmu->dmap->mmu_info, iova->pfn_lo << PAGE_SHIFT,
-		      (iova->pfn_hi - iova->pfn_lo + 1) << PAGE_SHIFT);
+		    (iova->pfn_hi - iova->pfn_lo + 1) << PAGE_SHIFT);
 
 	__dma_free_buffer(dev, pages, size, attrs);
 
-	mmu->tlb_invalidate(mmu);
-
 	__free_iova(&mmu->dmap->iovad, iova);
 
-	kfree(info);
+	mmu->tlb_invalidate(mmu);
 }
 
 static int ipu_dma_mmap(struct device *dev, struct vm_area_struct *vma,
 			void *addr, dma_addr_t iova, size_t size,
-			unsigned long attrs)
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0)
+			struct dma_attrs *attrs
+#else
+			unsigned long attrs
+#endif
+			)
 {
-	struct ipu_mmu *mmu = to_ipu_bus_device(dev)->mmu;
-	struct vm_info *info;
+	struct vm_struct *area = find_vm_area(addr);
 	size_t count = PAGE_ALIGN(size) >> PAGE_SHIFT;
 	size_t i;
 
-	info = get_vm_info(mmu, addr);
-	if (!info)
-		return -EFAULT;
-
-	if (!info->vaddr)
+	if (!area || !area->pages)
 		return -EFAULT;
 
 	if (vma->vm_start & ~PAGE_MASK)
 		return -EINVAL;
 
-	if (size > info->size)
+	if (size > area->size)
 		return -EFAULT;
 
 	for (i = 0; i < count; i++)
 		vm_insert_page(vma, vma->vm_start + (i << PAGE_SHIFT),
-			       info->pages[i]);
+			       area->pages[i]);
 
 	return 0;
 }
@@ -279,9 +305,15 @@ static int ipu_dma_mmap(struct device *dev, struct vm_area_struct *vma,
 static void ipu_dma_unmap_sg(struct device *dev,
 			     struct scatterlist *sglist,
 			     int nents, enum dma_data_direction dir,
-			     unsigned long attrs)
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0)
+			     struct dma_attrs *attrs
+#else
+			     unsigned long attrs
+#endif
+			)
 {
-	struct ipu_mmu *mmu = to_ipu_bus_device(dev)->mmu;
+	struct device *aiommu = to_ipu_bus_device(dev)->iommu;
+	struct ipu_mmu *mmu = dev_get_drvdata(aiommu);
 	struct iova *iova = find_iova(&mmu->dmap->iovad,
 				      sg_dma_address(sglist) >> PAGE_SHIFT);
 
@@ -291,11 +323,15 @@ static void ipu_dma_unmap_sg(struct device *dev,
 	if (WARN_ON(!iova))
 		return;
 
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0)
+	if (!dma_get_attr(DMA_ATTR_SKIP_CPU_SYNC, attrs))
+#else
 	if ((attrs & DMA_ATTR_SKIP_CPU_SYNC) == 0)
+#endif
 		ipu_dma_sync_sg_for_cpu(dev, sglist, nents, DMA_BIDIRECTIONAL);
 
 	ipu_mmu_unmap(mmu->dmap->mmu_info, iova->pfn_lo << PAGE_SHIFT,
-		      (iova->pfn_hi - iova->pfn_lo + 1) << PAGE_SHIFT);
+		    (iova->pfn_hi - iova->pfn_lo + 1) << PAGE_SHIFT);
 
 	mmu->tlb_invalidate(mmu);
 
@@ -304,9 +340,15 @@ static void ipu_dma_unmap_sg(struct device *dev,
 
 static int ipu_dma_map_sg(struct device *dev, struct scatterlist *sglist,
 			  int nents, enum dma_data_direction dir,
-			  unsigned long attrs)
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0)
+			  struct dma_attrs *attrs
+#else
+			  unsigned long attrs
+#endif
+			)
 {
-	struct ipu_mmu *mmu = to_ipu_bus_device(dev)->mmu;
+	struct device *aiommu = to_ipu_bus_device(dev)->iommu;
+	struct ipu_mmu *mmu = dev_get_drvdata(aiommu);
 	struct scatterlist *sg;
 	struct iova *iova;
 	size_t size = 0;
@@ -335,8 +377,8 @@ static int ipu_dma_map_sg(struct device *dev, struct scatterlist *sglist,
 			i, iova_addr << PAGE_SHIFT,
 			(unsigned long long)page_to_phys(sg_page(sg)));
 		rval = ipu_mmu_map(mmu->dmap->mmu_info, iova_addr << PAGE_SHIFT,
-				   page_to_phys(sg_page(sg)),
-				   PAGE_ALIGN(sg->length));
+				 page_to_phys(sg_page(sg)),
+				 PAGE_ALIGN(sg->length));
 		if (rval)
 			goto out_fail;
 		sg_dma_address(sg) = iova_addr << PAGE_SHIFT;
@@ -347,7 +389,11 @@ static int ipu_dma_map_sg(struct device *dev, struct scatterlist *sglist,
 		iova_addr += PAGE_ALIGN(sg->length) >> PAGE_SHIFT;
 	}
 
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0)
+	if (!dma_get_attr(DMA_ATTR_SKIP_CPU_SYNC, attrs))
+#else
 	if ((attrs & DMA_ATTR_SKIP_CPU_SYNC) == 0)
+#endif
 		ipu_dma_sync_sg_for_cpu(dev, sglist, nents, DMA_BIDIRECTIONAL);
 
 	mmu->tlb_invalidate(mmu);
@@ -365,26 +411,23 @@ static int ipu_dma_map_sg(struct device *dev, struct scatterlist *sglist,
  */
 static int ipu_dma_get_sgtable(struct device *dev, struct sg_table *sgt,
 			       void *cpu_addr, dma_addr_t handle, size_t size,
-			       unsigned long attrs)
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0)
+			       struct dma_attrs *attrs
+#else
+			       unsigned long attrs
+#endif
+				)
 {
-	struct ipu_mmu *mmu = to_ipu_bus_device(dev)->mmu;
-	struct vm_info *info;
+	struct vm_struct *area = find_vm_area(cpu_addr);
 	int n_pages;
 	int ret = 0;
 
-	info = get_vm_info(mmu, cpu_addr);
-	if (!info)
-		return -EFAULT;
-
-	if (!info->vaddr)
-		return -EFAULT;
-
-	if (WARN_ON(!info->pages))
+	if (WARN_ON(!area || !area->pages))
 		return -ENOMEM;
 
 	n_pages = PAGE_ALIGN(size) >> PAGE_SHIFT;
 
-	ret = sg_alloc_table_from_pages(sgt, info->pages, n_pages, 0, size,
+	ret = sg_alloc_table_from_pages(sgt, area->pages, n_pages, 0, size,
 					GFP_KERNEL);
 	if (ret)
 		dev_dbg(dev, "IPU get sgt table fail\n");
@@ -404,3 +447,4 @@ const struct dma_map_ops ipu_dma_ops = {
 	.sync_sg_for_device = ipu_dma_sync_sg_for_cpu,
 	.get_sgtable = ipu_dma_get_sgtable,
 };
+EXPORT_SYMBOL_GPL(ipu_dma_ops);
diff --git a/drivers/media/pci/intel/ipu-dma.h b/drivers/media/pci/intel/ipu-dma.h
index e3a68aa5adec..f5af2c6fe90b 100644
--- a/drivers/media/pci/intel/ipu-dma.h
+++ b/drivers/media/pci/intel/ipu-dma.h
@@ -1,5 +1,5 @@
 /* SPDX-License-Identifier: GPL-2.0 */
-/* Copyright (C) 2013 - 2020 Intel Corporation */
+/* Copyright (C) 2013 - 2018 Intel Corporation */
 
 #ifndef IPU_DMA_H
 #define IPU_DMA_H
diff --git a/drivers/media/pci/intel/ipu-fw-com.c b/drivers/media/pci/intel/ipu-fw-com.c
index 59d69ea6110c..4ddf1116a756 100644
--- a/drivers/media/pci/intel/ipu-fw-com.c
+++ b/drivers/media/pci/intel/ipu-fw-com.c
@@ -1,5 +1,5 @@
 // SPDX-License-Identifier: GPL-2.0
-// Copyright (C) 2013 - 2020 Intel Corporation
+// Copyright (C) 2013 - 2018 Intel Corporation
 
 #include <asm/cacheflush.h>
 
@@ -108,28 +108,28 @@ struct ipu_fw_com_context {
 	u32 specific_vied_addr;
 	u32 ibuf_vied_addr;
 	u32 obuf_vied_addr;
-
-	unsigned int buttress_boot_offset;
-	void __iomem *base_addr;
 };
 
 #define FW_COM_WR_REG 0
 #define FW_COM_RD_REG 4
 
 #define REGMEM_OFFSET 0
-#define TUNIT_MAGIC_PATTERN 0x5a5a5a5a
 
 enum regmem_id {
 	/* pass pkg_dir address to SPC in non-secure mode */
 	PKG_DIR_ADDR_REG = 0,
-	/* Tunit CFG blob for secure - provided by host.*/
-	TUNIT_CFG_DWR_REG = 1,
+	/* pass syscom configuration to SPC */
+	SYSCOM_CONFIG_REG = 1,
+	/* syscom state - modified by SP */
+	SYSCOM_STATE_REG = 2,
 	/* syscom commands - modified by the host */
-	SYSCOM_COMMAND_REG = 2,
+	SYSCOM_COMMAND_REG = 3,
 	/* Store interrupt status - updated by SP */
-	SYSCOM_IRQ_REG = 3,
+	SYSCOM_IRQ_REG = 4,
+	/* Store VTL0_ADDR_MASK in trusted secure regision - provided by host.*/
+	SYSCOM_VTL0_ADDR_MASK = 5,
 	/* first syscom queue pointer register */
-	SYSCOM_QPR_BASE_REG = 4
+	SYSCOM_QPR_BASE_REG = 6
 };
 
 enum message_direction {
@@ -137,20 +137,6 @@ enum message_direction {
 	DIR_SEND
 };
 
-#define BUTRESS_FW_BOOT_PARAMS_0 0x4000
-#define BUTTRESS_FW_BOOT_PARAM_REG(base, offset, id) ((base) \
-	+ BUTRESS_FW_BOOT_PARAMS_0 + ((offset) + (id)) * 4)
-
-enum buttress_syscom_id {
-	/* pass syscom configuration to SPC */
-	SYSCOM_CONFIG_ID		= 0,
-	/* syscom state - modified by SP */
-	SYSCOM_STATE_ID			= 1,
-	/* syscom vtl0 addr mask */
-	SYSCOM_VTL0_ADDR_MASK_ID	= 2,
-	SYSCOM_ID_MAX
-};
-
 static unsigned int num_messages(unsigned int wr, unsigned int rd,
 				 unsigned int size)
 {
@@ -188,8 +174,7 @@ static unsigned int ipu_sys_queue_buf_size(unsigned int size,
 }
 
 static void ipu_sys_queue_init(struct ipu_fw_sys_queue *q, unsigned int size,
-			       unsigned int token_size,
-			       struct ipu_fw_sys_queue_res *res)
+		    unsigned int token_size, struct ipu_fw_sys_queue_res *res)
 {
 	unsigned int buf_size;
 
@@ -232,8 +217,6 @@ void *ipu_fw_com_prepare(struct ipu_fw_com_cfg *cfg,
 	ctx->adev = adev;
 	ctx->cell_start = cfg->cell_start;
 	ctx->cell_ready = cfg->cell_ready;
-	ctx->buttress_boot_offset = cfg->buttress_boot_offset;
-	ctx->base_addr  = base;
 
 	ctx->num_input_queues = cfg->num_input_queues;
 	ctx->num_output_queues = cfg->num_output_queues;
@@ -262,11 +245,14 @@ void *ipu_fw_com_prepare(struct ipu_fw_com_cfg *cfg,
 
 	ctx->dma_buffer = dma_alloc_attrs(&ctx->adev->dev, sizeall,
 					  &ctx->dma_addr, GFP_KERNEL,
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 14, 0)
 					  attrs);
 	ctx->attrs = attrs;
+#else
+					  NULL);
+#endif
 	if (!ctx->dma_buffer) {
 		dev_err(&ctx->adev->dev, "failed to allocate dma memory\n");
-		kfree(ctx);
 		return NULL;
 	}
 
@@ -304,8 +290,8 @@ void *ipu_fw_com_prepare(struct ipu_fw_com_cfg *cfg,
 	res.vied_address = ctx->ibuf_vied_addr;
 	for (i = 0; i < cfg->num_input_queues; i++) {
 		ipu_sys_queue_init(ctx->input_queue + i,
-				   cfg->input[i].queue_size,
-				   cfg->input[i].token_size, &res);
+			       cfg->input[i].queue_size,
+			       cfg->input[i].token_size, &res);
 	}
 
 	/* initialize output queues */
@@ -313,8 +299,8 @@ void *ipu_fw_com_prepare(struct ipu_fw_com_cfg *cfg,
 	res.vied_address = ctx->obuf_vied_addr;
 	for (i = 0; i < cfg->num_output_queues; i++) {
 		ipu_sys_queue_init(ctx->output_queue + i,
-				   cfg->output[i].queue_size,
-				   cfg->output[i].token_size, &res);
+			       cfg->output[i].queue_size,
+			       cfg->output[i].token_size, &res);
 	}
 
 	/* copy firmware specific data */
@@ -329,36 +315,28 @@ void *ipu_fw_com_prepare(struct ipu_fw_com_cfg *cfg,
 	fw_cfg->output_queue = ctx->output_queue_vied_addr;
 	fw_cfg->specific_addr = ctx->specific_vied_addr;
 	fw_cfg->specific_size = cfg->specific_size;
+
+	clflush_cache_range(ctx->dma_buffer, sizeall);
+
 	return ctx;
 }
 EXPORT_SYMBOL_GPL(ipu_fw_com_prepare);
 
 int ipu_fw_com_open(struct ipu_fw_com_context *ctx)
 {
-	/*
-	 * Disable tunit configuration by FW.
-	 * This feature is used to configure tunit in secure mode.
-	 */
-	writel(TUNIT_MAGIC_PATTERN, ctx->dmem_addr + TUNIT_CFG_DWR_REG * 4);
 	/* Check if SP is in valid state */
 	if (!ctx->cell_ready(ctx->adev))
 		return -EIO;
 
+	/* store syscom uninitialized state */
+	writel(SYSCOM_STATE_UNINIT, ctx->dmem_addr + SYSCOM_STATE_REG * 4);
 	/* store syscom uninitialized command */
 	writel(SYSCOM_COMMAND_UNINIT,
-	       ctx->dmem_addr + SYSCOM_COMMAND_REG * 4);
-
-	/* store syscom uninitialized state */
-	writel(SYSCOM_STATE_UNINIT,
-	       BUTTRESS_FW_BOOT_PARAM_REG(ctx->base_addr,
-					  ctx->buttress_boot_offset,
-					  SYSCOM_STATE_ID));
-
+		   ctx->dmem_addr + SYSCOM_COMMAND_REG * 4);
 	/* store firmware configuration address */
 	writel(ctx->config_vied_addr,
-	       BUTTRESS_FW_BOOT_PARAM_REG(ctx->base_addr,
-					  ctx->buttress_boot_offset,
-					  SYSCOM_CONFIG_ID));
+		   ctx->dmem_addr + SYSCOM_CONFIG_REG * 4);
+
 	ctx->cell_start(ctx->adev);
 
 	return 0;
@@ -369,9 +347,7 @@ int ipu_fw_com_close(struct ipu_fw_com_context *ctx)
 {
 	int state;
 
-	state = readl(BUTTRESS_FW_BOOT_PARAM_REG(ctx->base_addr,
-						 ctx->buttress_boot_offset,
-						 SYSCOM_STATE_ID));
+	state = readl(ctx->dmem_addr + 4 * SYSCOM_STATE_REG);
 	if (state != SYSCOM_STATE_READY)
 		return -EBUSY;
 
@@ -391,7 +367,11 @@ int ipu_fw_com_release(struct ipu_fw_com_context *ctx, unsigned int force)
 
 	dma_free_attrs(&ctx->adev->dev, ctx->dma_size,
 		       ctx->dma_buffer, ctx->dma_addr,
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 14, 0)
 		       ctx->attrs);
+#else
+		       NULL);
+#endif
 	kfree(ctx);
 	return 0;
 }
@@ -401,9 +381,8 @@ int ipu_fw_com_ready(struct ipu_fw_com_context *ctx)
 {
 	int state;
 
-	state = readl(BUTTRESS_FW_BOOT_PARAM_REG(ctx->base_addr,
-						 ctx->buttress_boot_offset,
-						 SYSCOM_STATE_ID));
+	/* check if SP syscom is ready to open the queue */
+	state = readl(ctx->dmem_addr + SYSCOM_STATE_REG * 4);
 	if (state != SYSCOM_STATE_READY)
 		return -EBUSY;	/* SPC is not ready to handle messages yet */
 
@@ -434,7 +413,7 @@ void *ipu_send_get_token(struct ipu_fw_com_context *ctx, int q_nbr)
 		return NULL;
 
 	packets = num_free(wr + 1, rd, q->size);
-	if (!packets)
+	if (packets <= 0)
 		return NULL;
 
 	index = curr_index(q_dmem, DIR_SEND);
@@ -448,6 +427,10 @@ void ipu_send_put_token(struct ipu_fw_com_context *ctx, int q_nbr)
 	struct ipu_fw_sys_queue *q = &ctx->input_queue[q_nbr];
 	void __iomem *q_dmem = ctx->dmem_addr + q->wr_reg * 4;
 	int index = curr_index(q_dmem, DIR_SEND);
+	void *addr = (void *)(unsigned long)q->host_address +
+				(index * q->token_size);
+
+	clflush_cache_range(addr, q->token_size);
 
 	/* Increment index */
 	index = inc_index(q_dmem, q, DIR_SEND);
@@ -472,10 +455,11 @@ void *ipu_recv_get_token(struct ipu_fw_com_context *ctx, int q_nbr)
 		return NULL;
 
 	packets = num_messages(wr, rd, q->size);
-	if (!packets)
+	if (packets <= 0)
 		return NULL;
 
 	addr = (void *)(unsigned long)q->host_address + (rd * q->token_size);
+	clflush_cache_range(addr, q->token_size);
 
 	return addr;
 }
diff --git a/drivers/media/pci/intel/ipu-fw-com.h b/drivers/media/pci/intel/ipu-fw-com.h
index 855dba667372..de47455ea9a4 100644
--- a/drivers/media/pci/intel/ipu-fw-com.h
+++ b/drivers/media/pci/intel/ipu-fw-com.h
@@ -1,5 +1,5 @@
 /* SPDX-License-Identifier: GPL-2.0 */
-/* Copyright (C) 2013 - 2020 Intel Corporation */
+/* Copyright (C) 2013 - 2018 Intel Corporation */
 
 #ifndef IPU_FW_COM_H
 #define IPU_FW_COM_H
@@ -12,9 +12,6 @@ struct ipu_fw_syscom_queue_config {
 	unsigned int token_size;	/* bytes per token */
 };
 
-#define SYSCOM_BUTTRESS_FW_PARAMS_ISYS_OFFSET	0
-#define SYSCOM_BUTTRESS_FW_PARAMS_PSYS_OFFSET	7
-
 struct ipu_fw_com_cfg {
 	unsigned int num_input_queues;
 	unsigned int num_output_queues;
@@ -28,8 +25,6 @@ struct ipu_fw_com_cfg {
 	unsigned int specific_size;
 	int (*cell_ready)(struct ipu_bus_device *adev);
 	void (*cell_start)(struct ipu_bus_device *adev);
-
-	unsigned int buttress_boot_offset;
 };
 
 void *ipu_fw_com_prepare(struct ipu_fw_com_cfg *cfg,
diff --git a/drivers/media/pci/intel/ipu-fw-isys.c b/drivers/media/pci/intel/ipu-fw-isys.c
index fb03a9183025..130d2ca4a438 100644
--- a/drivers/media/pci/intel/ipu-fw-isys.c
+++ b/drivers/media/pci/intel/ipu-fw-isys.c
@@ -1,15 +1,11 @@
 // SPDX-License-Identifier: GPL-2.0
-// Copyright (C) 2013 - 2021 Intel Corporation
+// Copyright (C) 2013 - 2018 Intel Corporation
 
 #include <asm/cacheflush.h>
 
 #include <linux/kernel.h>
 #include <linux/delay.h>
-
-#include "ipu.h"
-#include "ipu-trace.h"
 #include "ipu-platform-regs.h"
-#include "ipu-platform.h"
 #include "ipu-fw-isys.h"
 #include "ipu-fw-com.h"
 #include "ipu-isys.h"
@@ -17,6 +13,7 @@
 #define IPU_FW_UNSUPPORTED_DATA_TYPE	0
 static const uint32_t
 extracted_bits_per_pixel_per_mipi_data_type[N_IPU_FW_ISYS_MIPI_DATA_TYPE] = {
+
 	64,	/* [0x00]   IPU_FW_ISYS_MIPI_DATA_TYPE_FRAME_START_CODE */
 	64,	/* [0x01]   IPU_FW_ISYS_MIPI_DATA_TYPE_FRAME_END_CODE */
 	64,	/* [0x02]   IPU_FW_ISYS_MIPI_DATA_TYPE_LINE_START_CODE */
@@ -83,388 +80,6 @@ extracted_bits_per_pixel_per_mipi_data_type[N_IPU_FW_ISYS_MIPI_DATA_TYPE] = {
 	IPU_FW_UNSUPPORTED_DATA_TYPE	/* [0x3F] */
 };
 
-static const char send_msg_types[N_IPU_FW_ISYS_SEND_TYPE][32] = {
-	"STREAM_OPEN",
-	"STREAM_START",
-	"STREAM_START_AND_CAPTURE",
-	"STREAM_CAPTURE",
-	"STREAM_STOP",
-	"STREAM_FLUSH",
-	"STREAM_CLOSE"
-};
-
-static int handle_proxy_response(struct ipu_isys *isys, unsigned int req_id)
-{
-	struct ipu_fw_isys_proxy_resp_info_abi *resp;
-	int rval = -EIO;
-
-	resp = (struct ipu_fw_isys_proxy_resp_info_abi *)
-	    ipu_recv_get_token(isys->fwcom, IPU_BASE_PROXY_RECV_QUEUES);
-	if (!resp)
-		return 1;
-
-	dev_dbg(&isys->adev->dev,
-		"Proxy response: id 0x%x, error %d, details %d\n",
-		resp->request_id, resp->error_info.error,
-		resp->error_info.error_details);
-
-	if (req_id == resp->request_id)
-		rval = 0;
-
-	ipu_recv_put_token(isys->fwcom, IPU_BASE_PROXY_RECV_QUEUES);
-	return rval;
-}
-
-/* Simple blocking proxy send function */
-int ipu_fw_isys_send_proxy_token(struct ipu_isys *isys,
-				 unsigned int req_id,
-				 unsigned int index,
-				 unsigned int offset, u32 value)
-{
-	struct ipu_fw_com_context *ctx = isys->fwcom;
-	struct ipu_fw_proxy_send_queue_token *token;
-	unsigned int timeout = 1000;
-	int rval = -EBUSY;
-
-	dev_dbg(&isys->adev->dev,
-		"proxy send token: req_id 0x%x, index %d, offset 0x%x, value 0x%x\n",
-		req_id, index, offset, value);
-
-	token = ipu_send_get_token(ctx, IPU_BASE_PROXY_SEND_QUEUES);
-	if (!token)
-		goto leave;
-
-	token->request_id = req_id;
-	token->region_index = index;
-	token->offset = offset;
-	token->value = value;
-	ipu_send_put_token(ctx, IPU_BASE_PROXY_SEND_QUEUES);
-
-	/* Currently proxy doesn't support irq based service. Poll */
-	do {
-		usleep_range(100, 110);
-		rval = handle_proxy_response(isys, req_id);
-		if (!rval)
-			break;
-		if (rval == -EIO) {
-			dev_err(&isys->adev->dev,
-				"Proxy response received with unexpected id\n");
-			break;
-		}
-		timeout--;
-	} while (rval && timeout);
-
-	if (!timeout)
-		dev_err(&isys->adev->dev, "Proxy response timed out\n");
-leave:
-	return rval;
-}
-
-int
-ipu_fw_isys_complex_cmd(struct ipu_isys *isys,
-			const unsigned int stream_handle,
-			void *cpu_mapped_buf,
-			dma_addr_t dma_mapped_buf,
-			size_t size, enum ipu_fw_isys_send_type send_type)
-{
-	struct ipu_fw_com_context *ctx = isys->fwcom;
-	struct ipu_fw_send_queue_token *token;
-
-	if (send_type >= N_IPU_FW_ISYS_SEND_TYPE)
-		return -EINVAL;
-
-	dev_dbg(&isys->adev->dev, "send_token: %s\n",
-		send_msg_types[send_type]);
-
-	/*
-	 * Time to flush cache in case we have some payload. Not all messages
-	 * have that
-	 */
-	if (cpu_mapped_buf)
-		clflush_cache_range(cpu_mapped_buf, size);
-
-	token = ipu_send_get_token(ctx,
-				   stream_handle + IPU_BASE_MSG_SEND_QUEUES);
-	if (!token)
-		return -EBUSY;
-
-	token->payload = dma_mapped_buf;
-	token->buf_handle = (unsigned long)cpu_mapped_buf;
-	token->send_type = send_type;
-
-	ipu_send_put_token(ctx, stream_handle + IPU_BASE_MSG_SEND_QUEUES);
-
-	return 0;
-}
-
-int ipu_fw_isys_simple_cmd(struct ipu_isys *isys,
-			   const unsigned int stream_handle,
-			   enum ipu_fw_isys_send_type send_type)
-{
-	return ipu_fw_isys_complex_cmd(isys, stream_handle, NULL, 0, 0,
-				       send_type);
-}
-
-int ipu_fw_isys_close(struct ipu_isys *isys)
-{
-	struct device *dev = &isys->adev->dev;
-	int timeout = IPU_ISYS_TURNOFF_TIMEOUT;
-	int rval;
-	unsigned long flags;
-	void *fwcom;
-
-	/*
-	 * Stop the isys fw. Actual close takes
-	 * some time as the FW must stop its actions including code fetch
-	 * to SP icache.
-	 * spinlock to wait the interrupt handler to be finished
-	 */
-	spin_lock_irqsave(&isys->power_lock, flags);
-	rval = ipu_fw_com_close(isys->fwcom);
-	fwcom = isys->fwcom;
-	isys->fwcom = NULL;
-	spin_unlock_irqrestore(&isys->power_lock, flags);
-	if (rval)
-		dev_err(dev, "Device close failure: %d\n", rval);
-
-	/* release probably fails if the close failed. Let's try still */
-	do {
-		usleep_range(IPU_ISYS_TURNOFF_DELAY_US,
-			     2 * IPU_ISYS_TURNOFF_DELAY_US);
-		rval = ipu_fw_com_release(fwcom, 0);
-		timeout--;
-	} while (rval != 0 && timeout);
-
-	if (rval) {
-		dev_err(dev, "Device release time out %d\n", rval);
-		spin_lock_irqsave(&isys->power_lock, flags);
-		isys->fwcom = fwcom;
-		spin_unlock_irqrestore(&isys->power_lock, flags);
-	}
-
-	return rval;
-}
-
-void ipu_fw_isys_cleanup(struct ipu_isys *isys)
-{
-	int ret;
-
-	ret = ipu_fw_com_release(isys->fwcom, 1);
-	if (ret < 0)
-		dev_err(&isys->adev->dev,
-			"Device busy, fw_com release failed.");
-	isys->fwcom = NULL;
-}
-
-static void start_sp(struct ipu_bus_device *adev)
-{
-	struct ipu_isys *isys = ipu_bus_get_drvdata(adev);
-	void __iomem *spc_regs_base = isys->pdata->base +
-	    isys->pdata->ipdata->hw_variant.spc_offset;
-	u32 val = 0;
-
-	val |= IPU_ISYS_SPC_STATUS_START |
-	    IPU_ISYS_SPC_STATUS_RUN |
-	    IPU_ISYS_SPC_STATUS_CTRL_ICACHE_INVALIDATE;
-	val |= isys->icache_prefetch ? IPU_ISYS_SPC_STATUS_ICACHE_PREFETCH : 0;
-
-	writel(val, spc_regs_base + IPU_ISYS_REG_SPC_STATUS_CTRL);
-}
-
-static int query_sp(struct ipu_bus_device *adev)
-{
-	struct ipu_isys *isys = ipu_bus_get_drvdata(adev);
-	void __iomem *spc_regs_base = isys->pdata->base +
-	    isys->pdata->ipdata->hw_variant.spc_offset;
-	u32 val = readl(spc_regs_base + IPU_ISYS_REG_SPC_STATUS_CTRL);
-
-	/* return true when READY == 1, START == 0 */
-	val &= IPU_ISYS_SPC_STATUS_READY | IPU_ISYS_SPC_STATUS_START;
-
-	return val == IPU_ISYS_SPC_STATUS_READY;
-}
-
-static int ipu6_isys_fwcom_cfg_init(struct ipu_isys *isys,
-				    struct ipu_fw_com_cfg *fwcom,
-				    unsigned int num_streams)
-{
-	int i;
-	unsigned int size;
-	struct ipu_fw_syscom_queue_config *input_queue_cfg;
-	struct ipu_fw_syscom_queue_config *output_queue_cfg;
-	struct ipu6_fw_isys_fw_config *isys_fw_cfg;
-	int num_out_message_queues = 1;
-	int type_proxy = IPU_FW_ISYS_QUEUE_TYPE_PROXY;
-	int type_dev = IPU_FW_ISYS_QUEUE_TYPE_DEV;
-	int type_msg = IPU_FW_ISYS_QUEUE_TYPE_MSG;
-	int base_dev_send = IPU_BASE_DEV_SEND_QUEUES;
-	int base_msg_send = IPU_BASE_MSG_SEND_QUEUES;
-	int base_msg_recv = IPU_BASE_MSG_RECV_QUEUES;
-	int num_in_message_queues;
-	unsigned int max_streams;
-	unsigned int max_send_queues, max_sram_blocks, max_devq_size;
-
-	max_streams = IPU6_ISYS_NUM_STREAMS;
-	max_send_queues = IPU6_N_MAX_SEND_QUEUES;
-	max_sram_blocks = IPU6_NOF_SRAM_BLOCKS_MAX;
-	max_devq_size = IPU6_DEV_SEND_QUEUE_SIZE;
-	if (ipu_ver == IPU_VER_6SE) {
-		max_streams = IPU6SE_ISYS_NUM_STREAMS;
-		max_send_queues = IPU6SE_N_MAX_SEND_QUEUES;
-		max_sram_blocks = IPU6SE_NOF_SRAM_BLOCKS_MAX;
-		max_devq_size = IPU6SE_DEV_SEND_QUEUE_SIZE;
-	}
-
-	num_in_message_queues = clamp_t(unsigned int, num_streams, 1,
-					max_streams);
-	isys_fw_cfg = devm_kzalloc(&isys->adev->dev, sizeof(*isys_fw_cfg),
-				   GFP_KERNEL);
-	if (!isys_fw_cfg)
-		return -ENOMEM;
-
-	isys_fw_cfg->num_send_queues[IPU_FW_ISYS_QUEUE_TYPE_PROXY] =
-		IPU_N_MAX_PROXY_SEND_QUEUES;
-	isys_fw_cfg->num_send_queues[IPU_FW_ISYS_QUEUE_TYPE_DEV] =
-		IPU_N_MAX_DEV_SEND_QUEUES;
-	isys_fw_cfg->num_send_queues[IPU_FW_ISYS_QUEUE_TYPE_MSG] =
-		num_in_message_queues;
-	isys_fw_cfg->num_recv_queues[IPU_FW_ISYS_QUEUE_TYPE_PROXY] =
-		IPU_N_MAX_PROXY_RECV_QUEUES;
-	/* Common msg/dev return queue */
-	isys_fw_cfg->num_recv_queues[IPU_FW_ISYS_QUEUE_TYPE_DEV] = 0;
-	isys_fw_cfg->num_recv_queues[IPU_FW_ISYS_QUEUE_TYPE_MSG] =
-		num_out_message_queues;
-
-	size = sizeof(*input_queue_cfg) * max_send_queues;
-	input_queue_cfg = devm_kzalloc(&isys->adev->dev, size, GFP_KERNEL);
-	if (!input_queue_cfg)
-		return -ENOMEM;
-
-	size = sizeof(*output_queue_cfg) * IPU_N_MAX_RECV_QUEUES;
-	output_queue_cfg = devm_kzalloc(&isys->adev->dev, size, GFP_KERNEL);
-	if (!output_queue_cfg)
-		return -ENOMEM;
-
-	fwcom->input = input_queue_cfg;
-	fwcom->output = output_queue_cfg;
-
-	fwcom->num_input_queues =
-		isys_fw_cfg->num_send_queues[type_proxy] +
-		isys_fw_cfg->num_send_queues[type_dev] +
-		isys_fw_cfg->num_send_queues[type_msg];
-
-	fwcom->num_output_queues =
-		isys_fw_cfg->num_recv_queues[type_proxy] +
-		isys_fw_cfg->num_recv_queues[type_dev] +
-		isys_fw_cfg->num_recv_queues[type_msg];
-
-	/* SRAM partitioning. Equal partitioning is set. */
-	for (i = 0; i < max_sram_blocks; i++) {
-		if (i < num_in_message_queues)
-			isys_fw_cfg->buffer_partition.num_gda_pages[i] =
-				(IPU_DEVICE_GDA_NR_PAGES *
-				 IPU_DEVICE_GDA_VIRT_FACTOR) /
-				num_in_message_queues;
-		else
-			isys_fw_cfg->buffer_partition.num_gda_pages[i] = 0;
-	}
-
-	/* FW assumes proxy interface at fwcom queue 0 */
-	for (i = 0; i < isys_fw_cfg->num_send_queues[type_proxy]; i++) {
-		input_queue_cfg[i].token_size =
-			sizeof(struct ipu_fw_proxy_send_queue_token);
-		input_queue_cfg[i].queue_size = IPU_ISYS_SIZE_PROXY_SEND_QUEUE;
-	}
-
-	for (i = 0; i < isys_fw_cfg->num_send_queues[type_dev]; i++) {
-		input_queue_cfg[base_dev_send + i].token_size =
-			sizeof(struct ipu_fw_send_queue_token);
-		input_queue_cfg[base_dev_send + i].queue_size = max_devq_size;
-	}
-
-	for (i = 0; i < isys_fw_cfg->num_send_queues[type_msg]; i++) {
-		input_queue_cfg[base_msg_send + i].token_size =
-			sizeof(struct ipu_fw_send_queue_token);
-		input_queue_cfg[base_msg_send + i].queue_size =
-			IPU_ISYS_SIZE_SEND_QUEUE;
-	}
-
-	for (i = 0; i < isys_fw_cfg->num_recv_queues[type_proxy]; i++) {
-		output_queue_cfg[i].token_size =
-			sizeof(struct ipu_fw_proxy_resp_queue_token);
-		output_queue_cfg[i].queue_size = IPU_ISYS_SIZE_PROXY_RECV_QUEUE;
-	}
-	/* There is no recv DEV queue */
-	for (i = 0; i < isys_fw_cfg->num_recv_queues[type_msg]; i++) {
-		output_queue_cfg[base_msg_recv + i].token_size =
-			sizeof(struct ipu_fw_resp_queue_token);
-		output_queue_cfg[base_msg_recv + i].queue_size =
-			IPU_ISYS_SIZE_RECV_QUEUE;
-	}
-
-	fwcom->dmem_addr = isys->pdata->ipdata->hw_variant.dmem_offset;
-	fwcom->specific_addr = isys_fw_cfg;
-	fwcom->specific_size = sizeof(*isys_fw_cfg);
-
-	return 0;
-}
-
-int ipu_fw_isys_init(struct ipu_isys *isys, unsigned int num_streams)
-{
-	int retry = IPU_ISYS_OPEN_RETRY;
-
-	struct ipu_fw_com_cfg fwcom = {
-		.cell_start = start_sp,
-		.cell_ready = query_sp,
-		.buttress_boot_offset = SYSCOM_BUTTRESS_FW_PARAMS_ISYS_OFFSET,
-	};
-
-	struct device *dev = &isys->adev->dev;
-	int rval;
-
-	ipu6_isys_fwcom_cfg_init(isys, &fwcom, num_streams);
-
-	isys->fwcom = ipu_fw_com_prepare(&fwcom, isys->adev, isys->pdata->base);
-	if (!isys->fwcom) {
-		dev_err(dev, "isys fw com prepare failed\n");
-		return -EIO;
-	}
-
-	rval = ipu_fw_com_open(isys->fwcom);
-	if (rval) {
-		dev_err(dev, "isys fw com open failed %d\n", rval);
-		return rval;
-	}
-
-	do {
-		usleep_range(IPU_ISYS_OPEN_TIMEOUT_US,
-			     IPU_ISYS_OPEN_TIMEOUT_US + 10);
-		rval = ipu_fw_com_ready(isys->fwcom);
-		if (!rval)
-			break;
-		retry--;
-	} while (retry > 0);
-
-	if (!retry && rval) {
-		dev_err(dev, "isys port open ready failed %d\n", rval);
-		ipu_fw_isys_close(isys);
-	}
-
-	return rval;
-}
-
-struct ipu_fw_isys_resp_info_abi *
-ipu_fw_isys_get_resp(void *context, unsigned int queue,
-		     struct ipu_fw_isys_resp_info_abi *response)
-{
-	return (struct ipu_fw_isys_resp_info_abi *)
-	    ipu_recv_get_token(context, queue);
-}
-
-void ipu_fw_isys_put_resp(void *context, unsigned int queue)
-{
-	ipu_recv_put_token(context, queue);
-}
 
 void ipu_fw_isys_set_params(struct ipu_fw_isys_stream_cfg_data_abi *stream_cfg)
 {
@@ -477,16 +92,6 @@ void ipu_fw_isys_set_params(struct ipu_fw_isys_stream_cfg_data_abi *stream_cfg)
 		    extracted_bits_per_pixel_per_mipi_data_type[idx];
 		stream_cfg->input_pins[i].mapped_dt =
 		    N_IPU_FW_ISYS_MIPI_DATA_TYPE;
-		stream_cfg->input_pins[i].mipi_decompression =
-		    IPU_FW_ISYS_MIPI_COMPRESSION_TYPE_NO_COMPRESSION;
-		/*
-		 * CSI BE can be used to crop and change bayer order.
-		 * NOTE: currently it only crops first and last lines in height.
-		 */
-		if (stream_cfg->crop.top_offset & 1)
-			stream_cfg->input_pins[i].crop_first_and_last_lines = 1;
-		stream_cfg->input_pins[i].capture_mode =
-			IPU_FW_ISYS_CAPTURE_MODE_REGULAR;
 	}
 }
 
@@ -519,19 +124,20 @@ ipu_fw_isys_dump_stream_cfg(struct device *dev,
 			stream_cfg->input_pins[i].input_res.width);
 		dev_dbg(dev, "Input res height %d\n",
 			stream_cfg->input_pins[i].input_res.height);
-		dev_dbg(dev, "mipi decompression %d\n",
-			stream_cfg->input_pins[i].mipi_decompression);
-		dev_dbg(dev, "capture_mode %d\n",
-			stream_cfg->input_pins[i].capture_mode);
 	}
 
-	dev_dbg(dev, "Crop info\n");
-	dev_dbg(dev, "Crop.top_offset %d\n", stream_cfg->crop.top_offset);
-	dev_dbg(dev, "Crop.left_offset %d\n", stream_cfg->crop.left_offset);
-	dev_dbg(dev, "Crop.bottom_offset %d\n",
-		stream_cfg->crop.bottom_offset);
-	dev_dbg(dev, "Crop.right_offset %d\n", stream_cfg->crop.right_offset);
-	dev_dbg(dev, "----------------\n");
+	for (i = 0; i < N_IPU_FW_ISYS_CROPPING_LOCATION; i++) {
+		dev_dbg(dev, "Crop info %d\n", i);
+		dev_dbg(dev, "Crop.top_offset %d\n",
+			stream_cfg->crop[i].top_offset);
+		dev_dbg(dev, "Crop.left_offset %d\n",
+			stream_cfg->crop[i].left_offset);
+		dev_dbg(dev, "Crop.bottom_offset %d\n",
+			stream_cfg->crop[i].bottom_offset);
+		dev_dbg(dev, "Crop.right_offset %d\n",
+			stream_cfg->crop[i].right_offset);
+		dev_dbg(dev, "----------------\n");
+	}
 
 	for (i = 0; i < stream_cfg->nof_output_pins; i++) {
 		dev_dbg(dev, "Output pin %d\n", i);
@@ -543,8 +149,6 @@ ipu_fw_isys_dump_stream_cfg(struct device *dev,
 			stream_cfg->output_pins[i].output_res.height);
 		dev_dbg(dev, "Stride %d\n", stream_cfg->output_pins[i].stride);
 		dev_dbg(dev, "Pin type %d\n", stream_cfg->output_pins[i].pt);
-		dev_dbg(dev, "Payload %d\n",
-			stream_cfg->output_pins[i].payload_buf_size);
 		dev_dbg(dev, "Ft %d\n", stream_cfg->output_pins[i].ft);
 		dev_dbg(dev, "Watermar in lines %d\n",
 			stream_cfg->output_pins[i].watermark_in_lines);
@@ -554,16 +158,29 @@ ipu_fw_isys_dump_stream_cfg(struct device *dev,
 			stream_cfg->output_pins[i].reserve_compression);
 		dev_dbg(dev, "snoopable %d\n",
 			stream_cfg->output_pins[i].snoopable);
-		dev_dbg(dev, "error_handling_enable %d\n",
-			stream_cfg->output_pins[i].error_handling_enable);
 		dev_dbg(dev, "sensor type %d\n",
 			stream_cfg->output_pins[i].sensor_type);
 		dev_dbg(dev, "----------------\n");
 	}
 
 	dev_dbg(dev, "Isl_use %d\n", stream_cfg->isl_use);
-	dev_dbg(dev, "stream sensor_type %d\n", stream_cfg->sensor_type);
-
+	switch (stream_cfg->isl_use) {
+	case IPU_FW_ISYS_USE_SINGLE_ISA:
+		dev_dbg(dev, "ISA cfg:\n");
+		dev_dbg(dev, "blc_enabled %d\n", stream_cfg->isa_cfg.cfg.blc);
+		dev_dbg(dev, "lsc_enabled %d\n", stream_cfg->isa_cfg.cfg.lsc);
+		dev_dbg(dev, "dpc_enabled %d\n", stream_cfg->isa_cfg.cfg.dpc);
+		dev_dbg(dev, "downscaler_enabled %d\n",
+			stream_cfg->isa_cfg.cfg.downscaler);
+		dev_dbg(dev, "awb_enabled %d\n", stream_cfg->isa_cfg.cfg.awb);
+		dev_dbg(dev, "af_enabled %d\n", stream_cfg->isa_cfg.cfg.af);
+		dev_dbg(dev, "ae_enabled %d\n", stream_cfg->isa_cfg.cfg.ae);
+		break;
+	case IPU_FW_ISYS_USE_SINGLE_DUAL_ISL:
+	case IPU_FW_ISYS_USE_NO_ISL_NO_ISA:
+	default:
+		break;
+	}
 }
 
 void ipu_fw_isys_dump_frame_buff_set(struct device *dev,
@@ -586,15 +203,16 @@ void ipu_fw_isys_dump_frame_buff_set(struct device *dev,
 		dev_dbg(dev, "----------------\n");
 	}
 
+	dev_dbg(dev, "process_group_light.addr 0x%x\n",
+		buf->process_group_light.addr);
+	dev_dbg(dev, "process_group_light.param_buf_id %llu\n",
+		buf->process_group_light.param_buf_id);
 	dev_dbg(dev, "send_irq_sof 0x%x\n", buf->send_irq_sof);
 	dev_dbg(dev, "send_irq_eof 0x%x\n", buf->send_irq_eof);
 	dev_dbg(dev, "send_resp_sof 0x%x\n", buf->send_resp_sof);
 	dev_dbg(dev, "send_resp_eof 0x%x\n", buf->send_resp_eof);
+#if defined(CONFIG_VIDEO_INTEL_IPU4) || defined(CONFIG_VIDEO_INTEL_IPU4P)
 	dev_dbg(dev, "send_irq_capture_ack 0x%x\n", buf->send_irq_capture_ack);
-	dev_dbg(dev, "send_irq_capture_done 0x%x\n",
-		buf->send_irq_capture_done);
-	dev_dbg(dev, "send_resp_capture_ack 0x%x\n",
-		buf->send_resp_capture_ack);
-	dev_dbg(dev, "send_resp_capture_done 0x%x\n",
-		buf->send_resp_capture_done);
+	dev_dbg(dev, "send_irq_capture_done 0x%x\n", buf->send_irq_capture_done);
+#endif
 }
diff --git a/drivers/media/pci/intel/ipu-fw-isys.h b/drivers/media/pci/intel/ipu-fw-isys.h
index 0dc320474b77..2853e1e1c9d9 100644
--- a/drivers/media/pci/intel/ipu-fw-isys.h
+++ b/drivers/media/pci/intel/ipu-fw-isys.h
@@ -1,5 +1,5 @@
 /* SPDX-License-Identifier: GPL-2.0 */
-/* Copyright (C) 2013 - 2020 Intel Corporation */
+/* Copyright (C) 2013 - 2018 Intel Corporation */
 
 #ifndef IPU_FW_ISYS_H
 #define IPU_FW_ISYS_H
@@ -9,19 +9,21 @@
 /* Max number of Input/Output Pins */
 #define IPU_MAX_IPINS 4
 
-#define IPU_MAX_OPINS ((IPU_MAX_IPINS) + 1)
+/* worst case is ISA use where a single input pin produces:
+ * Mipi output, NS Pixel Output, and Scaled Pixel Output.
+ * This is how the 2 is calculated
+ */
+#define IPU_MAX_OPINS ((IPU_MAX_IPINS) + 2)
 
-#define IPU6_STREAM_ID_MAX 16
-#define IPU6_NONSECURE_STREAM_ID_MAX 12
-#define IPU6_DEV_SEND_QUEUE_SIZE (IPU6_STREAM_ID_MAX)
-#define IPU6_NOF_SRAM_BLOCKS_MAX (IPU6_STREAM_ID_MAX)
-#define IPU6_N_MAX_MSG_SEND_QUEUES (IPU6_STREAM_ID_MAX)
-#define IPU6SE_STREAM_ID_MAX 8
-#define IPU6SE_NONSECURE_STREAM_ID_MAX 4
-#define IPU6SE_DEV_SEND_QUEUE_SIZE (IPU6SE_STREAM_ID_MAX)
-#define IPU6SE_NOF_SRAM_BLOCKS_MAX (IPU6SE_STREAM_ID_MAX)
-#define IPU6SE_N_MAX_MSG_SEND_QUEUES (IPU6SE_STREAM_ID_MAX)
+/* Max number of supported virtual streams */
+#if defined(CONFIG_VIDEO_INTEL_IPU4) || defined(CONFIG_VIDEO_INTEL_IPU4P)
+#define IPU_STREAM_ID_MAX 8
+#else
+#define IPU_STREAM_ID_MAX 16
+#endif
 
+/* Aligned with the approach of having one dedicated per stream */
+#define IPU_N_MAX_MSG_SEND_QUEUES (IPU_STREAM_ID_MAX)
 /* Single return queue for all streams/commands type */
 #define IPU_N_MAX_MSG_RECV_QUEUES 1
 /* Single device queue for high priority commands (bypass in-order queue) */
@@ -36,6 +38,8 @@
 	(IPU_BASE_PROXY_SEND_QUEUES + IPU_N_MAX_PROXY_SEND_QUEUES)
 #define IPU_BASE_MSG_SEND_QUEUES \
 	(IPU_BASE_DEV_SEND_QUEUES + IPU_N_MAX_DEV_SEND_QUEUES)
+#define IPU_N_MAX_SEND_QUEUES \
+	(IPU_BASE_MSG_SEND_QUEUES + IPU_N_MAX_MSG_SEND_QUEUES)
 /* Recv queues layout */
 #define IPU_BASE_PROXY_RECV_QUEUES 0
 #define IPU_BASE_MSG_RECV_QUEUES \
@@ -43,10 +47,18 @@
 #define IPU_N_MAX_RECV_QUEUES \
 	(IPU_BASE_MSG_RECV_QUEUES + IPU_N_MAX_MSG_RECV_QUEUES)
 
-#define IPU6_N_MAX_SEND_QUEUES \
-	(IPU_BASE_MSG_SEND_QUEUES + IPU6_N_MAX_MSG_SEND_QUEUES)
-#define IPU6SE_N_MAX_SEND_QUEUES \
-	(IPU_BASE_MSG_SEND_QUEUES + IPU6SE_N_MAX_MSG_SEND_QUEUES)
+/* Consider 1 slot per stream since driver is not expected to pipeline
+ * device commands for the same stream
+ */
+#define IPU_DEV_SEND_QUEUE_SIZE (IPU_STREAM_ID_MAX)
+
+/* Max number of supported SRAM buffer partitions.
+ * It refers to the size of stream partitions.
+ * These partitions are further subpartitioned internally
+ * by the FW, but by declaring statically the stream
+ * partitions we solve the buffer fragmentation issue
+ */
+#define IPU_NOF_SRAM_BLOCKS_MAX (IPU_STREAM_ID_MAX)
 
 /* Max number of supported input pins routed in ISL */
 #define IPU_MAX_IPINS_IN_ISL 2
@@ -136,6 +148,7 @@ enum ipu_fw_isys_stream_source {
 	N_IPU_FW_ISYS_STREAM_SRC
 };
 
+#if !defined(CONFIG_VIDEO_INTEL_IPU4) && !defined(CONFIG_VIDEO_INTEL_IPU4P)
 enum ipu_fw_isys_sensor_type {
 	/* non-snoopable to PSYS */
 	IPU_FW_ISYS_VC1_SENSOR_DATA	= 0,
@@ -148,60 +161,37 @@ enum ipu_fw_isys_sensor_type {
 	N_IPU_FW_ISYS_SENSOR_TYPE
 };
 
-enum ipu6se_fw_isys_sensor_info {
+enum ipu_fw_isys_sensor_info {
 	/* VC1 */
-	IPU6SE_FW_ISYS_SENSOR_DATA_1 = 1,
-	IPU6SE_FW_ISYS_SENSOR_DATA_2 = 2,
-	IPU6SE_FW_ISYS_SENSOR_DATA_3 = 3,
-	IPU6SE_FW_ISYS_SENSOR_PDAF_1 = 4,
-	IPU6SE_FW_ISYS_SENSOR_PDAF_2 = 4,
+	IPU_FW_ISYS_SENSOR_DATA_1 = 1,
+	IPU_FW_ISYS_SENSOR_DATA_2 = 2,
+	IPU_FW_ISYS_SENSOR_DATA_3 = 3,
+	IPU_FW_ISYS_SENSOR_DATA_4 = 4,
+	IPU_FW_ISYS_SENSOR_DATA_5 = 5,
+	IPU_FW_ISYS_SENSOR_DATA_6 = 6,
+	IPU_FW_ISYS_SENSOR_DATA_7 = 7,
+	IPU_FW_ISYS_SENSOR_DATA_8 = 8,
+	IPU_FW_ISYS_SENSOR_DATA_9 = 9,
+	IPU_FW_ISYS_SENSOR_DATA_10 = 10,
+	IPU_FW_ISYS_SENSOR_PDAF_1 = 11,
+	IPU_FW_ISYS_SENSOR_PDAF_2 = 12,
 	/* VC0 */
-	IPU6SE_FW_ISYS_SENSOR_METADATA = 5,
-	IPU6SE_FW_ISYS_SENSOR_DATA_4 = 6,
-	IPU6SE_FW_ISYS_SENSOR_DATA_5 = 7,
-	IPU6SE_FW_ISYS_SENSOR_DATA_6 = 8,
-	IPU6SE_FW_ISYS_SENSOR_DATA_7 = 9,
-	IPU6SE_FW_ISYS_SENSOR_DATA_8 = 10,
-	IPU6SE_FW_ISYS_SENSOR_DATA_9 = 11,
-	N_IPU6SE_FW_ISYS_SENSOR_INFO,
-	IPU6SE_FW_ISYS_VC1_SENSOR_DATA_START = IPU6SE_FW_ISYS_SENSOR_DATA_1,
-	IPU6SE_FW_ISYS_VC1_SENSOR_DATA_END = IPU6SE_FW_ISYS_SENSOR_DATA_3,
-	IPU6SE_FW_ISYS_VC0_SENSOR_DATA_START = IPU6SE_FW_ISYS_SENSOR_DATA_4,
-	IPU6SE_FW_ISYS_VC0_SENSOR_DATA_END = IPU6SE_FW_ISYS_SENSOR_DATA_9,
-	IPU6SE_FW_ISYS_VC1_SENSOR_PDAF_START = IPU6SE_FW_ISYS_SENSOR_PDAF_1,
-	IPU6SE_FW_ISYS_VC1_SENSOR_PDAF_END = IPU6SE_FW_ISYS_SENSOR_PDAF_2,
-};
-
-enum ipu6_fw_isys_sensor_info {
-	/* VC1 */
-	IPU6_FW_ISYS_SENSOR_DATA_1 = 1,
-	IPU6_FW_ISYS_SENSOR_DATA_2 = 2,
-	IPU6_FW_ISYS_SENSOR_DATA_3 = 3,
-	IPU6_FW_ISYS_SENSOR_DATA_4 = 4,
-	IPU6_FW_ISYS_SENSOR_DATA_5 = 5,
-	IPU6_FW_ISYS_SENSOR_DATA_6 = 6,
-	IPU6_FW_ISYS_SENSOR_DATA_7 = 7,
-	IPU6_FW_ISYS_SENSOR_DATA_8 = 8,
-	IPU6_FW_ISYS_SENSOR_DATA_9 = 9,
-	IPU6_FW_ISYS_SENSOR_DATA_10 = 10,
-	IPU6_FW_ISYS_SENSOR_PDAF_1 = 11,
-	IPU6_FW_ISYS_SENSOR_PDAF_2 = 12,
-	/* VC0 */
-	IPU6_FW_ISYS_SENSOR_METADATA = 13,
-	IPU6_FW_ISYS_SENSOR_DATA_11 = 14,
-	IPU6_FW_ISYS_SENSOR_DATA_12 = 15,
-	IPU6_FW_ISYS_SENSOR_DATA_13 = 16,
-	IPU6_FW_ISYS_SENSOR_DATA_14 = 17,
-	IPU6_FW_ISYS_SENSOR_DATA_15 = 18,
-	IPU6_FW_ISYS_SENSOR_DATA_16 = 19,
-	N_IPU6_FW_ISYS_SENSOR_INFO,
-	IPU6_FW_ISYS_VC1_SENSOR_DATA_START = IPU6_FW_ISYS_SENSOR_DATA_1,
-	IPU6_FW_ISYS_VC1_SENSOR_DATA_END = IPU6_FW_ISYS_SENSOR_DATA_10,
-	IPU6_FW_ISYS_VC0_SENSOR_DATA_START = IPU6_FW_ISYS_SENSOR_DATA_11,
-	IPU6_FW_ISYS_VC0_SENSOR_DATA_END = IPU6_FW_ISYS_SENSOR_DATA_16,
-	IPU6_FW_ISYS_VC1_SENSOR_PDAF_START = IPU6_FW_ISYS_SENSOR_PDAF_1,
-	IPU6_FW_ISYS_VC1_SENSOR_PDAF_END = IPU6_FW_ISYS_SENSOR_PDAF_2,
+	IPU_FW_ISYS_SENSOR_METADATA = 13,
+	IPU_FW_ISYS_SENSOR_DATA_11 = 14,
+	IPU_FW_ISYS_SENSOR_DATA_12 = 15,
+	IPU_FW_ISYS_SENSOR_DATA_13 = 16,
+	IPU_FW_ISYS_SENSOR_DATA_14 = 17,
+	IPU_FW_ISYS_SENSOR_DATA_15 = 18,
+	IPU_FW_ISYS_SENSOR_DATA_16 = 19,
+	N_IPU_FW_ISYS_SENSOR_INFO,
+	IPU_FW_ISYS_VC1_SENSOR_DATA_START = IPU_FW_ISYS_SENSOR_DATA_1,
+	IPU_FW_ISYS_VC1_SENSOR_DATA_END = IPU_FW_ISYS_SENSOR_DATA_10,
+	IPU_FW_ISYS_VC0_SENSOR_DATA_START = IPU_FW_ISYS_SENSOR_DATA_11,
+	IPU_FW_ISYS_VC0_SENSOR_DATA_END = IPU_FW_ISYS_SENSOR_DATA_16,
+	IPU_FW_ISYS_VC1_SENSOR_PDAF_START = IPU_FW_ISYS_SENSOR_PDAF_1,
+	IPU_FW_ISYS_VC1_SENSOR_PDAF_END = IPU_FW_ISYS_SENSOR_PDAF_2,
 };
+#endif
 
 #define IPU_FW_ISYS_STREAM_SRC_CSI2_PORT0 IPU_FW_ISYS_STREAM_SRC_PORT_0
 #define IPU_FW_ISYS_STREAM_SRC_CSI2_PORT1 IPU_FW_ISYS_STREAM_SRC_PORT_1
@@ -282,25 +272,6 @@ enum ipu_fw_isys_frame_format_type {
 /* Temporary for driver compatibility */
 #define IPU_FW_ISYS_FRAME_FORMAT_RAW		(IPU_FW_ISYS_FRAME_FORMAT_RAW16)
 
-enum ipu_fw_isys_mipi_compression_type {
-	IPU_FW_ISYS_MIPI_COMPRESSION_TYPE_NO_COMPRESSION = 0,
-	IPU_FW_ISYS_MIPI_COMPRESSION_TYPE_10_8_10_TYPE1,
-	IPU_FW_ISYS_MIPI_COMPRESSION_TYPE_10_8_10_TYPE2,
-	IPU_FW_ISYS_MIPI_COMPRESSION_TYPE_10_7_10_TYPE1,
-	IPU_FW_ISYS_MIPI_COMPRESSION_TYPE_10_7_10_TYPE2,
-	IPU_FW_ISYS_MIPI_COMPRESSION_TYPE_10_6_10_TYPE1,
-	IPU_FW_ISYS_MIPI_COMPRESSION_TYPE_10_6_10_TYPE2,
-	IPU_FW_ISYS_MIPI_COMPRESSION_TYPE_12_8_12_TYPE1,
-	IPU_FW_ISYS_MIPI_COMPRESSION_TYPE_12_8_12_TYPE2,
-	IPU_FW_ISYS_MIPI_COMPRESSION_TYPE_12_7_12_TYPE1,
-	IPU_FW_ISYS_MIPI_COMPRESSION_TYPE_12_7_12_TYPE2,
-	IPU_FW_ISYS_MIPI_COMPRESSION_TYPE_12_6_12_TYPE1,
-	IPU_FW_ISYS_MIPI_COMPRESSION_TYPE_12_6_12_TYPE2,
-	IPU_FW_ISYS_MIPI_COMPRESSION_TYPE_12_10_12_TYPE1,
-	IPU_FW_ISYS_MIPI_COMPRESSION_TYPE_12_10_12_TYPE2,
-	N_IPU_FW_ISYS_MIPI_COMPRESSION_TYPE,
-};
-
 /**
  *  Supported MIPI data type. Keep in sync array in ipu_fw_isys_private.c
  */
@@ -422,18 +393,47 @@ enum ipu_fw_isys_mipi_data_type {
 enum ipu_fw_isys_pin_type {
 	/* Captured as MIPI packets */
 	IPU_FW_ISYS_PIN_TYPE_MIPI = 0,
-	/* Captured through the RAW path */
-	IPU_FW_ISYS_PIN_TYPE_RAW_NS = 1,
+	/* Captured through the ISApf (with/without ISA)
+	 * and the non-scaled output path
+	 */
+	IPU_FW_ISYS_PIN_TYPE_RAW_NS,
+	/* Captured through the ISApf + ISA and the scaled output path */
+	IPU_FW_ISYS_PIN_TYPE_RAW_S,
 	/* Captured through the SoC path */
-	IPU_FW_ISYS_PIN_TYPE_RAW_SOC = 3,
+	IPU_FW_ISYS_PIN_TYPE_RAW_SOC,
 	/* Reserved for future use, maybe short packets */
-	IPU_FW_ISYS_PIN_TYPE_METADATA_0 = 4,
+	IPU_FW_ISYS_PIN_TYPE_METADATA_0,
 	/* Reserved for future use */
-	IPU_FW_ISYS_PIN_TYPE_METADATA_1 = 5,
+	IPU_FW_ISYS_PIN_TYPE_METADATA_1,
+	/* Legacy (non-PIV2), used for the AWB stats */
+	IPU_FW_ISYS_PIN_TYPE_AWB_STATS,
+	/* Legacy (non-PIV2), used for the AF stats */
+	IPU_FW_ISYS_PIN_TYPE_AF_STATS,
+	/* Legacy (non-PIV2), used for the AE stats */
+	IPU_FW_ISYS_PIN_TYPE_HIST_STATS,
+	/* Used for the PAF FF */
+	IPU_FW_ISYS_PIN_TYPE_PAF_FF,
+#if !defined(CONFIG_VIDEO_INTEL_IPU4) && !defined(CONFIG_VIDEO_INTEL_IPU4P)
+	/* Captured through the SoC path
+	 * (2D mode where odd and even lines are handled separately)
+	 */
+	IPU_FW_ISYS_PIN_TYPE_RAW_DUAL_SOC,
+#endif
 	/* Keep always last and max value */
 	N_IPU_FW_ISYS_PIN_TYPE
 };
 
+/**
+ * enum ipu_fw_isys_isl_use
+ * Describes the ISL/ISA use
+ */
+enum ipu_fw_isys_isl_use {
+	IPU_FW_ISYS_USE_NO_ISL_NO_ISA = 0,
+	IPU_FW_ISYS_USE_SINGLE_DUAL_ISL,
+	IPU_FW_ISYS_USE_SINGLE_ISA,
+	N_IPU_FW_ISYS_USE
+};
+
 /**
  * enum ipu_fw_isys_mipi_store_mode. Describes if long MIPI packets reach
  * MIPI SRAM with the long packet header or
@@ -446,20 +446,57 @@ enum ipu_fw_isys_mipi_store_mode {
 };
 
 /**
- * ISYS capture mode and sensor enums
- * Used for Tobii sensor, if doubt, use default value 0
+ * enum ipu_fw_isys_type_paf. Describes the Type of PAF enabled
  */
+enum ipu_fw_isys_type_paf {
+	/* PAF data not present */
+	IPU_FW_ISYS_TYPE_NO_PAF = 0,
+	/* Type 2 sensor types, PAF coming separately from Image Frame  */
+	/* PAF data in interleaved format(RLRL or LRLR) */
+	IPU_FW_ISYS_TYPE_INTERLEAVED_PAF,
+	/* PAF data in non-interleaved format(LL/RR or RR/LL) */
+	IPU_FW_ISYS_TYPE_NON_INTERLEAVED_PAF,
+	/* Type 3 sensor types , PAF data embedded in Image Frame */
+	/* Frame Embedded PAF in interleaved format(RLRL or LRLR) */
+	IPU_FW_ISYS_TYPE_FRAME_EMB_INTERLEAVED_PAF,
+	/* Frame Embedded PAF non-interleaved format(LL/RR or RR/LL) */
+	IPU_FW_ISYS_TYPE_FRAME_EMB_NON_INTERLEAVED_PAF,
+	N_IPU_FW_ISYS_TYPE_PAF
+};
 
-enum ipu_fw_isys_capture_mode {
-	IPU_FW_ISYS_CAPTURE_MODE_REGULAR = 0,
-	IPU_FW_ISYS_CAPTURE_MODE_BURST,
-	N_IPU_FW_ISYS_CAPTURE_MODE,
+/**
+ * enum ipu_fw_isys_cropping_location. Enumerates the cropping locations in ISYS
+ */
+enum ipu_fw_isys_cropping_location {
+	/* Cropping executed in ISAPF (mainly),
+	 * ISAPF preproc (odd column) and MIPI STR2MMIO (odd row)
+	 */
+	IPU_FW_ISYS_CROPPING_LOCATION_PRE_ISA = 0,
+	/* Reserved for legacy mode which will never be implemented */
+	IPU_FW_ISYS_CROPPING_LOCATION_RESERVED_1,
+	/* Cropping executed in StreamPifConv in the ISA output for
+	 * RAW_NS pin
+	 */
+	IPU_FW_ISYS_CROPPING_LOCATION_POST_ISA_NONSCALED,
+	/* Cropping executed in StreamScaledPifConv
+	 * in the ISA output for RAW_S pin
+	 */
+	IPU_FW_ISYS_CROPPING_LOCATION_POST_ISA_SCALED,
+	N_IPU_FW_ISYS_CROPPING_LOCATION
 };
 
-enum ipu_fw_isys_sensor_mode {
-	IPU_FW_ISYS_SENSOR_MODE_NORMAL = 0,
-	IPU_FW_ISYS_SENSOR_MODE_TOBII,
-	N_IPU_FW_ISYS_SENSOR_MODE,
+/**
+ * enum ipu_fw_isys_resolution_info. Describes the resolution,
+ * required to setup the various ISA GP registers.
+ */
+enum ipu_fw_isys_resolution_info {
+	/* Scaled ISA output resolution before
+	 * the StreamScaledPifConv cropping
+	 */
+	IPU_FW_ISYS_RESOLUTION_INFO_POST_ISA_NONSCALED = 0,
+	/* Non-Scaled ISA output resolution before the StreamPifConv cropping */
+	IPU_FW_ISYS_RESOLUTION_INFO_POST_ISA_SCALED,
+	N_IPU_FW_ISYS_RESOLUTION_INFO
 };
 
 /**
@@ -495,12 +532,20 @@ enum ipu_fw_proxy_error {
 
 struct ipu_isys;
 
-struct ipu6_fw_isys_buffer_partition_abi {
-	u32 num_gda_pages[IPU6_STREAM_ID_MAX];
+/**
+ * struct ipu_fw_isys_buffer_partition_abi - buffer partition information
+ * @num_gda_pages: Number of virtual gda pages available for each virtual stream
+ */
+struct ipu_fw_isys_buffer_partition_abi {
+	u32 num_gda_pages[IPU_STREAM_ID_MAX];
 };
 
-struct ipu6_fw_isys_fw_config {
-	struct ipu6_fw_isys_buffer_partition_abi buffer_partition;
+/**
+ * struct ipu_fw_isys_fw_config - contains the parts from
+ * ia_css_isys_device_cfg_data we need to transfer to the cell
+ */
+struct ipu_fw_isys_fw_config {
+	struct ipu_fw_isys_buffer_partition_abi buffer_partition;
 	u32 num_send_queues[N_IPU_FW_ISYS_QUEUE_TYPE];
 	u32 num_recv_queues[N_IPU_FW_ISYS_QUEUE_TYPE];
 };
@@ -545,9 +590,6 @@ struct ipu_fw_isys_output_pin_info_abi {
 	u32 stride;
 	u32 watermark_in_lines;
 	u32 payload_buf_size;
-	u32 ts_offsets[IPU_PIN_PLANES_MAX];
-	u32 s2m_pixel_soc_pixel_remapping;
-	u32 csi_be_soc_pixel_remapping;
 	u8 send_irq;
 	u8 input_pin_id;
 	u8 pt;
@@ -555,7 +597,6 @@ struct ipu_fw_isys_output_pin_info_abi {
 	u8 reserved;
 	u8 reserve_compression;
 	u8 snoopable;
-	u8 error_handling_enable;
 	u32 sensor_type;
 };
 
@@ -574,18 +615,17 @@ struct ipu_fw_isys_param_pin_abi {
  * @input_res: input resolution
  * @dt: mipi data type ((enum ipu_fw_isys_mipi_data_type)
  * @mipi_store_mode: defines if legacy long packet header will be stored or
- *		     discarded if discarded, output pin type for this
+ *		     discarded if discarded, output pin pin type for this
  *		     input pin can only be MIPI
  *		     (enum ipu_fw_isys_mipi_store_mode)
  * @bits_per_pix: native bits per pixel
  * @mapped_dt: actual data type from sensor
- * @mipi_decompression: defines which compression will be in mipi backend
-
+#if !defined(CONFIG_VIDEO_INTEL_IPU4) && !defined(CONFIG_VIDEO_INTEL_IPU4P)
  * @crop_first_and_last_lines    Control whether to crop the
  *                              first and last line of the
  *                              input image. Crop done by HW
  *                              device.
- * @capture_mode: mode of capture, regular or burst, default value is regular
+#endif
  */
 struct ipu_fw_isys_input_pin_info_abi {
 	struct ipu_fw_isys_resolution_abi input_res;
@@ -593,9 +633,29 @@ struct ipu_fw_isys_input_pin_info_abi {
 	u8 mipi_store_mode;
 	u8 bits_per_pix;
 	u8 mapped_dt;
-	u8 mipi_decompression;
+#if !defined(CONFIG_VIDEO_INTEL_IPU4) && !defined(CONFIG_VIDEO_INTEL_IPU4P)
 	u8 crop_first_and_last_lines;
-	u8 capture_mode;
+#endif
+};
+
+/**
+ * struct ipu_fw_isys_isa_cfg_abi. Describes the ISA cfg
+ */
+struct ipu_fw_isys_isa_cfg_abi {
+	struct ipu_fw_isys_resolution_abi
+	 isa_res[N_IPU_FW_ISYS_RESOLUTION_INFO];
+	struct {
+		unsigned int blc:1;
+		unsigned int lsc:1;
+		unsigned int dpc:1;
+		unsigned int downscaler:1;
+		unsigned int awb:1;
+		unsigned int af:1;
+		unsigned int ae:1;
+		unsigned int paf:8;
+		unsigned int send_irq_stats_ready:1;
+		unsigned int send_resp_stats_ready:1;
+	} cfg;
 };
 
 /**
@@ -611,6 +671,7 @@ struct ipu_fw_isys_cropping_abi {
 /**
  * struct ipu_fw_isys_stream_cfg_data_abi
  * ISYS stream configuration data structure
+ * @isa_cfg: details about what ACCs are active if ISA is used
  * @crop: defines cropping resolution for the
  * maximum number of input pins which can be cropped,
  * it is directly mapped to the HW devices
@@ -636,10 +697,10 @@ struct ipu_fw_isys_cropping_abi {
  * @src: Stream source index e.g. MIPI_generator_0, CSI2-rx_1
  * @vc: MIPI Virtual Channel (up to 4 virtual per physical channel)
  * @isl_use: indicates whether stream requires ISL and how
- * @sensor_type: type of connected sensor, tobii or others, default is 0
  */
 struct ipu_fw_isys_stream_cfg_data_abi {
-	struct ipu_fw_isys_cropping_abi crop;
+	struct ipu_fw_isys_isa_cfg_abi isa_cfg;
+	struct ipu_fw_isys_cropping_abi crop[N_IPU_FW_ISYS_CROPPING_LOCATION];
 	struct ipu_fw_isys_input_pin_info_abi input_pins[IPU_MAX_IPINS];
 	struct ipu_fw_isys_output_pin_info_abi output_pins[IPU_MAX_OPINS];
 	u32 compfmt;
@@ -652,12 +713,12 @@ struct ipu_fw_isys_stream_cfg_data_abi {
 	u8 src;
 	u8 vc;
 	u8 isl_use;
-	u8 sensor_type;
 };
 
 /**
  * struct ipu_fw_isys_frame_buff_set - frame buffer set
  * @output_pins: output pin addresses
+ * @process_group_light: process_group_light buffer address
  * @send_irq_sof: send irq on frame sof response
  *		- if '1' it will override the send_resp_sof and
  *		  send the response
@@ -672,19 +733,18 @@ struct ipu_fw_isys_stream_cfg_data_abi {
  *		   used only when send_irq_sof is '0'
  * @send_resp_eof: send response for frame eof detected,
  *		   used only when send_irq_eof is '0'
- * @send_resp_capture_ack: send response for capture ack event
- * @send_resp_capture_done: send response for capture done event
  */
 struct ipu_fw_isys_frame_buff_set_abi {
 	struct ipu_fw_isys_output_pin_payload_abi output_pins[IPU_MAX_OPINS];
+	struct ipu_fw_isys_param_pin_abi process_group_light;
 	u8 send_irq_sof;
 	u8 send_irq_eof;
+#if defined(CONFIG_VIDEO_INTEL_IPU4) || defined(CONFIG_VIDEO_INTEL_IPU4P)
 	u8 send_irq_capture_ack;
 	u8 send_irq_capture_done;
+#endif
 	u8 send_resp_sof;
 	u8 send_resp_eof;
-	u8 send_resp_capture_ack;
-	u8 send_resp_capture_done;
 	u8 reserved;
 };
 
@@ -702,20 +762,27 @@ struct ipu_fw_isys_error_info_abi {
  * struct ipu_fw_isys_resp_info_comm
  * @pin: this var is only valid for pin event related responses,
  *     contains pin addresses
+ * @process_group_light: this var is valid for stats ready related responses,
+ *			contains process group addresses
  * @error_info: error information from the FW
  * @timestamp: Time information for event if available
  * @stream_handle: stream id the response corresponds to
  * @type: response type (enum ipu_fw_isys_resp_type)
  * @pin_id: pin id that the pin payload corresponds to
+ * @acc_id: this var is valid for stats ready related responses,
+ *	   contains accelerator id that finished producing
+ *	   all related statistics
  */
 struct ipu_fw_isys_resp_info_abi {
 	u64 buf_id;
 	struct ipu_fw_isys_output_pin_payload_abi pin;
+	struct ipu_fw_isys_param_pin_abi process_group_light;
 	struct ipu_fw_isys_error_info_abi error_info;
 	u32 timestamp[2];
 	u8 stream_handle;
 	u8 type;
 	u8 pin_id;
+	u8 acc_id;
 	u16 reserved;
 };
 
@@ -809,8 +876,10 @@ int ipu_fw_isys_send_proxy_token(struct ipu_isys *isys,
 				 unsigned int index,
 				 unsigned int offset, u32 value);
 void ipu_fw_isys_cleanup(struct ipu_isys *isys);
-struct ipu_fw_isys_resp_info_abi *
-ipu_fw_isys_get_resp(void *context, unsigned int queue,
-		     struct ipu_fw_isys_resp_info_abi *response);
+struct ipu_fw_isys_resp_info_abi *ipu_fw_isys_get_resp(void *context,
+						       unsigned int queue,
+						       struct
+						       ipu_fw_isys_resp_info_abi
+						       *response);
 void ipu_fw_isys_put_resp(void *context, unsigned int queue);
 #endif
diff --git a/drivers/media/pci/intel/ipu-fw-psys.c b/drivers/media/pci/intel/ipu-fw-psys.c
index 68da73fa5c7a..9ffe8cae1d88 100644
--- a/drivers/media/pci/intel/ipu-fw-psys.c
+++ b/drivers/media/pci/intel/ipu-fw-psys.c
@@ -1,5 +1,5 @@
 // SPDX-License-Identifier: GPL-2.0
-// Copyright (C) 2016 - 2020 Intel Corporation
+// Copyright (C) 2016 - 2018 Intel Corporation
 
 #include <linux/delay.h>
 
@@ -15,65 +15,36 @@ int ipu_fw_psys_pg_start(struct ipu_psys_kcmd *kcmd)
 	return 0;
 }
 
-int ipu_fw_psys_pg_disown(struct ipu_psys_kcmd *kcmd)
+int ipu_fw_psys_pg_load_cycles(struct ipu_psys_kcmd *kcmd)
 {
-	struct ipu_fw_psys_cmd *psys_cmd;
-	int ret = 0;
-
-	psys_cmd = ipu_send_get_token(kcmd->fh->psys->fwcom, 0);
-	if (!psys_cmd) {
-		dev_err(&kcmd->fh->psys->adev->dev,
-			"%s failed to get token!\n", __func__);
-		kcmd->pg_user = NULL;
-		ret = -ENODATA;
-		goto out;
-	}
-	psys_cmd->command = IPU_FW_PSYS_PROCESS_GROUP_CMD_START;
-	psys_cmd->msg = 0;
-	psys_cmd->context_handle = kcmd->kpg->pg->ipu_virtual_address;
-	ipu_send_put_token(kcmd->fh->psys->fwcom, 0);
+	return 0;
+}
 
-out:
-	return ret;
+int ipu_fw_psys_pg_init_cycles(struct ipu_psys_kcmd *kcmd)
+{
+	return 0;
 }
 
-int ipu_fw_psys_ppg_suspend(struct ipu_psys_kcmd *kcmd)
+int ipu_fw_psys_pg_processing_cycles(struct ipu_psys_kcmd *kcmd)
 {
-	struct ipu_fw_psys_cmd *psys_cmd;
-	int ret = 0;
+	return 0;
+}
 
-	/* ppg suspend cmd uses QUEUE_DEVICE_ID instead of QUEUE_COMMAND_ID */
-	psys_cmd = ipu_send_get_token(kcmd->fh->psys->fwcom, 1);
-	if (!psys_cmd) {
-		dev_err(&kcmd->fh->psys->adev->dev,
-			"%s failed to get token!\n", __func__);
-		kcmd->pg_user = NULL;
-		ret = -ENODATA;
-		goto out;
-	}
-	psys_cmd->command = IPU_FW_PSYS_PROCESS_GROUP_CMD_SUSPEND;
-	psys_cmd->msg = 0;
-	psys_cmd->context_handle = kcmd->kpg->pg->ipu_virtual_address;
-	ipu_send_put_token(kcmd->fh->psys->fwcom, 1);
 
-out:
-	return ret;
-}
 
-int ipu_fw_psys_ppg_resume(struct ipu_psys_kcmd *kcmd)
+int ipu_fw_psys_pg_disown(struct ipu_psys_kcmd *kcmd)
 {
 	struct ipu_fw_psys_cmd *psys_cmd;
 	int ret = 0;
 
 	psys_cmd = ipu_send_get_token(kcmd->fh->psys->fwcom, 0);
 	if (!psys_cmd) {
-		dev_err(&kcmd->fh->psys->adev->dev,
-			"%s failed to get token!\n", __func__);
+		dev_err(&kcmd->fh->psys->adev->dev, "failed to get token!\n");
 		kcmd->pg_user = NULL;
 		ret = -ENODATA;
 		goto out;
 	}
-	psys_cmd->command = IPU_FW_PSYS_PROCESS_GROUP_CMD_RESUME;
+	psys_cmd->command = IPU_FW_PSYS_PROCESS_GROUP_CMD_START;
 	psys_cmd->msg = 0;
 	psys_cmd->context_handle = kcmd->kpg->pg->ipu_virtual_address;
 	ipu_send_put_token(kcmd->fh->psys->fwcom, 0);
@@ -82,6 +53,7 @@ int ipu_fw_psys_ppg_resume(struct ipu_psys_kcmd *kcmd)
 	return ret;
 }
 
+
 int ipu_fw_psys_pg_abort(struct ipu_psys_kcmd *kcmd)
 {
 	struct ipu_fw_psys_cmd *psys_cmd;
@@ -89,8 +61,7 @@ int ipu_fw_psys_pg_abort(struct ipu_psys_kcmd *kcmd)
 
 	psys_cmd = ipu_send_get_token(kcmd->fh->psys->fwcom, 0);
 	if (!psys_cmd) {
-		dev_err(&kcmd->fh->psys->adev->dev,
-			"%s failed to get token!\n", __func__);
+		dev_err(&kcmd->fh->psys->adev->dev, "failed to get token!\n");
 		kcmd->pg_user = NULL;
 		ret = -ENODATA;
 		goto out;
@@ -142,7 +113,6 @@ int ipu_fw_psys_terminal_set(struct ipu_fw_psys_terminal *terminal,
 	case IPU_FW_PSYS_TERMINAL_TYPE_PARAM_SLICED_IN:
 	case IPU_FW_PSYS_TERMINAL_TYPE_PARAM_SLICED_OUT:
 	case IPU_FW_PSYS_TERMINAL_TYPE_PROGRAM:
-	case IPU_FW_PSYS_TERMINAL_TYPE_PROGRAM_CONTROL_INIT:
 		buffer_state = IPU_FW_PSYS_BUFFER_UNDEFINED;
 		break;
 	case IPU_FW_PSYS_TERMINAL_TYPE_PARAM_STREAM:
@@ -182,10 +152,72 @@ int ipu_fw_psys_terminal_set(struct ipu_fw_psys_terminal *terminal,
 	return 0;
 }
 
+static int process_get_cell(struct ipu_fw_psys_process *process, int index)
+{
+	int cell;
+
+#if defined(CONFIG_VIDEO_INTEL_IPU4) || defined(CONFIG_VIDEO_INTEL_IPU4P)
+	cell = process->cell_id;
+#else
+	cell = process->cells[index];
+#endif
+	return cell;
+}
+
+static u32 process_get_cells_bitmap(struct ipu_fw_psys_process *process)
+{
+	unsigned int i;
+	int cell_id;
+	u32 bitmap = 0;
+
+	for (i = 0; i < IPU_FW_PSYS_PROCESS_MAX_CELLS; i++) {
+		cell_id = process_get_cell(process, i);
+		if (cell_id != IPU_FW_PSYS_N_CELL_ID)
+			bitmap |= (1 << cell_id);
+	}
+	return bitmap;
+}
+
 void ipu_fw_psys_pg_dump(struct ipu_psys *psys,
 			 struct ipu_psys_kcmd *kcmd, const char *note)
 {
-	ipu6_fw_psys_pg_dump(psys, kcmd, note);
+	struct ipu_fw_psys_process_group *pg = kcmd->kpg->pg;
+	u32 pgid = pg->ID;
+	u8 processes = pg->process_count;
+	u16 *process_offset_table = (u16 *)((char *)pg + pg->processes_offset);
+	unsigned int p, chn, mem, mem_id;
+	int cell;
+
+	dev_dbg(&psys->adev->dev, "%s %s pgid %i has %i processes:\n",
+		__func__, note, pgid, processes);
+
+	for (p = 0; p < processes; p++) {
+		struct ipu_fw_psys_process *process =
+		    (struct ipu_fw_psys_process *)
+		    ((char *)pg + process_offset_table[p]);
+		cell = process_get_cell(process, 0);
+		dev_dbg(&psys->adev->dev, "\t process %i size=%u",
+			p, process->size);
+		dev_dbg(&psys->adev->dev,
+			"\t cell %i cell_bitmap=0x%x kernel_bitmap 0x%llx",
+			cell, process_get_cells_bitmap(process),
+			(u64) process->kernel_bitmap[1] << 32 |
+			(u64) process->kernel_bitmap[0]);
+		for (mem = 0; mem < IPU_FW_PSYS_N_DATA_MEM_TYPE_ID; mem++) {
+			mem_id = process->ext_mem_id[mem];
+			if (mem_id != IPU_FW_PSYS_N_MEM_ID)
+				dev_dbg(&psys->adev->dev,
+					"\t mem type %u id %d offset=0x%x",
+					mem, mem_id,
+					process->ext_mem_offset[mem]);
+		}
+		for (chn = 0; chn < IPU_FW_PSYS_N_DEV_CHN_ID; chn++) {
+			if (process->dev_chn_offset[chn] != (u16)(-1))
+				dev_dbg(&psys->adev->dev,
+					"\t dev_chn[%u]=0x%x\n",
+					chn, process->dev_chn_offset[chn]);
+		}
+	}
 }
 
 int ipu_fw_psys_pg_get_id(struct ipu_psys_kcmd *kcmd)
@@ -239,154 +271,6 @@ int ipu_fw_psys_pg_get_protocol(struct ipu_psys_kcmd *kcmd)
 	return kcmd->kpg->pg->protocol_version;
 }
 
-int ipu_fw_psys_ppg_set_buffer_set(struct ipu_psys_kcmd *kcmd,
-				   struct ipu_fw_psys_terminal *terminal,
-				   int terminal_idx, u32 buffer)
-{
-	u32 type;
-	u32 buffer_state;
-	u32 *buffer_ptr;
-	struct ipu_fw_psys_buffer_set *buf_set = kcmd->kbuf_set->buf_set;
-
-	type = terminal->terminal_type;
-
-	switch (type) {
-	case IPU_FW_PSYS_TERMINAL_TYPE_PARAM_CACHED_IN:
-	case IPU_FW_PSYS_TERMINAL_TYPE_PARAM_CACHED_OUT:
-	case IPU_FW_PSYS_TERMINAL_TYPE_PARAM_SPATIAL_IN:
-	case IPU_FW_PSYS_TERMINAL_TYPE_PARAM_SPATIAL_OUT:
-	case IPU_FW_PSYS_TERMINAL_TYPE_PARAM_SLICED_IN:
-	case IPU_FW_PSYS_TERMINAL_TYPE_PARAM_SLICED_OUT:
-	case IPU_FW_PSYS_TERMINAL_TYPE_PROGRAM:
-	case IPU_FW_PSYS_TERMINAL_TYPE_PROGRAM_CONTROL_INIT:
-		buffer_state = IPU_FW_PSYS_BUFFER_UNDEFINED;
-		break;
-	case IPU_FW_PSYS_TERMINAL_TYPE_PARAM_STREAM:
-	case IPU_FW_PSYS_TERMINAL_TYPE_DATA_IN:
-	case IPU_FW_PSYS_TERMINAL_TYPE_STATE_IN:
-		buffer_state = IPU_FW_PSYS_BUFFER_FULL;
-		break;
-	case IPU_FW_PSYS_TERMINAL_TYPE_DATA_OUT:
-	case IPU_FW_PSYS_TERMINAL_TYPE_STATE_OUT:
-		buffer_state = IPU_FW_PSYS_BUFFER_EMPTY;
-		break;
-	default:
-		dev_err(&kcmd->fh->psys->adev->dev,
-			"unknown terminal type: 0x%x\n", type);
-		return -EAGAIN;
-	}
-
-	buffer_ptr = (u32 *)((char *)buf_set + sizeof(*buf_set) +
-			      terminal_idx * sizeof(*buffer_ptr));
-
-	*buffer_ptr = buffer;
-
-	if (type == IPU_FW_PSYS_TERMINAL_TYPE_DATA_IN ||
-	    type == IPU_FW_PSYS_TERMINAL_TYPE_DATA_OUT) {
-		struct ipu_fw_psys_data_terminal *dterminal =
-		    (struct ipu_fw_psys_data_terminal *)terminal;
-		dterminal->frame.buffer_state = buffer_state;
-	}
-
-	return 0;
-}
-
-size_t ipu_fw_psys_ppg_get_buffer_set_size(struct ipu_psys_kcmd *kcmd)
-{
-	return (sizeof(struct ipu_fw_psys_buffer_set) +
-		kcmd->kpg->pg->terminal_count * sizeof(u32));
-}
-
-int
-ipu_fw_psys_ppg_buffer_set_vaddress(struct ipu_fw_psys_buffer_set *buf_set,
-				    u32 vaddress)
-{
-	buf_set->ipu_virtual_address = vaddress;
-	return 0;
-}
-
-int ipu_fw_psys_ppg_buffer_set_set_kernel_enable_bitmap(
-		struct ipu_fw_psys_buffer_set *buf_set,
-		u32 *kernel_enable_bitmap)
-{
-	memcpy(buf_set->kernel_enable_bitmap, (u8 *)kernel_enable_bitmap,
-	       sizeof(buf_set->kernel_enable_bitmap));
-	return 0;
-}
-
-struct ipu_fw_psys_buffer_set *
-ipu_fw_psys_ppg_create_buffer_set(struct ipu_psys_kcmd *kcmd,
-				  void *kaddr, u32 frame_counter)
-{
-	struct ipu_fw_psys_buffer_set *buffer_set = NULL;
-	unsigned int i;
-
-	buffer_set = (struct ipu_fw_psys_buffer_set *)kaddr;
-
-	/*
-	 * Set base struct members
-	 */
-	buffer_set->ipu_virtual_address = 0;
-	buffer_set->process_group_handle = kcmd->kpg->pg->ipu_virtual_address;
-	buffer_set->frame_counter = frame_counter;
-	buffer_set->terminal_count = kcmd->kpg->pg->terminal_count;
-
-	/*
-	 * Initialize adjacent buffer addresses
-	 */
-	for (i = 0; i < buffer_set->terminal_count; i++) {
-		u32 *buffer =
-		    (u32 *)((char *)buffer_set +
-			     sizeof(*buffer_set) + sizeof(u32) * i);
-
-		*buffer = 0;
-	}
-
-	return buffer_set;
-}
-
-int ipu_fw_psys_ppg_enqueue_bufs(struct ipu_psys_kcmd *kcmd)
-{
-	struct ipu_fw_psys_cmd *psys_cmd;
-	unsigned int queue_id;
-	int ret = 0;
-	unsigned int size;
-
-	if (ipu_ver == IPU_VER_6SE)
-		size = IPU6SE_FW_PSYS_N_PSYS_CMD_QUEUE_ID;
-	else
-		size = IPU6_FW_PSYS_N_PSYS_CMD_QUEUE_ID;
-	queue_id = kcmd->kpg->pg->base_queue_id;
-
-	if (queue_id >= size)
-		return -EINVAL;
-
-	psys_cmd = ipu_send_get_token(kcmd->fh->psys->fwcom, queue_id);
-	if (!psys_cmd) {
-		dev_err(&kcmd->fh->psys->adev->dev,
-			"%s failed to get token!\n", __func__);
-		kcmd->pg_user = NULL;
-		return -ENODATA;
-	}
-
-	psys_cmd->command = IPU_FW_PSYS_PROCESS_GROUP_CMD_RUN;
-	psys_cmd->msg = 0;
-	psys_cmd->context_handle = kcmd->kbuf_set->buf_set->ipu_virtual_address;
-
-	ipu_send_put_token(kcmd->fh->psys->fwcom, queue_id);
-
-	return ret;
-}
-
-u8 ipu_fw_psys_ppg_get_base_queue_id(struct ipu_psys_kcmd *kcmd)
-{
-	return kcmd->kpg->pg->base_queue_id;
-}
-
-void ipu_fw_psys_ppg_set_base_queue_id(struct ipu_psys_kcmd *kcmd, u8 queue_id)
-{
-	kcmd->kpg->pg->base_queue_id = queue_id;
-}
 
 int ipu_fw_psys_open(struct ipu_psys *psys)
 {
diff --git a/drivers/media/pci/intel/ipu-fw-psys.h b/drivers/media/pci/intel/ipu-fw-psys.h
index 912a0986c060..1738f6cec768 100644
--- a/drivers/media/pci/intel/ipu-fw-psys.h
+++ b/drivers/media/pci/intel/ipu-fw-psys.h
@@ -1,19 +1,20 @@
 /* SPDX-License-Identifier: GPL-2.0 */
-/* Copyright (C) 2016 - 2020 Intel Corporation */
+/* Copyright (C) 2016 - 2018 Intel Corporation */
 
 #ifndef IPU_FW_PSYS_H
 #define IPU_FW_PSYS_H
 
-#include "ipu6-platform-resources.h"
-#include "ipu6se-platform-resources.h"
-#include "ipu6ep-platform-resources.h"
+#include "ipu-platform-resources.h"
 
+/* ia_css_psys_device.c */
 #define IPU_FW_PSYS_CMD_QUEUE_SIZE 0x20
 #define IPU_FW_PSYS_EVENT_QUEUE_SIZE 0x40
 
+/* ia_css_psys_transport.h */
 #define IPU_FW_PSYS_CMD_BITS 64
 #define IPU_FW_PSYS_EVENT_BITS 128
 
+/* ia_css_psys_transport.h */
 enum {
 	IPU_FW_PSYS_EVENT_TYPE_SUCCESS = 0,
 	IPU_FW_PSYS_EVENT_TYPE_UNKNOWN_ERROR = 1,
@@ -27,8 +28,7 @@ enum {
 	IPU_FW_PSYS_EVENT_TYPE_PROC_GRP_PROCESS_INIT_ERR = 9,
 	IPU_FW_PSYS_EVENT_TYPE_PROC_GRP_ABORT = 10,
 	IPU_FW_PSYS_EVENT_TYPE_PROC_GRP_NULL = 11,
-	IPU_FW_PSYS_EVENT_TYPE_PROC_GRP_VALIDATION_ERR = 12,
-	IPU_FW_PSYS_EVENT_TYPE_PROC_GRP_INVALID_FRAME = 13
+	IPU_FW_PSYS_EVENT_TYPE_PROC_GRP_VALIDATION_ERR = 12
 };
 
 enum {
@@ -105,23 +105,19 @@ enum {
 
 enum {
 	IPU_FW_PSYS_PROCESS_GROUP_PROTOCOL_LEGACY = 0,
-	IPU_FW_PSYS_PROCESS_GROUP_PROTOCOL_PPG,
 	IPU_FW_PSYS_PROCESS_GROUP_N_PROTOCOLS
 };
 
+/* ia_css_psys_process_group_cmd_impl.h */
 struct __packed ipu_fw_psys_process_group {
 	u64 token;
 	u64 private_token;
 	u32 routing_bitmap[IPU_FW_PSYS_RBM_NOF_ELEMS];
-	u32 kernel_bitmap[IPU_FW_PSYS_KBM_NOF_ELEMS];
 	u32 size;
-	u32 psys_server_init_cycles;
 	u32 pg_load_start_ts;
 	u32 pg_load_cycles;
 	u32 pg_init_cycles;
 	u32 pg_processing_cycles;
-	u32 pg_next_frame_init_cycles;
-	u32 pg_complete_cycles;
 	u32 ID;
 	u32 state;
 	u32 ipu_virtual_address;
@@ -137,11 +133,10 @@ struct __packed ipu_fw_psys_process_group {
 	u8 protocol_version;
 	u8 base_queue_id;
 	u8 num_queues;
-	u8 mask_irq;
-	u8 error_handling_enable;
 	u8 padding[IPU_FW_PSYS_N_PADDING_UINT8_IN_PROCESS_GROUP_STRUCT];
 };
 
+/* ia_css_psys_init.h */
 struct ipu_fw_psys_srv_init {
 	void *host_ddr_pkg_dir;
 	u32 ddr_pkg_dir_address;
@@ -151,6 +146,7 @@ struct ipu_fw_psys_srv_init {
 	u32 icache_prefetch_isp;
 };
 
+/* ia_css_psys_transport.h */
 struct __packed ipu_fw_psys_cmd {
 	u16 command;
 	u16 msg;
@@ -164,6 +160,7 @@ struct __packed ipu_fw_psys_event {
 	u64 token;
 };
 
+/* ia_css_terminal_base_types.h */
 struct ipu_fw_psys_terminal {
 	u32 terminal_type;
 	s16 parent_offset;
@@ -173,12 +170,14 @@ struct ipu_fw_psys_terminal {
 	u8 padding[IPU_FW_PSYS_N_PADDING_UINT8_IN_TERMINAL_STRUCT];
 };
 
+/* ia_css_terminal_types.h */
 struct ipu_fw_psys_param_payload {
 	u64 host_buffer;
 	u32 buffer;
 	u32 terminal_index;
 };
 
+/* ia_css_program_group_param_types.h */
 struct ipu_fw_psys_param_terminal {
 	struct ipu_fw_psys_terminal base;
 	struct ipu_fw_psys_param_payload param_payload;
@@ -197,12 +196,12 @@ struct ipu_fw_psys_frame {
 	u8 padding[IPU_FW_PSYS_N_PADDING_UINT8_IN_FRAME_STRUCT];
 };
 
+/* ia_css_program_group_data.h */
 struct ipu_fw_psys_frame_descriptor {
 	u32 frame_format_type;
 	u32 plane_count;
 	u32 plane_offsets[IPU_FW_PSYS_N_FRAME_PLANES];
 	u32 stride[1];
-	u32 ts_offsets[IPU_FW_PSYS_N_FRAME_PLANES];
 	u16 dimension[2];
 	u16 size;
 	u8 bpp;
@@ -215,6 +214,7 @@ struct ipu_fw_psys_stream {
 	u64 dummy;
 };
 
+/* ia_css_psys_terminal_private_types.h */
 struct ipu_fw_psys_data_terminal {
 	struct ipu_fw_psys_terminal base;
 	struct ipu_fw_psys_frame_descriptor frame_descriptor;
@@ -228,12 +228,10 @@ struct ipu_fw_psys_data_terminal {
 	u8 padding[IPU_FW_PSYS_N_PADDING_UINT8_IN_DATA_TERMINAL_STRUCT];
 };
 
+/* ia_css_psys_buffer_set.h */
 struct ipu_fw_psys_buffer_set {
 	u64 token;
 	u32 kernel_enable_bitmap[IPU_FW_PSYS_KERNEL_BITMAP_NOF_ELEMS];
-	u32 terminal_enable_bitmap[IPU_FW_PSYS_KERNEL_BITMAP_NOF_ELEMS];
-	u32 routing_enable_bitmap[IPU_FW_PSYS_KERNEL_BITMAP_NOF_ELEMS];
-	u32 rbm[IPU_FW_PSYS_RBM_NOF_ELEMS];
 	u32 ipu_virtual_address;
 	u32 process_group_handle;
 	u16 terminal_count;
@@ -270,10 +268,23 @@ struct ipu_fw_generic_program_manifest {
 	u32 *dfm_active_port_bitmap;
 };
 
+struct ipu_fw_generic_process {
+	u16 ext_mem_id;
+	u16 ext_mem_offset;
+	u16 dev_chn_offset;
+	u16 cell_id;
+	u16 dfm_port_bitmap;
+	u16 dfm_active_port_bitmap;
+};
+
 struct ipu_fw_resource_definitions {
 	u32 num_cells;
 	u32 num_cells_type;
+#if defined(CONFIG_VIDEO_INTEL_IPU4) || defined(CONFIG_VIDEO_INTEL_IPU4P)
+	const u32 *cells;
+#else
 	const u8 *cells;
+#endif
 	u32 num_dev_channels;
 	const u16 *dev_channels;
 
@@ -285,37 +296,23 @@ struct ipu_fw_resource_definitions {
 	const u16 *dfms;
 
 	u32 cell_mem_row;
+#if defined(CONFIG_VIDEO_INTEL_IPU4) || defined(CONFIG_VIDEO_INTEL_IPU4P)
+	const enum ipu_mem_id *cell_mem;
+#else
 	const u8 *cell_mem;
+#endif
+	struct ipu_fw_generic_process process;
 };
 
-struct ipu6_psys_hw_res_variant {
-	unsigned int queue_num;
-	unsigned int cell_num;
-	int (*set_proc_dev_chn)(struct ipu_fw_psys_process *ptr, u16 offset,
-				u16 value);
-	int (*set_proc_dfm_bitmap)(struct ipu_fw_psys_process *ptr,
-				   u16 id, u32 bitmap, u32 active_bitmap);
-	int (*set_proc_ext_mem)(struct ipu_fw_psys_process *ptr,
-				u16 type_id, u16 mem_id, u16 offset);
-	int (*get_pgm_by_proc)(struct ipu_fw_generic_program_manifest *gen_pm,
-			       const struct ipu_fw_psys_program_group_manifest
-			       *pg_manifest,
-			       struct ipu_fw_psys_process *process);
-};
 struct ipu_psys_kcmd;
 struct ipu_psys;
 int ipu_fw_psys_pg_start(struct ipu_psys_kcmd *kcmd);
 int ipu_fw_psys_pg_disown(struct ipu_psys_kcmd *kcmd);
 int ipu_fw_psys_pg_abort(struct ipu_psys_kcmd *kcmd);
 int ipu_fw_psys_pg_submit(struct ipu_psys_kcmd *kcmd);
-int ipu_fw_psys_ppg_suspend(struct ipu_psys_kcmd *kcmd);
-int ipu_fw_psys_ppg_resume(struct ipu_psys_kcmd *kcmd);
 int ipu_fw_psys_pg_load_cycles(struct ipu_psys_kcmd *kcmd);
 int ipu_fw_psys_pg_init_cycles(struct ipu_psys_kcmd *kcmd);
 int ipu_fw_psys_pg_processing_cycles(struct ipu_psys_kcmd *kcmd);
-int ipu_fw_psys_pg_server_init_cycles(struct ipu_psys_kcmd *kcmd);
-int ipu_fw_psys_pg_next_frame_init_cycles(struct ipu_psys_kcmd *kcmd);
-int ipu_fw_psys_pg_complete_cycles(struct ipu_psys_kcmd *kcmd);
 int ipu_fw_psys_rcv_event(struct ipu_psys *psys,
 			  struct ipu_fw_psys_event *event);
 int ipu_fw_psys_terminal_set(struct ipu_fw_psys_terminal *terminal,
@@ -333,21 +330,6 @@ struct ipu_fw_psys_terminal *ipu_fw_psys_pg_get_terminal(struct ipu_psys_kcmd
 							 *kcmd, int index);
 void ipu_fw_psys_pg_set_token(struct ipu_psys_kcmd *kcmd, u64 token);
 u64 ipu_fw_psys_pg_get_token(struct ipu_psys_kcmd *kcmd);
-int ipu_fw_psys_ppg_set_buffer_set(struct ipu_psys_kcmd *kcmd,
-				   struct ipu_fw_psys_terminal *terminal,
-				   int terminal_idx, u32 buffer);
-size_t ipu_fw_psys_ppg_get_buffer_set_size(struct ipu_psys_kcmd *kcmd);
-int
-ipu_fw_psys_ppg_buffer_set_vaddress(struct ipu_fw_psys_buffer_set *buf_set,
-				    u32 vaddress);
-int ipu_fw_psys_ppg_buffer_set_set_kernel_enable_bitmap(
-	struct ipu_fw_psys_buffer_set *buf_set, u32 *kernel_enable_bitmap);
-struct ipu_fw_psys_buffer_set *
-ipu_fw_psys_ppg_create_buffer_set(struct ipu_psys_kcmd *kcmd,
-				  void *kaddr, u32 frame_counter);
-int ipu_fw_psys_ppg_enqueue_bufs(struct ipu_psys_kcmd *kcmd);
-u8 ipu_fw_psys_ppg_get_base_queue_id(struct ipu_psys_kcmd *kcmd);
-void ipu_fw_psys_ppg_set_base_queue_id(struct ipu_psys_kcmd *kcmd, u8 queue_id);
 int ipu_fw_psys_pg_get_protocol(struct ipu_psys_kcmd *kcmd);
 int ipu_fw_psys_open(struct ipu_psys *psys);
 int ipu_fw_psys_close(struct ipu_psys *psys);
@@ -357,26 +339,12 @@ int ipu_fw_psys_set_process_cell_id(struct ipu_fw_psys_process *ptr, u8 index,
 				    u8 value);
 u8 ipu_fw_psys_get_process_cell_id(struct ipu_fw_psys_process *ptr, u8 index);
 int ipu_fw_psys_clear_process_cell(struct ipu_fw_psys_process *ptr);
-int ipu_fw_psys_set_proc_dev_chn(struct ipu_fw_psys_process *ptr, u16 offset,
-				 u16 value);
+int ipu_fw_psys_set_process_dev_chn_offset(struct ipu_fw_psys_process *ptr,
+					   u16 offset, u16 value);
 int ipu_fw_psys_set_process_ext_mem(struct ipu_fw_psys_process *ptr,
 				    u16 type_id, u16 mem_id, u16 offset);
 int ipu_fw_psys_get_program_manifest_by_process(
 	struct ipu_fw_generic_program_manifest *gen_pm,
 	const struct ipu_fw_psys_program_group_manifest *pg_manifest,
 	struct ipu_fw_psys_process *process);
-int ipu6_fw_psys_set_proc_dev_chn(struct ipu_fw_psys_process *ptr, u16 offset,
-				  u16 value);
-int ipu6_fw_psys_set_proc_dfm_bitmap(struct ipu_fw_psys_process *ptr,
-				     u16 id, u32 bitmap,
-				     u32 active_bitmap);
-int ipu6_fw_psys_set_process_ext_mem(struct ipu_fw_psys_process *ptr,
-				     u16 type_id, u16 mem_id, u16 offset);
-int ipu6_fw_psys_get_program_manifest_by_process(
-	struct ipu_fw_generic_program_manifest *gen_pm,
-	const struct ipu_fw_psys_program_group_manifest *pg_manifest,
-	struct ipu_fw_psys_process *process);
-void ipu6_fw_psys_pg_dump(struct ipu_psys *psys,
-			  struct ipu_psys_kcmd *kcmd, const char *note);
-void ipu6_psys_hw_res_variant_init(void);
 #endif /* IPU_FW_PSYS_H */
diff --git a/drivers/media/pci/intel/ipu-isys-csi2-be-soc.c b/drivers/media/pci/intel/ipu-isys-csi2-be-soc.c
index 7072500d930a..9253f9f1e505 100644
--- a/drivers/media/pci/intel/ipu-isys-csi2-be-soc.c
+++ b/drivers/media/pci/intel/ipu-isys-csi2-be-soc.c
@@ -1,5 +1,5 @@
 // SPDX-License-Identifier: GPL-2.0
-// Copyright (C) 2014 - 2021 Intel Corporation
+// Copyright (C) 2014 - 2018 Intel Corporation
 
 #include <linux/device.h>
 #include <linux/module.h>
@@ -23,8 +23,14 @@ static const u32 csi2_be_soc_supported_codes_pad[] = {
 	MEDIA_BUS_FMT_Y10_1X10,
 	MEDIA_BUS_FMT_RGB565_1X16,
 	MEDIA_BUS_FMT_RGB888_1X24,
+	/* YUV420 plannar */
+	MEDIA_BUS_FMT_UYVY8_2X8,
 	MEDIA_BUS_FMT_UYVY8_1X16,
 	MEDIA_BUS_FMT_YUYV8_1X16,
+	MEDIA_BUS_FMT_SBGGR14_1X14,
+	MEDIA_BUS_FMT_SGBRG14_1X14,
+	MEDIA_BUS_FMT_SGRBG14_1X14,
+	MEDIA_BUS_FMT_SRGGB14_1X14,
 	MEDIA_BUS_FMT_SBGGR12_1X12,
 	MEDIA_BUS_FMT_SGBRG12_1X12,
 	MEDIA_BUS_FMT_SGRBG12_1X12,
@@ -40,37 +46,6 @@ static const u32 csi2_be_soc_supported_codes_pad[] = {
 	0,
 };
 
-/*
- * Raw bayer format pixel order MUST BE MAINTAINED in groups of four codes.
- * Otherwise pixel order calculation below WILL BREAK!
- */
-static const u32 csi2_be_soc_supported_raw_bayer_codes_pad[] = {
-	MEDIA_BUS_FMT_SBGGR12_1X12,
-	MEDIA_BUS_FMT_SGBRG12_1X12,
-	MEDIA_BUS_FMT_SGRBG12_1X12,
-	MEDIA_BUS_FMT_SRGGB12_1X12,
-	MEDIA_BUS_FMT_SBGGR10_1X10,
-	MEDIA_BUS_FMT_SGBRG10_1X10,
-	MEDIA_BUS_FMT_SGRBG10_1X10,
-	MEDIA_BUS_FMT_SRGGB10_1X10,
-	MEDIA_BUS_FMT_SBGGR8_1X8,
-	MEDIA_BUS_FMT_SGBRG8_1X8,
-	MEDIA_BUS_FMT_SGRBG8_1X8,
-	MEDIA_BUS_FMT_SRGGB8_1X8,
-	0,
-};
-
-static int get_supported_code_index(u32 code)
-{
-	int i;
-
-	for (i = 0; csi2_be_soc_supported_raw_bayer_codes_pad[i]; i++) {
-		if (csi2_be_soc_supported_raw_bayer_codes_pad[i] == code)
-			return i;
-	}
-	return -EINVAL;
-}
-
 static const u32 *csi2_be_soc_supported_codes[NR_OF_CSI2_BE_SOC_PADS];
 
 static struct v4l2_subdev_internal_ops csi2_be_soc_sd_internal_ops = {
@@ -81,17 +56,6 @@ static struct v4l2_subdev_internal_ops csi2_be_soc_sd_internal_ops = {
 static const struct v4l2_subdev_core_ops csi2_be_soc_sd_core_ops = {
 };
 
-static const struct v4l2_ctrl_config compression_ctrl_cfg = {
-	.ops = NULL,
-	.id = V4L2_CID_IPU_ISYS_COMPRESSION,
-	.name = "ISYS BE-SOC compression",
-	.type = V4L2_CTRL_TYPE_BOOLEAN,
-	.min = 0,
-	.max = 1,
-	.step = 1,
-	.def = 0,
-};
-
 static int set_stream(struct v4l2_subdev *sd, int enable)
 {
 	return 0;
@@ -116,7 +80,7 @@ __subdev_link_validate(struct v4l2_subdev *sd, struct media_link *link,
 
 static int
 ipu_isys_csi2_be_soc_set_sel(struct v4l2_subdev *sd,
-			     struct v4l2_subdev_state *sd_state,
+			     struct v4l2_subdev_state *state,
 			     struct v4l2_subdev_selection *sel)
 {
 	struct ipu_isys_subdev *asd = to_ipu_isys_subdev(sd);
@@ -125,27 +89,41 @@ ipu_isys_csi2_be_soc_set_sel(struct v4l2_subdev *sd,
 	if (sel->target == V4L2_SEL_TGT_CROP &&
 	    pad->flags & MEDIA_PAD_FL_SOURCE &&
 	    asd->valid_tgts[sel->pad].crop) {
-		enum isys_subdev_prop_tgt tgt =
-		    IPU_ISYS_SUBDEV_PROP_TGT_SOURCE_CROP;
-		struct v4l2_mbus_framefmt *ffmt =
-			__ipu_isys_get_ffmt(sd, sd_state, sel->pad, sel->which);
-
-		if (get_supported_code_index(ffmt->code) < 0) {
-			/* Non-bayer formats can't be odd lines cropped */
-			sel->r.left &= ~1;
-			sel->r.top &= ~1;
+		struct v4l2_rect *r;
+		unsigned int sink_pad = 0;
+		int i;
+
+		for (i = 0; i < asd->nstreams; i++) {
+			if (!(asd->route[i].flags &
+			      V4L2_SUBDEV_ROUTE_FL_ACTIVE))
+				continue;
+			if (asd->route[i].source == sel->pad) {
+				sink_pad = asd->route[i].sink;
+				break;
+			}
 		}
 
-		sel->r.width = clamp(sel->r.width, IPU_ISYS_MIN_WIDTH,
+		if (i == asd->nstreams) {
+			dev_dbg(&asd->isys->adev->dev, "No sink pad routed.\n");
+			return -EINVAL;
+		}
+		r = __ipu_isys_get_selection(sd, state, sel->target,
+					     sink_pad, sel->which);
+
+		/* Cropping is not supported by SoC BE.
+		 * Only horizontal padding is allowed.
+		 */
+		sel->r.top = r->top;
+		sel->r.left = r->left;
+		sel->r.width = clamp(sel->r.width, r->width,
 				     IPU_ISYS_MAX_WIDTH);
+		sel->r.height = r->height;
 
-		sel->r.height = clamp(sel->r.height, IPU_ISYS_MIN_HEIGHT,
-				      IPU_ISYS_MAX_HEIGHT);
-
-		*__ipu_isys_get_selection(sd, sd_state, sel->target, sel->pad,
+		*__ipu_isys_get_selection(sd, state, sel->target, sel->pad,
 					  sel->which) = sel->r;
-		ipu_isys_subdev_fmt_propagate(sd, sd_state, NULL, &sel->r,
-					      tgt, sel->pad, sel->which);
+		ipu_isys_subdev_fmt_propagate(sd, state, NULL, &sel->r,
+					IPU_ISYS_SUBDEV_PROP_TGT_SOURCE_CROP,
+					sel->pad, sel->which);
 		return 0;
 	}
 	return -EINVAL;
@@ -158,6 +136,8 @@ static const struct v4l2_subdev_pad_ops csi2_be_soc_sd_pad_ops = {
 	.get_selection = ipu_isys_subdev_get_sel,
 	.set_selection = ipu_isys_csi2_be_soc_set_sel,
 	.enum_mbus_code = ipu_isys_subdev_enum_mbus_code,
+	.set_routing = ipu_isys_subdev_set_routing,
+	.get_routing = ipu_isys_subdev_get_routing,
 };
 
 static struct v4l2_subdev_ops csi2_be_soc_sd_ops = {
@@ -168,71 +148,98 @@ static struct v4l2_subdev_ops csi2_be_soc_sd_ops = {
 
 static struct media_entity_operations csi2_be_soc_entity_ops = {
 	.link_validate = v4l2_subdev_link_validate,
+	.has_route = ipu_isys_subdev_has_route,
 };
 
 static void csi2_be_soc_set_ffmt(struct v4l2_subdev *sd,
-				 struct v4l2_subdev_state *sd_state,
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 1, 0)
+				 struct v4l2_subdev_fh *cfg,
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(5, 14, 0)
+				 struct v4l2_subdev_pad_config *cfg,
+#else
+		 struct v4l2_subdev_state *cfg,
+#endif
 				 struct v4l2_subdev_format *fmt)
 {
 	struct v4l2_mbus_framefmt *ffmt =
-		__ipu_isys_get_ffmt(sd, sd_state, fmt->pad,
+		__ipu_isys_get_ffmt(sd, cfg, fmt->pad,
+				    fmt->stream,
 				    fmt->which);
 
+#if !defined(CONFIG_VIDEO_INTEL_IPU4) && !defined(CONFIG_VIDEO_INTEL_IPU4P)
+			struct ipu_isys_csi2_be_soc *csi2_be_soc =
+						to_ipu_isys_csi2_be_soc(sd);
+#endif
+
 	if (sd->entity.pads[fmt->pad].flags & MEDIA_PAD_FL_SINK) {
 		if (fmt->format.field != V4L2_FIELD_ALTERNATE)
 			fmt->format.field = V4L2_FIELD_NONE;
 		*ffmt = fmt->format;
 
-		ipu_isys_subdev_fmt_propagate(sd, sd_state, &fmt->format,
+		ipu_isys_subdev_fmt_propagate(sd, cfg, &fmt->format,
 					      NULL,
 					      IPU_ISYS_SUBDEV_PROP_TGT_SINK_FMT,
 					      fmt->pad, fmt->which);
 	} else if (sd->entity.pads[fmt->pad].flags & MEDIA_PAD_FL_SOURCE) {
 		struct v4l2_mbus_framefmt *sink_ffmt;
-		struct v4l2_rect *r = __ipu_isys_get_selection(sd, sd_state,
-			V4L2_SEL_TGT_CROP, fmt->pad, fmt->which);
+		struct v4l2_rect *r;
 		struct ipu_isys_subdev *asd = to_ipu_isys_subdev(sd);
-		u32 code;
-		int idx;
-
-		sink_ffmt = __ipu_isys_get_ffmt(sd, sd_state, 0, fmt->which);
-		code = sink_ffmt->code;
-		idx = get_supported_code_index(code);
-
-		if (asd->valid_tgts[fmt->pad].crop && idx >= 0) {
-			int crop_info = 0;
+		unsigned int sink_pad = 0;
+		int i;
+
+		for (i = 0; i < asd->nsinks; i++)
+			if (media_entity_has_route(&sd->entity, fmt->pad, i))
+				break;
+		if (i != asd->nsinks)
+			sink_pad = i;
+		sink_ffmt = __ipu_isys_get_ffmt(sd, cfg, sink_pad,
+						fmt->stream,
+						fmt->which);
+		r = __ipu_isys_get_selection(sd, cfg, V4L2_SEL_TGT_CROP,
+					     fmt->pad, fmt->which);
 
-			/* Only croping odd line at top side. */
-			if (r->top & 1)
-				crop_info |= CSI2_BE_CROP_VER;
-
-			code = csi2_be_soc_supported_raw_bayer_codes_pad
-				[((idx & CSI2_BE_CROP_MASK) ^ crop_info)
-				+ (idx & ~CSI2_BE_CROP_MASK)];
-
-		}
-		ffmt->code = code;
 		ffmt->width = r->width;
 		ffmt->height = r->height;
+		ffmt->code = sink_ffmt->code;
 		ffmt->field = sink_ffmt->field;
 
+#if !defined(CONFIG_VIDEO_INTEL_IPU4) && !defined(CONFIG_VIDEO_INTEL_IPU4P)
+		/*
+		 * For new IPU special case, format changing in BE-SOC,
+		 * from YUV422 to I420, which is used to adapt multiple
+		 * YUV sensors and provide I420 to BB for partial processing.
+		 * Use original source pad format from user space.
+		 * And change pin type to RAW_DUAL_SOC for this special case
+		 */
+		if (fmt->format.code == MEDIA_BUS_FMT_UYVY8_2X8 &&
+			(sink_ffmt->code == MEDIA_BUS_FMT_YUYV8_1X16 ||
+			sink_ffmt->code == MEDIA_BUS_FMT_UYVY8_1X16)) {
+			ffmt->code = fmt->format.code;
+
+			for (i = 0; i < NR_OF_CSI2_BE_SOC_SOURCE_PADS; i++)
+				csi2_be_soc->av[i].aq.css_pin_type =
+					IPU_FW_ISYS_PIN_TYPE_RAW_DUAL_SOC;
+		}
+#endif
 	}
 }
 
 void ipu_isys_csi2_be_soc_cleanup(struct ipu_isys_csi2_be_soc *csi2_be_soc)
 {
+	int i;
+
 	v4l2_device_unregister_subdev(&csi2_be_soc->asd.sd);
 	ipu_isys_subdev_cleanup(&csi2_be_soc->asd);
-	v4l2_ctrl_handler_free(&csi2_be_soc->av.ctrl_handler);
-	ipu_isys_video_cleanup(&csi2_be_soc->av);
+	for (i = 0; i < NR_OF_CSI2_BE_SOC_STREAMS; i++)
+		ipu_isys_video_cleanup(&csi2_be_soc->av[i]);
 }
 
 int ipu_isys_csi2_be_soc_init(struct ipu_isys_csi2_be_soc *csi2_be_soc,
-			      struct ipu_isys *isys, int index)
+			      struct ipu_isys *isys)
 {
 	struct v4l2_subdev_format fmt = {
 		.which = V4L2_SUBDEV_FORMAT_ACTIVE,
-		.pad = CSI2_BE_SOC_PAD_SINK,
+		.pad = CSI2_BE_SOC_PAD_SINK(0),
 		.format = {
 			   .width = 4096,
 			   .height = 3072,
@@ -246,15 +253,21 @@ int ipu_isys_csi2_be_soc_init(struct ipu_isys_csi2_be_soc *csi2_be_soc,
 	rval = ipu_isys_subdev_init(&csi2_be_soc->asd,
 				    &csi2_be_soc_sd_ops, 0,
 				    NR_OF_CSI2_BE_SOC_PADS,
+				    NR_OF_CSI2_BE_SOC_STREAMS,
 				    NR_OF_CSI2_BE_SOC_SOURCE_PADS,
 				    NR_OF_CSI2_BE_SOC_SINK_PADS, 0);
 	if (rval)
 		goto fail;
 
-	csi2_be_soc->asd.pad[CSI2_BE_SOC_PAD_SINK].flags = MEDIA_PAD_FL_SINK;
-	csi2_be_soc->asd.pad[CSI2_BE_SOC_PAD_SOURCE].flags =
-		MEDIA_PAD_FL_SOURCE;
-	csi2_be_soc->asd.valid_tgts[CSI2_BE_SOC_PAD_SOURCE].crop = true;
+	for (i = CSI2_BE_SOC_PAD_SINK(0); i < NR_OF_CSI2_BE_SOC_SINK_PADS; i++)
+		csi2_be_soc->asd.pad[i].flags = MEDIA_PAD_FL_SINK;
+
+	for (i = CSI2_BE_SOC_PAD_SOURCE(0);
+	     i < NR_OF_CSI2_BE_SOC_SOURCE_PADS + CSI2_BE_SOC_PAD_SOURCE(0);
+	     i++) {
+		csi2_be_soc->asd.pad[i].flags = MEDIA_PAD_FL_SOURCE;
+		csi2_be_soc->asd.valid_tgts[i].crop = true;
+	}
 
 	for (i = 0; i < NR_OF_CSI2_BE_SOC_PADS; i++)
 		csi2_be_soc_supported_codes[i] =
@@ -264,16 +277,21 @@ int ipu_isys_csi2_be_soc_init(struct ipu_isys_csi2_be_soc *csi2_be_soc,
 	csi2_be_soc->asd.isl_mode = IPU_ISL_OFF;
 	csi2_be_soc->asd.set_ffmt = csi2_be_soc_set_ffmt;
 
-	fmt.pad = CSI2_BE_SOC_PAD_SINK;
-	ipu_isys_subdev_set_ffmt(&csi2_be_soc->asd.sd, NULL, &fmt);
-	fmt.pad = CSI2_BE_SOC_PAD_SOURCE;
+	for (i = CSI2_BE_SOC_PAD_SINK(0); i < NR_OF_CSI2_BE_SOC_SINK_PADS;
+	     i++) {
+		fmt.pad = CSI2_BE_SOC_PAD_SINK(i);
+		ipu_isys_subdev_set_ffmt(&csi2_be_soc->asd.sd, NULL, &fmt);
+	}
+
 	ipu_isys_subdev_set_ffmt(&csi2_be_soc->asd.sd, NULL, &fmt);
 	csi2_be_soc->asd.sd.internal_ops = &csi2_be_soc_sd_internal_ops;
 
 	snprintf(csi2_be_soc->asd.sd.name, sizeof(csi2_be_soc->asd.sd.name),
-		 IPU_ISYS_ENTITY_PREFIX " CSI2 BE SOC %d", index);
+		 IPU_ISYS_ENTITY_PREFIX " CSI2 BE SOC");
+
 	v4l2_set_subdevdata(&csi2_be_soc->asd.sd, &csi2_be_soc->asd);
 
+	mutex_lock(&csi2_be_soc->asd.mutex);
 	rval = v4l2_device_register_subdev(&isys->v4l2_dev,
 					   &csi2_be_soc->asd.sd);
 	if (rval) {
@@ -281,55 +299,62 @@ int ipu_isys_csi2_be_soc_init(struct ipu_isys_csi2_be_soc *csi2_be_soc,
 		goto fail;
 	}
 
-	snprintf(csi2_be_soc->av.vdev.name, sizeof(csi2_be_soc->av.vdev.name),
-		 IPU_ISYS_ENTITY_PREFIX " BE SOC capture %d", index);
-
-	/*
-	 * Pin type could be overwritten for YUV422 to I420 case, at
-	 * set_format phase
-	 */
-	csi2_be_soc->av.aq.css_pin_type = IPU_FW_ISYS_PIN_TYPE_RAW_SOC;
-	csi2_be_soc->av.isys = isys;
-	csi2_be_soc->av.pfmts = ipu_isys_pfmts_be_soc;
-	csi2_be_soc->av.try_fmt_vid_mplane =
-		ipu_isys_video_try_fmt_vid_mplane_default;
-	csi2_be_soc->av.prepare_fw_stream =
-		ipu_isys_prepare_fw_cfg_default;
-	csi2_be_soc->av.aq.buf_prepare = ipu_isys_buf_prepare;
-	csi2_be_soc->av.aq.fill_frame_buff_set_pin =
-		ipu_isys_buffer_to_fw_frame_buff_pin;
-	csi2_be_soc->av.aq.link_fmt_validate = ipu_isys_link_fmt_validate;
-	csi2_be_soc->av.aq.vbq.buf_struct_size =
-		sizeof(struct ipu_isys_video_buffer);
-
-	/* create v4l2 ctrl for be-soc video node */
-	rval = v4l2_ctrl_handler_init(&csi2_be_soc->av.ctrl_handler, 0);
-	if (rval) {
-		dev_err(&isys->adev->dev,
-			"failed to init v4l2 ctrl handler for be_soc\n");
-		goto fail;
+	/* create default route information */
+	for (i = 0; i < NR_OF_CSI2_BE_SOC_STREAMS; i++) {
+		csi2_be_soc->asd.route[i].sink = CSI2_BE_SOC_PAD_SINK(i);
+		csi2_be_soc->asd.route[i].source = CSI2_BE_SOC_PAD_SOURCE(i);
+		csi2_be_soc->asd.route[i].flags = 0;
 	}
 
-	csi2_be_soc->av.compression_ctrl =
-		v4l2_ctrl_new_custom(&csi2_be_soc->av.ctrl_handler,
-				     &compression_ctrl_cfg, NULL);
-	if (!csi2_be_soc->av.compression_ctrl) {
-		dev_err(&isys->adev->dev,
-			"failed to create BE-SOC cmprs ctrl\n");
-		goto fail;
+	for (i = 0; i < NR_OF_CSI2_BE_SOC_SOURCE_PADS; i++) {
+		csi2_be_soc->asd.stream[CSI2_BE_SOC_PAD_SINK(i)].stream_id[0]
+		    = 0;
+		csi2_be_soc->asd.stream[CSI2_BE_SOC_PAD_SOURCE(i)].stream_id[0]
+		    = 0;
 	}
-	csi2_be_soc->av.compression = 0;
-	csi2_be_soc->av.vdev.ctrl_handler =
-		&csi2_be_soc->av.ctrl_handler;
-
-	rval = ipu_isys_video_init(&csi2_be_soc->av,
-				   &csi2_be_soc->asd.sd.entity,
-				   CSI2_BE_SOC_PAD_SOURCE,
-				   MEDIA_PAD_FL_SINK,
-				   MEDIA_LNK_FL_DYNAMIC);
-	if (rval) {
-		dev_info(&isys->adev->dev, "can't init video node\n");
-		goto fail;
+	for (i = 0; i < NR_OF_CSI2_BE_SOC_STREAMS; i++) {
+		csi2_be_soc->asd.route[i].flags = V4L2_SUBDEV_ROUTE_FL_ACTIVE;
+		bitmap_set(csi2_be_soc->asd.stream[CSI2_BE_SOC_PAD_SINK(i)].
+			   streams_stat, 0, 1);
+		bitmap_set(csi2_be_soc->asd.stream[CSI2_BE_SOC_PAD_SOURCE(i)].
+			   streams_stat, 0, 1);
+	}
+	csi2_be_soc->asd.route[0].flags |= V4L2_SUBDEV_ROUTE_FL_IMMUTABLE;
+	mutex_unlock(&csi2_be_soc->asd.mutex);
+	for (i = 0; i < NR_OF_CSI2_BE_SOC_SOURCE_PADS; i++) {
+		snprintf(csi2_be_soc->av[i].vdev.name,
+			 sizeof(csi2_be_soc->av[i].vdev.name),
+			 IPU_ISYS_ENTITY_PREFIX " BE SOC capture %d", i);
+		/*
+		 * Pin type could be overwritten for YUV422 to I420 case, at
+		 * set_format phase
+		 */
+		csi2_be_soc->av[i].aq.css_pin_type =
+			IPU_FW_ISYS_PIN_TYPE_RAW_SOC;
+		csi2_be_soc->av[i].isys = isys;
+		csi2_be_soc->av[i].pfmts = ipu_isys_pfmts_be_soc;
+
+		csi2_be_soc->av[i].try_fmt_vid_mplane =
+		    ipu_isys_video_try_fmt_vid_mplane_default;
+		csi2_be_soc->av[i].prepare_firmware_stream_cfg =
+		    ipu_isys_prepare_firmware_stream_cfg_default;
+		csi2_be_soc->av[i].aq.buf_prepare = ipu_isys_buf_prepare;
+		csi2_be_soc->av[i].aq.fill_frame_buff_set_pin =
+		    ipu_isys_buffer_list_to_ipu_fw_isys_frame_buff_set_pin;
+		csi2_be_soc->av[i].aq.link_fmt_validate =
+		    ipu_isys_link_fmt_validate;
+		csi2_be_soc->av[i].aq.vbq.buf_struct_size =
+		    sizeof(struct ipu_isys_video_buffer);
+
+		rval = ipu_isys_video_init(&csi2_be_soc->av[i],
+					   &csi2_be_soc->asd.sd.entity,
+					   CSI2_BE_SOC_PAD_SOURCE(i),
+					   MEDIA_PAD_FL_SINK,
+					   MEDIA_LNK_FL_DYNAMIC);
+		if (rval) {
+			dev_info(&isys->adev->dev, "can't init video node\n");
+			goto fail;
+		}
 	}
 
 	return 0;
diff --git a/drivers/media/pci/intel/ipu-isys-csi2-be.c b/drivers/media/pci/intel/ipu-isys-csi2-be.c
index 1ef87fe3dee8..019de72a4390 100644
--- a/drivers/media/pci/intel/ipu-isys-csi2-be.c
+++ b/drivers/media/pci/intel/ipu-isys-csi2-be.c
@@ -1,5 +1,5 @@
 // SPDX-License-Identifier: GPL-2.0
-// Copyright (C) 2014 - 2020 Intel Corporation
+// Copyright (C) 2014 - 2018 Intel Corporation
 
 #include <linux/device.h>
 #include <linux/module.h>
@@ -20,6 +20,10 @@
  * Otherwise pixel order calculation below WILL BREAK!
  */
 static const u32 csi2_be_supported_codes_pad[] = {
+	MEDIA_BUS_FMT_SBGGR14_1X14,
+	MEDIA_BUS_FMT_SGBRG14_1X14,
+	MEDIA_BUS_FMT_SGRBG14_1X14,
+	MEDIA_BUS_FMT_SRGGB14_1X14,
 	MEDIA_BUS_FMT_SBGGR12_1X12,
 	MEDIA_BUS_FMT_SGBRG12_1X12,
 	MEDIA_BUS_FMT_SGRBG12_1X12,
@@ -48,17 +52,6 @@ static struct v4l2_subdev_internal_ops csi2_be_sd_internal_ops = {
 static const struct v4l2_subdev_core_ops csi2_be_sd_core_ops = {
 };
 
-static const struct v4l2_ctrl_config compression_ctrl_cfg = {
-	.ops = NULL,
-	.id = V4L2_CID_IPU_ISYS_COMPRESSION,
-	.name = "ISYS CSI-BE compression",
-	.type = V4L2_CTRL_TYPE_BOOLEAN,
-	.min = 0,
-	.max = 1,
-	.step = 1,
-	.def = 0,
-};
-
 static int set_stream(struct v4l2_subdev *sd, int enable)
 {
 	return 0;
@@ -93,7 +86,7 @@ static int get_supported_code_index(u32 code)
 }
 
 static int ipu_isys_csi2_be_set_sel(struct v4l2_subdev *sd,
-				    struct v4l2_subdev_state *sd_state,
+				    struct v4l2_subdev_state *state,
 				    struct v4l2_subdev_selection *sel)
 {
 	struct ipu_isys_subdev *asd = to_ipu_isys_subdev(sd);
@@ -103,9 +96,9 @@ static int ipu_isys_csi2_be_set_sel(struct v4l2_subdev *sd,
 	    pad->flags & MEDIA_PAD_FL_SOURCE &&
 	    asd->valid_tgts[CSI2_BE_PAD_SOURCE].crop) {
 		struct v4l2_mbus_framefmt *ffmt =
-			__ipu_isys_get_ffmt(sd, sd_state, sel->pad, sel->which);
+			__ipu_isys_get_ffmt(sd, state, sel->pad, 0, sel->which);
 		struct v4l2_rect *r = __ipu_isys_get_selection
-		    (sd, sd_state, sel->target, CSI2_BE_PAD_SINK, sel->which);
+		    (sd, state, sel->target, CSI2_BE_PAD_SINK, sel->which);
 
 		if (get_supported_code_index(ffmt->code) < 0) {
 			/* Non-bayer formats can't be single line cropped */
@@ -122,20 +115,20 @@ static int ipu_isys_csi2_be_set_sel(struct v4l2_subdev *sd,
 		}
 
 		/*
-		 * Vertical padding is not supported, height is
+		 * ISAPF can pad only horizontally, height is
 		 * restricted by sink pad resolution.
 		 */
 		sel->r.height = clamp(sel->r.height, IPU_ISYS_MIN_HEIGHT,
 				      r->height);
-		*__ipu_isys_get_selection(sd, sd_state, sel->target,
-					sel->pad, sel->which) = sel->r;
+		*__ipu_isys_get_selection(sd, state, sel->target, sel->pad,
+					  sel->which) = sel->r;
 		ipu_isys_subdev_fmt_propagate
-		    (sd, sd_state, NULL, &sel->r,
+		    (sd, state, NULL, &sel->r,
 		     IPU_ISYS_SUBDEV_PROP_TGT_SOURCE_CROP,
 		     sel->pad, sel->which);
 		return 0;
 	}
-	return ipu_isys_subdev_set_sel(sd, sd_state, sel);
+	return ipu_isys_subdev_set_sel(sd, state, sel);
 }
 
 static const struct v4l2_subdev_pad_ops csi2_be_sd_pad_ops = {
@@ -157,13 +150,20 @@ static struct media_entity_operations csi2_be_entity_ops = {
 	.link_validate = v4l2_subdev_link_validate,
 };
 
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 1, 0)
+static void csi2_be_set_ffmt(struct v4l2_subdev *sd,
+			     struct v4l2_subdev_fh *cfg,
+			     struct v4l2_subdev_format *fmt)
+#else
 static void csi2_be_set_ffmt(struct v4l2_subdev *sd,
-			     struct v4l2_subdev_state *sd_state,
+			     struct v4l2_subdev_state *state,
 			     struct v4l2_subdev_format *fmt)
+#endif
 {
 	struct ipu_isys_csi2 *csi2 = to_ipu_isys_csi2(sd);
 	struct v4l2_mbus_framefmt *ffmt =
-		__ipu_isys_get_ffmt(sd, sd_state, fmt->pad, fmt->which);
+		__ipu_isys_get_ffmt(sd, state, fmt->pad, fmt->stream,
+				    fmt->which);
 
 	switch (fmt->pad) {
 	case CSI2_BE_PAD_SINK:
@@ -172,15 +172,15 @@ static void csi2_be_set_ffmt(struct v4l2_subdev *sd,
 		*ffmt = fmt->format;
 
 		ipu_isys_subdev_fmt_propagate
-		    (sd, sd_state, &fmt->format, NULL,
+		    (sd, state, &fmt->format, NULL,
 		     IPU_ISYS_SUBDEV_PROP_TGT_SINK_FMT, fmt->pad, fmt->which);
 		return;
 	case CSI2_BE_PAD_SOURCE: {
 		struct v4l2_mbus_framefmt *sink_ffmt =
-			__ipu_isys_get_ffmt(sd, sd_state, CSI2_BE_PAD_SINK,
-					    fmt->which);
+			__ipu_isys_get_ffmt(sd, state, CSI2_BE_PAD_SINK,
+					    fmt->stream, fmt->which);
 		struct v4l2_rect *r =
-			__ipu_isys_get_selection(sd, sd_state, V4L2_SEL_TGT_CROP,
+			__ipu_isys_get_selection(sd, state, V4L2_SEL_TGT_CROP,
 						 CSI2_BE_PAD_SOURCE,
 						 fmt->which);
 		struct ipu_isys_subdev *asd = to_ipu_isys_subdev(sd);
@@ -212,7 +212,6 @@ static void csi2_be_set_ffmt(struct v4l2_subdev *sd,
 
 void ipu_isys_csi2_be_cleanup(struct ipu_isys_csi2_be *csi2_be)
 {
-	v4l2_ctrl_handler_free(&csi2_be->av.ctrl_handler);
 	v4l2_device_unregister_subdev(&csi2_be->asd.sd);
 	ipu_isys_subdev_cleanup(&csi2_be->asd);
 	ipu_isys_video_cleanup(&csi2_be->av);
@@ -245,6 +244,7 @@ int ipu_isys_csi2_be_init(struct ipu_isys_csi2_be *csi2_be,
 
 	rval = ipu_isys_subdev_init(&csi2_be->asd, &csi2_be_sd_ops, 0,
 				    NR_OF_CSI2_BE_PADS,
+				    NR_OF_CSI2_BE_STREAMS,
 				    NR_OF_CSI2_BE_SOURCE_PADS,
 				    NR_OF_CSI2_BE_SINK_PADS, 0);
 	if (rval)
@@ -281,34 +281,15 @@ int ipu_isys_csi2_be_init(struct ipu_isys_csi2_be *csi2_be,
 	csi2_be->av.pfmts = ipu_isys_pfmts;
 	csi2_be->av.try_fmt_vid_mplane =
 	    ipu_isys_video_try_fmt_vid_mplane_default;
-	csi2_be->av.prepare_fw_stream =
-	    ipu_isys_prepare_fw_cfg_default;
+	csi2_be->av.prepare_firmware_stream_cfg =
+	    ipu_isys_prepare_firmware_stream_cfg_default;
 	csi2_be->av.aq.buf_prepare = ipu_isys_buf_prepare;
 	csi2_be->av.aq.fill_frame_buff_set_pin =
-	    ipu_isys_buffer_to_fw_frame_buff_pin;
+	    ipu_isys_buffer_list_to_ipu_fw_isys_frame_buff_set_pin;
 	csi2_be->av.aq.link_fmt_validate = ipu_isys_link_fmt_validate;
 	csi2_be->av.aq.vbq.buf_struct_size =
 	    sizeof(struct ipu_isys_video_buffer);
 
-	/* create v4l2 ctrl for csi-be video node */
-	rval = v4l2_ctrl_handler_init(&csi2_be->av.ctrl_handler, 0);
-	if (rval) {
-		dev_err(&isys->adev->dev,
-			"failed to init v4l2 ctrl handler for csi2_be\n");
-		goto fail;
-	}
-
-	csi2_be->av.compression_ctrl =
-		v4l2_ctrl_new_custom(&csi2_be->av.ctrl_handler,
-				     &compression_ctrl_cfg, NULL);
-	if (!csi2_be->av.compression_ctrl) {
-		dev_err(&isys->adev->dev,
-			"failed to create CSI-BE cmprs ctrl\n");
-		goto fail;
-	}
-	csi2_be->av.compression = 0;
-	csi2_be->av.vdev.ctrl_handler = &csi2_be->av.ctrl_handler;
-
 	rval = ipu_isys_video_init(&csi2_be->av, &csi2_be->asd.sd.entity,
 				   CSI2_BE_PAD_SOURCE, MEDIA_PAD_FL_SINK, 0);
 	if (rval) {
diff --git a/drivers/media/pci/intel/ipu-isys-csi2-be.h b/drivers/media/pci/intel/ipu-isys-csi2-be.h
index a9f5880f3394..70a17833a9c4 100644
--- a/drivers/media/pci/intel/ipu-isys-csi2-be.h
+++ b/drivers/media/pci/intel/ipu-isys-csi2-be.h
@@ -1,5 +1,5 @@
 /* SPDX-License-Identifier: GPL-2.0 */
-/* Copyright (C) 2014 - 2020 Intel Corporation */
+/* Copyright (C) 2014 - 2018 Intel Corporation */
 
 #ifndef IPU_ISYS_CSI2_BE_H
 #define IPU_ISYS_CSI2_BE_H
@@ -22,10 +22,18 @@ struct ipu_isys;
 #define NR_OF_CSI2_BE_SOURCE_PADS	1
 #define NR_OF_CSI2_BE_SINK_PADS		1
 
-#define NR_OF_CSI2_BE_SOC_SOURCE_PADS	1
-#define NR_OF_CSI2_BE_SOC_SINK_PADS	1
-#define CSI2_BE_SOC_PAD_SINK 0
-#define CSI2_BE_SOC_PAD_SOURCE 1
+#define NR_OF_CSI2_BE_STREAMS	1
+#define NR_OF_CSI2_BE_SOC_SOURCE_PADS	NR_OF_CSI2_BE_SOC_STREAMS
+#define NR_OF_CSI2_BE_SOC_SINK_PADS	NR_OF_CSI2_BE_SOC_STREAMS
+#define CSI2_BE_SOC_PAD_SINK(n)		\
+	({ typeof(n) __n = (n);	\
+	   (__n) >= NR_OF_CSI2_BE_SOC_SINK_PADS ?	\
+	   (NR_OF_CSI2_BE_SOC_SINK_PADS) : (__n); })
+#define CSI2_BE_SOC_PAD_SOURCE(n)	\
+	({ typeof(n) __n = (n);  \
+	   (__n) >= NR_OF_CSI2_BE_SOC_SOURCE_PADS ? \
+		(NR_OF_CSI2_BE_SOC_PADS - 1) : \
+		((__n) + NR_OF_CSI2_BE_SOC_SINK_PADS); })
 #define NR_OF_CSI2_BE_SOC_PADS \
 	(NR_OF_CSI2_BE_SOC_SOURCE_PADS + NR_OF_CSI2_BE_SOC_SINK_PADS)
 
@@ -45,7 +53,7 @@ struct ipu_isys_csi2_be {
 struct ipu_isys_csi2_be_soc {
 	struct ipu_isys_csi2_be_pdata *pdata;
 	struct ipu_isys_subdev asd;
-	struct ipu_isys_video av;
+	struct ipu_isys_video av[NR_OF_CSI2_BE_SOC_SOURCE_PADS];
 };
 
 #define to_ipu_isys_csi2_be(sd)	\
@@ -56,8 +64,11 @@ struct ipu_isys_csi2_be_soc {
 	container_of(to_ipu_isys_subdev(sd), \
 	struct ipu_isys_csi2_be_soc, asd)
 
-int ipu_isys_csi2_be_soc_init(struct ipu_isys_csi2_be_soc *csi2_be_soc,
-			      struct ipu_isys *isys, int index);
+int ipu_isys_csi2_be_init(struct ipu_isys_csi2_be *csi2_be,
+			  struct ipu_isys *isys);
+int ipu_isys_csi2_be_soc_init(
+	struct ipu_isys_csi2_be_soc *csi2_be_soc, struct ipu_isys *isys);
+void ipu_isys_csi2_be_cleanup(struct ipu_isys_csi2_be *csi2_be);
 void ipu_isys_csi2_be_soc_cleanup(struct ipu_isys_csi2_be_soc *csi2_be);
 
 #endif /* IPU_ISYS_CSI2_BE_H */
diff --git a/drivers/media/pci/intel/ipu-isys-csi2.c b/drivers/media/pci/intel/ipu-isys-csi2.c
index 2865c461a1be..719955bbf540 100644
--- a/drivers/media/pci/intel/ipu-isys-csi2.c
+++ b/drivers/media/pci/intel/ipu-isys-csi2.c
@@ -1,9 +1,8 @@
 // SPDX-License-Identifier: GPL-2.0
-// Copyright (C) 2013 - 2021 Intel Corporation
+// Copyright (C) 2013 - 2018 Intel Corporation
 
 #include <linux/device.h>
 #include <linux/module.h>
-#include <linux/version.h>
 
 #include <media/ipu-isys.h>
 #include <media/media-entity.h>
@@ -18,6 +17,11 @@
 #include "ipu-isys-video.h"
 #include "ipu-platform-regs.h"
 
+#define CREATE_TRACE_POINTS
+#define IPU_SOF_SEQID_TRACE
+#define IPU_EOF_SEQID_TRACE
+#include "ipu-trace-event.h"
+
 static const u32 csi2_supported_codes_pad_sink[] = {
 	MEDIA_BUS_FMT_Y10_1X10,
 	MEDIA_BUS_FMT_RGB565_1X16,
@@ -37,6 +41,10 @@ static const u32 csi2_supported_codes_pad_sink[] = {
 	MEDIA_BUS_FMT_SGBRG12_1X12,
 	MEDIA_BUS_FMT_SGRBG12_1X12,
 	MEDIA_BUS_FMT_SRGGB12_1X12,
+	MEDIA_BUS_FMT_SBGGR14_1X14,
+	MEDIA_BUS_FMT_SGBRG14_1X14,
+	MEDIA_BUS_FMT_SGRBG14_1X14,
+	MEDIA_BUS_FMT_SRGGB14_1X14,
 	MEDIA_BUS_FMT_SBGGR8_1X8,
 	MEDIA_BUS_FMT_SGBRG8_1X8,
 	MEDIA_BUS_FMT_SGRBG8_1X8,
@@ -59,6 +67,10 @@ static const u32 csi2_supported_codes_pad_source[] = {
 	MEDIA_BUS_FMT_SGBRG12_1X12,
 	MEDIA_BUS_FMT_SGRBG12_1X12,
 	MEDIA_BUS_FMT_SRGGB12_1X12,
+	MEDIA_BUS_FMT_SBGGR14_1X14,
+	MEDIA_BUS_FMT_SGBRG14_1X14,
+	MEDIA_BUS_FMT_SGRBG14_1X14,
+	MEDIA_BUS_FMT_SRGGB14_1X14,
 	MEDIA_BUS_FMT_SBGGR8_1X8,
 	MEDIA_BUS_FMT_SGBRG8_1X8,
 	MEDIA_BUS_FMT_SGRBG8_1X8,
@@ -66,6 +78,11 @@ static const u32 csi2_supported_codes_pad_source[] = {
 	0,
 };
 
+static const u32 csi2_supported_codes_pad_meta[] = {
+	MEDIA_BUS_FMT_FIXED,
+	0,
+};
+
 static const u32 *csi2_supported_codes[NR_OF_CSI2_PADS];
 
 static struct v4l2_subdev_internal_ops csi2_sd_internal_ops = {
@@ -91,10 +108,7 @@ int ipu_isys_csi2_get_link_freq(struct ipu_isys_csi2 *csi2, __s64 *link_freq)
 		WARN_ON(1);
 		return -ENODEV;
 	}
-	rval = v4l2_g_ext_ctrls(ext_sd->ctrl_handler,
-				ext_sd->devnode,
-				ext_sd->v4l2_dev->mdev,
-				&cs);
+	rval = v4l2_g_ext_ctrls(ext_sd->ctrl_handler, &csi2->av_meta.vdev, &csi2->isys->media_dev, &cs);
 	if (rval) {
 		dev_info(&csi2->isys->adev->dev, "can't get link frequency\n");
 		return rval;
@@ -117,6 +131,68 @@ int ipu_isys_csi2_get_link_freq(struct ipu_isys_csi2 *csi2, __s64 *link_freq)
 	return 0;
 }
 
+static int ipu_get_frame_desc_entry_by_dt(struct v4l2_subdev *sd,
+					  struct v4l2_mbus_frame_desc_entry
+					  *entry, u8 data_type)
+{
+	struct v4l2_mbus_frame_desc desc = {
+		.num_entries = V4L2_FRAME_DESC_ENTRY_MAX,
+	};
+	int rval, i;
+
+	rval = v4l2_subdev_call(sd, pad, get_frame_desc, 0, &desc);
+	if (rval)
+		return rval;
+
+	for (i = 0; i < desc.num_entries; i++) {
+		if (desc.entry[i].bus.csi2.data_type != data_type)
+			continue;
+		*entry = desc.entry[i];
+		return 0;
+	}
+
+	return -EINVAL;
+}
+
+static void csi2_meta_prepare_firmware_stream_cfg_default(
+			struct ipu_isys_video *av,
+			struct ipu_fw_isys_stream_cfg_data_abi *cfg)
+{
+	struct ipu_isys_pipeline *ip =
+	    to_ipu_isys_pipeline(av->vdev.entity.pipe);
+	struct ipu_isys_queue *aq = &av->aq;
+	struct ipu_fw_isys_output_pin_info_abi *pin_info;
+	struct v4l2_mbus_frame_desc_entry entry;
+	int pin = cfg->nof_output_pins++;
+	int inpin = cfg->nof_input_pins++;
+	int rval;
+
+	aq->fw_output = pin;
+	ip->output_pins[pin].pin_ready = ipu_isys_queue_buf_ready;
+	ip->output_pins[pin].aq = aq;
+
+	pin_info = &cfg->output_pins[pin];
+	pin_info->input_pin_id = inpin;
+	pin_info->output_res.width = av->mpix.width;
+	pin_info->output_res.height = av->mpix.height;
+	pin_info->stride = av->mpix.plane_fmt[0].bytesperline;
+	pin_info->pt = aq->css_pin_type;
+	pin_info->ft = av->pfmt->css_pixelformat;
+	pin_info->send_irq = 1;
+
+	rval =
+	    ipu_get_frame_desc_entry_by_dt(media_entity_to_v4l2_subdev
+					   (ip->external->entity), &entry,
+					   IPU_ISYS_MIPI_CSI2_TYPE_EMBEDDED8);
+	if (!rval) {
+		cfg->input_pins[inpin].dt = IPU_ISYS_MIPI_CSI2_TYPE_EMBEDDED8;
+		cfg->input_pins[inpin].input_res.width =
+		    entry.two_dim.width * entry.bpp / BITS_PER_BYTE;
+		cfg->input_pins[inpin].input_res.height =
+		    entry.two_dim.height;
+	}
+}
+
 static int subscribe_event(struct v4l2_subdev *sd, struct v4l2_fh *fh,
 			   struct v4l2_event_subscription *sub)
 {
@@ -140,6 +216,11 @@ static const struct v4l2_subdev_core_ops csi2_sd_core_ops = {
 	.unsubscribe_event = v4l2_event_subdev_unsubscribe,
 };
 
+static struct ipu_isys_pixelformat csi2_meta_pfmts[] = {
+	{V4L2_FMT_IPU_ISYS_META, 8, 8, 0, MEDIA_BUS_FMT_FIXED, 0},
+	{},
+};
+
 /*
  * The input system CSI2+ receiver has several
  * parameters affecting the receiver timings. These depend
@@ -149,7 +230,7 @@ static const struct v4l2_subdev_core_ops csi2_sd_core_ops = {
  * where
  *	UI = 1 / (2 * F) in seconds
  *	COUNT_ACC = counter accuracy in seconds
- *	For legacy IPU,  COUNT_ACC = 0.125 ns
+ *	For IPU4,  COUNT_ACC = 0.125 ns
  *
  * A and B are coefficients from the table below,
  * depending whether the register minimum or maximum value is
@@ -221,7 +302,8 @@ static int set_stream(struct v4l2_subdev *sd, int enable)
 						    pipe);
 	struct ipu_isys_csi2_config *cfg;
 	struct v4l2_subdev *ext_sd;
-	struct ipu_isys_csi2_timing timing = {0};
+	struct v4l2_control c = {.id = V4L2_CID_MIPI_LANES, };
+	struct ipu_isys_csi2_timing timing;
 	unsigned int nlanes;
 	int rval;
 
@@ -235,23 +317,37 @@ static int set_stream(struct v4l2_subdev *sd, int enable)
 	cfg = v4l2_get_subdev_hostdata(ext_sd);
 
 	if (!enable) {
+		csi2->stream_count--;
+		if (csi2->stream_count)
+			return 0;
+
 		ipu_isys_csi2_set_stream(sd, timing, 0, enable);
 		return 0;
 	}
 
 	ip->has_sof = true;
 
-	nlanes = cfg->nlanes;
+	if (csi2->stream_count) {
+		csi2->stream_count++;
+		return 0;
+	}
 
-	dev_dbg(&csi2->isys->adev->dev, "lane nr %d.\n", nlanes);
+	rval = v4l2_g_ctrl(ext_sd->ctrl_handler, &c);
+	if (!rval && c.value > 0 && cfg->nlanes > c.value) {
+		nlanes = c.value;
+		dev_dbg(&csi2->isys->adev->dev, "lane nr %d.\n", nlanes);
+	} else {
+		nlanes = cfg->nlanes;
+	}
 
 	rval = ipu_isys_csi2_calc_timing(csi2, &timing, CSI2_ACCINV);
 	if (rval)
 		return rval;
 
-	rval = ipu_isys_csi2_set_stream(sd, timing, nlanes, enable);
+	ipu_isys_csi2_set_stream(sd, timing, nlanes, enable);
+	csi2->stream_count++;
 
-	return rval;
+	return 0;
 }
 
 static void csi2_capture_done(struct ipu_isys_pipeline *ip,
@@ -270,12 +366,22 @@ static void csi2_capture_done(struct ipu_isys_pipeline *ip,
 		}
 		spin_unlock_irqrestore(&ip->short_packet_queue_lock, flags);
 	}
+	if (ip->csi2) {
+		ipu_isys_csi2_error(ip->csi2);
+	}
 }
 
 static int csi2_link_validate(struct media_link *link)
 {
 	struct ipu_isys_csi2 *csi2;
 	struct ipu_isys_pipeline *ip;
+	struct v4l2_subdev_route r[IPU_ISYS_MAX_STREAMS];
+	struct v4l2_subdev_routing routing = {
+		.routes = r,
+		.num_routes = IPU_ISYS_MAX_STREAMS,
+	};
+	unsigned int active = 0;
+	int i;
 	int rval;
 
 	if (!link->sink->entity ||
@@ -295,36 +401,98 @@ static int csi2_link_validate(struct media_link *link)
 		return rval;
 
 	if (!v4l2_ctrl_g_ctrl(csi2->store_csi2_header)) {
-		struct media_pad *remote_pad =
-		    media_entity_remote_pad(&csi2->asd.pad[CSI2_PAD_SOURCE]);
-
-		if (remote_pad &&
-		    is_media_entity_v4l2_subdev(remote_pad->entity)) {
-			dev_err(&csi2->isys->adev->dev,
-				"CSI2 BE requires CSI2 headers.\n");
-			return -EINVAL;
+		for (i = 0; i < NR_OF_CSI2_SOURCE_PADS; i++) {
+			struct media_pad *remote_pad =
+			    media_entity_remote_pad(&csi2->asd.
+						    pad[CSI2_PAD_SOURCE(i)]);
+
+			if (remote_pad &&
+			    is_media_entity_v4l2_subdev(remote_pad->entity)) {
+				dev_err(&csi2->isys->adev->dev,
+					"CSI2 BE requires CSI2 headers.\n");
+				return -EINVAL;
+			}
 		}
 	}
 
+	rval =
+	    v4l2_subdev_call(media_entity_to_v4l2_subdev(link->source->entity),
+			     pad, get_routing, &routing);
+
+	if (rval) {
+		csi2->remote_streams = 1;
+		return 0;
+	}
+
+	for (i = 0; i < routing.num_routes; i++) {
+		if (routing.routes[i].flags & V4L2_SUBDEV_ROUTE_FL_ACTIVE)
+			active++;
+	}
+
+	if (active !=
+	    bitmap_weight(csi2->asd.stream[link->sink->index].streams_stat, 32))
+		return -EINVAL;
+
+	csi2->remote_streams = active;
+
 	return 0;
 }
 
+static bool csi2_has_route(struct media_entity *entity, unsigned int pad0,
+			   unsigned int pad1, int *stream)
+{
+	if (pad0 == CSI2_PAD_META || pad1 == CSI2_PAD_META)
+		return true;
+	return ipu_isys_subdev_has_route(entity, pad0, pad1, stream);
+}
+
 static const struct v4l2_subdev_video_ops csi2_sd_video_ops = {
 	.s_stream = set_stream,
 };
 
+static int get_metadata_fmt(struct v4l2_subdev *sd,
+			    struct v4l2_subdev_state *state,
+			    struct v4l2_subdev_format *fmt)
+{
+	struct media_pad *pad =
+	    media_entity_remote_pad(&sd->entity.pads[CSI2_PAD_SINK]);
+	struct v4l2_mbus_frame_desc_entry entry;
+	int rval;
+
+	if (!pad)
+		return -EINVAL;
+
+	rval =
+	    ipu_get_frame_desc_entry_by_dt(media_entity_to_v4l2_subdev
+					   (pad->entity), &entry,
+					   IPU_ISYS_MIPI_CSI2_TYPE_EMBEDDED8);
+
+	if (!rval) {
+		fmt->format.width =
+		    entry.two_dim.width * entry.bpp / BITS_PER_BYTE;
+		fmt->format.height = entry.two_dim.height;
+		fmt->format.code = entry.pixelcode;
+		fmt->format.field = V4L2_FIELD_NONE;
+	}
+	return rval;
+}
+
 static int ipu_isys_csi2_get_fmt(struct v4l2_subdev *sd,
-				 struct v4l2_subdev_state *sd_state,
+				 struct v4l2_subdev_state *state,
 				 struct v4l2_subdev_format *fmt)
 {
-	return ipu_isys_subdev_get_ffmt(sd, sd_state, fmt);
+	if (fmt->pad == CSI2_PAD_META)
+		return get_metadata_fmt(sd, state, fmt);
+	return ipu_isys_subdev_get_ffmt(sd, state, fmt);
 }
 
 static int ipu_isys_csi2_set_fmt(struct v4l2_subdev *sd,
-				 struct v4l2_subdev_state *sd_state,
+				 struct v4l2_subdev_state *state,
 				 struct v4l2_subdev_format *fmt)
 {
-	return ipu_isys_subdev_set_ffmt(sd, sd_state, fmt);
+	if (fmt->pad == CSI2_PAD_META)
+		return get_metadata_fmt(sd, state, fmt);
+	return ipu_isys_subdev_set_ffmt(sd, state, fmt);
 }
 
 static int __subdev_link_validate(struct v4l2_subdev *sd,
@@ -347,6 +515,8 @@ static const struct v4l2_subdev_pad_ops csi2_sd_pad_ops = {
 	.get_fmt = ipu_isys_csi2_get_fmt,
 	.set_fmt = ipu_isys_csi2_set_fmt,
 	.enum_mbus_code = ipu_isys_subdev_enum_mbus_code,
+	.set_routing = ipu_isys_subdev_set_routing,
+	.get_routing = ipu_isys_subdev_get_routing,
 };
 
 static struct v4l2_subdev_ops csi2_sd_ops = {
@@ -357,15 +527,16 @@ static struct v4l2_subdev_ops csi2_sd_ops = {
 
 static struct media_entity_operations csi2_entity_ops = {
 	.link_validate = csi2_link_validate,
+	.has_route = csi2_has_route,
 };
 
 static void csi2_set_ffmt(struct v4l2_subdev *sd,
-			  struct v4l2_subdev_state *sd_state,
+			  struct v4l2_subdev_state *state,
 			  struct v4l2_subdev_format *fmt)
 {
-	enum isys_subdev_prop_tgt tgt = IPU_ISYS_SUBDEV_PROP_TGT_SINK_FMT;
 	struct v4l2_mbus_framefmt *ffmt =
-		__ipu_isys_get_ffmt(sd, sd_state, fmt->pad,
+		__ipu_isys_get_ffmt(sd, state, fmt->pad,
+				    fmt->stream,
 				    fmt->which);
 
 	if (fmt->format.field != V4L2_FIELD_ALTERNATE)
@@ -373,11 +544,47 @@ static void csi2_set_ffmt(struct v4l2_subdev *sd,
 
 	if (fmt->pad == CSI2_PAD_SINK) {
 		*ffmt = fmt->format;
-		ipu_isys_subdev_fmt_propagate(sd, sd_state, &fmt->format, NULL,
-					      tgt, fmt->pad, fmt->which);
+		if (fmt->stream)
+			return;
+		ipu_isys_subdev_fmt_propagate(
+			sd, state, &fmt->format, NULL,
+			IPU_ISYS_SUBDEV_PROP_TGT_SINK_FMT,
+			fmt->pad, fmt->which);
 		return;
 	}
 
+	if (fmt->pad == CSI2_PAD_META) {
+		struct v4l2_mbus_framefmt *ffmt =
+			__ipu_isys_get_ffmt(sd, state, fmt->pad,
+					    fmt->stream,
+					    fmt->which);
+		struct media_pad *pad = media_entity_remote_pad(
+			&sd->entity.pads[CSI2_PAD_SINK]);
+		struct v4l2_mbus_frame_desc_entry entry;
+		int rval;
+
+		if (!pad) {
+			ffmt->width = 0;
+			ffmt->height = 0;
+			ffmt->code = 0;
+			return;
+		}
+
+		rval = ipu_get_frame_desc_entry_by_dt(
+				media_entity_to_v4l2_subdev(pad->entity),
+				&entry,
+				IPU_ISYS_MIPI_CSI2_TYPE_EMBEDDED8);
+
+		if (!rval) {
+			ffmt->width = entry.two_dim.width * entry.bpp
+			    / BITS_PER_BYTE;
+			ffmt->height = entry.two_dim.height;
+			ffmt->code = entry.pixelcode;
+			ffmt->field = V4L2_FIELD_NONE;
+		}
+
+		return;
+	}
 	if (sd->entity.pads[fmt->pad].flags & MEDIA_PAD_FL_SOURCE) {
 		ffmt->width = fmt->format.width;
 		ffmt->height = fmt->format.height;
@@ -394,10 +601,16 @@ static const struct ipu_isys_pixelformat *
 csi2_try_fmt(struct ipu_isys_video *av,
 	     struct v4l2_pix_format_mplane *mpix)
 {
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 5, 0)
+	struct v4l2_subdev *sd =
+	    media_entity_to_v4l2_subdev(av->vdev.entity.links[0].source->
+					entity);
+#else
 	struct media_link *link = list_first_entry(&av->vdev.entity.links,
 						   struct media_link, list);
 	struct v4l2_subdev *sd =
 	    media_entity_to_v4l2_subdev(link->source->entity);
+#endif
 	struct ipu_isys_csi2 *csi2;
 
 	if (!sd)
@@ -411,11 +624,16 @@ csi2_try_fmt(struct ipu_isys_video *av,
 
 void ipu_isys_csi2_cleanup(struct ipu_isys_csi2 *csi2)
 {
+	int i;
+
 	if (!csi2->isys)
 		return;
 
 	v4l2_device_unregister_subdev(&csi2->asd.sd);
 	ipu_isys_subdev_cleanup(&csi2->asd);
+	for (i = 0; i < NR_OF_CSI2_SOURCE_PADS; i++)
+		ipu_isys_video_cleanup(&csi2->av[i]);
+	ipu_isys_video_cleanup(&csi2->av_meta);
 	csi2->isys = NULL;
 }
 
@@ -449,10 +667,12 @@ int ipu_isys_csi2_init(struct ipu_isys_csi2 *csi2,
 			   .height = 3072,
 			  },
 	};
+	struct v4l2_subdev_format fmt_meta = {
+		.which = V4L2_SUBDEV_FORMAT_ACTIVE,
+		.pad = CSI2_PAD_META,
+	};
 	int i, rval, src;
 
-	dev_dbg(&isys->adev->dev, "csi-%d base = 0x%lx\n", index,
-		(unsigned long)base);
 	csi2->isys = isys;
 	csi2->base = base;
 	csi2->index = index;
@@ -461,24 +681,35 @@ int ipu_isys_csi2_init(struct ipu_isys_csi2 *csi2,
 	csi2->asd.ctrl_init = csi_ctrl_init;
 	csi2->asd.isys = isys;
 	init_completion(&csi2->eof_completion);
+	csi2->remote_streams = 1;
+	csi2->stream_count = 0;
+
 	rval = ipu_isys_subdev_init(&csi2->asd, &csi2_sd_ops, 0,
 				    NR_OF_CSI2_PADS,
+				    NR_OF_CSI2_STREAMS,
 				    NR_OF_CSI2_SOURCE_PADS,
 				    NR_OF_CSI2_SINK_PADS,
-				    0);
+				    V4L2_SUBDEV_FL_HAS_SUBSTREAMS);
 	if (rval)
 		goto fail;
 
 	csi2->asd.pad[CSI2_PAD_SINK].flags = MEDIA_PAD_FL_SINK
-		| MEDIA_PAD_FL_MUST_CONNECT;
-	csi2->asd.pad[CSI2_PAD_SOURCE].flags = MEDIA_PAD_FL_SOURCE;
+	    | MEDIA_PAD_FL_MUST_CONNECT | MEDIA_PAD_FL_MULTIPLEX;
+	for (i = CSI2_PAD_SOURCE(0);
+	     i < (NR_OF_CSI2_SOURCE_PADS + CSI2_PAD_SOURCE(0)); i++)
+		csi2->asd.pad[i].flags = MEDIA_PAD_FL_SOURCE;
 
+	csi2->asd.pad[CSI2_PAD_META].flags = MEDIA_PAD_FL_SOURCE;
 	src = index;
+#ifdef CONFIG_VIDEO_INTEL_IPU4P
+	src = index ? (index + 5) : (index + 3);
+#endif
 	csi2->asd.source = IPU_FW_ISYS_STREAM_SRC_CSI2_PORT0 + src;
 	csi2_supported_codes[CSI2_PAD_SINK] = csi2_supported_codes_pad_sink;
 
 	for (i = 0; i < NR_OF_CSI2_SOURCE_PADS; i++)
 		csi2_supported_codes[i + 1] = csi2_supported_codes_pad_source;
+	csi2_supported_codes[CSI2_PAD_META] = csi2_supported_codes_pad_meta;
 	csi2->asd.supported_codes = csi2_supported_codes;
 	csi2->asd.set_ffmt = csi2_set_ffmt;
 
@@ -488,16 +719,94 @@ int ipu_isys_csi2_init(struct ipu_isys_csi2 *csi2,
 		 IPU_ISYS_ENTITY_PREFIX " CSI-2 %u", index);
 	v4l2_set_subdevdata(&csi2->asd.sd, &csi2->asd);
 
+	mutex_lock(&csi2->asd.mutex);
 	rval = v4l2_device_register_subdev(&isys->v4l2_dev, &csi2->asd.sd);
 	if (rval) {
+		mutex_unlock(&csi2->asd.mutex);
 		dev_info(&isys->adev->dev, "can't register v4l2 subdev\n");
 		goto fail;
 	}
 
-	mutex_lock(&csi2->asd.mutex);
 	__ipu_isys_subdev_set_ffmt(&csi2->asd.sd, NULL, &fmt);
+	__ipu_isys_subdev_set_ffmt(&csi2->asd.sd, NULL, &fmt_meta);
+
+	/* create default route information */
+	for (i = 0; i < NR_OF_CSI2_STREAMS; i++) {
+		csi2->asd.route[i].sink = CSI2_PAD_SINK;
+		csi2->asd.route[i].source = CSI2_PAD_SOURCE(i);
+		csi2->asd.route[i].flags = 0;
+	}
+
+	for (i = 0; i < NR_OF_CSI2_SOURCE_PADS; i++) {
+		csi2->asd.stream[CSI2_PAD_SINK].stream_id[i] = i;
+		csi2->asd.stream[CSI2_PAD_SOURCE(i)].stream_id[CSI2_PAD_SINK]
+		    = i;
+	}
+	csi2->asd.route[0].flags = V4L2_SUBDEV_ROUTE_FL_ACTIVE |
+	    V4L2_SUBDEV_ROUTE_FL_IMMUTABLE;
+	bitmap_set(csi2->asd.stream[CSI2_PAD_SINK].streams_stat, 0, 1);
+	bitmap_set(csi2->asd.stream[CSI2_PAD_SOURCE(0)].streams_stat, 0, 1);
+
 	mutex_unlock(&csi2->asd.mutex);
 
+	for (i = 0; i < NR_OF_CSI2_SOURCE_PADS; i++) {
+		snprintf(csi2->av[i].vdev.name, sizeof(csi2->av[i].vdev.name),
+			 IPU_ISYS_ENTITY_PREFIX " CSI-2 %u capture %d",
+			 index, i);
+		csi2->av[i].isys = isys;
+		csi2->av[i].aq.css_pin_type = IPU_FW_ISYS_PIN_TYPE_MIPI;
+		csi2->av[i].pfmts = ipu_isys_pfmts_packed;
+		csi2->av[i].try_fmt_vid_mplane = csi2_try_fmt;
+		csi2->av[i].prepare_firmware_stream_cfg =
+		    ipu_isys_prepare_firmware_stream_cfg_default;
+		csi2->av[i].packed = true;
+		csi2->av[i].line_header_length =
+		    IPU_ISYS_CSI2_LONG_PACKET_HEADER_SIZE;
+		csi2->av[i].line_footer_length =
+		    IPU_ISYS_CSI2_LONG_PACKET_FOOTER_SIZE;
+		csi2->av[i].aq.buf_prepare = ipu_isys_buf_prepare;
+		csi2->av[i].aq.fill_frame_buff_set_pin =
+		    ipu_isys_buffer_list_to_ipu_fw_isys_frame_buff_set_pin;
+		csi2->av[i].aq.link_fmt_validate = ipu_isys_link_fmt_validate;
+		csi2->av[i].aq.vbq.buf_struct_size =
+		    sizeof(struct ipu_isys_video_buffer);
+
+		rval = ipu_isys_video_init(&csi2->av[i],
+					   &csi2->asd.sd.entity,
+					   CSI2_PAD_SOURCE(i),
+					   MEDIA_PAD_FL_SINK, 0);
+		if (rval) {
+			dev_info(&isys->adev->dev, "can't init video node\n");
+			goto fail;
+		}
+	}
+
+	snprintf(csi2->av_meta.vdev.name, sizeof(csi2->av_meta.vdev.name),
+		 IPU_ISYS_ENTITY_PREFIX " CSI-2 %u meta", index);
+	csi2->av_meta.isys = isys;
+	csi2->av_meta.aq.css_pin_type = IPU_FW_ISYS_PIN_TYPE_MIPI;
+	csi2->av_meta.pfmts = csi2_meta_pfmts;
+	csi2->av_meta.try_fmt_vid_mplane = csi2_try_fmt;
+	csi2->av_meta.prepare_firmware_stream_cfg =
+	    csi2_meta_prepare_firmware_stream_cfg_default;
+	csi2->av_meta.packed = true;
+	csi2->av_meta.line_header_length =
+	    IPU_ISYS_CSI2_LONG_PACKET_HEADER_SIZE;
+	csi2->av_meta.line_footer_length =
+	    IPU_ISYS_CSI2_LONG_PACKET_FOOTER_SIZE;
+	csi2->av_meta.aq.buf_prepare = ipu_isys_buf_prepare;
+	csi2->av_meta.aq.fill_frame_buff_set_pin =
+	    ipu_isys_buffer_list_to_ipu_fw_isys_frame_buff_set_pin;
+	csi2->av_meta.aq.link_fmt_validate = ipu_isys_link_fmt_validate;
+	csi2->av_meta.aq.vbq.buf_struct_size =
+	    sizeof(struct ipu_isys_video_buffer);
+
+	rval = ipu_isys_video_init(&csi2->av_meta, &csi2->asd.sd.entity,
+				   CSI2_PAD_META, MEDIA_PAD_FL_SINK, 0);
+	if (rval) {
+		dev_info(&isys->adev->dev, "can't init metadata node\n");
+		goto fail;
+	}
 	return 0;
 
 fail:
@@ -506,7 +815,7 @@ int ipu_isys_csi2_init(struct ipu_isys_csi2 *csi2,
 	return rval;
 }
 
-void ipu_isys_csi2_sof_event(struct ipu_isys_csi2 *csi2)
+void ipu_isys_csi2_sof_event(struct ipu_isys_csi2 *csi2, unsigned int vc)
 {
 	struct ipu_isys_pipeline *ip = NULL;
 	struct v4l2_event ev = {
@@ -517,10 +826,11 @@ void ipu_isys_csi2_sof_event(struct ipu_isys_csi2 *csi2)
 	unsigned int i;
 
 	spin_lock_irqsave(&csi2->isys->lock, flags);
-	csi2->in_frame = true;
+	csi2->in_frame[vc] = true;
 
 	for (i = 0; i < IPU_ISYS_MAX_STREAMS; i++) {
 		if (csi2->isys->pipes[i] &&
+		    csi2->isys->pipes[i]->vc == vc &&
 		    csi2->isys->pipes[i]->csi2 == csi2) {
 			ip = csi2->isys->pipes[i];
 			break;
@@ -534,15 +844,17 @@ void ipu_isys_csi2_sof_event(struct ipu_isys_csi2 *csi2)
 	}
 
 	ev.u.frame_sync.frame_sequence = atomic_inc_return(&ip->sequence) - 1;
+	ev.id = ip->stream_id;
 	spin_unlock_irqrestore(&csi2->isys->lock, flags);
 
+	trace_ipu_sof_seqid(ev.u.frame_sync.frame_sequence, csi2->index, vc);
 	v4l2_event_queue(vdev, &ev);
 	dev_dbg(&csi2->isys->adev->dev,
-		"sof_event::csi2-%i sequence: %i\n",
-		csi2->index, ev.u.frame_sync.frame_sequence);
+		"sof_event::csi2-%i CPU-timestamp:%lld, sequence:%i, vc:%d, stream_id:%d\n",
+		csi2->index, ktime_get_ns(), ev.u.frame_sync.frame_sequence, vc, ip->stream_id);
 }
 
-void ipu_isys_csi2_eof_event(struct ipu_isys_csi2 *csi2)
+void ipu_isys_csi2_eof_event(struct ipu_isys_csi2 *csi2, unsigned int vc)
 {
 	struct ipu_isys_pipeline *ip = NULL;
 	unsigned long flags;
@@ -550,12 +862,14 @@ void ipu_isys_csi2_eof_event(struct ipu_isys_csi2 *csi2)
 	u32 frame_sequence;
 
 	spin_lock_irqsave(&csi2->isys->lock, flags);
-	csi2->in_frame = false;
-	if (csi2->wait_for_sync)
+	csi2->in_frame[vc] = false;
+	if (csi2->wait_for_sync[vc])
 		complete(&csi2->eof_completion);
+	spin_unlock_irqrestore(&csi2->isys->lock, flags);
 
 	for (i = 0; i < IPU_ISYS_MAX_STREAMS; i++) {
 		if (csi2->isys->pipes[i] &&
+		    csi2->isys->pipes[i]->vc == vc &&
 		    csi2->isys->pipes[i]->csi2 == csi2) {
 			ip = csi2->isys->pipes[i];
 			break;
@@ -564,55 +878,52 @@ void ipu_isys_csi2_eof_event(struct ipu_isys_csi2 *csi2)
 
 	if (ip) {
 		frame_sequence = atomic_read(&ip->sequence);
-		spin_unlock_irqrestore(&csi2->isys->lock, flags);
+
+	trace_ipu_eof_seqid(frame_sequence, csi2->index, vc);
 
 		dev_dbg(&csi2->isys->adev->dev,
-			"eof_event::csi2-%i sequence: %i\n",
-			csi2->index, frame_sequence);
-		return;
+			"eof_event::csi2-%i sequence: %i, vc: %d, stream_id: %d\n",
+			csi2->index, frame_sequence, vc, ip->stream_id);
 	}
-
-	spin_unlock_irqrestore(&csi2->isys->lock, flags);
 }
 
 /* Call this function only _after_ the sensor has been stopped */
 void ipu_isys_csi2_wait_last_eof(struct ipu_isys_csi2 *csi2)
 {
 	unsigned long flags, tout;
+	unsigned int i;
 
-	spin_lock_irqsave(&csi2->isys->lock, flags);
+	for (i = 0; i < NR_OF_CSI2_VC; i++) {
+		spin_lock_irqsave(&csi2->isys->lock, flags);
+
+		if (!csi2->in_frame[i]) {
+			spin_unlock_irqrestore(&csi2->isys->lock, flags);
+			continue;
+		}
 
-	if (!csi2->in_frame) {
+		reinit_completion(&csi2->eof_completion);
+		csi2->wait_for_sync[i] = true;
 		spin_unlock_irqrestore(&csi2->isys->lock, flags);
-		return;
+		tout = wait_for_completion_timeout(&csi2->eof_completion,
+						   IPU_EOF_TIMEOUT_JIFFIES);
+		if (!tout)
+			dev_err(&csi2->isys->adev->dev,
+				"csi2-%d: timeout at sync to eof of vc %d\n",
+				csi2->index, i);
+		csi2->wait_for_sync[i] = false;
 	}
-
-	reinit_completion(&csi2->eof_completion);
-	csi2->wait_for_sync = true;
-	spin_unlock_irqrestore(&csi2->isys->lock, flags);
-	tout = wait_for_completion_timeout(&csi2->eof_completion,
-					   IPU_EOF_TIMEOUT_JIFFIES);
-	if (!tout)
-		dev_err(&csi2->isys->adev->dev,
-			"csi2-%d: timeout at sync to eof\n",
-			csi2->index);
-	csi2->wait_for_sync = false;
 }
 
-struct ipu_isys_buffer *
-ipu_isys_csi2_get_short_packet_buffer(struct ipu_isys_pipeline *ip,
-				      struct ipu_isys_buffer_list *bl)
+struct ipu_isys_buffer *ipu_isys_csi2_get_short_packet_buffer(struct
+							      ipu_isys_pipeline
+							      *ip)
 {
 	struct ipu_isys_buffer *ib;
 	struct ipu_isys_private_buffer *pb;
 	struct ipu_isys_mipi_packet_header *ph;
-	unsigned long flags;
 
-	spin_lock_irqsave(&ip->short_packet_queue_lock, flags);
-	if (list_empty(&ip->short_packet_incoming)) {
-		spin_unlock_irqrestore(&ip->short_packet_queue_lock, flags);
+	if (list_empty(&ip->short_packet_incoming))
 		return NULL;
-	}
 	ib = list_last_entry(&ip->short_packet_incoming,
 			     struct ipu_isys_buffer, head);
 	pb = ipu_isys_buffer_to_private_buffer(ib);
@@ -624,8 +935,5 @@ ipu_isys_csi2_get_short_packet_buffer(struct ipu_isys_pipeline *ip,
 
 	dma_sync_single_for_cpu(&ip->isys->adev->dev, pb->dma_addr,
 				sizeof(*ph), DMA_BIDIRECTIONAL);
-	spin_unlock_irqrestore(&ip->short_packet_queue_lock, flags);
-	list_move(&ib->head, &bl->head);
-
 	return ib;
 }
diff --git a/drivers/media/pci/intel/ipu-isys-csi2.h b/drivers/media/pci/intel/ipu-isys-csi2.h
index 04c45571e9e1..d7f2df3eb805 100644
--- a/drivers/media/pci/intel/ipu-isys-csi2.h
+++ b/drivers/media/pci/intel/ipu-isys-csi2.h
@@ -1,5 +1,5 @@
 /* SPDX-License-Identifier: GPL-2.0 */
-/* Copyright (C) 2013 - 2020 Intel Corporation */
+/* Copyright (C) 2013 - 2018 Intel Corporation */
 
 #ifndef IPU_ISYS_CSI2_H
 #define IPU_ISYS_CSI2_H
@@ -18,9 +18,17 @@ struct ipu_isys;
 
 #define NR_OF_CSI2_SINK_PADS		1
 #define CSI2_PAD_SINK			0
-#define NR_OF_CSI2_SOURCE_PADS		1
-#define CSI2_PAD_SOURCE			1
-#define NR_OF_CSI2_PADS	(NR_OF_CSI2_SINK_PADS + NR_OF_CSI2_SOURCE_PADS)
+#define NR_OF_CSI2_STREAMS		NR_OF_CSI2_VC
+#define NR_OF_CSI2_SOURCE_PADS		NR_OF_CSI2_STREAMS
+#define CSI2_PAD_SOURCE(n)		\
+	({ typeof(n) __n = (n);		\
+	(__n >= NR_OF_CSI2_SOURCE_PADS ? \
+		(NR_OF_CSI2_PADS - 2) : \
+		(__n + NR_OF_CSI2_SINK_PADS)); })
+#define NR_OF_CSI2_META_PADS		1
+#define NR_OF_CSI2_PADS			\
+	(NR_OF_CSI2_SINK_PADS + NR_OF_CSI2_SOURCE_PADS + NR_OF_CSI2_META_PADS)
+#define CSI2_PAD_META			(NR_OF_CSI2_PADS - 1)
 
 #define IPU_ISYS_SHORT_PACKET_BUFFER_NUM	VIDEO_MAX_FRAME
 #define IPU_ISYS_SHORT_PACKET_WIDTH	32
@@ -81,7 +89,8 @@ struct ipu_isys_csi2 {
 	struct ipu_isys_csi2_pdata *pdata;
 	struct ipu_isys *isys;
 	struct ipu_isys_subdev asd;
-	struct ipu_isys_video av;
+	struct ipu_isys_video av[NR_OF_CSI2_SOURCE_PADS];
+	struct ipu_isys_video av_meta;
 	struct completion eof_completion;
 
 	void __iomem *base;
@@ -89,8 +98,11 @@ struct ipu_isys_csi2 {
 	unsigned int nlanes;
 	unsigned int index;
 	atomic_t sof_sequence;
-	bool in_frame;
-	bool wait_for_sync;
+	bool in_frame[NR_OF_CSI2_VC];
+	bool wait_for_sync[NR_OF_CSI2_VC];
+
+	unsigned int remote_streams;
+	unsigned int stream_count;
 
 	struct v4l2_ctrl *store_csi2_header;
 };
@@ -146,10 +158,9 @@ int ipu_isys_csi2_init(struct ipu_isys_csi2 *csi2,
 		       void __iomem *base, unsigned int index);
 void ipu_isys_csi2_cleanup(struct ipu_isys_csi2 *csi2);
 struct ipu_isys_buffer *
-ipu_isys_csi2_get_short_packet_buffer(struct ipu_isys_pipeline *ip,
-				      struct ipu_isys_buffer_list *bl);
-void ipu_isys_csi2_sof_event(struct ipu_isys_csi2 *csi2);
-void ipu_isys_csi2_eof_event(struct ipu_isys_csi2 *csi2);
+ipu_isys_csi2_get_short_packet_buffer(struct ipu_isys_pipeline *ip);
+void ipu_isys_csi2_sof_event(struct ipu_isys_csi2 *csi2, unsigned int vc);
+void ipu_isys_csi2_eof_event(struct ipu_isys_csi2 *csi2, unsigned int vc);
 void ipu_isys_csi2_wait_last_eof(struct ipu_isys_csi2 *csi2);
 
 /* interface for platform specific */
@@ -160,5 +171,7 @@ unsigned int ipu_isys_csi2_get_current_field(struct ipu_isys_pipeline *ip,
 					     unsigned int *timestamp);
 void ipu_isys_csi2_isr(struct ipu_isys_csi2 *csi2);
 void ipu_isys_csi2_error(struct ipu_isys_csi2 *csi2);
+bool ipu_isys_csi2_skew_cal_required(struct ipu_isys_csi2 *csi2);
+int ipu_isys_csi2_set_skew_cal(struct ipu_isys_csi2 *csi2, int enable);
 
 #endif /* IPU_ISYS_CSI2_H */
diff --git a/drivers/media/pci/intel/ipu-isys-media.h b/drivers/media/pci/intel/ipu-isys-media.h
index 72b48bcbf7f1..c3dd8d03c3e9 100644
--- a/drivers/media/pci/intel/ipu-isys-media.h
+++ b/drivers/media/pci/intel/ipu-isys-media.h
@@ -1,5 +1,5 @@
 /* SPDX-License-Identifier: GPL-2.0 */
-/* Copyright (C) 2016 - 2020 Intel Corporation */
+/* Copyright (C) 2016 - 2018 Intel Corporation */
 
 #ifndef IPU_ISYS_MEDIA_H
 #define IPU_ISYS_MEDIA_H
@@ -7,6 +7,86 @@
 #include <linux/slab.h>
 #include <media/media-entity.h>
 
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 5, 0)
+#define is_media_entity_v4l2_subdev(e) \
+	(media_entity_type(e) == MEDIA_ENT_T_V4L2_SUBDEV)
+#define is_media_entity_v4l2_io(e) \
+	(media_entity_type(e) == MEDIA_ENT_T_DEVNODE)
+#define media_create_pad_link(a, b, c, d, e)	\
+	media_entity_create_link(a, b, c, d, e)
+#define media_entity_pads_init(a, b, c)	\
+	media_entity_init(a, b, c, 0)
+#define media_entity_id(ent) ((ent)->id)
+#define media_entity_graph_walk_init(a, b) 0
+#define media_entity_graph_walk_cleanup(a) do { } while (0)
+
+#define IPU_COMPAT_MAX_ENTITIES MEDIA_ENTITY_ENUM_MAX_ID
+
+struct media_entity_enum {
+	unsigned long *bmap;
+	int idx_max;
+};
+
+static inline int media_entity_enum_init(struct media_entity_enum *ent_enum,
+			   struct media_device *mdev)
+{
+	int idx_max = IPU_COMPAT_MAX_ENTITIES;
+
+	ent_enum->bmap = kcalloc(DIV_ROUND_UP(idx_max, BITS_PER_LONG),
+				 sizeof(long), GFP_KERNEL);
+	if (!ent_enum->bmap)
+		return -ENOMEM;
+
+	bitmap_zero(ent_enum->bmap, idx_max);
+
+	ent_enum->idx_max = idx_max;
+	return 0;
+}
+
+static inline void media_entity_enum_cleanup(struct media_entity_enum *ent_enum)
+{
+	kfree(ent_enum->bmap);
+}
+
+static inline void media_entity_enum_set(struct media_entity_enum *ent_enum,
+					 struct media_entity *entity)
+{
+	if (media_entity_id(entity) >= ent_enum->idx_max) {
+		WARN_ON(1);
+		return;
+	}
+	__set_bit(media_entity_id(entity), ent_enum->bmap);
+}
+
+static inline void media_entity_enum_zero(struct media_entity_enum *ent_enum)
+{
+	bitmap_zero(ent_enum->bmap, ent_enum->idx_max);
+}
+
+static inline bool media_entity_enum_test(struct media_entity_enum *ent_enum,
+					  struct media_entity *entity)
+{
+	if (media_entity_id(entity) >= ent_enum->idx_max) {
+		WARN_ON(1);
+		return false;
+	}
+
+	return test_bit(media_entity_id(entity), ent_enum->bmap);
+}
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(4, 14, 0)
+#define media_pipeline_start(e, p) media_entity_pipeline_start(e, p)
+
+#define media_pipeline_stop(e) media_entity_pipeline_stop(e)
+
+#define media_graph_walk_init(g, d) media_entity_graph_walk_init(g, d)
+
+#define media_graph_walk_start(g, p) media_entity_graph_walk_start(g, p)
+
+#define media_graph_walk_next(g) media_entity_graph_walk_next(g)
+
+#define media_graph_walk_cleanup(g) media_entity_graph_walk_cleanup(g)
+#endif
+
 struct __packed media_request_cmd {
 	__u32 cmd;
 	__u32 request;
@@ -54,24 +134,5 @@ struct media_device_request {
 	u32 flags;
 };
 
-static inline struct media_device_request *
-media_device_request_find(struct media_device *mdev, u16 reqid)
-{
-	return NULL;
-}
-
-static inline void media_device_request_get(struct media_device_request *req)
-{
-}
-
-static inline void media_device_request_put(struct media_device_request *req)
-{
-}
-
-static inline void
-media_device_request_complete(struct media_device *mdev,
-			      struct media_device_request *req)
-{
-}
 
 #endif /* IPU_ISYS_MEDIA_H */
diff --git a/drivers/media/pci/intel/ipu-isys-queue.c b/drivers/media/pci/intel/ipu-isys-queue.c
index b415df667e82..45d67e9a83c6 100644
--- a/drivers/media/pci/intel/ipu-isys-queue.c
+++ b/drivers/media/pci/intel/ipu-isys-queue.c
@@ -1,5 +1,5 @@
 // SPDX-License-Identifier: GPL-2.0
-// Copyright (C) 2013 - 2020 Intel Corporation
+// Copyright (C) 2013 - 2018 Intel Corporation
 
 #include <linux/completion.h>
 #include <linux/device.h>
@@ -22,25 +22,58 @@ module_param(wall_clock_ts_on, bool, 0660);
 MODULE_PARM_DESC(wall_clock_ts_on, "Timestamp based on REALTIME clock");
 
 static int queue_setup(struct vb2_queue *q,
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 5, 0)
+		       const struct v4l2_format *__fmt,
+#endif
 		       unsigned int *num_buffers, unsigned int *num_planes,
 		       unsigned int sizes[],
-		       struct device *alloc_devs[])
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0)
+		       void *alloc_ctxs[]
+#else
+		       struct device *alloc_devs[]
+#endif
+			)
 {
 	struct ipu_isys_queue *aq = vb2_queue_to_ipu_isys_queue(q);
 	struct ipu_isys_video *av = ipu_isys_queue_to_video(aq);
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 4, 0)
+	const struct v4l2_format *fmt = __fmt;
+	const struct ipu_isys_pixelformat *pfmt;
+	struct v4l2_pix_format_mplane mpix;
+#else
 	bool use_fmt = false;
+#endif
 	unsigned int i;
 
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 4, 0)
+	if (fmt)
+		mpix = fmt->fmt.pix_mp;
+	else
+		mpix = av->mpix;
+
+	pfmt = av->try_fmt_vid_mplane(av, &mpix);
+
+	*num_planes = mpix.num_planes;
+#else
 	/* num_planes == 0: we're being called through VIDIOC_REQBUFS */
 	if (!*num_planes) {
 		use_fmt = true;
 		*num_planes = av->mpix.num_planes;
 	}
+#endif
 
 	for (i = 0; i < *num_planes; i++) {
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 4, 0)
+		sizes[i] = mpix.plane_fmt[i].sizeimage;
+#else
 		if (use_fmt)
 			sizes[i] = av->mpix.plane_fmt[i].sizeimage;
+#endif
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0)
+		alloc_ctxs[i] = aq->ctx;
+#else
 		alloc_devs[i] = aq->dev;
+#endif
 		dev_dbg(&av->isys->adev->dev,
 			"%s: queue setup: plane %d size %u\n",
 			av->vdev.name, i, sizes[i]);
@@ -49,7 +82,7 @@ static int queue_setup(struct vb2_queue *q,
 	return 0;
 }
 
-static void ipu_isys_queue_lock(struct vb2_queue *q)
+void ipu_isys_queue_lock(struct vb2_queue *q)
 {
 	struct ipu_isys_queue *aq = vb2_queue_to_ipu_isys_queue(q);
 	struct ipu_isys_video *av = ipu_isys_queue_to_video(aq);
@@ -58,7 +91,7 @@ static void ipu_isys_queue_lock(struct vb2_queue *q)
 	mutex_lock(&av->mutex);
 }
 
-static void ipu_isys_queue_unlock(struct vb2_queue *q)
+void ipu_isys_queue_unlock(struct vb2_queue *q)
 {
 	struct ipu_isys_queue *aq = vb2_queue_to_ipu_isys_queue(q);
 	struct ipu_isys_video *av = ipu_isys_queue_to_video(aq);
@@ -96,7 +129,11 @@ int ipu_isys_buf_prepare(struct vb2_buffer *vb)
 
 	vb2_set_plane_payload(vb, 0, av->mpix.plane_fmt[0].bytesperline *
 			      av->mpix.height);
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 4, 0)
+	vb->v4l2_planes[0].data_offset = av->line_header_length / BITS_PER_BYTE;
+#else
 	vb->planes[0].data_offset = av->line_header_length / BITS_PER_BYTE;
+#endif
 
 	return 0;
 }
@@ -105,12 +142,61 @@ static int buf_prepare(struct vb2_buffer *vb)
 {
 	struct ipu_isys_queue *aq = vb2_queue_to_ipu_isys_queue(vb->vb2_queue);
 	struct ipu_isys_video *av = ipu_isys_queue_to_video(aq);
+	struct ipu_isys_buffer *ib = vb2_buffer_to_ipu_isys_buffer(vb);
+	struct vb2_v4l2_buffer *b = to_vb2_v4l2_buffer(vb);
+	struct ipu_isys_request *ireq;
+	u32 request_state;
+	unsigned long flags;
 	int rval;
 
 	if (av->isys->adev->isp->flr_done)
 		return -EIO;
 
+	if (b->flags & V4L2_BUF_FLAG_REQUEST_FD) {
+		ib->req = media_request_get_by_fd(&av->isys->media_dev, b->request_fd);
+		if (IS_ERR(ib->req)) {
+			dev_err(&av->isys->adev->dev,
+				"can't find request %u (%ld)\n", b->request_fd, PTR_ERR(ib->req));
+			return ib->req;
+		} else if (!ib->req) {
+			dev_dbg(&av->isys->adev->dev,
+				"can't find request %u\n", b->request_fd);
+			return -ENOENT;
+		}
+	}
+
 	rval = aq->buf_prepare(vb);
+	if (!ib->req)
+		return rval;
+	if (rval)
+		goto out_put_request;
+
+	ireq = to_ipu_isys_request(ib->req);
+
+	spin_lock_irqsave(&ireq->lock, flags);
+	spin_lock(&ib->req->lock);
+	request_state = ib->req->state;
+	if (request_state == MEDIA_DEVICE_REQUEST_STATE_IDLE)
+		list_add(&ib->req_head, &ireq->buffers);
+	spin_unlock(&ib->req->lock);
+	spin_unlock_irqrestore(&ireq->lock, flags);
+	if (request_state != MEDIA_DEVICE_REQUEST_STATE_IDLE) {
+		dev_dbg(&av->isys->adev->dev,
+			"%s[%s]: request state %u\n", __func__, ib->req->debug_str,
+			request_state);
+		rval = -EINVAL;
+	} else {
+		dev_dbg(&av->isys->adev->dev,
+			"%s[%s]: request\n", __func__, ib->req->debug_str);
+	}
+
+	if (!rval)
+		return 0;
+
+out_put_request:
+	media_request_put(ib->req);
+	ib->req = NULL;
+
 	return rval;
 }
 
@@ -118,10 +204,32 @@ static void buf_finish(struct vb2_buffer *vb)
 {
 	struct ipu_isys_queue *aq = vb2_queue_to_ipu_isys_queue(vb->vb2_queue);
 	struct ipu_isys_video *av = ipu_isys_queue_to_video(aq);
+	struct ipu_isys_buffer *ib = vb2_buffer_to_ipu_isys_buffer(vb);
 
 	dev_dbg(&av->isys->adev->dev, "buffer: %s: %s\n", av->vdev.name,
 		__func__);
 
+	if (ib->req) {
+		struct ipu_isys_request *ireq = to_ipu_isys_request(ib->req);
+		unsigned long flags;
+		bool done;
+
+		spin_lock_irqsave(&ireq->lock, flags);
+		list_del(&ib->req_head);
+		done = list_empty(&ireq->buffers);
+		spin_unlock_irqrestore(&ireq->lock, flags);
+		dev_dbg(&av->isys->adev->dev, "%s: request complete %s\n",
+			ib->req->debug_str, done ? "true" : "false");
+		if (done) {
+			v4l2_ctrl_request_complete(ib->req,
+						      av->vdev.ctrl_handler);
+			mutex_lock(&av->isys->stream_mutex);
+			list_del(&ireq->head);
+			mutex_unlock(&av->isys->stream_mutex);
+		}
+		media_request_put(ib->req);
+		ib->req = NULL;
+	}
 }
 
 static void buf_cleanup(struct vb2_buffer *vb)
@@ -196,7 +304,7 @@ void ipu_isys_buffer_list_queue(struct ipu_isys_buffer_list *bl,
 
 		if (first) {
 			dev_dbg(&av->isys->adev->dev,
-				"queue buf list %p flags %lx, s %d, %d bufs\n",
+				"queue buffer list %p op_flags %lx, state %d, %d buffers\n",
 				bl, op_flags, state, bl->nbufs);
 			first = false;
 		}
@@ -235,7 +343,11 @@ static void flush_firmware_streamon_fail(struct ipu_isys_pipeline *ip)
 				dev_dbg(&av->isys->adev->dev,
 					"%s: queue buffer %u back to incoming\n",
 					av->vdev.name,
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 4, 0)
+					vb->v4l2_buf.index);
+#else
 					vb->index);
+#endif
 				/* Queue already streaming, return to driver. */
 				list_add(&ib->head, &aq->incoming);
 				continue;
@@ -244,7 +356,11 @@ static void flush_firmware_streamon_fail(struct ipu_isys_pipeline *ip)
 			dev_dbg(&av->isys->adev->dev,
 				"%s: return %u back to videobuf2\n",
 				av->vdev.name,
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 4, 0)
+				vb->v4l2_buf.index);
+#else
 				vb->index);
+#endif
 			vb2_buffer_done(ipu_isys_buffer_to_vb2_buffer(ib),
 					VB2_BUF_STATE_QUEUED);
 		}
@@ -289,7 +405,11 @@ static int buffer_list_get(struct ipu_isys_pipeline *ip,
 
 		dev_dbg(&ip->isys->adev->dev, "buffer: %s: buffer %u\n",
 			ipu_isys_queue_to_video(aq)->vdev.name,
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 4, 0)
+			ipu_isys_buffer_to_vb2_buffer(ib)->v4l2_buf.index
+#else
 			ipu_isys_buffer_to_vb2_buffer(ib)->index
+#endif
 		    );
 		list_del(&ib->head);
 		list_add(&ib->head, &bl->head);
@@ -309,14 +429,19 @@ static int buffer_list_get(struct ipu_isys_pipeline *ip,
 	/* Get short packet buffer. */
 	if (ip->interlaced && ip->isys->short_packet_source ==
 	    IPU_ISYS_SHORT_PACKET_FROM_RECEIVER) {
-		ib = ipu_isys_csi2_get_short_packet_buffer(ip, bl);
+		spin_lock_irqsave(&ip->short_packet_queue_lock, flags);
+		ib = ipu_isys_csi2_get_short_packet_buffer(ip);
 		if (!ib) {
+			spin_unlock_irqrestore(&ip->short_packet_queue_lock,
+					       flags);
 			ret = -ENODATA;
 			dev_err(&ip->isys->adev->dev,
 				"No more short packet buffers. Driver bug?");
 			WARN_ON(1);
 			goto error;
 		}
+		list_move(&ib->head, &bl->head);
+		spin_unlock_irqrestore(&ip->short_packet_queue_lock, flags);
 		bl->nbufs++;
 	}
 
@@ -331,31 +456,30 @@ static int buffer_list_get(struct ipu_isys_pipeline *ip,
 	return ret;
 }
 
-void
-ipu_isys_buffer_to_fw_frame_buff_pin(struct vb2_buffer *vb,
-				     struct ipu_fw_isys_frame_buff_set_abi *set)
+void ipu_isys_buffer_list_to_ipu_fw_isys_frame_buff_set_pin(
+			struct vb2_buffer *vb,
+			struct ipu_fw_isys_frame_buff_set_abi *set)
 {
 	struct ipu_isys_queue *aq = vb2_queue_to_ipu_isys_queue(vb->vb2_queue);
-	struct ipu_isys_video *av = container_of(aq, struct ipu_isys_video, aq);
-
-	if (av->compression)
-		set->output_pins[aq->fw_output].compress = 1;
 
 	set->output_pins[aq->fw_output].addr =
 	    vb2_dma_contig_plane_dma_addr(vb, 0);
 	set->output_pins[aq->fw_output].out_buf_id =
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 4, 0)
+	    vb->v4l2_buf.index + 1;
+#else
 	    vb->index + 1;
+#endif
 }
 
 /*
  * Convert a buffer list to a isys fw ABI framebuffer set. The
  * buffer list is not modified.
  */
-#define IPU_ISYS_FRAME_NUM_THRESHOLD  (30)
-void
-ipu_isys_buffer_to_fw_frame_buff(struct ipu_fw_isys_frame_buff_set_abi *set,
-				 struct ipu_isys_pipeline *ip,
-				 struct ipu_isys_buffer_list *bl)
+void ipu_isys_buffer_list_to_ipu_fw_isys_frame_buff_set(
+			struct ipu_fw_isys_frame_buff_set_abi *set,
+			struct ipu_isys_pipeline *ip,
+			struct ipu_isys_buffer_list *bl)
 {
 	struct ipu_isys_buffer *ib;
 
@@ -363,22 +487,16 @@ ipu_isys_buffer_to_fw_frame_buff(struct ipu_fw_isys_frame_buff_set_abi *set,
 
 	set->send_irq_sof = 1;
 	set->send_resp_sof = 1;
+
+#if defined(CONFIG_VIDEO_INTEL_IPU4) || defined(CONFIG_VIDEO_INTEL_IPU4P)
+	set->send_irq_capture_ack = 1;
+	set->send_irq_capture_done = 1;
+	set->send_irq_eof = 1;
+	set->send_resp_eof = 1;
+#else
 	set->send_irq_eof = 0;
 	set->send_resp_eof = 0;
-
-	if (ip->streaming)
-		set->send_irq_capture_ack = 0;
-	else
-		set->send_irq_capture_ack = 1;
-	set->send_irq_capture_done = 0;
-
-	set->send_resp_capture_ack = 1;
-	set->send_resp_capture_done = 1;
-	if (!ip->interlaced &&
-	    atomic_read(&ip->sequence) >= IPU_ISYS_FRAME_NUM_THRESHOLD) {
-		set->send_resp_capture_ack = 0;
-		set->send_resp_capture_done = 0;
-	}
+#endif
 
 	list_for_each_entry(ib, &bl->head, head) {
 		if (ib->type == IPU_ISYS_VIDEO_BUFFER) {
@@ -403,13 +521,79 @@ ipu_isys_buffer_to_fw_frame_buff(struct ipu_fw_isys_frame_buff_set_abi *set,
 	}
 }
 
+static void
+ipu_isys_req_dispatch(struct media_device *mdev,
+		      struct ipu_isys_request *ireq,
+		      struct ipu_isys_pipeline *ip,
+		      struct ipu_fw_isys_frame_buff_set_abi *set,
+		      dma_addr_t dma_addr);
+
+struct ipu_isys_request *ipu_isys_next_queued_request(struct ipu_isys_pipeline
+						      *ip)
+{
+	struct ipu_isys *isys =
+	    container_of(ip, struct ipu_isys_video, ip)->isys;
+	struct ipu_isys_request *ireq;
+	struct ipu_isys_buffer *ib;
+	unsigned long flags;
+
+	lockdep_assert_held(&isys->stream_mutex);
+
+	if (list_empty(&isys->requests)) {
+		dev_dbg(&isys->adev->dev, "%s: no requests found\n", __func__);
+		return NULL;
+	}
+
+	list_for_each_entry_reverse(ireq, &isys->requests, head) {
+		/* Does the request belong to this pipeline? */
+		bool is_ours = false;
+		bool is_others = false;
+
+		dev_dbg(&isys->adev->dev, "%s[%s]: checking request\n",
+			__func__, ireq->req.debug_str);
+
+		spin_lock_irqsave(&ireq->lock, flags);
+		list_for_each_entry(ib, &ireq->buffers, req_head) {
+			struct vb2_buffer *vb =
+			    ipu_isys_buffer_to_vb2_buffer(ib);
+			struct ipu_isys_queue *aq =
+			    vb2_queue_to_ipu_isys_queue(vb->vb2_queue);
+			struct ipu_isys_video *av = ipu_isys_queue_to_video(aq);
+
+			dev_dbg(&isys->adev->dev, "%s: buffer in vdev %s\n",
+				__func__, av->vdev.name);
+
+			if (media_entity_enum_test(&ip->entity_enum,
+						   &av->vdev.entity))
+				is_ours = true;
+			else
+				is_others = true;
+		}
+		spin_unlock_irqrestore(&ireq->lock, flags);
+
+		dev_dbg(&isys->adev->dev, "%s: is%s ours, is%s others'\n",
+			__func__, is_ours ? "" : "n't", is_others ? "" : "n't");
+
+		if (!is_ours || WARN_ON(is_others))
+			continue;
+
+		list_del_init(&ireq->head);
+
+		return ireq;
+	}
+
+	return NULL;
+}
+
 /* Start streaming for real. The buffer list must be available. */
 static int ipu_isys_stream_start(struct ipu_isys_pipeline *ip,
 				 struct ipu_isys_buffer_list *bl, bool error)
 {
 	struct ipu_isys_video *pipe_av =
 	    container_of(ip, struct ipu_isys_video, ip);
+	struct media_device *mdev = &pipe_av->isys->media_dev;
 	struct ipu_isys_buffer_list __bl;
+	struct ipu_isys_request *ireq;
 	int rval;
 
 	mutex_lock(&pipe_av->isys->stream_mutex);
@@ -422,6 +606,35 @@ static int ipu_isys_stream_start(struct ipu_isys_pipeline *ip,
 
 	ip->streaming = 1;
 
+	dev_dbg(&pipe_av->isys->adev->dev, "dispatching queued requests\n");
+
+	while ((ireq = ipu_isys_next_queued_request(ip))) {
+		struct ipu_fw_isys_frame_buff_set_abi *set;
+		struct isys_fw_msgs *msg;
+
+		msg = ipu_get_fw_msg_buf(ip);
+		if (!msg) {
+			/* TODO: A PROPER CLEAN UP */
+			mutex_unlock(&pipe_av->isys->stream_mutex);
+			return -ENOMEM;
+		}
+
+		set = to_frame_msg_buf(msg);
+
+		rval = ipu_isys_req_prepare(mdev, ireq, ip, set);
+		if (rval) {
+			mutex_unlock(&pipe_av->isys->stream_mutex);
+			goto out_requeue;
+		}
+
+		ipu_fw_isys_dump_frame_buff_set(&pipe_av->isys->adev->dev, set,
+						ip->nr_output_pins);
+		ipu_isys_req_dispatch(mdev, ireq, ip, set, to_dma_addr(msg));
+	}
+
+	dev_dbg(&pipe_av->isys->adev->dev,
+		"done dispatching queued requests\n");
+
 	mutex_unlock(&pipe_av->isys->stream_mutex);
 
 	bl = &__bl;
@@ -429,8 +642,6 @@ static int ipu_isys_stream_start(struct ipu_isys_pipeline *ip,
 	do {
 		struct ipu_fw_isys_frame_buff_set_abi *buf = NULL;
 		struct isys_fw_msgs *msg;
-		enum ipu_fw_isys_send_type send_type =
-		    IPU_FW_ISYS_SEND_TYPE_STREAM_CAPTURE;
 
 		rval = buffer_list_get(ip, bl);
 		if (rval == -EINVAL)
@@ -440,11 +651,12 @@ static int ipu_isys_stream_start(struct ipu_isys_pipeline *ip,
 
 		msg = ipu_get_fw_msg_buf(ip);
 		if (!msg)
+			/* TODO: PROPER CLEANUP */
 			return -ENOMEM;
 
 		buf = to_frame_msg_buf(msg);
 
-		ipu_isys_buffer_to_fw_frame_buff(buf, ip, bl);
+		ipu_isys_buffer_list_to_ipu_fw_isys_frame_buff_set(buf, ip, bl);
 
 		ipu_fw_isys_dump_frame_buff_set(&pipe_av->isys->adev->dev, buf,
 						ip->nr_output_pins);
@@ -453,11 +665,11 @@ static int ipu_isys_stream_start(struct ipu_isys_pipeline *ip,
 					   IPU_ISYS_BUFFER_LIST_FL_ACTIVE, 0);
 
 		rval = ipu_fw_isys_complex_cmd(pipe_av->isys,
-					       ip->stream_handle,
-					       buf, to_dma_addr(msg),
-					       sizeof(*buf),
-					       send_type);
-		ipu_put_fw_mgs_buf(pipe_av->isys, (uintptr_t)buf);
+					ip->stream_handle,
+					buf, to_dma_addr(msg),
+					sizeof(*buf),
+					IPU_FW_ISYS_SEND_TYPE_STREAM_CAPTURE);
+		ipu_put_fw_mgs_buffer(pipe_av->isys, (uintptr_t) buf);
 	} while (!WARN_ON(rval));
 
 	return 0;
@@ -496,12 +708,16 @@ static void __buf_queue(struct vb2_buffer *vb, bool force)
 
 	dev_dbg(&av->isys->adev->dev, "buffer: %s: buf_queue %u\n",
 		av->vdev.name,
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 4, 0)
+		vb->v4l2_buf.index
+#else
 		vb->index
+#endif
 	    );
 
 	for (i = 0; i < vb->num_planes; i++)
 		dev_dbg(&av->isys->adev->dev, "iova: plane %u iova 0x%x\n", i,
-			(u32)vb2_dma_contig_plane_dma_addr(vb, i));
+			(u32) vb2_dma_contig_plane_dma_addr(vb, i));
 
 	spin_lock_irqsave(&aq->lock, flags);
 	list_add(&ib->head, &aq->incoming);
@@ -550,18 +766,18 @@ static void __buf_queue(struct vb2_buffer *vb, bool force)
 	}
 	buf = to_frame_msg_buf(msg);
 
-	ipu_isys_buffer_to_fw_frame_buff(buf, ip, &bl);
+	ipu_isys_buffer_list_to_ipu_fw_isys_frame_buff_set(buf, ip, &bl);
 
 	ipu_fw_isys_dump_frame_buff_set(&pipe_av->isys->adev->dev, buf,
 					ip->nr_output_pins);
 
 	if (!ip->streaming) {
 		dev_dbg(&av->isys->adev->dev,
-			"got a buffer to start streaming!\n");
+			"Wow! Got a buffer to start streaming!\n");
 		rval = ipu_isys_stream_start(ip, &bl, true);
 		if (rval)
 			dev_err(&av->isys->adev->dev,
-				"stream start failed.\n");
+				"Ouch. Stream start failed.\n");
 		goto out;
 	}
 
@@ -578,7 +794,11 @@ static void __buf_queue(struct vb2_buffer *vb, bool force)
 				       buf, to_dma_addr(msg),
 				       sizeof(*buf),
 				       IPU_FW_ISYS_SEND_TYPE_STREAM_CAPTURE);
-	ipu_put_fw_mgs_buf(pipe_av->isys, (uintptr_t)buf);
+	ipu_put_fw_mgs_buffer(pipe_av->isys, (uintptr_t) buf);
+	/*
+	 * FIXME: mark the buffers in the buffer list if the queue
+	 * operation fails.
+	 */
 	if (!WARN_ON(rval < 0))
 		dev_dbg(&av->isys->adev->dev, "queued buffer\n");
 
@@ -610,6 +830,7 @@ int ipu_isys_link_fmt_validate(struct ipu_isys_queue *aq)
 
 	fmt.which = V4L2_SUBDEV_FORMAT_ACTIVE;
 	fmt.pad = pad->index;
+	fmt.stream = 0;
 	rval = v4l2_subdev_call(sd, pad, get_fmt, NULL, &fmt);
 	if (rval)
 		return rval;
@@ -665,7 +886,11 @@ static void return_buffers(struct ipu_isys_queue *aq,
 			"%s: stop_streaming incoming %u\n",
 			ipu_isys_queue_to_video(vb2_queue_to_ipu_isys_queue
 						(vb->vb2_queue))->vdev.name,
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 4, 0)
+			vb->v4l2_buf.index);
+#else
 			vb->index);
+#endif
 
 		spin_lock_irqsave(&aq->lock, flags);
 	}
@@ -690,7 +915,11 @@ static void return_buffers(struct ipu_isys_queue *aq,
 		dev_warn(&av->isys->adev->dev, "%s: cleaning active queue %u\n",
 			 ipu_isys_queue_to_video(vb2_queue_to_ipu_isys_queue
 						 (vb->vb2_queue))->vdev.name,
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 4, 0)
+			 vb->v4l2_buf.index);
+#else
 			 vb->index);
+#endif
 
 		spin_lock_irqsave(&aq->lock, flags);
 		reset_needed = 1;
@@ -759,7 +988,7 @@ static int start_streaming(struct vb2_queue *q, unsigned int count)
 			goto out_stream_start;
 		} else if (rval < 0) {
 			dev_dbg(&av->isys->adev->dev,
-				"no request available, postponing streamon\n");
+				"no request available --- postponing streamon\n");
 			goto out;
 		}
 	}
@@ -831,20 +1060,13 @@ get_sof_sequence_by_timestamp(struct ipu_isys_pipeline *ip,
 {
 	struct ipu_isys *isys =
 	    container_of(ip, struct ipu_isys_video, ip)->isys;
-	u64 time = (u64)info->timestamp[1] << 32 | info->timestamp[0];
+	u64 time = (u64) info->timestamp[1] << 32 | info->timestamp[0];
 	unsigned int i;
 
-	/*
-	 * The timestamp is invalid as no TSC in some FPGA platform,
-	 * so get the sequence from pipeline directly in this case.
-	 */
-	if (time == 0)
-		return atomic_read(&ip->sequence) - 1;
-
 	for (i = 0; i < IPU_ISYS_MAX_PARALLEL_SOF; i++)
 		if (time == ip->seq[i].timestamp) {
 			dev_dbg(&isys->adev->dev,
-				"sof: using seq nr %u for ts 0x%16.16llx\n",
+				"sof: using sequence number %u for timestamp 0x%16.16llx\n",
 				ip->seq[i].sequence, time);
 			return ip->seq[i].sequence;
 		}
@@ -868,11 +1090,11 @@ static u64 get_sof_ns_delta(struct ipu_isys_video *av,
 
 	if (!ipu_buttress_tsc_read(isp, &tsc_now))
 		delta = tsc_now -
-		    ((u64)info->timestamp[1] << 32 | info->timestamp[0]);
+		    ((u64) info->timestamp[1] << 32 | info->timestamp[0]);
 	else
 		delta = 0;
 
-	return ipu_buttress_tsc_ticks_to_ns(delta, isp);
+	return ipu_buttress_tsc_ticks_to_ns(delta);
 }
 
 void
@@ -880,10 +1102,14 @@ ipu_isys_buf_calc_sequence_time(struct ipu_isys_buffer *ib,
 				struct ipu_fw_isys_resp_info_abi *info)
 {
 	struct vb2_buffer *vb = ipu_isys_buffer_to_vb2_buffer(ib);
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 4, 0)
 	struct vb2_v4l2_buffer *vbuf = to_vb2_v4l2_buffer(vb);
+#endif
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 5, 0)
+	struct timespec ts_now;
+#endif
 	struct ipu_isys_queue *aq = vb2_queue_to_ipu_isys_queue(vb->vb2_queue);
 	struct ipu_isys_video *av = ipu_isys_queue_to_video(aq);
-	struct device *dev = &av->isys->adev->dev;
 	struct ipu_isys_pipeline *ip =
 	    to_ipu_isys_pipeline(av->vdev.entity.pipe);
 	u64 ns;
@@ -900,13 +1126,29 @@ ipu_isys_buf_calc_sequence_time(struct ipu_isys_buffer *ib,
 		    / ip->nr_queues;
 	}
 
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 4, 0)
+	vb->v4l2_buf.sequence = sequence;
+	ts_now = ns_to_timespec(ns);
+	vb->v4l2_buf.timestamp.tv_sec = ts_now.tv_sec;
+	vb->v4l2_buf.timestamp.tv_usec = ts_now.tv_nsec / NSEC_PER_USEC;
+
+	dev_dbg(&av->isys->adev->dev, "buffer: %s: buffer done %u\n",
+		av->vdev.name, vb->v4l2_buf.index);
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(4, 5, 0)
+	vbuf->sequence = sequence;
+	ts_now = ns_to_timespec(ns);
+	vbuf->timestamp.tv_sec = ts_now.tv_sec;
+	vbuf->timestamp.tv_usec = ts_now.tv_nsec / NSEC_PER_USEC;
+
+	dev_dbg(&av->isys->adev->dev, "%s: buffer done %u\n", av->vdev.name,
+		vb->index);
+#else
 	vbuf->vb2_buf.timestamp = ns;
 	vbuf->sequence = sequence;
 
-	dev_dbg(dev, "buf: %s: buffer done, CPU-timestamp:%lld, sequence:%d\n",
-		av->vdev.name, ktime_get_ns(), sequence);
-	dev_dbg(dev, "index:%d, vbuf timestamp:%lld, endl\n",
-		vb->index, vbuf->vb2_buf.timestamp);
+	dev_dbg(&av->isys->adev->dev, "buffer: %s: buffer done, CPU-timestamp:%lld, sequence:%d, vc:%d, index:%d, vbuf timestamp:%lld, endl\n",
+		av->vdev.name, ktime_get_ns(), sequence, ip->vc, vb->index, vbuf->vb2_buf.timestamp);
+#endif
 }
 
 void ipu_isys_queue_buf_done(struct ipu_isys_buffer *ib)
@@ -935,7 +1177,11 @@ void ipu_isys_queue_buf_ready(struct ipu_isys_pipeline *ip,
 	struct vb2_buffer *vb;
 	unsigned long flags;
 	bool first = true;
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 4, 0)
+	struct v4l2_buffer *buf;
+#else
 	struct vb2_v4l2_buffer *buf;
+#endif
 
 	dev_dbg(&isys->adev->dev, "buffer: %s: received buffer %8.8x\n",
 		ipu_isys_queue_to_video(aq)->vdev.name, info->pin.addr);
@@ -956,7 +1202,7 @@ void ipu_isys_queue_buf_ready(struct ipu_isys_pipeline *ip,
 		if (info->pin.addr != addr) {
 			if (first)
 				dev_err(&isys->adev->dev,
-					"WARN: buffer address %pad expected!\n",
+					"WARNING: buffer address %pad expected!\n",
 					&addr);
 			first = false;
 			continue;
@@ -972,9 +1218,22 @@ void ipu_isys_queue_buf_ready(struct ipu_isys_pipeline *ip,
 		}
 		dev_dbg(&isys->adev->dev, "buffer: found buffer %pad\n", &addr);
 
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 4, 0)
+		buf = &vb->v4l2_buf;
+#else
 		buf = to_vb2_v4l2_buffer(vb);
+#endif
 		buf->field = V4L2_FIELD_NONE;
 
+		/*
+		 * Use "reserved" field to pass csi2 index and vc.
+		 * May need to change to other approach.
+		 */
+		buf->reserved &= 0xFFFFFF00;
+		if (ip->csi2)
+			buf->reserved |= ip->csi2->index << 4;
+		buf->reserved |= ip->vc;
+
 		list_del(&ib->head);
 		spin_unlock_irqrestore(&aq->lock, flags);
 
@@ -1018,6 +1277,200 @@ ipu_isys_queue_short_packet_ready(struct ipu_isys_pipeline *ip,
 	spin_unlock_irqrestore(&ip->short_packet_queue_lock, flags);
 }
 
+void ipu_isys_req_free(struct media_request *req)
+{
+	struct ipu_isys_request *ireq = to_ipu_isys_request(req);
+
+	kfree(ireq);
+}
+
+struct
+media_request *ipu_isys_req_alloc(struct media_device *mdev)
+{
+	struct ipu_isys_request *ireq;
+
+	ireq = kzalloc(sizeof(*ireq), GFP_KERNEL);
+	if (!ireq)
+		return NULL;
+
+	INIT_LIST_HEAD(&ireq->buffers);
+	spin_lock_init(&ireq->lock);
+	INIT_LIST_HEAD(&ireq->head);
+
+	return &ireq->req;
+}
+
+int ipu_isys_req_prepare(struct media_device *mdev,
+			 struct ipu_isys_request *ireq,
+			 struct ipu_isys_pipeline *ip,
+			 struct ipu_fw_isys_frame_buff_set_abi *set)
+{
+	struct ipu_isys *isys =
+	    container_of(ip, struct ipu_isys_video, ip)->isys;
+	struct media_request *req = &ireq->req;
+	struct ipu_isys_buffer *ib;
+	unsigned long flags;
+
+	dev_dbg(&isys->adev->dev, "%s: preparing request\n", req->debug_str);
+
+	set->send_irq_sof = 1;
+	set->send_resp_sof = 1;
+	set->send_irq_eof = 1;
+	set->send_resp_eof = 1;
+#if defined(CONFIG_VIDEO_INTEL_IPU4) || defined(CONFIG_VIDEO_INTEL_IPU4P)
+	set->send_irq_capture_ack = 1;
+	set->send_irq_capture_done = 1;
+#endif
+
+	spin_lock_irqsave(&ireq->lock, flags);
+
+	list_for_each_entry(ib, &ireq->buffers, req_head) {
+		struct vb2_buffer *vb = ipu_isys_buffer_to_vb2_buffer(ib);
+		struct ipu_isys_queue *aq =
+		    vb2_queue_to_ipu_isys_queue(vb->vb2_queue);
+
+		if (aq->prepare_frame_buff_set)
+			aq->prepare_frame_buff_set(vb);
+
+		if (aq->fill_frame_buff_set_pin)
+			aq->fill_frame_buff_set_pin(vb, set);
+
+		spin_lock(&aq->lock);
+		list_move(&ib->head, &aq->active);
+		spin_unlock(&aq->lock);
+	}
+
+	spin_unlock_irqrestore(&ireq->lock, flags);
+
+	return 0;
+}
+
+static void
+ipu_isys_req_dispatch(struct media_device *mdev,
+		      struct ipu_isys_request *ireq,
+		      struct ipu_isys_pipeline *ip,
+		      struct ipu_fw_isys_frame_buff_set_abi *set,
+		      dma_addr_t dma_addr)
+{
+	struct ipu_isys_video *pipe_av =
+	    container_of(ip, struct ipu_isys_video, ip);
+	int rval;
+
+	rval = ipu_fw_isys_complex_cmd(pipe_av->isys,
+				       ip->stream_handle,
+				       set, dma_addr, sizeof(*set),
+				       IPU_FW_ISYS_SEND_TYPE_STREAM_CAPTURE);
+	ipu_put_fw_mgs_buffer(pipe_av->isys, (uintptr_t) set);
+
+	WARN_ON(rval);
+}
+
+void ipu_isys_req_queue(struct media_request *req)
+{
+    struct media_device *mdev = req->mdev;
+	struct ipu_isys *isys = container_of(mdev, struct ipu_isys, media_dev);
+	struct ipu_isys_request *ireq = to_ipu_isys_request(req);
+	struct ipu_isys_pipeline *ip;
+	struct ipu_isys_buffer *ib;
+	struct media_pipeline *pipe = NULL;
+	unsigned long flags;
+	bool no_pipe = false;
+	int rval = 0;
+
+	spin_lock_irqsave(&ireq->lock, flags);
+	if (list_empty(&ireq->buffers)) {
+		rval = -ENODATA;
+		goto out_list_empty;
+	}
+
+	/* Verify that all buffers are related to a single pipeline. */
+	list_for_each_entry(ib, &ireq->buffers, req_head) {
+		struct vb2_buffer *vb = ipu_isys_buffer_to_vb2_buffer(ib);
+		struct ipu_isys_queue *aq =
+		    vb2_queue_to_ipu_isys_queue(vb->vb2_queue);
+		struct ipu_isys_video *av = ipu_isys_queue_to_video(aq);
+
+		dev_dbg(&isys->adev->dev, "%s: device %s, id %u\n", __func__,
+			av->vdev.name, vb->
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 4, 0)
+			v4l2_buf.
+#endif
+			index);
+		if (!pipe) {
+			if (!av->vdev.entity.pipe) {
+				no_pipe = true;
+				continue;
+			}
+
+			pipe = av->vdev.entity.pipe;
+			dev_dbg(&isys->adev->dev, "%s: pipe %p\n",
+				av->vdev.name, pipe);
+			continue;
+		}
+
+		if (av->vdev.entity.pipe != pipe) {
+			dev_dbg(&isys->adev->dev,
+				"%s: request includes buffers in multiple pipelines\n",
+				req->debug_str);
+			rval = -EINVAL;
+			goto out_list_empty;
+		}
+	}
+
+	spin_unlock_irqrestore(&ireq->lock, flags);
+
+	mutex_lock(&isys->stream_mutex);
+
+	ip = to_ipu_isys_pipeline(pipe);
+
+	if (pipe && ip->streaming) {
+		struct isys_fw_msgs *msg;
+		struct ipu_fw_isys_frame_buff_set_abi *set;
+
+		msg = ipu_get_fw_msg_buf(ip);
+		if (!msg) {
+			rval = -ENOMEM;
+			goto out_mutex_unlock;
+		}
+
+		set = to_frame_msg_buf(msg);
+
+		if (no_pipe) {
+			dev_dbg(&isys->adev->dev,
+				"%s: request includes buffers in and outside pipelines\n",
+				req->debug_str);
+			rval = -EINVAL;
+			goto out_mutex_unlock;
+		}
+
+		dev_dbg(&isys->adev->dev,
+			"request has a pipeline, dispatching\n");
+		rval = ipu_isys_req_prepare(mdev, ireq, ip, set);
+		if (rval)
+			goto out_mutex_unlock;
+
+		ipu_fw_isys_dump_frame_buff_set(&isys->adev->dev, set,
+						ip->nr_output_pins);
+		ipu_isys_req_dispatch(mdev, ireq, ip, set, to_dma_addr(msg));
+	} else {
+		dev_dbg(&isys->adev->dev,
+			"%s[%s]: adding request to the mdev queue\n", __func__,
+			req->debug_str);
+
+		list_add(&ireq->head, &isys->requests);
+	}
+
+out_mutex_unlock:
+	mutex_unlock(&isys->stream_mutex);
+
+	return;
+
+out_list_empty:
+	spin_unlock_irqrestore(&ireq->lock, flags);
+
+	return;
+}
+
 struct vb2_ops ipu_isys_queue_ops = {
 	.queue_setup = queue_setup,
 	.wait_prepare = ipu_isys_queue_unlock,
@@ -1039,6 +1492,7 @@ int ipu_isys_queue_init(struct ipu_isys_queue *aq)
 	if (!aq->vbq.io_modes)
 		aq->vbq.io_modes = VB2_USERPTR | VB2_MMAP | VB2_DMABUF;
 	aq->vbq.drv_priv = aq;
+//	aq->vbq.allow_requests = true;
 	aq->vbq.ops = &ipu_isys_queue_ops;
 	aq->vbq.mem_ops = &vb2_dma_contig_memops;
 	aq->vbq.timestamp_flags = (wall_clock_ts_on) ?
@@ -1048,8 +1502,16 @@ int ipu_isys_queue_init(struct ipu_isys_queue *aq)
 	if (rval)
 		return rval;
 
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0)
+	aq->ctx = vb2_dma_contig_init_ctx(&isys->adev->dev);
+	if (IS_ERR(aq->ctx)) {
+		vb2_queue_release(&aq->vbq);
+		return PTR_ERR(aq->ctx);
+	}
+#else
 	aq->dev = &isys->adev->dev;
 	aq->vbq.dev = &isys->adev->dev;
+#endif
 	spin_lock_init(&aq->lock);
 	INIT_LIST_HEAD(&aq->active);
 	INIT_LIST_HEAD(&aq->incoming);
@@ -1059,5 +1521,12 @@ int ipu_isys_queue_init(struct ipu_isys_queue *aq)
 
 void ipu_isys_queue_cleanup(struct ipu_isys_queue *aq)
 {
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0)
+	if (IS_ERR_OR_NULL(aq->ctx))
+		return;
+
+	vb2_dma_contig_cleanup_ctx(aq->ctx);
+	aq->ctx = NULL;
+#endif
 	vb2_queue_release(&aq->vbq);
 }
diff --git a/drivers/media/pci/intel/ipu-isys-queue.h b/drivers/media/pci/intel/ipu-isys-queue.h
index 99be2989a088..3c0586954277 100644
--- a/drivers/media/pci/intel/ipu-isys-queue.h
+++ b/drivers/media/pci/intel/ipu-isys-queue.h
@@ -1,5 +1,5 @@
 /* SPDX-License-Identifier: GPL-2.0 */
-/* Copyright (C) 2013 - 2020 Intel Corporation */
+/* Copyright (C) 2013 - 2018 Intel Corporation */
 
 #ifndef IPU_ISYS_QUEUE_H
 #define IPU_ISYS_QUEUE_H
@@ -7,7 +7,11 @@
 #include <linux/list.h>
 #include <linux/spinlock.h>
 
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 4, 0)
+#include <media/videobuf2-core.h>
+#else
 #include <media/videobuf2-v4l2.h>
+#endif
 
 #include "ipu-isys-media.h"
 
@@ -24,7 +28,11 @@ enum ipu_isys_buffer_type {
 struct ipu_isys_queue {
 	struct list_head node;	/* struct ipu_isys_pipeline.queues */
 	struct vb2_queue vbq;
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0)
+	struct vb2_alloc_ctx *ctx;
+#else
 	struct device *dev;
+#endif
 	/*
 	 * @lock: serialise access to queued and pre_streamon_queued
 	 */
@@ -38,8 +46,8 @@ struct ipu_isys_queue {
 	int (*buf_prepare)(struct vb2_buffer *vb);
 	void (*prepare_frame_buff_set)(struct vb2_buffer *vb);
 	void (*fill_frame_buff_set_pin)(struct vb2_buffer *vb,
-					struct ipu_fw_isys_frame_buff_set_abi *
-					set);
+					 struct ipu_fw_isys_frame_buff_set_abi *
+					 set);
 	int (*link_fmt_validate)(struct ipu_isys_queue *aq);
 };
 
@@ -47,12 +55,16 @@ struct ipu_isys_buffer {
 	struct list_head head;
 	enum ipu_isys_buffer_type type;
 	struct list_head req_head;
-	struct media_device_request *req;
+	struct media_request *req;
 	atomic_t str2mmio_flag;
 };
 
 struct ipu_isys_video_buffer {
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 4, 0)
+	struct vb2_buffer vb;
+#else
 	struct vb2_v4l2_buffer vb_v4l2;
+#endif
 	struct ipu_isys_buffer ib;
 };
 
@@ -80,12 +92,20 @@ struct ipu_isys_buffer_list {
 #define ipu_isys_to_isys_video_buffer(__ib) \
 	container_of(__ib, struct ipu_isys_video_buffer, ib)
 
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 4, 0)
+#define vb2_buffer_to_ipu_isys_video_buffer(__vb) \
+	container_of(__vb, struct ipu_isys_video_buffer, vb)
+
+#define ipu_isys_buffer_to_vb2_buffer(__ib) \
+	(&ipu_isys_to_isys_video_buffer(__ib)->vb)
+#else
 #define vb2_buffer_to_ipu_isys_video_buffer(__vb) \
 	container_of(to_vb2_v4l2_buffer(__vb), \
 	struct ipu_isys_video_buffer, vb_v4l2)
 
 #define ipu_isys_buffer_to_vb2_buffer(__ib) \
 	(&ipu_isys_to_isys_video_buffer(__ib)->vb_v4l2.vb2_buf)
+#endif
 
 #define vb2_buffer_to_ipu_isys_buffer(__vb) \
 	(&vb2_buffer_to_ipu_isys_video_buffer(__vb)->ib)
@@ -94,7 +114,7 @@ struct ipu_isys_buffer_list {
 	container_of(__ib, struct ipu_isys_private_buffer, ib)
 
 struct ipu_isys_request {
-	struct media_device_request req;
+	struct media_request req;
 	/* serialise access to buffers */
 	spinlock_t lock;
 	struct list_head buffers;	/* struct ipu_isys_buffer.head */
@@ -109,21 +129,23 @@ struct ipu_isys_request {
 #define to_ipu_isys_request(__req) \
 	container_of(__req, struct ipu_isys_request, req)
 
+void ipu_isys_queue_lock(struct vb2_queue *q);
+void ipu_isys_queue_unlock(struct vb2_queue *q);
+
 int ipu_isys_buf_prepare(struct vb2_buffer *vb);
 
 void ipu_isys_buffer_list_queue(struct ipu_isys_buffer_list *bl,
 				unsigned long op_flags,
 				enum vb2_buffer_state state);
-struct ipu_isys_request *
-ipu_isys_next_queued_request(struct ipu_isys_pipeline *ip);
-void
-ipu_isys_buffer_to_fw_frame_buff_pin(struct vb2_buffer *vb,
-				     struct ipu_fw_isys_frame_buff_set_abi *
-				     set);
-void
-ipu_isys_buffer_to_fw_frame_buff(struct ipu_fw_isys_frame_buff_set_abi *set,
-				 struct ipu_isys_pipeline *ip,
-				 struct ipu_isys_buffer_list *bl);
+struct ipu_isys_request *ipu_isys_next_queued_request(
+				struct ipu_isys_pipeline *ip);
+void ipu_isys_buffer_list_to_ipu_fw_isys_frame_buff_set_pin(
+				struct vb2_buffer *vb,
+				struct ipu_fw_isys_frame_buff_set_abi *set);
+void ipu_isys_buffer_list_to_ipu_fw_isys_frame_buff_set(
+				struct ipu_fw_isys_frame_buff_set_abi *set,
+				struct ipu_isys_pipeline *ip,
+				struct ipu_isys_buffer_list *bl);
 int ipu_isys_link_fmt_validate(struct ipu_isys_queue *aq);
 
 void
@@ -136,6 +158,14 @@ void
 ipu_isys_queue_short_packet_ready(struct ipu_isys_pipeline *ip,
 				  struct ipu_fw_isys_resp_info_abi *inf);
 
+void ipu_isys_req_free(struct media_request *req);
+struct media_request *ipu_isys_req_alloc(struct media_device *mdev);
+int ipu_isys_req_prepare(struct media_device *mdev,
+			 struct ipu_isys_request *ireq,
+			 struct ipu_isys_pipeline *ip,
+			 struct ipu_fw_isys_frame_buff_set_abi *set);
+void ipu_isys_req_queue(struct media_request *req);
+
 int ipu_isys_queue_init(struct ipu_isys_queue *aq);
 void ipu_isys_queue_cleanup(struct ipu_isys_queue *aq);
 
diff --git a/drivers/media/pci/intel/ipu-isys-subdev.c b/drivers/media/pci/intel/ipu-isys-subdev.c
index 7f00fa817252..ad4fc8707823 100644
--- a/drivers/media/pci/intel/ipu-isys-subdev.c
+++ b/drivers/media/pci/intel/ipu-isys-subdev.c
@@ -1,5 +1,5 @@
 // SPDX-License-Identifier: GPL-2.0
-// Copyright (C) 2013 - 2020 Intel Corporation
+// Copyright (C) 2013 - 2018 Intel Corporation
 
 #include <linux/types.h>
 #include <linux/videodev2.h>
@@ -24,6 +24,11 @@ unsigned int ipu_isys_mbus_code_to_bpp(u32 code)
 	case MEDIA_BUS_FMT_UYVY8_1X16:
 	case MEDIA_BUS_FMT_YUYV8_1X16:
 		return 16;
+	case MEDIA_BUS_FMT_SBGGR14_1X14:
+	case MEDIA_BUS_FMT_SGBRG14_1X14:
+	case MEDIA_BUS_FMT_SGRBG14_1X14:
+	case MEDIA_BUS_FMT_SRGGB14_1X14:
+		return 14;
 	case MEDIA_BUS_FMT_SBGGR12_1X12:
 	case MEDIA_BUS_FMT_SGBRG12_1X12:
 	case MEDIA_BUS_FMT_SGRBG12_1X12:
@@ -61,6 +66,11 @@ unsigned int ipu_isys_mbus_code_to_mipi(u32 code)
 	case MEDIA_BUS_FMT_UYVY8_1X16:
 	case MEDIA_BUS_FMT_YUYV8_1X16:
 		return IPU_ISYS_MIPI_CSI2_TYPE_YUV422_8;
+	case MEDIA_BUS_FMT_SBGGR14_1X14:
+	case MEDIA_BUS_FMT_SGBRG14_1X14:
+	case MEDIA_BUS_FMT_SGRBG14_1X14:
+	case MEDIA_BUS_FMT_SRGGB14_1X14:
+		return IPU_ISYS_MIPI_CSI2_TYPE_RAW14;
 	case MEDIA_BUS_FMT_SBGGR12_1X12:
 	case MEDIA_BUS_FMT_SGBRG12_1X12:
 	case MEDIA_BUS_FMT_SGRBG12_1X12:
@@ -91,21 +101,25 @@ unsigned int ipu_isys_mbus_code_to_mipi(u32 code)
 enum ipu_isys_subdev_pixelorder ipu_isys_subdev_get_pixelorder(u32 code)
 {
 	switch (code) {
+	case MEDIA_BUS_FMT_SBGGR14_1X14:
 	case MEDIA_BUS_FMT_SBGGR12_1X12:
 	case MEDIA_BUS_FMT_SBGGR10_1X10:
 	case MEDIA_BUS_FMT_SBGGR8_1X8:
 	case MEDIA_BUS_FMT_SBGGR10_DPCM8_1X8:
 		return IPU_ISYS_SUBDEV_PIXELORDER_BGGR;
+	case MEDIA_BUS_FMT_SGBRG14_1X14:
 	case MEDIA_BUS_FMT_SGBRG12_1X12:
 	case MEDIA_BUS_FMT_SGBRG10_1X10:
 	case MEDIA_BUS_FMT_SGBRG8_1X8:
 	case MEDIA_BUS_FMT_SGBRG10_DPCM8_1X8:
 		return IPU_ISYS_SUBDEV_PIXELORDER_GBRG;
+	case MEDIA_BUS_FMT_SGRBG14_1X14:
 	case MEDIA_BUS_FMT_SGRBG12_1X12:
 	case MEDIA_BUS_FMT_SGRBG10_1X10:
 	case MEDIA_BUS_FMT_SGRBG8_1X8:
 	case MEDIA_BUS_FMT_SGRBG10_DPCM8_1X8:
 		return IPU_ISYS_SUBDEV_PIXELORDER_GRBG;
+	case MEDIA_BUS_FMT_SRGGB14_1X14:
 	case MEDIA_BUS_FMT_SRGGB12_1X12:
 	case MEDIA_BUS_FMT_SRGGB10_1X10:
 	case MEDIA_BUS_FMT_SRGGB8_1X8:
@@ -134,20 +148,37 @@ u32 ipu_isys_subdev_code_to_uncompressed(u32 sink_code)
 }
 
 struct v4l2_mbus_framefmt *__ipu_isys_get_ffmt(struct v4l2_subdev *sd,
-					       struct v4l2_subdev_state *sd_state,
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 1, 0)
+					       struct v4l2_subdev_fh *cfg,
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(5, 14, 0)
+					       struct v4l2_subdev_pad_config *cfg,
+#else
+			   struct v4l2_subdev_state *cfg,
+#endif
 					       unsigned int pad,
+					       unsigned int stream,
 					       unsigned int which)
 {
 	struct ipu_isys_subdev *asd = to_ipu_isys_subdev(sd);
 
 	if (which == V4L2_SUBDEV_FORMAT_ACTIVE)
-		return &asd->ffmt[pad];
+		return &asd->ffmt[pad][stream];
 	else
-		return v4l2_subdev_get_try_format(sd, sd_state, pad);
+		return v4l2_subdev_get_try_format(
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 1, 0)
+							 sd,
+#endif
+							 cfg, pad);
 }
 
 struct v4l2_rect *__ipu_isys_get_selection(struct v4l2_subdev *sd,
-					   struct v4l2_subdev_state *sd_state,
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 1, 0)
+					   struct v4l2_subdev_fh *cfg,
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(5, 14, 0)
+					   struct v4l2_subdev_pad_config *cfg,
+#else
+		       struct v4l2_subdev_state *cfg,
+#endif
 					   unsigned int target,
 					   unsigned int pad, unsigned int which)
 {
@@ -163,9 +194,17 @@ struct v4l2_rect *__ipu_isys_get_selection(struct v4l2_subdev *sd,
 	} else {
 		switch (target) {
 		case V4L2_SEL_TGT_CROP:
-			return v4l2_subdev_get_try_crop(sd, sd_state, pad);
+			return v4l2_subdev_get_try_crop(
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 1, 0)
+							       sd,
+#endif
+							       cfg, pad);
 		case V4L2_SEL_TGT_COMPOSE:
-			return v4l2_subdev_get_try_compose(sd, sd_state, pad);
+			return v4l2_subdev_get_try_compose(
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 1, 0)
+								  sd,
+#endif
+								  cfg, pad);
 		}
 	}
 	WARN_ON(1);
@@ -188,11 +227,17 @@ static int target_valid(struct v4l2_subdev *sd, unsigned int target,
 }
 
 int ipu_isys_subdev_fmt_propagate(struct v4l2_subdev *sd,
-				  struct v4l2_subdev_state *sd_state,
-				  struct v4l2_mbus_framefmt *ffmt,
-				  struct v4l2_rect *r,
-				  enum isys_subdev_prop_tgt tgt,
-				  unsigned int pad, unsigned int which)
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 1, 0)
+				   struct v4l2_subdev_fh *cfg,
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(5, 14, 0)
+				   struct v4l2_subdev_pad_config *cfg,
+#else
+		    struct v4l2_subdev_state *cfg,
+#endif
+				   struct v4l2_mbus_framefmt *ffmt,
+				   struct v4l2_rect *r,
+				   enum isys_subdev_prop_tgt tgt,
+				   unsigned int pad, unsigned int which)
 {
 	struct ipu_isys_subdev *asd = to_ipu_isys_subdev(sd);
 	struct v4l2_mbus_framefmt **ffmts = NULL;
@@ -220,18 +265,18 @@ int ipu_isys_subdev_fmt_propagate(struct v4l2_subdev *sd,
 		goto out_subdev_fmt_propagate;
 	}
 	compose = kcalloc(sd->entity.num_pads,
-			  sizeof(*compose), GFP_KERNEL);
+			sizeof(*compose), GFP_KERNEL);
 	if (!compose) {
 		rval = -ENOMEM;
 		goto out_subdev_fmt_propagate;
 	}
 
 	for (i = 0; i < sd->entity.num_pads; i++) {
-		ffmts[i] = __ipu_isys_get_ffmt(sd, sd_state, i, which);
-		crops[i] = __ipu_isys_get_selection(sd, sd_state,
-						    V4L2_SEL_TGT_CROP, i, which);
-		compose[i] = __ipu_isys_get_selection(sd, sd_state,
-						      V4L2_SEL_TGT_COMPOSE, i, which);
+		ffmts[i] = __ipu_isys_get_ffmt(sd, cfg, i, 0, which);
+		crops[i] = __ipu_isys_get_selection(
+			sd, cfg, V4L2_SEL_TGT_CROP, i, which);
+		compose[i] = __ipu_isys_get_selection(
+			sd, cfg, V4L2_SEL_TGT_COMPOSE, i, which);
 	}
 
 	switch (tgt) {
@@ -240,8 +285,8 @@ int ipu_isys_subdev_fmt_propagate(struct v4l2_subdev *sd,
 		crops[pad]->top = 0;
 		crops[pad]->width = ffmt->width;
 		crops[pad]->height = ffmt->height;
-		rval = ipu_isys_subdev_fmt_propagate(sd, sd_state, ffmt,
-						     crops[pad], tgt + 1, pad, which);
+		rval = ipu_isys_subdev_fmt_propagate(sd, cfg, ffmt, crops[pad],
+					      tgt + 1, pad, which);
 		goto out_subdev_fmt_propagate;
 	case IPU_ISYS_SUBDEV_PROP_TGT_SINK_CROP:
 		if (WARN_ON(sd->entity.pads[pad].flags & MEDIA_PAD_FL_SOURCE))
@@ -251,8 +296,9 @@ int ipu_isys_subdev_fmt_propagate(struct v4l2_subdev *sd,
 		compose[pad]->top = 0;
 		compose[pad]->width = r->width;
 		compose[pad]->height = r->height;
-		rval = ipu_isys_subdev_fmt_propagate(sd, sd_state, ffmt,
-						     compose[pad], tgt + 1, pad, which);
+		rval = ipu_isys_subdev_fmt_propagate(sd, cfg, ffmt,
+					      compose[pad], tgt + 1,
+					      pad, which);
 		goto out_subdev_fmt_propagate;
 	case IPU_ISYS_SUBDEV_PROP_TGT_SINK_COMPOSE:
 		if (WARN_ON(sd->entity.pads[pad].flags & MEDIA_PAD_FL_SOURCE)) {
@@ -260,19 +306,56 @@ int ipu_isys_subdev_fmt_propagate(struct v4l2_subdev *sd,
 			goto out_subdev_fmt_propagate;
 		}
 
-		for (i = 1; i < sd->entity.num_pads; i++) {
-			if (!(sd->entity.pads[i].flags &
-					MEDIA_PAD_FL_SOURCE))
-				continue;
-
-			compose[i]->left = 0;
-			compose[i]->top = 0;
-			compose[i]->width = r->width;
-			compose[i]->height = r->height;
-			rval = ipu_isys_subdev_fmt_propagate(sd, sd_state,
-							ffmt, compose[i], tgt + 1, i, which);
+		/* 1:n and 1:1 case: only propagate to the first source pad */
+		if (asd->nsinks == 1 && asd->nsources >= 1) {
+			compose[asd->nsinks]->left =
+			    compose[asd->nsinks]->top = 0;
+			compose[asd->nsinks]->width = r->width;
+			compose[asd->nsinks]->height = r->height;
+			rval = ipu_isys_subdev_fmt_propagate(sd, cfg, ffmt,
+						      compose[asd->nsinks],
+						      tgt + 1, asd->nsinks,
+						      which);
 			if (rval)
 				goto out_subdev_fmt_propagate;
+			/* n:n case: propagate according to route info */
+		} else if (asd->nsinks == asd->nsources && asd->nsources > 1) {
+			for (i = asd->nsinks; i < sd->entity.num_pads; i++)
+				if (media_entity_has_route(&sd->entity, pad, i))
+					break;
+
+			if (i != sd->entity.num_pads) {
+				compose[i]->left = 0;
+				compose[i]->top = 0;
+				compose[i]->width = r->width;
+				compose[i]->height = r->height;
+				rval = ipu_isys_subdev_fmt_propagate(sd, cfg, ffmt,
+							      compose[i],
+							      tgt + 1, i,
+							      which);
+				if (rval)
+					goto out_subdev_fmt_propagate;
+			}
+			/* n:m case: propagate to all source pad */
+		} else if (asd->nsinks != asd->nsources && asd->nsources > 1 &&
+			   asd->nsources > 1) {
+			for (i = 1; i < sd->entity.num_pads; i++) {
+				if (!(sd->entity.pads[i].flags &
+				      MEDIA_PAD_FL_SOURCE))
+					continue;
+
+				compose[i]->left = 0;
+				compose[i]->top = 0;
+				compose[i]->width = r->width;
+				compose[i]->height = r->height;
+				rval = ipu_isys_subdev_fmt_propagate(sd, cfg,
+							      ffmt,
+							      compose[i],
+							      tgt + 1, i,
+							      which);
+				if (rval)
+					goto out_subdev_fmt_propagate;
+			}
 		}
 		goto out_subdev_fmt_propagate;
 	case IPU_ISYS_SUBDEV_PROP_TGT_SOURCE_COMPOSE:
@@ -285,28 +368,29 @@ int ipu_isys_subdev_fmt_propagate(struct v4l2_subdev *sd,
 		crops[pad]->top = 0;
 		crops[pad]->width = r->width;
 		crops[pad]->height = r->height;
-		rval = ipu_isys_subdev_fmt_propagate(sd, sd_state, ffmt,
-						     crops[pad], tgt + 1, pad, which);
+		rval = ipu_isys_subdev_fmt_propagate(sd, cfg, ffmt,
+					      crops[pad], tgt + 1, pad, which);
 		goto out_subdev_fmt_propagate;
 	case IPU_ISYS_SUBDEV_PROP_TGT_SOURCE_CROP:{
 			struct v4l2_subdev_format fmt = {
 				.which = which,
 				.pad = pad,
 				.format = {
-					.width = r->width,
-					.height = r->height,
-					/*
-					 * Either use the code from sink pad
-					 * or the current one.
-					 */
-					.code = ffmt ? ffmt->code :
-						       ffmts[pad]->code,
-					.field = ffmt ? ffmt->field :
-							ffmts[pad]->field,
-				},
+					   .width = r->width,
+					   .height = r->height,
+					   /*
+					    * Either use the code from sink pad
+					    * or the current one.
+					    */
+					   .code =
+					   ffmt ? ffmt->code : ffmts[pad]->code,
+					   .field =
+					   ffmt ? ffmt->field : ffmts[pad]->
+					   field,
+					   },
 			};
 
-			asd->set_ffmt(sd, sd_state, &fmt);
+			asd->set_ffmt(sd, cfg, &fmt);
 			goto out_subdev_fmt_propagate;
 		}
 	}
@@ -319,23 +403,29 @@ int ipu_isys_subdev_fmt_propagate(struct v4l2_subdev *sd,
 }
 
 int ipu_isys_subdev_set_ffmt_default(struct v4l2_subdev *sd,
-				     struct v4l2_subdev_state *sd_state,
-				     struct v4l2_subdev_format *fmt)
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 1, 0)
+				      struct v4l2_subdev_fh *cfg,
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(5, 14, 0)
+					  struct v4l2_subdev_pad_config *cfg,
+#else
+		      struct v4l2_subdev_state *cfg,
+#endif
+				      struct v4l2_subdev_format *fmt)
 {
 	struct v4l2_mbus_framefmt *ffmt =
-		__ipu_isys_get_ffmt(sd, sd_state, fmt->pad, fmt->which);
+		__ipu_isys_get_ffmt(sd, cfg, fmt->pad, fmt->stream,
+					   fmt->which);
 
 	/* No propagation for non-zero pads. */
 	if (fmt->pad) {
 		struct v4l2_mbus_framefmt *sink_ffmt =
-			__ipu_isys_get_ffmt(sd, sd_state, 0, fmt->which);
+			__ipu_isys_get_ffmt(sd, cfg, 0, fmt->stream,
+						   fmt->which);
 
 		ffmt->width = sink_ffmt->width;
 		ffmt->height = sink_ffmt->height;
 		ffmt->code = sink_ffmt->code;
 		ffmt->field = sink_ffmt->field;
-
-		return 0;
 	}
 
 	ffmt->width = fmt->format.width;
@@ -343,18 +433,25 @@ int ipu_isys_subdev_set_ffmt_default(struct v4l2_subdev *sd,
 	ffmt->code = fmt->format.code;
 	ffmt->field = fmt->format.field;
 
-	return ipu_isys_subdev_fmt_propagate(sd, sd_state, &fmt->format, NULL,
-					     IPU_ISYS_SUBDEV_PROP_TGT_SINK_FMT,
-					     fmt->pad, fmt->which);
+	return ipu_isys_subdev_fmt_propagate(sd, cfg, &fmt->format, NULL,
+				      IPU_ISYS_SUBDEV_PROP_TGT_SINK_FMT,
+				      fmt->pad, fmt->which);
 }
 
 int __ipu_isys_subdev_set_ffmt(struct v4l2_subdev *sd,
-			       struct v4l2_subdev_state *sd_state,
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 1, 0)
+			       struct v4l2_subdev_fh *cfg,
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(5, 14, 0)
+				   struct v4l2_subdev_pad_config *cfg,
+#else
+		   struct v4l2_subdev_state *cfg,
+#endif
 			       struct v4l2_subdev_format *fmt)
 {
 	struct ipu_isys_subdev *asd = to_ipu_isys_subdev(sd);
 	struct v4l2_mbus_framefmt *ffmt =
-		__ipu_isys_get_ffmt(sd, sd_state, fmt->pad, fmt->which);
+		__ipu_isys_get_ffmt(sd, cfg, fmt->pad, fmt->stream,
+					   fmt->which);
 	u32 code = asd->supported_codes[fmt->pad][0];
 	unsigned int i;
 
@@ -374,7 +471,7 @@ int __ipu_isys_subdev_set_ffmt(struct v4l2_subdev *sd,
 
 	fmt->format.code = code;
 
-	asd->set_ffmt(sd, sd_state, fmt);
+	asd->set_ffmt(sd, cfg, fmt);
 
 	fmt->format = *ffmt;
 
@@ -382,35 +479,226 @@ int __ipu_isys_subdev_set_ffmt(struct v4l2_subdev *sd,
 }
 
 int ipu_isys_subdev_set_ffmt(struct v4l2_subdev *sd,
-			     struct v4l2_subdev_state *sd_state,
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 1, 0)
+			     struct v4l2_subdev_fh *cfg,
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(5, 14, 0)
+			     struct v4l2_subdev_pad_config *cfg,
+#else
+		 struct v4l2_subdev_state *cfg,
+#endif
 			     struct v4l2_subdev_format *fmt)
 {
 	struct ipu_isys_subdev *asd = to_ipu_isys_subdev(sd);
 	int rval;
 
+	if (fmt->stream >= asd->nstreams)
+		return -EINVAL;
+
 	mutex_lock(&asd->mutex);
-	rval = __ipu_isys_subdev_set_ffmt(sd, sd_state, fmt);
+	rval = __ipu_isys_subdev_set_ffmt(sd, cfg, fmt);
 	mutex_unlock(&asd->mutex);
 
 	return rval;
 }
 
 int ipu_isys_subdev_get_ffmt(struct v4l2_subdev *sd,
-			     struct v4l2_subdev_state *sd_state,
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 1, 0)
+			     struct v4l2_subdev_fh *cfg,
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(5, 14, 0)
+			     struct v4l2_subdev_pad_config *cfg,
+#else
+		 struct v4l2_subdev_state *cfg,
+#endif
 			     struct v4l2_subdev_format *fmt)
 {
 	struct ipu_isys_subdev *asd = to_ipu_isys_subdev(sd);
 
+	if (fmt->stream >= asd->nstreams)
+		return -EINVAL;
+
 	mutex_lock(&asd->mutex);
-	fmt->format = *__ipu_isys_get_ffmt(sd, sd_state, fmt->pad,
+	fmt->format = *__ipu_isys_get_ffmt(sd, cfg, fmt->pad,
+					   fmt->stream,
 					   fmt->which);
 	mutex_unlock(&asd->mutex);
 
 	return 0;
 }
 
+int ipu_isys_subdev_get_frame_desc(struct v4l2_subdev *sd,
+				   struct v4l2_mbus_frame_desc *desc)
+{
+	int i, rval = 0;
+
+	for (i = 0; i < sd->entity.num_pads; i++) {
+		if (!(sd->entity.pads[i].flags & MEDIA_PAD_FL_SOURCE))
+			continue;
+
+		rval = v4l2_subdev_call(sd, pad, get_frame_desc, i, desc);
+		if (!rval)
+			return rval;
+	}
+
+	if (i == sd->entity.num_pads)
+		rval = -EINVAL;
+
+	return rval;
+}
+
+bool ipu_isys_subdev_has_route(struct media_entity *entity,
+			       unsigned int pad0, unsigned int pad1, int *stream)
+{
+	struct ipu_isys_subdev *asd;
+	int i;
+
+	if (!entity) {
+		WARN_ON(1);
+		return false;
+	}
+	asd = to_ipu_isys_subdev(media_entity_to_v4l2_subdev(entity));
+
+	/* Two sinks are never connected together. */
+	if (pad0 < asd->nsinks && pad1 < asd->nsinks)
+		return false;
+
+	for (i = 0; i < asd->nstreams; i++) {
+		if ((asd->route[i].flags & V4L2_SUBDEV_ROUTE_FL_ACTIVE) &&
+		    ((asd->route[i].sink == pad0 &&
+		      asd->route[i].source == pad1) ||
+		     (asd->route[i].sink == pad1 &&
+			  asd->route[i].source == pad0))) {
+			if (stream)
+				*stream = i;
+			return true;
+		}
+	}
+
+	return false;
+}
+
+int ipu_isys_subdev_set_routing(struct v4l2_subdev *sd,
+				struct v4l2_subdev_routing *route)
+{
+	struct ipu_isys_subdev *asd = to_ipu_isys_subdev(sd);
+	int i, j, ret = 0;
+
+	WARN_ON(!mutex_is_locked(&sd->entity.
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 5, 0)
+				 parent
+#else
+				 graph_obj.mdev
+#endif
+				 ->graph_mutex));
+
+	for (i = 0; i < min(route->num_routes, asd->nstreams); ++i) {
+		struct v4l2_subdev_route *t = &route->routes[i];
+
+		if (t->sink_stream > asd->nstreams - 1 ||
+		    t->source_stream > asd->nstreams - 1)
+			continue;
+
+		for (j = 0; j < asd->nstreams; j++) {
+			if (t->sink_pad == asd->route[j].sink &&
+			    t->source_pad == asd->route[j].source)
+				break;
+		}
+
+		if (j == asd->nstreams)
+			continue;
+
+		if (asd->route[j].flags & V4L2_SUBDEV_ROUTE_FL_IMMUTABLE)
+			continue;
+
+		if ((t->flags & V4L2_SUBDEV_ROUTE_FL_SOURCE) && asd->nsinks)
+			continue;
+
+		if (!(t->flags & V4L2_SUBDEV_ROUTE_FL_SOURCE)) {
+			int source_pad = 0;
+
+			if (sd->entity.pads[t->sink_pad].flags &
+			    MEDIA_PAD_FL_MULTIPLEX)
+				source_pad = t->source_pad - asd->nsinks;
+
+			asd->stream[t->sink_pad].stream_id[source_pad] =
+			    t->sink_stream;
+		}
+
+		if (sd->entity.pads[t->source_pad].flags &
+		    MEDIA_PAD_FL_MULTIPLEX)
+			asd->stream[t->source_pad].stream_id[t->sink_pad] =
+			    t->source_stream;
+		else
+			asd->stream[t->source_pad].stream_id[0] =
+			    t->source_stream;
+
+		if (t->flags & V4L2_SUBDEV_ROUTE_FL_ACTIVE) {
+			bitmap_set(asd->stream[t->source_pad].streams_stat,
+				   t->source_stream, 1);
+			if (!(t->flags & V4L2_SUBDEV_ROUTE_FL_SOURCE))
+				bitmap_set(asd->stream[t->sink_pad]
+					   .streams_stat, t->sink_stream, 1);
+			asd->route[j].flags |= V4L2_SUBDEV_ROUTE_FL_ACTIVE;
+		} else if (!(t->flags & V4L2_SUBDEV_ROUTE_FL_ACTIVE)) {
+			bitmap_clear(asd->stream[t->source_pad].streams_stat,
+				     t->source_stream, 1);
+			if (!(t->flags & V4L2_SUBDEV_ROUTE_FL_SOURCE))
+				bitmap_clear(asd->stream[t->sink_pad]
+					     .streams_stat, t->sink_stream, 1);
+			asd->route[j].flags &= (~V4L2_SUBDEV_ROUTE_FL_ACTIVE);
+		}
+	}
+
+	return ret;
+}
+
+int ipu_isys_subdev_get_routing(struct v4l2_subdev *sd,
+				struct v4l2_subdev_routing *route)
+{
+	struct ipu_isys_subdev *asd = to_ipu_isys_subdev(sd);
+	int i, j;
+
+	for (i = 0, j = 0; i < min(asd->nstreams, route->num_routes); ++i) {
+		route->routes[j].sink_pad = asd->route[i].sink;
+		if (sd->entity.pads[asd->route[i].sink].flags &
+		    MEDIA_PAD_FL_MULTIPLEX) {
+			int source_pad = asd->route[i].source - asd->nsinks;
+
+			route->routes[j].sink_stream =
+			    asd->stream[asd->route[i].sink].
+			    stream_id[source_pad];
+		} else {
+			route->routes[j].sink_stream =
+			    asd->stream[asd->route[i].sink].stream_id[0];
+		}
+
+		route->routes[j].source_pad = asd->route[i].source;
+		if (sd->entity.pads[asd->route[i].source].flags &
+		    MEDIA_PAD_FL_MULTIPLEX) {
+			route->routes[j].source_stream =
+			    asd->stream[asd->route[i].source].stream_id[asd->
+									route
+									[i].
+									sink];
+		} else {
+			route->routes[j].source_stream =
+			    asd->stream[asd->route[i].source].stream_id[0];
+		}
+		route->routes[j++].flags = asd->route[i].flags;
+	}
+
+	route->num_routes = j;
+
+	return 0;
+}
+
 int ipu_isys_subdev_set_sel(struct v4l2_subdev *sd,
-			    struct v4l2_subdev_state *sd_state,
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 1, 0)
+			    struct v4l2_subdev_fh *cfg,
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(5, 14, 0)
+			    struct v4l2_subdev_pad_config *cfg,
+#else
+		struct v4l2_subdev_state *cfg,
+#endif
 			    struct v4l2_subdev_selection *sel)
 {
 	struct ipu_isys_subdev *asd = to_ipu_isys_subdev(sd);
@@ -425,8 +713,8 @@ int ipu_isys_subdev_set_sel(struct v4l2_subdev *sd,
 	case V4L2_SEL_TGT_CROP:
 		if (pad->flags & MEDIA_PAD_FL_SINK) {
 			struct v4l2_mbus_framefmt *ffmt =
-				__ipu_isys_get_ffmt(sd, sd_state, sel->pad,
-						    sel->which);
+				__ipu_isys_get_ffmt(sd, cfg, sel->pad, 0,
+							   sel->which);
 
 			__r.width = ffmt->width;
 			__r.height = ffmt->height;
@@ -434,7 +722,7 @@ int ipu_isys_subdev_set_sel(struct v4l2_subdev *sd,
 			tgt = IPU_ISYS_SUBDEV_PROP_TGT_SINK_CROP;
 		} else {
 			/* 0 is the sink pad. */
-			r = __ipu_isys_get_selection(sd, sd_state, sel->target, 0,
+			r = __ipu_isys_get_selection(sd, cfg, sel->target, 0,
 						     sel->which);
 			tgt = IPU_ISYS_SUBDEV_PROP_TGT_SOURCE_CROP;
 		}
@@ -442,11 +730,11 @@ int ipu_isys_subdev_set_sel(struct v4l2_subdev *sd,
 		break;
 	case V4L2_SEL_TGT_COMPOSE:
 		if (pad->flags & MEDIA_PAD_FL_SINK) {
-			r = __ipu_isys_get_selection(sd, sd_state, V4L2_SEL_TGT_CROP,
+			r = __ipu_isys_get_selection(sd, cfg, V4L2_SEL_TGT_CROP,
 						     sel->pad, sel->which);
 			tgt = IPU_ISYS_SUBDEV_PROP_TGT_SINK_COMPOSE;
 		} else {
-			r = __ipu_isys_get_selection(sd, sd_state,
+			r = __ipu_isys_get_selection(sd, cfg,
 						     V4L2_SEL_TGT_COMPOSE, 0,
 						     sel->which);
 			tgt = IPU_ISYS_SUBDEV_PROP_TGT_SOURCE_COMPOSE;
@@ -458,32 +746,62 @@ int ipu_isys_subdev_set_sel(struct v4l2_subdev *sd,
 
 	sel->r.width = clamp(sel->r.width, IPU_ISYS_MIN_WIDTH, r->width);
 	sel->r.height = clamp(sel->r.height, IPU_ISYS_MIN_HEIGHT, r->height);
-	*__ipu_isys_get_selection(sd, sd_state, sel->target, sel->pad,
+	*__ipu_isys_get_selection(sd, cfg, sel->target, sel->pad,
 				  sel->which) = sel->r;
-	return ipu_isys_subdev_fmt_propagate(sd, sd_state, NULL, &sel->r, tgt,
-					     sel->pad, sel->which);
+	return ipu_isys_subdev_fmt_propagate(sd, cfg, NULL, &sel->r, tgt,
+				      sel->pad, sel->which);
 }
 
 int ipu_isys_subdev_get_sel(struct v4l2_subdev *sd,
-			    struct v4l2_subdev_state *sd_state,
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 1, 0)
+			    struct v4l2_subdev_fh *cfg,
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(5, 14, 0)
+			    struct v4l2_subdev_pad_config *cfg,
+#else
+		struct v4l2_subdev_state *cfg,
+#endif
 			    struct v4l2_subdev_selection *sel)
 {
 	if (!target_valid(sd, sel->target, sel->pad))
 		return -EINVAL;
 
-	sel->r = *__ipu_isys_get_selection(sd, sd_state, sel->target,
+	sel->r = *__ipu_isys_get_selection(sd, cfg, sel->target,
 					   sel->pad, sel->which);
 
 	return 0;
 }
 
 int ipu_isys_subdev_enum_mbus_code(struct v4l2_subdev *sd,
-				   struct v4l2_subdev_state *sd_state,
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 1, 0)
+				   struct v4l2_subdev_fh *cfg,
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(5, 14, 0)
+			   struct v4l2_subdev_pad_config *cfg,
+#else
+		   struct v4l2_subdev_state *cfg,
+#endif
 				   struct v4l2_subdev_mbus_code_enum *code)
 {
 	struct ipu_isys_subdev *asd = to_ipu_isys_subdev(sd);
 	const u32 *supported_codes = asd->supported_codes[code->pad];
 	u32 index;
+	bool next_stream = false;
+
+	if (sd->entity.pads[code->pad].flags & MEDIA_PAD_FL_MULTIPLEX) {
+		if (code->stream & V4L2_SUBDEV_FLAG_NEXT_STREAM) {
+			next_stream = true;
+			code->stream &= ~V4L2_SUBDEV_FLAG_NEXT_STREAM;
+		}
+
+		if (code->stream > asd->nstreams - 1)
+			return -EINVAL;
+
+		if (next_stream && code->stream < asd->nstreams) {
+			code->stream++;
+			return 0;
+		}
+
+		return -EINVAL;
+	}
 
 	for (index = 0; supported_codes[index]; index++) {
 		if (index == code->index) {
@@ -495,6 +813,58 @@ int ipu_isys_subdev_enum_mbus_code(struct v4l2_subdev *sd,
 	return -EINVAL;
 }
 
+#if !defined(CONFIG_VIDEO_INTEL_IPU4) && !defined(CONFIG_VIDEO_INTEL_IPU4P)
+/*
+ * IPU private link validation
+ * In advanced IPU and special case, there will be format change between
+ * sink/source pads in ISYS.
+ * Format code checking is not necessary for these features.
+ */
+static int ipu_isys_subdev_link_validate_private(
+					struct v4l2_subdev *sd,
+					struct media_link *link,
+					struct v4l2_subdev_format *source_fmt,
+					struct v4l2_subdev_format *sink_fmt)
+{
+	struct ipu_isys_subdev *asd = to_ipu_isys_subdev(sd);
+
+	/* The width and height must match. */
+	if (source_fmt->format.width != sink_fmt->format.width
+	    || source_fmt->format.height != sink_fmt->format.height)
+		return -EPIPE;
+
+	/*
+	 * The field order must match, or the sink field order must be NONE
+	 * to support interlaced hardware connected to bridges that support
+	 * progressive formats only.
+	 */
+	if (source_fmt->format.field != sink_fmt->format.field &&
+	    sink_fmt->format.field != V4L2_FIELD_NONE)
+		return -EPIPE;
+
+	if (source_fmt->stream != sink_fmt->stream)
+		return -EINVAL;
+
+	/*
+	 * For new IPU special case, YUV format changing in BE-SOC,
+	 * from YUV422 to I420, which is used to adapt multiple
+	 * YUV sensors and provide I420 to BB for partial processing.
+	 * If this entity doing format convert, ignore format check
+	 */
+	if (source_fmt->format.code != sink_fmt->format.code) {
+		if (source_fmt->format.code == MEDIA_BUS_FMT_UYVY8_2X8 &&
+			(sink_fmt->format.code == MEDIA_BUS_FMT_YUYV8_1X16 ||
+			sink_fmt->format.code == MEDIA_BUS_FMT_UYVY8_1X16))
+			dev_warn(&asd->isys->adev->dev,
+				"YUV format change, ignore code check\n");
+		else
+			return -EINVAL;
+	}
+
+	return 0;
+}
+#endif
+
 /*
  * Besides validating the link, figure out the external pad and the
  * ISYS FW ABI source.
@@ -514,7 +884,7 @@ int ipu_isys_subdev_link_validate(struct v4l2_subdev *sd,
 	if (!source_sd)
 		return -ENODEV;
 	if (strncmp(source_sd->name, IPU_ISYS_ENTITY_PREFIX,
-		    strlen(IPU_ISYS_ENTITY_PREFIX)) != 0) {
+		strlen(IPU_ISYS_ENTITY_PREFIX)) != 0) {
 		/*
 		 * source_sd isn't ours --- sd must be the external
 		 * sub-device.
@@ -535,8 +905,13 @@ int ipu_isys_subdev_link_validate(struct v4l2_subdev *sd,
 	if (asd->isl_mode != IPU_ISL_OFF)
 		ip->isl_mode = asd->isl_mode;
 
+#if !defined(CONFIG_VIDEO_INTEL_IPU4) && !defined(CONFIG_VIDEO_INTEL_IPU4P)
+	return ipu_isys_subdev_link_validate_private(sd, link, source_fmt,
+						    sink_fmt);
+#else
 	return v4l2_subdev_link_validate_default(sd, link, source_fmt,
 						 sink_fmt);
+#endif
 }
 
 int ipu_isys_subdev_open(struct v4l2_subdev *sd, struct v4l2_subdev_fh *fh)
@@ -548,13 +923,37 @@ int ipu_isys_subdev_open(struct v4l2_subdev *sd, struct v4l2_subdev_fh *fh)
 
 	for (i = 0; i < asd->sd.entity.num_pads; i++) {
 		struct v4l2_mbus_framefmt *try_fmt =
-			v4l2_subdev_get_try_format(sd, fh->state, i);
+			v4l2_subdev_get_try_format(
+#if LINUX_VERSION_CODE > KERNEL_VERSION(5, 14, 0)
+			sd, fh->state,
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(4, 1, 0)
+			sd, fh->pad,
+#else
+			fh,
+#endif
+			i);
 		struct v4l2_rect *try_crop =
-			v4l2_subdev_get_try_crop(sd, fh->state, i);
+			v4l2_subdev_get_try_crop(
+#if LINUX_VERSION_CODE > KERNEL_VERSION(5, 14, 0)
+			sd, fh->state,
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(4, 1, 0)
+			sd, fh->pad,
+#else
+			fh,
+#endif
+			i);
 		struct v4l2_rect *try_compose =
-			v4l2_subdev_get_try_compose(sd, fh->state, i);
-
-		*try_fmt = asd->ffmt[i];
+			v4l2_subdev_get_try_compose(
+#if LINUX_VERSION_CODE > KERNEL_VERSION(5, 14, 0)
+			sd, fh->state,
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(4, 1, 0)
+			sd, fh->pad,
+#else
+			fh,
+#endif
+			i);
+
+		*try_fmt = asd->ffmt[i][0];
 		*try_crop = asd->crop[i];
 		*try_compose = asd->compose[i];
 	}
@@ -573,10 +972,12 @@ int ipu_isys_subdev_init(struct ipu_isys_subdev *asd,
 			 struct v4l2_subdev_ops *ops,
 			 unsigned int nr_ctrls,
 			 unsigned int num_pads,
+			 unsigned int num_streams,
 			 unsigned int num_source,
 			 unsigned int num_sink,
 			 unsigned int sd_flags)
 {
+	int i;
 	int rval = -EINVAL;
 
 	mutex_init(&asd->mutex);
@@ -585,16 +986,18 @@ int ipu_isys_subdev_init(struct ipu_isys_subdev *asd,
 
 	asd->sd.flags |= V4L2_SUBDEV_FL_HAS_DEVNODE | sd_flags;
 	asd->sd.owner = THIS_MODULE;
-	asd->sd.entity.function = MEDIA_ENT_F_VID_IF_BRIDGE;
 
+	asd->nstreams = num_streams;
 	asd->nsources = num_source;
 	asd->nsinks = num_sink;
 
 	asd->pad = devm_kcalloc(&asd->isys->adev->dev, num_pads,
 				sizeof(*asd->pad), GFP_KERNEL);
 
-	asd->ffmt = devm_kcalloc(&asd->isys->adev->dev, num_pads,
-				 sizeof(*asd->ffmt), GFP_KERNEL);
+	asd->ffmt = (struct v4l2_mbus_framefmt **)
+			devm_kcalloc(&asd->isys->adev->dev, num_pads,
+				     sizeof(struct v4l2_mbus_framefmt *),
+				     GFP_KERNEL);
 
 	asd->crop = devm_kcalloc(&asd->isys->adev->dev, num_pads,
 				 sizeof(*asd->crop), GFP_KERNEL);
@@ -604,10 +1007,30 @@ int ipu_isys_subdev_init(struct ipu_isys_subdev *asd,
 
 	asd->valid_tgts = devm_kcalloc(&asd->isys->adev->dev, num_pads,
 				       sizeof(*asd->valid_tgts), GFP_KERNEL);
+	asd->route = devm_kcalloc(&asd->isys->adev->dev, num_streams,
+				  sizeof(*asd->route), GFP_KERNEL);
+
+	asd->stream = devm_kcalloc(&asd->isys->adev->dev, num_pads,
+				   sizeof(*asd->stream), GFP_KERNEL);
+
 	if (!asd->pad || !asd->ffmt || !asd->crop || !asd->compose ||
-	    !asd->valid_tgts)
+	    !asd->valid_tgts || !asd->route || !asd->stream)
 		return -ENOMEM;
 
+	for (i = 0; i < num_pads; i++) {
+		asd->ffmt[i] = (struct v4l2_mbus_framefmt *)
+		    devm_kcalloc(&asd->isys->adev->dev, num_streams,
+				 sizeof(struct v4l2_mbus_framefmt), GFP_KERNEL);
+		if (!asd->ffmt[i])
+			return -ENOMEM;
+
+		asd->stream[i].stream_id =
+		    devm_kcalloc(&asd->isys->adev->dev, num_source,
+				 sizeof(*asd->stream[i].stream_id), GFP_KERNEL);
+		if (!asd->stream[i].stream_id)
+			return -ENOMEM;
+	}
+
 	rval = media_entity_pads_init(&asd->sd.entity, num_pads, asd->pad);
 	if (rval)
 		goto out_mutex_destroy;
diff --git a/drivers/media/pci/intel/ipu-isys-subdev.h b/drivers/media/pci/intel/ipu-isys-subdev.h
index 053ac094642d..b47c85d3ac03 100644
--- a/drivers/media/pci/intel/ipu-isys-subdev.h
+++ b/drivers/media/pci/intel/ipu-isys-subdev.h
@@ -1,5 +1,5 @@
 /* SPDX-License-Identifier: GPL-2.0 */
-/* Copyright (C) 2013 - 2020 Intel Corporation */
+/* Copyright (C) 2013 - 2018 Intel Corporation */
 
 #ifndef IPU_ISYS_SUBDEV_H
 #define IPU_ISYS_SUBDEV_H
@@ -42,8 +42,9 @@ enum isys_subdev_prop_tgt {
 	(IPU_ISYS_SUBDEV_PROP_TGT_SOURCE_CROP + 1)
 
 enum ipu_isl_mode {
-	IPU_ISL_OFF = 0,	/* SOC BE */
-	IPU_ISL_CSI2_BE,	/* RAW BE */
+	IPU_ISL_OFF = 0,	/* IPU_FW_ISYS_USE_NO_ISL_NO_ISA */
+	IPU_ISL_CSI2_BE,	/* IPU_FW_ISYS_USE_SINGLE_DUAL_ISL */
+	IPU_ISL_ISA	/* IPU_FW_ISYS_USE_SINGLE_ISA */
 };
 
 enum ipu_be_mode {
@@ -67,16 +68,32 @@ struct ipu_isys_subdev {
 	struct ipu_isys *isys;
 	u32 const *const *supported_codes;
 	struct media_pad *pad;
-	struct v4l2_mbus_framefmt *ffmt;
+	struct v4l2_mbus_framefmt **ffmt;
 	struct v4l2_rect *crop;
 	struct v4l2_rect *compose;
+	struct {
+		unsigned int *stream_id;
+		 DECLARE_BITMAP(streams_stat, 32);
+	} *stream;	/* stream enable/disable status, indexed by pad */
+	struct {
+		unsigned int sink;
+		unsigned int source;
+		int flags;
+	} *route;	/* pad level info, indexed by stream */
+	unsigned int nstreams;
 	unsigned int nsinks;
 	unsigned int nsources;
 	struct v4l2_ctrl_handler ctrl_handler;
 	void (*ctrl_init)(struct v4l2_subdev *sd);
 	void (*set_ffmt)(struct v4l2_subdev *sd,
-			 struct v4l2_subdev_state *sd_state,
-			 struct v4l2_subdev_format *fmt);
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 1, 0)
+			  struct v4l2_subdev_fh *cfg,
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(5, 14, 0)
+			  struct v4l2_subdev_pad_config *cfg,
+#else
+	      struct v4l2_subdev_state *cfg,
+#endif
+			  struct v4l2_subdev_format *fmt);
 	struct {
 		bool crop;
 		bool compose;
@@ -90,8 +107,15 @@ struct ipu_isys_subdev {
 	container_of(__sd, struct ipu_isys_subdev, sd)
 
 struct v4l2_mbus_framefmt *__ipu_isys_get_ffmt(struct v4l2_subdev *sd,
-					       struct v4l2_subdev_state *sd_state,
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 1, 0)
+					       struct v4l2_subdev_fh *cfg,
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(5, 14, 0)
+				   struct v4l2_subdev_pad_config *cfg,
+#else
+			   struct v4l2_subdev_state *cfg,
+#endif
 					       unsigned int pad,
+					       unsigned int stream,
 					       unsigned int which);
 
 unsigned int ipu_isys_mbus_code_to_bpp(u32 code);
@@ -101,37 +125,79 @@ u32 ipu_isys_subdev_code_to_uncompressed(u32 sink_code);
 enum ipu_isys_subdev_pixelorder ipu_isys_subdev_get_pixelorder(u32 code);
 
 int ipu_isys_subdev_fmt_propagate(struct v4l2_subdev *sd,
-				  struct v4l2_subdev_state *sd_state,
-				  struct v4l2_mbus_framefmt *ffmt,
-				  struct v4l2_rect *r,
-				  enum isys_subdev_prop_tgt tgt,
-				  unsigned int pad, unsigned int which);
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 1, 0)
+				   struct v4l2_subdev_fh *cfg,
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(5, 14, 0)
+		   struct v4l2_subdev_pad_config *cfg,
+#else
+		   struct v4l2_subdev_state *cfg,
+#endif
+				   struct v4l2_mbus_framefmt *ffmt,
+				   struct v4l2_rect *r,
+				   enum isys_subdev_prop_tgt tgt,
+				   unsigned int pad, unsigned int which);
 
 int ipu_isys_subdev_set_ffmt_default(struct v4l2_subdev *sd,
-				     struct v4l2_subdev_state *sd_state,
-				     struct v4l2_subdev_format *fmt);
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 1, 0)
+				      struct v4l2_subdev_fh *cfg,
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(5, 14, 0)
+		      struct v4l2_subdev_pad_config *cfg,
+#else
+		      struct v4l2_subdev_state *cfg,
+#endif
+				      struct v4l2_subdev_format *fmt);
 int __ipu_isys_subdev_set_ffmt(struct v4l2_subdev *sd,
-			       struct v4l2_subdev_state *sd_state,
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 1, 0)
+			       struct v4l2_subdev_fh *cfg,
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(5, 14, 0)
+		   struct v4l2_subdev_pad_config *cfg,
+#else
+		   struct v4l2_subdev_state *cfg,
+#endif
 			       struct v4l2_subdev_format *fmt);
 struct v4l2_rect *__ipu_isys_get_selection(struct v4l2_subdev *sd,
-					   struct v4l2_subdev_state *sd_state,
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 1, 0)
+					   struct v4l2_subdev_fh *cfg,
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(5, 14, 0)
+		       struct v4l2_subdev_pad_config *cfg,
+#else
+		       struct v4l2_subdev_state *cfg,
+#endif
 					   unsigned int target,
 					   unsigned int pad,
 					   unsigned int which);
 int ipu_isys_subdev_set_ffmt(struct v4l2_subdev *sd,
-			     struct v4l2_subdev_state *sd_state,
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 1, 0)
+			     struct v4l2_subdev_fh *cfg,
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(5, 14, 0)
+		 struct v4l2_subdev_pad_config *cfg,
+#else
+		 struct v4l2_subdev_state *cfg,
+#endif
 			     struct v4l2_subdev_format *fmt);
 int ipu_isys_subdev_get_ffmt(struct v4l2_subdev *sd,
-			     struct v4l2_subdev_state *sd_state,
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 1, 0)
+			     struct v4l2_subdev_fh *cfg,
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(5, 14, 0)
+		 struct v4l2_subdev_pad_config *cfg,
+#else
+		 struct v4l2_subdev_state *cfg,
+#endif
 			     struct v4l2_subdev_format *fmt);
 int ipu_isys_subdev_get_sel(struct v4l2_subdev *sd,
-			    struct v4l2_subdev_state *sd_state,
+			    struct v4l2_subdev_state *cfg,
 			    struct v4l2_subdev_selection *sel);
 int ipu_isys_subdev_set_sel(struct v4l2_subdev *sd,
-			    struct v4l2_subdev_state *sd_state,
+			    struct v4l2_subdev_state *cfg,
 			    struct v4l2_subdev_selection *sel);
 int ipu_isys_subdev_enum_mbus_code(struct v4l2_subdev *sd,
-				   struct v4l2_subdev_state *sd_state,
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 1, 0)
+				   struct v4l2_subdev_fh *cfg,
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(5, 14, 0)
+		   struct v4l2_subdev_pad_config *cfg,
+#else
+		   struct v4l2_subdev_state *cfg,
+#endif
 				   struct v4l2_subdev_mbus_code_enum
 				   *code);
 int ipu_isys_subdev_link_validate(struct v4l2_subdev *sd,
@@ -145,8 +211,17 @@ int ipu_isys_subdev_init(struct ipu_isys_subdev *asd,
 			 struct v4l2_subdev_ops *ops,
 			 unsigned int nr_ctrls,
 			 unsigned int num_pads,
+			 unsigned int num_streams,
 			 unsigned int num_source,
 			 unsigned int num_sink,
 			 unsigned int sd_flags);
 void ipu_isys_subdev_cleanup(struct ipu_isys_subdev *asd);
+int ipu_isys_subdev_get_frame_desc(struct v4l2_subdev *sd,
+				   struct v4l2_mbus_frame_desc *desc);
+int ipu_isys_subdev_set_routing(struct v4l2_subdev *sd,
+				struct v4l2_subdev_routing *route);
+int ipu_isys_subdev_get_routing(struct v4l2_subdev *sd,
+				struct v4l2_subdev_routing *route);
+bool ipu_isys_subdev_has_route(struct media_entity *entity,
+			       unsigned int pad0, unsigned int pad1, int *stream);
 #endif /* IPU_ISYS_SUBDEV_H */
diff --git a/drivers/media/pci/intel/ipu-isys-tpg.c b/drivers/media/pci/intel/ipu-isys-tpg.c
index b77ea5d55881..8928cbaf2091 100644
--- a/drivers/media/pci/intel/ipu-isys-tpg.c
+++ b/drivers/media/pci/intel/ipu-isys-tpg.c
@@ -1,8 +1,9 @@
 // SPDX-License-Identifier: GPL-2.0
-// Copyright (C) 2013 - 2020 Intel Corporation
+// Copyright (C) 2013 - 2018 Intel Corporation
 
 #include <linux/device.h>
 #include <linux/module.h>
+#include <linux/crlmodule.h>
 
 #include <media/media-entity.h>
 #include <media/v4l2-device.h>
@@ -56,6 +57,18 @@ static int ipu_isys_tpg_s_ctrl(struct v4l2_ctrl *ctrl)
 	case V4L2_CID_VBLANK:
 		writel(ctrl->val, tpg->base + MIPI_GEN_REG_SYNG_VBLANK_CYC);
 		break;
+	case V4L2_CID_LINE_LENGTH_PIXELS:
+		if (ctrl->val > tpg->asd.ffmt[TPG_PAD_SOURCE][0].width)
+			writel(ctrl->val -
+				   tpg->asd.ffmt[TPG_PAD_SOURCE][0].width,
+				   tpg->base + MIPI_GEN_REG_SYNG_HBLANK_CYC);
+		break;
+	case V4L2_CID_FRAME_LENGTH_LINES:
+		if (ctrl->val > tpg->asd.ffmt[TPG_PAD_SOURCE][0].height)
+			writel(ctrl->val -
+				   tpg->asd.ffmt[TPG_PAD_SOURCE][0].height,
+				   tpg->base + MIPI_GEN_REG_SYNG_VBLANK_CYC);
+		break;
 	case V4L2_CID_TEST_PATTERN:
 		writel(ctrl->val, tpg->base + MIPI_GEN_REG_TPG_MODE);
 		break;
@@ -70,7 +83,7 @@ static const struct v4l2_ctrl_ops ipu_isys_tpg_ctrl_ops = {
 
 static s64 ipu_isys_tpg_rate(struct ipu_isys_tpg *tpg, unsigned int bpp)
 {
-	return MIPI_GEN_PPC * IPU_ISYS_FREQ / bpp;
+	return MIPI_GEN_PPC * IPU_ISYS_FREQ;
 }
 
 static const char *const tpg_mode_items[] = {
@@ -105,7 +118,15 @@ static void ipu_isys_tpg_init_controls(struct v4l2_subdev *sd)
 {
 	struct ipu_isys_tpg *tpg = to_ipu_isys_tpg(sd);
 	int hblank;
-	u64 default_pixel_rate;
+	struct v4l2_ctrl_config cfg = {
+		.ops = &ipu_isys_tpg_ctrl_ops,
+		.type = V4L2_CTRL_TYPE_INTEGER,
+		.max = 65535,
+		.min = 8,
+		.step = 1,
+		.qmenu = NULL,
+		.elem_size = 0,
+	};
 
 	hblank = 1024;
 
@@ -117,44 +138,64 @@ static void ipu_isys_tpg_init_controls(struct v4l2_subdev *sd)
 					&ipu_isys_tpg_ctrl_ops,
 					V4L2_CID_VBLANK, 8, 65535, 1, 1024);
 
-	default_pixel_rate = ipu_isys_tpg_rate(tpg, 8);
+	cfg.id = V4L2_CID_LINE_LENGTH_PIXELS;
+	cfg.name = "Line Length Pixels";
+	cfg.def = 1024 + 4096;
+
+	tpg->llp = v4l2_ctrl_new_custom(&tpg->asd.ctrl_handler, &cfg, NULL);
+
+	cfg.id = V4L2_CID_FRAME_LENGTH_LINES;
+	cfg.name = "Frame Length Lines";
+	cfg.def = 1024 + 3072;
+	tpg->fll = v4l2_ctrl_new_custom(&tpg->asd.ctrl_handler, &cfg, NULL);
+
 	tpg->pixel_rate = v4l2_ctrl_new_std(&tpg->asd.ctrl_handler,
 					    &ipu_isys_tpg_ctrl_ops,
-					    V4L2_CID_PIXEL_RATE,
-					    default_pixel_rate,
-					    default_pixel_rate,
-					    1, default_pixel_rate);
+					    V4L2_CID_PIXEL_RATE, 0, 0, 1, 0);
+
 	if (tpg->pixel_rate) {
-		tpg->pixel_rate->cur.val = default_pixel_rate;
+		tpg->pixel_rate->cur.val = ipu_isys_tpg_rate(tpg, 8);
 		tpg->pixel_rate->flags |= V4L2_CTRL_FLAG_READ_ONLY;
 	}
 
 	v4l2_ctrl_new_custom(&tpg->asd.ctrl_handler, &tpg_mode, NULL);
 	tpg->store_csi2_header =
-		v4l2_ctrl_new_custom(&tpg->asd.ctrl_handler,
-				     &csi2_header_cfg, NULL);
+		v4l2_ctrl_new_custom(&tpg->asd.ctrl_handler, &csi2_header_cfg, NULL);
 }
 
 static void tpg_set_ffmt(struct v4l2_subdev *sd,
-			 struct v4l2_subdev_state *sd_state,
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 1, 0)
+			 struct v4l2_subdev_fh *cfg,
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(5, 14, 0)
+			 struct v4l2_subdev_pad_config *cfg,
+#else
+	     struct v4l2_subdev_state *cfg,
+#endif
 			 struct v4l2_subdev_format *fmt)
 {
 	fmt->format.field = V4L2_FIELD_NONE;
-	*__ipu_isys_get_ffmt(sd, sd_state, fmt->pad, fmt->which) = fmt->format;
+	*__ipu_isys_get_ffmt(sd, cfg, fmt->pad, fmt->stream,
+			     fmt->which) = fmt->format;
 }
 
 static int ipu_isys_tpg_set_ffmt(struct v4l2_subdev *sd,
-				 struct v4l2_subdev_state *sd_state,
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 1, 0)
+				 struct v4l2_subdev_fh *cfg,
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(5, 14, 0)
+			 struct v4l2_subdev_pad_config *cfg,
+#else
+	     struct v4l2_subdev_state *cfg,
+#endif
 				 struct v4l2_subdev_format *fmt)
 {
 	struct ipu_isys_tpg *tpg = to_ipu_isys_tpg(sd);
-	__u32 code = tpg->asd.ffmt[TPG_PAD_SOURCE].code;
+	__u32 code = tpg->asd.ffmt[TPG_PAD_SOURCE][0].code;
 	unsigned int bpp = ipu_isys_mbus_code_to_bpp(code);
 	s64 tpg_rate = ipu_isys_tpg_rate(tpg, bpp);
 	int rval;
 
 	mutex_lock(&tpg->asd.mutex);
-	rval = __ipu_isys_subdev_set_ffmt(sd, sd_state, fmt);
+	rval = __ipu_isys_subdev_set_ffmt(sd, cfg, fmt);
 	mutex_unlock(&tpg->asd.mutex);
 
 	if (rval || fmt->which != V4L2_SUBDEV_FORMAT_ACTIVE)
@@ -165,14 +206,20 @@ static int ipu_isys_tpg_set_ffmt(struct v4l2_subdev *sd,
 	return 0;
 }
 
-static const struct ipu_isys_pixelformat *
-ipu_isys_tpg_try_fmt(struct ipu_isys_video *av,
-		     struct v4l2_pix_format_mplane *mpix)
+static const struct ipu_isys_pixelformat *ipu_isys_tpg_try_fmt(
+					struct ipu_isys_video *av,
+					struct v4l2_pix_format_mplane *mpix)
 {
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 5, 0)
+	struct media_entity entity = av->vdev.entity;
+	struct v4l2_subdev *sd =
+		media_entity_to_v4l2_subdev(entity.links[0].source->entity);
+#else
 	struct media_link *link = list_first_entry(&av->vdev.entity.links,
 						   struct media_link, list);
 	struct v4l2_subdev *sd =
 		media_entity_to_v4l2_subdev(link->source->entity);
+#endif
 	struct ipu_isys_tpg *tpg;
 
 	if (!sd)
@@ -194,10 +241,6 @@ static int subscribe_event(struct v4l2_subdev *sd, struct v4l2_fh *fh,
 			   struct v4l2_event_subscription *sub)
 {
 	switch (sub->type) {
-#ifdef IPU_TPG_FRAME_SYNC
-	case V4L2_EVENT_FRAME_SYNC:
-		return v4l2_event_subscribe(fh, sub, 10, NULL);
-#endif
 	case V4L2_EVENT_CTRL:
 		return v4l2_ctrl_subscribe_event(fh, sub);
 	default:
@@ -254,13 +297,18 @@ int ipu_isys_tpg_init(struct ipu_isys_tpg *tpg,
 
 	rval = ipu_isys_subdev_init(&tpg->asd, &tpg_sd_ops, 5,
 				    NR_OF_TPG_PADS,
+				    NR_OF_TPG_STREAMS,
 				    NR_OF_TPG_SOURCE_PADS,
 				    NR_OF_TPG_SINK_PADS,
 				    V4L2_SUBDEV_FL_HAS_EVENTS);
 	if (rval)
 		return rval;
 
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 5, 0)
+	tpg->asd.sd.entity.type = MEDIA_ENT_T_V4L2_SUBDEV_SENSOR;
+#else
 	tpg->asd.sd.entity.function = MEDIA_ENT_F_CAM_SENSOR;
+#endif
 	tpg->asd.pad[TPG_PAD_SOURCE].flags = MEDIA_PAD_FL_SOURCE;
 
 	tpg->asd.source = IPU_FW_ISYS_STREAM_SRC_MIPIGEN_PORT0 + index;
@@ -284,14 +332,14 @@ int ipu_isys_tpg_init(struct ipu_isys_tpg *tpg,
 	tpg->av.aq.css_pin_type = IPU_FW_ISYS_PIN_TYPE_MIPI;
 	tpg->av.pfmts = ipu_isys_pfmts_packed;
 	tpg->av.try_fmt_vid_mplane = ipu_isys_tpg_try_fmt;
-	tpg->av.prepare_fw_stream =
-	    ipu_isys_prepare_fw_cfg_default;
+	tpg->av.prepare_firmware_stream_cfg =
+	    ipu_isys_prepare_firmware_stream_cfg_default;
 	tpg->av.packed = true;
 	tpg->av.line_header_length = IPU_ISYS_CSI2_LONG_PACKET_HEADER_SIZE;
 	tpg->av.line_footer_length = IPU_ISYS_CSI2_LONG_PACKET_FOOTER_SIZE;
 	tpg->av.aq.buf_prepare = ipu_isys_buf_prepare;
 	tpg->av.aq.fill_frame_buff_set_pin =
-	    ipu_isys_buffer_to_fw_frame_buff_pin;
+	    ipu_isys_buffer_list_to_ipu_fw_isys_frame_buff_set_pin;
 	tpg->av.aq.link_fmt_validate = ipu_isys_link_fmt_validate;
 	tpg->av.aq.vbq.buf_struct_size = sizeof(struct ipu_isys_video_buffer);
 
diff --git a/drivers/media/pci/intel/ipu-isys-tpg.h b/drivers/media/pci/intel/ipu-isys-tpg.h
index 332f087ed774..29ce5002219f 100644
--- a/drivers/media/pci/intel/ipu-isys-tpg.h
+++ b/drivers/media/pci/intel/ipu-isys-tpg.h
@@ -1,5 +1,5 @@
 /* SPDX-License-Identifier: GPL-2.0 */
-/* Copyright (C) 2013 - 2020 Intel Corporation */
+/* Copyright (C) 2013 - 2018 Intel Corporation */
 
 #ifndef IPU_ISYS_TPG_H
 #define IPU_ISYS_TPG_H
@@ -78,6 +78,8 @@ struct ipu_isys_tpg {
 
 	struct v4l2_ctrl *hblank;
 	struct v4l2_ctrl *vblank;
+	struct v4l2_ctrl *llp;
+	struct v4l2_ctrl *fll;
 	struct v4l2_ctrl *pixel_rate;
 	struct v4l2_ctrl *store_csi2_header;
 };
@@ -85,10 +87,6 @@ struct ipu_isys_tpg {
 #define to_ipu_isys_tpg(sd)		\
 	container_of(to_ipu_isys_subdev(sd), \
 	struct ipu_isys_tpg, asd)
-#ifdef IPU_TPG_FRAME_SYNC
-void ipu_isys_tpg_sof_event(struct ipu_isys_tpg *tpg);
-void ipu_isys_tpg_eof_event(struct ipu_isys_tpg *tpg);
-#endif
 int ipu_isys_tpg_init(struct ipu_isys_tpg *tpg,
 		      struct ipu_isys *isys,
 		      void __iomem *base, void __iomem *sel,
diff --git a/drivers/media/pci/intel/ipu-isys-video.c b/drivers/media/pci/intel/ipu-isys-video.c
index a16892948575..cfd80d24e2ab 100644
--- a/drivers/media/pci/intel/ipu-isys-video.c
+++ b/drivers/media/pci/intel/ipu-isys-video.c
@@ -1,5 +1,5 @@
 // SPDX-License-Identifier: GPL-2.0
-// Copyright (C) 2013 - 2021 Intel Corporation
+// Copyright (C) 2013 - 2018 Intel Corporation
 
 #include <linux/delay.h>
 #include <linux/firmware.h>
@@ -10,12 +10,18 @@
 #include <linux/version.h>
 #include <linux/compat.h>
 
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 14, 0)
+#include <linux/sched.h>
+#else
 #include <uapi/linux/sched/types.h>
+#endif
 
 #include <media/media-entity.h>
 #include <media/v4l2-device.h>
 #include <media/v4l2-ioctl.h>
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 6, 0)
 #include <media/v4l2-mc.h>
+#endif
 
 #include "ipu.h"
 #include "ipu-bus.h"
@@ -29,8 +35,13 @@
 #include "ipu-fw-isys.h"
 #include "ipu-fw-com.h"
 
-/* use max resolution pixel rate by default */
-#define DEFAULT_PIXEL_RATE	(360000000ULL * 2 * 4 / 10)
+static unsigned int num_stream_support = IPU_ISYS_NUM_STREAMS;
+module_param(num_stream_support, uint, 0660);
+MODULE_PARM_DESC(num_stream_support, "IPU project support number of stream");
+
+static bool use_stream_stop;
+module_param(use_stream_stop, bool, 0660);
+MODULE_PARM_DESC(use_stream_stop, "Use STOP command if running in CSI capture mode");
 
 const struct ipu_isys_pixelformat ipu_isys_pfmts_be_soc[] = {
 	{V4L2_PIX_FMT_Y10, 16, 10, 0, MEDIA_BUS_FMT_Y10_1X10,
@@ -41,11 +52,21 @@ const struct ipu_isys_pixelformat ipu_isys_pfmts_be_soc[] = {
 	 IPU_FW_ISYS_FRAME_FORMAT_YUYV},
 	{V4L2_PIX_FMT_NV16, 16, 16, 8, MEDIA_BUS_FMT_UYVY8_1X16,
 	 IPU_FW_ISYS_FRAME_FORMAT_NV16},
+	{V4L2_PIX_FMT_YUV420, 12, 0, 8, MEDIA_BUS_FMT_UYVY8_2X8,
+	 IPU_FW_ISYS_FRAME_FORMAT_YUV420},
 	{V4L2_PIX_FMT_XRGB32, 32, 32, 0, MEDIA_BUS_FMT_RGB565_1X16,
 	 IPU_FW_ISYS_FRAME_FORMAT_RGBA888},
 	{V4L2_PIX_FMT_XBGR32, 32, 32, 0, MEDIA_BUS_FMT_RGB888_1X24,
 	 IPU_FW_ISYS_FRAME_FORMAT_RGBA888},
 	/* Raw bayer formats. */
+	{V4L2_PIX_FMT_SBGGR14, 16, 14, 0, MEDIA_BUS_FMT_SBGGR14_1X14,
+	 IPU_FW_ISYS_FRAME_FORMAT_RAW16},
+	{V4L2_PIX_FMT_SGBRG14, 16, 14, 0, MEDIA_BUS_FMT_SGBRG14_1X14,
+	 IPU_FW_ISYS_FRAME_FORMAT_RAW16},
+	{V4L2_PIX_FMT_SGRBG14, 16, 14, 0, MEDIA_BUS_FMT_SGRBG14_1X14,
+	 IPU_FW_ISYS_FRAME_FORMAT_RAW16},
+	{V4L2_PIX_FMT_SRGGB14, 16, 14, 0, MEDIA_BUS_FMT_SRGGB14_1X14,
+	 IPU_FW_ISYS_FRAME_FORMAT_RAW16},
 	{V4L2_PIX_FMT_SBGGR12, 16, 12, 0, MEDIA_BUS_FMT_SBGGR12_1X12,
 	 IPU_FW_ISYS_FRAME_FORMAT_RAW16},
 	{V4L2_PIX_FMT_SGBRG12, 16, 12, 0, MEDIA_BUS_FMT_SGBRG12_1X12,
@@ -76,10 +97,8 @@ const struct ipu_isys_pixelformat ipu_isys_pfmts_be_soc[] = {
 const struct ipu_isys_pixelformat ipu_isys_pfmts_packed[] = {
 	{V4L2_PIX_FMT_Y10, 10, 10, 0, MEDIA_BUS_FMT_Y10_1X10,
 	 IPU_FW_ISYS_FRAME_FORMAT_RAW10},
-#ifdef V4L2_PIX_FMT_Y210
 	{V4L2_PIX_FMT_Y210, 20, 20, 0, MEDIA_BUS_FMT_YUYV10_1X20,
 	 IPU_FW_ISYS_FRAME_FORMAT_YUYV},
-#endif
 	{V4L2_PIX_FMT_UYVY, 16, 16, 0, MEDIA_BUS_FMT_UYVY8_1X16,
 	 IPU_FW_ISYS_FRAME_FORMAT_UYVY},
 	{V4L2_PIX_FMT_YUYV, 16, 16, 0, MEDIA_BUS_FMT_YUYV8_1X16,
@@ -97,6 +116,14 @@ const struct ipu_isys_pixelformat ipu_isys_pfmts_packed[] = {
 	 IPU_FW_ISYS_FRAME_FORMAT_RAW12},
 	{V4L2_PIX_FMT_SRGGB12, 12, 12, 0, MEDIA_BUS_FMT_SRGGB12_1X12,
 	 IPU_FW_ISYS_FRAME_FORMAT_RAW12},
+	{V4L2_PIX_FMT_SBGGR14, 14, 14, 0, MEDIA_BUS_FMT_SBGGR14_1X14,
+	 IPU_FW_ISYS_FRAME_FORMAT_RAW14},
+	{V4L2_PIX_FMT_SGBRG14, 14, 14, 0, MEDIA_BUS_FMT_SGBRG14_1X14,
+	 IPU_FW_ISYS_FRAME_FORMAT_RAW14},
+	{V4L2_PIX_FMT_SGRBG14, 14, 14, 0, MEDIA_BUS_FMT_SGRBG14_1X14,
+	 IPU_FW_ISYS_FRAME_FORMAT_RAW14},
+	{V4L2_PIX_FMT_SRGGB14, 14, 14, 0, MEDIA_BUS_FMT_SRGGB14_1X14,
+	 IPU_FW_ISYS_FRAME_FORMAT_RAW14},
 #else /* V4L2_PIX_FMT_SBGGR12P */
 	{V4L2_PIX_FMT_SBGGR12P, 12, 12, 0, MEDIA_BUS_FMT_SBGGR12_1X12,
 	 IPU_FW_ISYS_FRAME_FORMAT_RAW12},
@@ -106,6 +133,14 @@ const struct ipu_isys_pixelformat ipu_isys_pfmts_packed[] = {
 	 IPU_FW_ISYS_FRAME_FORMAT_RAW12},
 	{V4L2_PIX_FMT_SRGGB12P, 12, 12, 0, MEDIA_BUS_FMT_SRGGB12_1X12,
 	 IPU_FW_ISYS_FRAME_FORMAT_RAW12},
+	{V4L2_PIX_FMT_SBGGR14P, 14, 14, 0, MEDIA_BUS_FMT_SBGGR14_1X14,
+	 IPU_FW_ISYS_FRAME_FORMAT_RAW14},
+	{V4L2_PIX_FMT_SGBRG14P, 14, 14, 0, MEDIA_BUS_FMT_SGBRG14_1X14,
+	 IPU_FW_ISYS_FRAME_FORMAT_RAW14},
+	{V4L2_PIX_FMT_SGRBG14P, 14, 14, 0, MEDIA_BUS_FMT_SGRBG14_1X14,
+	 IPU_FW_ISYS_FRAME_FORMAT_RAW14},
+	{V4L2_PIX_FMT_SRGGB14P, 14, 14, 0, MEDIA_BUS_FMT_SRGGB14_1X14,
+	 IPU_FW_ISYS_FRAME_FORMAT_RAW14},
 #endif /* V4L2_PIX_FMT_SBGGR12P */
 	{V4L2_PIX_FMT_SBGGR10P, 10, 10, 0, MEDIA_BUS_FMT_SBGGR10_1X10,
 	 IPU_FW_ISYS_FRAME_FORMAT_RAW10},
@@ -133,7 +168,6 @@ static int video_open(struct file *file)
 	struct ipu_bus_device *adev = to_ipu_bus_device(&isys->adev->dev);
 	struct ipu_device *isp = adev->isp;
 	int rval;
-	const struct ipu_isys_internal_pdata *ipdata;
 
 	mutex_lock(&isys->mutex);
 
@@ -144,6 +178,12 @@ static int video_open(struct file *file)
 	}
 	mutex_unlock(&isys->mutex);
 
+	rval = ipu_buttress_authenticate(isp);
+	if (rval) {
+		dev_err(&isys->adev->dev, "FW authentication failed\n");
+		return rval;
+	}
+
 	rval = pm_runtime_get_sync(&isys->adev->dev);
 	if (rval < 0) {
 		pm_runtime_put_noidle(&isys->adev->dev);
@@ -154,7 +194,13 @@ static int video_open(struct file *file)
 	if (rval)
 		goto out_power_down;
 
-	rval = v4l2_pipeline_pm_get(&av->vdev.entity);
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 6, 0)
+	rval = ipu_pipeline_pm_use(&av->vdev.entity, 1);
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(5, 7, 0)
+	rval = v4l2_pipeline_pm_use(&av->vdev.entity, 1);
+#else
+    rval = v4l2_pipeline_pm_get(&av->vdev.entity);
+#endif
 	if (rval)
 		goto out_v4l2_fh_release;
 
@@ -166,9 +212,8 @@ static int video_open(struct file *file)
 		return 0;
 	}
 
-	ipdata = isys->pdata->ipdata;
 	ipu_configure_spc(adev->isp,
-			  &ipdata->hw_variant,
+			  &isys->pdata->ipdata->hw_variant,
 			  IPU_CPD_PKG_DIR_ISYS_SERVER_IDX,
 			  isys->pdata->base, isys->pkg_dir,
 			  isys->pkg_dir_dma_addr);
@@ -188,7 +233,8 @@ static int video_open(struct file *file)
 		ipu_fw_isys_cleanup(isys);
 	}
 
-	rval = ipu_fw_isys_init(av->isys, ipdata->num_parallel_streams);
+
+	rval = ipu_fw_isys_init(av->isys, num_stream_support);
 	if (rval < 0)
 		goto out_lib_init;
 
@@ -199,7 +245,13 @@ static int video_open(struct file *file)
 out_lib_init:
 	isys->video_opened--;
 	mutex_unlock(&isys->mutex);
-	v4l2_pipeline_pm_put(&av->vdev.entity);
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 6, 0)
+	ipu_pipeline_pm_use(&av->vdev.entity, 0);
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(5, 7, 0)
+	v4l2_pipeline_pm_use(&av->vdev.entity, 0);
+#else
+    v4l2_pipeline_pm_put(&av->vdev.entity);
+#endif
 
 out_v4l2_fh_release:
 	v4l2_fh_release(file);
@@ -228,7 +280,13 @@ static int video_release(struct file *file)
 
 	mutex_unlock(&av->isys->mutex);
 
-	v4l2_pipeline_pm_put(&av->vdev.entity);
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 6, 0)
+	ipu_pipeline_pm_use(&av->vdev.entity, 0);
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(5, 7, 0)
+	v4l2_pipeline_pm_use(&av->vdev.entity, 0);
+#else
+    v4l2_pipeline_pm_put(&av->vdev.entity);
+#endif
 
 	if (av->isys->reset_needed)
 		pm_runtime_put_sync(&av->isys->adev->dev);
@@ -238,6 +296,7 @@ static int video_release(struct file *file)
 	return ret;
 }
 
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 5, 0)
 static struct media_pad *other_pad(struct media_pad *pad)
 {
 	struct media_link *link;
@@ -253,11 +312,19 @@ static struct media_pad *other_pad(struct media_pad *pad)
 	WARN_ON(1);
 	return NULL;
 }
+#endif
 
-const struct ipu_isys_pixelformat *
-ipu_isys_get_pixelformat(struct ipu_isys_video *av, u32 pixelformat)
+const struct ipu_isys_pixelformat *ipu_isys_get_pixelformat(
+					struct ipu_isys_video *av,
+					u32 pixelformat)
 {
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 5, 0)
+	struct media_pad *pad =
+	    av->vdev.entity.pads[0].flags & MEDIA_PAD_FL_SOURCE ?
+	    av->vdev.entity.links[0].sink : av->vdev.entity.links[0].source;
+#else
 	struct media_pad *pad = other_pad(&av->vdev.entity.pads[0]);
+#endif
 	struct v4l2_subdev *sd;
 	const u32 *supported_codes;
 	const struct ipu_isys_pixelformat *pfmt;
@@ -301,6 +368,28 @@ int ipu_isys_vidioc_querycap(struct file *file, void *fh,
 	strlcpy(cap->card, av->isys->media_dev.model, sizeof(cap->card));
 	snprintf(cap->bus_info, sizeof(cap->bus_info), "PCI:%s",
 		 av->isys->media_dev.bus_info);
+
+	cap->capabilities = V4L2_CAP_VIDEO_CAPTURE
+	    | V4L2_CAP_VIDEO_CAPTURE_MPLANE
+	    | V4L2_CAP_VIDEO_OUTPUT_MPLANE | V4L2_CAP_STREAMING
+	    | V4L2_CAP_DEVICE_CAPS;
+
+	cap->device_caps = V4L2_CAP_STREAMING;
+
+	switch (av->aq.vbq.type) {
+	case V4L2_BUF_TYPE_VIDEO_CAPTURE:
+		cap->device_caps |= V4L2_CAP_VIDEO_CAPTURE;
+		break;
+	case V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE:
+		cap->device_caps |= V4L2_CAP_VIDEO_CAPTURE_MPLANE;
+		break;
+	case V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE:
+		cap->device_caps |= V4L2_CAP_VIDEO_OUTPUT_MPLANE;
+		break;
+	default:
+		WARN_ON(1);
+	}
+
 	return 0;
 }
 
@@ -308,7 +397,13 @@ int ipu_isys_vidioc_enum_fmt(struct file *file, void *fh,
 			     struct v4l2_fmtdesc *f)
 {
 	struct ipu_isys_video *av = video_drvdata(file);
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 5, 0)
+	struct media_pad *pad =
+	    av->vdev.entity.pads[0].flags & MEDIA_PAD_FL_SOURCE ?
+	    av->vdev.entity.links[0].sink : av->vdev.entity.links[0].source;
+#else
 	struct media_pad *pad = other_pad(&av->vdev.entity.pads[0]);
+#endif
 	struct v4l2_subdev *sd;
 	const u32 *supported_codes;
 	const struct ipu_isys_pixelformat *pfmt;
@@ -362,10 +457,10 @@ ipu_isys_video_try_fmt_vid_mplane_default(struct ipu_isys_video *av,
 	return ipu_isys_video_try_fmt_vid_mplane(av, mpix, 0);
 }
 
-const struct ipu_isys_pixelformat *
-ipu_isys_video_try_fmt_vid_mplane(struct ipu_isys_video *av,
-				  struct v4l2_pix_format_mplane *mpix,
-				  int store_csi2_header)
+const struct ipu_isys_pixelformat *ipu_isys_video_try_fmt_vid_mplane(
+				struct ipu_isys_video *av,
+				struct v4l2_pix_format_mplane *mpix,
+				int store_csi2_header)
 {
 	const struct ipu_isys_pixelformat *pfmt =
 	    ipu_isys_get_pixelformat(av, mpix->pixelformat);
@@ -398,7 +493,6 @@ ipu_isys_video_try_fmt_vid_mplane(struct ipu_isys_video *av,
 
 	mpix->plane_fmt[0].bytesperline = ALIGN(mpix->plane_fmt[0].bytesperline,
 						av->isys->line_align);
-
 	if (pfmt->bpp_planar)
 		mpix->plane_fmt[0].bytesperline =
 		    mpix->plane_fmt[0].bytesperline *
@@ -418,43 +512,6 @@ ipu_isys_video_try_fmt_vid_mplane(struct ipu_isys_video *av,
 		    max(mpix->plane_fmt[0].bytesperline,
 			av->isys->pdata->ipdata->isys_dma_overshoot)), 1U);
 
-	if (av->compression_ctrl)
-		av->compression = v4l2_ctrl_g_ctrl(av->compression_ctrl);
-
-	/* overwrite bpl/height with compression alignment */
-	if (av->compression) {
-		u32 planar_tile_status_size, tile_status_size;
-
-		mpix->plane_fmt[0].bytesperline =
-		    ALIGN(mpix->plane_fmt[0].bytesperline,
-			  IPU_ISYS_COMPRESSION_LINE_ALIGN);
-		mpix->height = ALIGN(mpix->height,
-				     IPU_ISYS_COMPRESSION_HEIGHT_ALIGN);
-
-		mpix->plane_fmt[0].sizeimage =
-		    ALIGN(mpix->plane_fmt[0].bytesperline * mpix->height,
-			  IPU_ISYS_COMPRESSION_PAGE_ALIGN);
-
-		/* ISYS compression only for RAW and single plannar */
-		planar_tile_status_size =
-		    DIV_ROUND_UP_ULL((mpix->plane_fmt[0].bytesperline *
-				      mpix->height /
-				      IPU_ISYS_COMPRESSION_TILE_SIZE_BYTES) *
-				     IPU_ISYS_COMPRESSION_TILE_STATUS_BITS,
-				     BITS_PER_BYTE);
-		tile_status_size = ALIGN(planar_tile_status_size,
-					 IPU_ISYS_COMPRESSION_PAGE_ALIGN);
-
-		/* tile status buffer offsets relative to buffer base address */
-		av->ts_offsets[0] = mpix->plane_fmt[0].sizeimage;
-		mpix->plane_fmt[0].sizeimage += tile_status_size;
-
-		dev_dbg(&av->isys->adev->dev,
-			"cmprs: bpl:%d, height:%d img size:%d, ts_sz:%d\n",
-			mpix->plane_fmt[0].bytesperline, mpix->height,
-			av->ts_offsets[0], tile_status_size);
-	}
-
 	memset(mpix->plane_fmt[0].reserved, 0,
 	       sizeof(mpix->plane_fmt[0].reserved));
 
@@ -493,6 +550,80 @@ static int vidioc_try_fmt_vid_cap_mplane(struct file *file, void *fh,
 	return 0;
 }
 
+static void fmt_sp_to_mp(struct v4l2_pix_format_mplane *mpix,
+			 struct v4l2_pix_format *pix)
+{
+	mpix->width = pix->width;
+	mpix->height = pix->height;
+	mpix->pixelformat = pix->pixelformat;
+	mpix->field = pix->field;
+	mpix->num_planes = 1;
+	mpix->plane_fmt[0].bytesperline = pix->bytesperline;
+	mpix->plane_fmt[0].sizeimage = pix->sizeimage;
+	mpix->flags = pix->flags;
+}
+
+static void fmt_mp_to_sp(struct v4l2_pix_format *pix,
+			 struct v4l2_pix_format_mplane *mpix)
+{
+	pix->width = mpix->width;
+	pix->height = mpix->height;
+	pix->pixelformat = mpix->pixelformat;
+	pix->field = mpix->field;
+	WARN_ON(mpix->num_planes != 1);
+	pix->bytesperline = mpix->plane_fmt[0].bytesperline;
+	pix->sizeimage = mpix->plane_fmt[0].sizeimage;
+	pix->flags = mpix->flags;
+	pix->colorspace = mpix->colorspace;
+	pix->ycbcr_enc = mpix->ycbcr_enc;
+	pix->quantization = mpix->quantization;
+	pix->xfer_func = mpix->xfer_func;
+}
+
+static int vidioc_g_fmt_vid_cap(struct file *file, void *fh,
+				struct v4l2_format *f)
+{
+	struct ipu_isys_video *av = video_drvdata(file);
+
+	fmt_mp_to_sp(&f->fmt.pix, &av->mpix);
+
+	return 0;
+}
+
+static int vidioc_s_fmt_vid_cap(struct file *file, void *fh,
+				struct v4l2_format *f)
+{
+	struct ipu_isys_video *av = video_drvdata(file);
+	struct v4l2_pix_format_mplane mpix = { 0 };
+
+	if (av->aq.vbq.streaming)
+		return -EBUSY;
+
+	fmt_sp_to_mp(&mpix, &f->fmt.pix);
+
+	av->pfmt = av->try_fmt_vid_mplane(av, &mpix);
+	av->mpix = mpix;
+
+	fmt_mp_to_sp(&f->fmt.pix, &mpix);
+
+	return 0;
+}
+
+static int vidioc_try_fmt_vid_cap(struct file *file, void *fh,
+				  struct v4l2_format *f)
+{
+	struct ipu_isys_video *av = video_drvdata(file);
+	struct v4l2_pix_format_mplane mpix = { 0 };
+
+	fmt_sp_to_mp(&mpix, &f->fmt.pix);
+
+	av->try_fmt_vid_mplane(av, &mpix);
+
+	fmt_mp_to_sp(&f->fmt.pix, &mpix);
+
+	return 0;
+}
+
 static long ipu_isys_vidioc_private(struct file *file, void *fh,
 				    bool valid_prio, unsigned int cmd,
 				    void *arg)
@@ -545,6 +676,7 @@ static int vidioc_s_input(struct file *file, void *fh, unsigned int input)
 static bool is_external(struct ipu_isys_video *av, struct media_entity *entity)
 {
 	struct v4l2_subdev *sd;
+	unsigned int i;
 
 	/* All video nodes are ours. */
 	if (!is_media_entity_v4l2_subdev(entity))
@@ -552,9 +684,14 @@ static bool is_external(struct ipu_isys_video *av, struct media_entity *entity)
 
 	sd = media_entity_to_v4l2_subdev(entity);
 	if (strncmp(sd->name, IPU_ISYS_ENTITY_PREFIX,
-		    strlen(IPU_ISYS_ENTITY_PREFIX)) != 0)
+		strlen(IPU_ISYS_ENTITY_PREFIX)) != 0)
 		return true;
 
+	for (i = 0; i < av->isys->pdata->ipdata->tpg.ntpgs &&
+	     av->isys->tpg[i].isys; i++)
+		if (entity == &av->isys->tpg[i].asd.sd.entity)
+			return true;
+
 	return false;
 }
 
@@ -565,6 +702,12 @@ static int link_validate(struct media_link *link)
 	/* All sub-devices connected to a video node are ours. */
 	struct ipu_isys_pipeline *ip =
 		to_ipu_isys_pipeline(av->vdev.entity.pipe);
+	struct v4l2_subdev_route r[IPU_ISYS_MAX_STREAMS];
+	struct v4l2_subdev_routing routing = {
+		.routes = r,
+		.num_routes = IPU_ISYS_MAX_STREAMS,
+	};
+	int i, rval, active = 0;
 	struct v4l2_subdev *sd;
 
 	if (!link->source->entity)
@@ -575,6 +718,32 @@ static int link_validate(struct media_link *link)
 		ip->source = to_ipu_isys_subdev(sd)->source;
 	}
 
+	rval = v4l2_subdev_call(sd, pad, get_routing, &routing);
+	if (rval)
+		goto err_subdev;
+
+	for (i = 0; i < routing.num_routes; i++) {
+		if (!(routing.routes[i].flags & V4L2_SUBDEV_ROUTE_FL_ACTIVE))
+			continue;
+
+		if (routing.routes[i].source_pad == link->source->index)
+			ip->stream_id = routing.routes[i].sink_stream;
+
+		active++;
+	}
+
+	if (ip->external) {
+		struct v4l2_mbus_frame_desc desc = {
+			.num_entries = V4L2_FRAME_DESC_ENTRY_MAX,
+		};
+
+		sd = media_entity_to_v4l2_subdev(ip->external->entity);
+		rval = ipu_isys_subdev_get_frame_desc(sd, &desc);
+		if (!rval && ip->stream_id < desc.num_entries)
+			ip->vc = desc.entry[ip->stream_id].bus.csi2.channel;
+	}
+
+err_subdev:
 	ip->nr_queues++;
 
 	return 0;
@@ -645,9 +814,8 @@ static int get_external_facing_format(struct ipu_isys_pipeline *ip,
 	}
 	sd = media_entity_to_v4l2_subdev(ip->external->entity);
 	external_facing = (strncmp(sd->name, IPU_ISYS_ENTITY_PREFIX,
-			   strlen(IPU_ISYS_ENTITY_PREFIX)) == 0) ?
-			   ip->external :
-			   media_entity_remote_pad(ip->external);
+		strlen(IPU_ISYS_ENTITY_PREFIX)) == 0) ?
+	    ip->external : media_entity_remote_pad(ip->external);
 	if (WARN_ON(!external_facing)) {
 		dev_warn(&av->isys->adev->dev,
 			 "no external facing pad --- driver bug?\n");
@@ -656,6 +824,7 @@ static int get_external_facing_format(struct ipu_isys_pipeline *ip,
 
 	format->which = V4L2_SUBDEV_FORMAT_ACTIVE;
 	format->pad = 0;
+	format->stream = ip->stream_id;
 	sd = media_entity_to_v4l2_subdev(external_facing->entity);
 
 	return v4l2_subdev_call(sd, pad, get_fmt, NULL, format);
@@ -664,16 +833,33 @@ static int get_external_facing_format(struct ipu_isys_pipeline *ip,
 static void short_packet_queue_destroy(struct ipu_isys_pipeline *ip)
 {
 	struct ipu_isys_video *av = container_of(ip, struct ipu_isys_video, ip);
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0)
+	struct dma_attrs attrs;
+#else
+	unsigned long attrs;
+#endif
 	unsigned int i;
 
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0)
+	init_dma_attrs(&attrs);
+	dma_set_attr(DMA_ATTR_NON_CONSISTENT, &attrs);
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(5, 9, 0)
+	attrs = DMA_ATTR_NON_CONSISTENT;
+#endif
 	if (!ip->short_packet_bufs)
 		return;
 	for (i = 0; i < IPU_ISYS_SHORT_PACKET_BUFFER_NUM; i++) {
 		if (ip->short_packet_bufs[i].buffer)
-			dma_free_coherent(&av->isys->adev->dev,
-					  ip->short_packet_buffer_size,
-					  ip->short_packet_bufs[i].buffer,
-					  ip->short_packet_bufs[i].dma_addr);
+			dma_free_attrs(&av->isys->adev->dev,
+				       ip->short_packet_buffer_size,
+				       ip->short_packet_bufs[i].buffer,
+				       ip->short_packet_bufs[i].dma_addr,
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0)
+				       &attrs
+#else
+				       attrs
+#endif
+			    );
 	}
 	kfree(ip->short_packet_bufs);
 	ip->short_packet_bufs = NULL;
@@ -683,6 +869,11 @@ static int short_packet_queue_setup(struct ipu_isys_pipeline *ip)
 {
 	struct ipu_isys_video *av = container_of(ip, struct ipu_isys_video, ip);
 	struct v4l2_subdev_format source_fmt = { 0 };
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0)
+	struct dma_attrs attrs;
+#else
+	unsigned long attrs;
+#endif
 	unsigned int i;
 	int rval;
 	size_t buf_size;
@@ -706,6 +897,12 @@ static int short_packet_queue_setup(struct ipu_isys_pipeline *ip)
 	/* Initialize short packet queue. */
 	INIT_LIST_HEAD(&ip->short_packet_incoming);
 	INIT_LIST_HEAD(&ip->short_packet_active);
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0)
+	init_dma_attrs(&attrs);
+	dma_set_attr(DMA_ATTR_NON_CONSISTENT, &attrs);
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(5, 9, 0)
+	attrs = DMA_ATTR_NON_CONSISTENT;
+#endif
 
 	ip->short_packet_bufs =
 	    kzalloc(sizeof(struct ipu_isys_private_buffer) *
@@ -720,8 +917,14 @@ static int short_packet_queue_setup(struct ipu_isys_pipeline *ip)
 		buf->ip = ip;
 		buf->ib.type = IPU_ISYS_SHORT_PACKET_BUFFER;
 		buf->bytesused = buf_size;
-		buf->buffer = dma_alloc_coherent(&av->isys->adev->dev, buf_size,
-						 &buf->dma_addr, GFP_KERNEL);
+		buf->buffer = dma_alloc_attrs(&av->isys->adev->dev, buf_size,
+					      &buf->dma_addr, GFP_KERNEL,
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0)
+					      &attrs
+#else
+					      attrs
+#endif
+		    );
 		if (!buf->buffer) {
 			short_packet_queue_destroy(ip);
 			return -ENOMEM;
@@ -732,8 +935,8 @@ static int short_packet_queue_setup(struct ipu_isys_pipeline *ip)
 	return 0;
 }
 
-static void
-csi_short_packet_prepare_fw_cfg(struct ipu_isys_pipeline *ip,
+static void csi_short_packet_prepare_firmware_stream_cfg(
+				struct ipu_isys_pipeline *ip,
 				struct ipu_fw_isys_stream_cfg_data_abi *cfg)
 {
 	int input_pin = cfg->nof_input_pins++;
@@ -742,7 +945,6 @@ csi_short_packet_prepare_fw_cfg(struct ipu_isys_pipeline *ip,
 	    &cfg->input_pins[input_pin];
 	struct ipu_fw_isys_output_pin_info_abi *output_info =
 	    &cfg->output_pins[output_pin];
-	struct ipu_isys *isys = ip->isys;
 
 	/*
 	 * Setting dt as IPU_ISYS_SHORT_PACKET_GENERAL_DT will cause
@@ -765,26 +967,24 @@ csi_short_packet_prepare_fw_cfg(struct ipu_isys_pipeline *ip,
 	output_info->pt = IPU_ISYS_SHORT_PACKET_PT;
 	output_info->ft = IPU_ISYS_SHORT_PACKET_FT;
 	output_info->send_irq = 1;
-	memset(output_info->ts_offsets, 0, sizeof(output_info->ts_offsets));
-	output_info->s2m_pixel_soc_pixel_remapping =
-	    S2M_PIXEL_SOC_PIXEL_REMAPPING_FLAG_NO_REMAPPING;
-	output_info->csi_be_soc_pixel_remapping =
-	    CSI_BE_SOC_PIXEL_REMAPPING_FLAG_NO_REMAPPING;
-	output_info->sensor_type = isys->sensor_info.sensor_metadata;
+#if !defined(CONFIG_VIDEO_INTEL_IPU4) && !defined(CONFIG_VIDEO_INTEL_IPU4P)
 	output_info->snoopable = true;
-	output_info->error_handling_enable = false;
+	output_info->sensor_type = IPU_FW_ISYS_SENSOR_METADATA;
+#endif
 }
 
-void
-ipu_isys_prepare_fw_cfg_default(struct ipu_isys_video *av,
-				struct ipu_fw_isys_stream_cfg_data_abi *cfg)
+void ipu_isys_prepare_firmware_stream_cfg_default(
+			struct ipu_isys_video *av,
+			struct ipu_fw_isys_stream_cfg_data_abi *cfg)
 {
 	struct ipu_isys_pipeline *ip =
 	    to_ipu_isys_pipeline(av->vdev.entity.pipe);
 	struct ipu_isys_queue *aq = &av->aq;
 	struct ipu_fw_isys_output_pin_info_abi *pin_info;
+#if !defined(CONFIG_VIDEO_INTEL_IPU4) && !defined(CONFIG_VIDEO_INTEL_IPU4P)
 	struct ipu_isys *isys = av->isys;
-	unsigned int type_index, type;
+	unsigned int type_index;
+#endif
 	int pin = cfg->nof_output_pins++;
 
 	aq->fw_output = pin;
@@ -807,81 +1007,66 @@ ipu_isys_prepare_fw_cfg_default(struct ipu_isys_video *av,
 	pin_info->pt = aq->css_pin_type;
 	pin_info->ft = av->pfmt->css_pixelformat;
 	pin_info->send_irq = 1;
-	memset(pin_info->ts_offsets, 0, sizeof(pin_info->ts_offsets));
-	pin_info->s2m_pixel_soc_pixel_remapping =
-	    S2M_PIXEL_SOC_PIXEL_REMAPPING_FLAG_NO_REMAPPING;
-	pin_info->csi_be_soc_pixel_remapping =
-	    CSI_BE_SOC_PIXEL_REMAPPING_FLAG_NO_REMAPPING;
-	cfg->vc = 0;
+	cfg->vc = ip->vc;
 
+#if !defined(CONFIG_VIDEO_INTEL_IPU4) && !defined(CONFIG_VIDEO_INTEL_IPU4P)
 	switch (pin_info->pt) {
 	/* non-snoopable sensor data to PSYS */
+	case IPU_FW_ISYS_PIN_TYPE_RAW_DUAL_SOC:
 	case IPU_FW_ISYS_PIN_TYPE_RAW_NS:
+	case IPU_FW_ISYS_PIN_TYPE_RAW_S:
 		type_index = IPU_FW_ISYS_VC1_SENSOR_DATA;
 		pin_info->sensor_type = isys->sensor_types[type_index]++;
 		pin_info->snoopable = false;
-		pin_info->error_handling_enable = false;
-		type = isys->sensor_types[type_index];
-		if (type > isys->sensor_info.vc1_data_end)
+
+		if (isys->sensor_types[type_index] >
+				IPU_FW_ISYS_VC1_SENSOR_DATA_END)
 			isys->sensor_types[type_index] =
-				isys->sensor_info.vc1_data_start;
+				IPU_FW_ISYS_VC1_SENSOR_DATA_START;
+
+		break;
+	/* non-snoopable PDAF data */
+	case IPU_FW_ISYS_PIN_TYPE_PAF_FF:
+		type_index = IPU_FW_ISYS_VC1_SENSOR_PDAF;
+		pin_info->sensor_type = isys->sensor_types[type_index]++;
+		pin_info->snoopable = false;
+
+		if (isys->sensor_types[type_index] >
+				IPU_FW_ISYS_VC1_SENSOR_PDAF_END)
+			isys->sensor_types[type_index] =
+				IPU_FW_ISYS_VC1_SENSOR_PDAF_START;
 
 		break;
 	/* snoopable META/Stats data to CPU */
 	case IPU_FW_ISYS_PIN_TYPE_METADATA_0:
 	case IPU_FW_ISYS_PIN_TYPE_METADATA_1:
-		pin_info->sensor_type = isys->sensor_info.sensor_metadata;
+	case IPU_FW_ISYS_PIN_TYPE_AWB_STATS:
+	case IPU_FW_ISYS_PIN_TYPE_AF_STATS:
+	case IPU_FW_ISYS_PIN_TYPE_HIST_STATS:
+		pin_info->sensor_type = IPU_FW_ISYS_SENSOR_METADATA;
 		pin_info->snoopable = true;
-		pin_info->error_handling_enable = false;
-		break;
-	case IPU_FW_ISYS_PIN_TYPE_RAW_SOC:
-		if (av->compression) {
-			type_index = IPU_FW_ISYS_VC1_SENSOR_DATA;
-			pin_info->sensor_type
-				= isys->sensor_types[type_index]++;
-			pin_info->snoopable = false;
-			pin_info->error_handling_enable = false;
-			type = isys->sensor_types[type_index];
-			if (type > isys->sensor_info.vc1_data_end)
-				isys->sensor_types[type_index] =
-					isys->sensor_info.vc1_data_start;
-		} else {
-			type_index = IPU_FW_ISYS_VC0_SENSOR_DATA;
-			pin_info->sensor_type
-				= isys->sensor_types[type_index]++;
-			pin_info->snoopable = true;
-			pin_info->error_handling_enable = false;
-			type = isys->sensor_types[type_index];
-			if (type > isys->sensor_info.vc0_data_end)
-				isys->sensor_types[type_index] =
-					isys->sensor_info.vc0_data_start;
-		}
 		break;
+	/* snoopable sensor data to CPU */
 	case IPU_FW_ISYS_PIN_TYPE_MIPI:
+	case IPU_FW_ISYS_PIN_TYPE_RAW_SOC:
 		type_index = IPU_FW_ISYS_VC0_SENSOR_DATA;
 		pin_info->sensor_type = isys->sensor_types[type_index]++;
 		pin_info->snoopable = true;
-		pin_info->error_handling_enable = false;
-		type = isys->sensor_types[type_index];
-		if (type > isys->sensor_info.vc0_data_end)
+
+		if (isys->sensor_types[type_index] >
+				IPU_FW_ISYS_VC0_SENSOR_DATA_END)
 			isys->sensor_types[type_index] =
-				isys->sensor_info.vc0_data_start;
+				IPU_FW_ISYS_VC0_SENSOR_DATA_START;
 
 		break;
-
 	default:
 		dev_err(&av->isys->adev->dev,
 			"Unknown pin type, use metadata type as default\n");
 
-		pin_info->sensor_type = isys->sensor_info.sensor_metadata;
+		pin_info->sensor_type = IPU_FW_ISYS_SENSOR_METADATA;
 		pin_info->snoopable = true;
-		pin_info->error_handling_enable = false;
-	}
-	if (av->compression) {
-		pin_info->payload_buf_size = av->mpix.plane_fmt[0].sizeimage;
-		pin_info->reserve_compression = av->compression;
-		pin_info->ts_offsets[0] = av->ts_offsets[0];
 	}
+#endif
 }
 
 static unsigned int ipu_isys_get_compression_scheme(u32 code)
@@ -945,11 +1130,10 @@ static int start_stream_firmware(struct ipu_isys_video *av,
 	struct ipu_fw_isys_frame_buff_set_abi *buf = NULL;
 	struct ipu_isys_queue *aq;
 	struct ipu_isys_video *isl_av = NULL;
+	struct ipu_isys_request *ireq = NULL;
 	struct v4l2_subdev_format source_fmt = { 0 };
 	struct v4l2_subdev *be_sd = NULL;
 	struct media_pad *source_pad = media_entity_remote_pad(&av->pad);
-	struct ipu_fw_isys_cropping_abi *crop;
-	enum ipu_fw_isys_send_type send_type;
 	int rval, rvalout, tout;
 
 	rval = get_external_facing_format(ip, &source_fmt);
@@ -967,19 +1151,18 @@ static int start_stream_firmware(struct ipu_isys_video *av,
 	stream_cfg->input_pins[0].dt =
 	    ipu_isys_mbus_code_to_mipi(source_fmt.format.code);
 	stream_cfg->input_pins[0].mapped_dt = N_IPU_FW_ISYS_MIPI_DATA_TYPE;
-	stream_cfg->input_pins[0].mipi_decompression =
-	    IPU_FW_ISYS_MIPI_COMPRESSION_TYPE_NO_COMPRESSION;
-	stream_cfg->input_pins[0].capture_mode =
-		IPU_FW_ISYS_CAPTURE_MODE_REGULAR;
+
 	if (ip->csi2 && !v4l2_ctrl_g_ctrl(ip->csi2->store_csi2_header))
 		stream_cfg->input_pins[0].mipi_store_mode =
 		    IPU_FW_ISYS_MIPI_STORE_MODE_DISCARD_LONG_HEADER;
+	else if (ip->tpg && !v4l2_ctrl_g_ctrl(ip->tpg->store_csi2_header))
+		stream_cfg->input_pins[0].mipi_store_mode =
+		    IPU_FW_ISYS_MIPI_STORE_MODE_DISCARD_LONG_HEADER;
 
 	stream_cfg->src = ip->source;
 	stream_cfg->vc = 0;
 	stream_cfg->isl_use = ip->isl_mode;
 	stream_cfg->nof_input_pins = 1;
-	stream_cfg->sensor_type = IPU_FW_ISYS_SENSOR_MODE_NORMAL;
 
 	/*
 	 * Only CSI2-BE and SOC BE has the capability to do crop,
@@ -992,17 +1175,18 @@ static int start_stream_firmware(struct ipu_isys_video *av,
 		if (source_pad)
 			sel_fmt.pad = source_pad->index;
 	}
-	crop = &stream_cfg->crop;
 	if (be_sd &&
 	    !v4l2_subdev_call(be_sd, pad, get_selection, NULL, &sel_fmt)) {
-		crop->left_offset = sel_fmt.r.left;
-		crop->top_offset = sel_fmt.r.top;
-		crop->right_offset = sel_fmt.r.left + sel_fmt.r.width;
-		crop->bottom_offset = sel_fmt.r.top + sel_fmt.r.height;
+		stream_cfg->crop[0].left_offset = sel_fmt.r.left;
+		stream_cfg->crop[0].top_offset = sel_fmt.r.top;
+		stream_cfg->crop[0].right_offset = sel_fmt.r.left +
+		    sel_fmt.r.width;
+		stream_cfg->crop[0].bottom_offset = sel_fmt.r.top +
+		    sel_fmt.r.height;
 
 	} else {
-		crop->right_offset = source_fmt.format.width;
-		crop->bottom_offset = source_fmt.format.height;
+		stream_cfg->crop[0].right_offset = source_fmt.format.width;
+		stream_cfg->crop[0].bottom_offset = source_fmt.format.height;
 	}
 
 	/*
@@ -1012,6 +1196,8 @@ static int start_stream_firmware(struct ipu_isys_video *av,
 	 */
 	if (ip->isl_mode == IPU_ISL_CSI2_BE)
 		isl_av = &ip->csi2_be->av;
+	else if (ip->isl_mode == IPU_ISL_ISA)
+		isl_av = &av->isys->isa.av;
 
 	if (isl_av) {
 		struct ipu_isys_queue *safe;
@@ -1031,12 +1217,12 @@ static int start_stream_firmware(struct ipu_isys_video *av,
 	list_for_each_entry(aq, &ip->queues, node) {
 		struct ipu_isys_video *__av = ipu_isys_queue_to_video(aq);
 
-		__av->prepare_fw_stream(__av, stream_cfg);
+		__av->prepare_firmware_stream_cfg(__av, stream_cfg);
 	}
 
 	if (ip->interlaced && ip->isys->short_packet_source ==
 	    IPU_ISYS_SHORT_PACKET_FROM_RECEIVER)
-		csi_short_packet_prepare_fw_cfg(ip, stream_cfg);
+		csi_short_packet_prepare_firmware_stream_cfg(ip, stream_cfg);
 
 	ipu_fw_isys_dump_stream_cfg(dev, stream_cfg);
 
@@ -1058,7 +1244,7 @@ static int start_stream_firmware(struct ipu_isys_video *av,
 				       to_dma_addr(msg),
 				       sizeof(*stream_cfg),
 				       IPU_FW_ISYS_SEND_TYPE_STREAM_OPEN);
-	ipu_put_fw_mgs_buf(av->isys, (uintptr_t)stream_cfg);
+	ipu_put_fw_mgs_buffer(av->isys, (uintptr_t) stream_cfg);
 
 	if (rval < 0) {
 		dev_err(dev, "can't open stream (%d)\n", rval);
@@ -1081,7 +1267,9 @@ static int start_stream_firmware(struct ipu_isys_video *av,
 	}
 	dev_dbg(dev, "start stream: open complete\n");
 
-	if (bl) {
+	ireq = ipu_isys_next_queued_request(ip);
+
+	if (bl || ireq) {
 		msg = ipu_get_fw_msg_buf(ip);
 		if (!msg) {
 			rval = -ENOMEM;
@@ -1091,28 +1279,31 @@ static int start_stream_firmware(struct ipu_isys_video *av,
 	}
 
 	if (bl) {
-		ipu_isys_buffer_to_fw_frame_buff(buf, ip, bl);
+		ipu_isys_buffer_list_to_ipu_fw_isys_frame_buff_set(buf, ip, bl);
 		ipu_isys_buffer_list_queue(bl,
 					   IPU_ISYS_BUFFER_LIST_FL_ACTIVE, 0);
+	} else if (ireq) {
+		rval = ipu_isys_req_prepare(&av->isys->media_dev,
+					    ireq, ip, buf);
+		if (rval)
+			goto out_put_stream_opened;
 	}
 
 	reinit_completion(&ip->stream_start_completion);
 
-	if (bl) {
-		send_type = IPU_FW_ISYS_SEND_TYPE_STREAM_START_AND_CAPTURE;
+	if (bl || ireq) {
 		ipu_fw_isys_dump_frame_buff_set(dev, buf,
 						stream_cfg->nof_output_pins);
 		rval = ipu_fw_isys_complex_cmd(av->isys,
-					       ip->stream_handle,
-					       buf, to_dma_addr(msg),
-					       sizeof(*buf),
-					       send_type);
-		ipu_put_fw_mgs_buf(av->isys, (uintptr_t)buf);
+				ip->stream_handle,
+				buf, to_dma_addr(msg),
+				sizeof(*buf),
+				IPU_FW_ISYS_SEND_TYPE_STREAM_START_AND_CAPTURE);
+		ipu_put_fw_mgs_buffer(av->isys, (uintptr_t) buf);
 	} else {
-		send_type = IPU_FW_ISYS_SEND_TYPE_STREAM_START;
 		rval = ipu_fw_isys_simple_cmd(av->isys,
-					      ip->stream_handle,
-					      send_type);
+					ip->stream_handle,
+					IPU_FW_ISYS_SEND_TYPE_STREAM_START);
 	}
 
 	if (rval < 0) {
@@ -1175,6 +1366,10 @@ static void stop_streaming_firmware(struct ipu_isys_video *av)
 
 	reinit_completion(&ip->stream_stop_completion);
 
+	/* Use STOP command if running in CSI capture mode */
+	if (use_stream_stop)
+		send_type = IPU_FW_ISYS_SEND_TYPE_STREAM_STOP;
+
 	rval = ipu_fw_isys_simple_cmd(av->isys, ip->stream_handle,
 				      send_type);
 
@@ -1254,7 +1449,11 @@ int ipu_isys_video_prepare_streaming(struct ipu_isys_video *av,
 	struct ipu_isys *isys = av->isys;
 	struct device *dev = &isys->adev->dev;
 	struct ipu_isys_pipeline *ip;
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 14, 0)
 	struct media_graph graph;
+#else
+	struct media_entity_graph graph;
+#endif
 	struct media_entity *entity;
 	struct media_device *mdev = &av->isys->media_dev;
 	int rval;
@@ -1287,6 +1486,7 @@ int ipu_isys_video_prepare_streaming(struct ipu_isys_video *av,
 	ip->csi2_be = NULL;
 	ip->csi2_be_soc = NULL;
 	ip->csi2 = NULL;
+	ip->tpg = NULL;
 	ip->seq_index = 0;
 	memset(ip->seq, 0, sizeof(ip->seq));
 
@@ -1315,7 +1515,7 @@ int ipu_isys_video_prepare_streaming(struct ipu_isys_video *av,
 
 	/* Gather all entities in the graph. */
 	mutex_lock(&mdev->graph_mutex);
-	media_graph_walk_start(&graph, &av->vdev.entity);
+	media_graph_walk_start(&graph, &av->vdev.entity.pads[0]);
 	while ((entity = media_graph_walk_next(&graph)))
 		media_entity_enum_set(&ip->entity_enum, entity);
 
@@ -1346,107 +1546,34 @@ int ipu_isys_video_prepare_streaming(struct ipu_isys_video *av,
 	return rval;
 }
 
-static void configure_stream_watermark(struct ipu_isys_video *av)
+static int perform_skew_cal(struct ipu_isys_pipeline *ip)
 {
-	u32 vblank, hblank;
-	u64 pixel_rate;
-	int ret = 0;
-	struct v4l2_subdev *esd;
-	struct v4l2_ctrl *ctrl;
-	struct ipu_isys_pipeline *ip;
-	struct isys_iwake_watermark *iwake_watermark;
-	struct v4l2_control vb = { .id = V4L2_CID_VBLANK, .value = 0 };
-	struct v4l2_control hb = { .id = V4L2_CID_HBLANK, .value = 0 };
+	struct v4l2_subdev *ext_sd =
+	    media_entity_to_v4l2_subdev(ip->external->entity);
+	int rval;
 
-	ip = to_ipu_isys_pipeline(av->vdev.entity.pipe);
-	if (!ip->external->entity) {
+	if (!ext_sd) {
 		WARN_ON(1);
-		return;
+		return -ENODEV;
 	}
-	esd = media_entity_to_v4l2_subdev(ip->external->entity);
-
-	av->watermark->width = av->mpix.width;
-	av->watermark->height = av->mpix.height;
+	ipu_isys_csi2_set_skew_cal(ip->csi2, true);
 
-	ret = v4l2_g_ctrl(esd->ctrl_handler, &vb);
-	if (!ret && vb.value >= 0)
-		vblank = vb.value;
-	else
-		vblank = 0;
-
-	ret = v4l2_g_ctrl(esd->ctrl_handler, &hb);
-	if (!ret && hb.value >= 0)
-		hblank = hb.value;
-	else
-		hblank = 0;
+	rval = v4l2_subdev_call(ext_sd, video, s_stream, true);
+	if (rval)
+		goto turn_off_skew_cal;
 
-	ctrl = v4l2_ctrl_find(esd->ctrl_handler, V4L2_CID_PIXEL_RATE);
+	/* TODO: do we have a better way available than waiting for a while ? */
+	msleep(50);
 
-	if (!ctrl)
-		pixel_rate = DEFAULT_PIXEL_RATE;
-	else
-		pixel_rate = v4l2_ctrl_g_ctrl_int64(ctrl);
-
-	av->watermark->vblank = vblank;
-	av->watermark->hblank = hblank;
-	av->watermark->pixel_rate = pixel_rate;
-	if (!pixel_rate) {
-		iwake_watermark = av->isys->iwake_watermark;
-		mutex_lock(&iwake_watermark->mutex);
-		iwake_watermark->force_iwake_disable = true;
-		mutex_unlock(&iwake_watermark->mutex);
-		WARN(1, "%s Invalid pixel_rate, disable iwake.\n", __func__);
-		return;
-	}
-}
+	rval = v4l2_subdev_call(ext_sd, video, s_stream, false);
 
-static void calculate_stream_datarate(struct video_stream_watermark *watermark)
-{
-	u64 pixels_per_line, bytes_per_line, line_time_ns;
-	u64 pages_per_line, pb_bytes_per_line, stream_data_rate;
-	u16 sram_granulrity_shift =
-		(ipu_ver == IPU_VER_6 || ipu_ver == IPU_VER_6EP) ?
-		IPU6_SRAM_GRANULRITY_SHIFT : IPU6SE_SRAM_GRANULRITY_SHIFT;
-	u16 sram_granulrity_size =
-		(ipu_ver == IPU_VER_6 || ipu_ver == IPU_VER_6EP) ?
-		IPU6_SRAM_GRANULRITY_SIZE : IPU6SE_SRAM_GRANULRITY_SIZE;
-
-	pixels_per_line = watermark->width + watermark->hblank;
-	line_time_ns =
-		pixels_per_line * 1000 / (watermark->pixel_rate / 1000000);
-	/* 2 bytes per Bayer pixel */
-	bytes_per_line = watermark->width << 1;
-	/* bytes to IS pixel buffer pages */
-	pages_per_line = bytes_per_line >> sram_granulrity_shift;
-
-	/* pages for each line */
-	pages_per_line = DIV_ROUND_UP(bytes_per_line,
-				      sram_granulrity_size);
-	pb_bytes_per_line = pages_per_line << sram_granulrity_shift;
-
-	/* data rate MB/s */
-	stream_data_rate = (pb_bytes_per_line * 1000) / line_time_ns;
-	watermark->stream_data_rate = stream_data_rate;
-}
+turn_off_skew_cal:
+	ipu_isys_csi2_set_skew_cal(ip->csi2, false);
 
-static void update_stream_watermark(struct ipu_isys_video *av, bool state)
-{
-	struct isys_iwake_watermark *iwake_watermark;
+	/* TODO: do we have a better way available than waiting for a while ? */
+	msleep(50);
 
-	iwake_watermark = av->isys->iwake_watermark;
-	if (state) {
-		calculate_stream_datarate(av->watermark);
-		mutex_lock(&iwake_watermark->mutex);
-		list_add(&av->watermark->stream_node,
-			 &iwake_watermark->video_list);
-		mutex_unlock(&iwake_watermark->mutex);
-	} else {
-		av->watermark->stream_data_rate = 0;
-		mutex_lock(&iwake_watermark->mutex);
-		list_del(&av->watermark->stream_node);
-		mutex_unlock(&iwake_watermark->mutex);
-	}
-	update_watermark_setting(av->isys);
+	return rval;
 }
 
 int ipu_isys_video_set_streaming(struct ipu_isys_video *av,
@@ -1454,7 +1581,12 @@ int ipu_isys_video_set_streaming(struct ipu_isys_video *av,
 				 struct ipu_isys_buffer_list *bl)
 {
 	struct device *dev = &av->isys->adev->dev;
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 5, 0)
+	struct media_device *mdev = av->vdev.entity.parent;
+	struct media_entity_graph graph;
+#else
 	struct media_device *mdev = av->vdev.entity.graph_obj.mdev;
+#endif
 	struct media_entity_enum entities;
 
 	struct media_entity *entity, *entity2;
@@ -1484,31 +1616,49 @@ int ipu_isys_video_set_streaming(struct ipu_isys_video *av,
 		stop_streaming_firmware(av);
 
 		/* stop external sub-device now. */
-		dev_info(dev, "stream off %s\n", ip->external->entity->name);
+		dev_err(dev, "s_stream %s (ext)\n", ip->external->entity->name);
 
-		v4l2_subdev_call(esd, video, s_stream, state);
+		if (ip->csi2) {
+			if (ip->csi2->stream_count == 1) {
+				v4l2_subdev_call(esd, video, s_stream, state);
+#if defined(CONFIG_VIDEO_INTEL_IPU4) || defined(CONFIG_VIDEO_INTEL_IPU4P)
+				ipu_isys_csi2_wait_last_eof(ip->csi2);
+#endif
+			}
+		} else {
+			v4l2_subdev_call(esd, video, s_stream, state);
+		}
 	}
 
 	mutex_lock(&mdev->graph_mutex);
 
-	media_graph_walk_start(&ip->graph,
-			       &av->vdev.entity);
+	media_graph_walk_start(&
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 5, 0)
+				      ip->
+#endif
+				      graph,
+				      &av->vdev.entity.pads[0]);
 
-	while ((entity = media_graph_walk_next(&ip->graph))) {
+	while ((entity = media_graph_walk_next(&
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 5, 0)
+						      ip->
+#endif
+						      graph))) {
 		sd = media_entity_to_v4l2_subdev(entity);
 
+		dev_dbg(dev, "set stream: entity %s\n", entity->name);
+
 		/* Non-subdev nodes can be safely ignored here. */
 		if (!is_media_entity_v4l2_subdev(entity))
 			continue;
 
 		/* Don't start truly external devices quite yet. */
 		if (strncmp(sd->name, IPU_ISYS_ENTITY_PREFIX,
-			    strlen(IPU_ISYS_ENTITY_PREFIX)) != 0 ||
-		    ip->external->entity == entity)
+			strlen(IPU_ISYS_ENTITY_PREFIX)) != 0 ||
+			ip->external->entity == entity)
 			continue;
 
-		dev_dbg(dev, "s_stream %s entity %s\n", state ? "on" : "off",
-			entity->name);
+		dev_dbg(dev, "s_stream %s\n", entity->name);
 		rval = v4l2_subdev_call(sd, video, s_stream, state);
 		if (!state)
 			continue;
@@ -1522,14 +1672,12 @@ int ipu_isys_video_set_streaming(struct ipu_isys_video *av,
 
 	mutex_unlock(&mdev->graph_mutex);
 
-	if (av->aq.css_pin_type == IPU_FW_ISYS_PIN_TYPE_RAW_SOC) {
-		if (state)
-			configure_stream_watermark(av);
-		update_stream_watermark(av, state);
-	}
-
 	/* Oh crap */
 	if (state) {
+		if (ipu_isys_csi2_skew_cal_required(ip->csi2) &&
+		    ip->csi2->remote_streams == ip->csi2->stream_count)
+			perform_skew_cal(ip);
+
 		rval = start_stream_firmware(av, bl);
 		if (rval)
 			goto out_media_entity_stop_streaming;
@@ -1538,13 +1686,20 @@ int ipu_isys_video_set_streaming(struct ipu_isys_video *av,
 			ip->source, ip->stream_handle);
 
 		/* Start external sub-device now. */
-		dev_info(dev, "stream on %s\n", ip->external->entity->name);
-
-		rval = v4l2_subdev_call(esd, video, s_stream, state);
+		dev_dbg(dev, "set stream: s_stream %s (ext)\n",
+			ip->external->entity->name);
+
+		if (ip->csi2 &&
+		    ip->csi2->remote_streams == ip->csi2->stream_count)
+			rval = v4l2_subdev_call(esd, video, s_stream, state);
+		else if (!ip->csi2)
+			rval = v4l2_subdev_call(esd, video, s_stream, state);
 		if (rval)
 			goto out_media_entity_stop_streaming_firmware;
 	} else {
 		close_streaming_firmware(av);
+		av->ip.stream_id = 0;
+		av->ip.vc = 0;
 	}
 
 	if (state)
@@ -1561,10 +1716,18 @@ int ipu_isys_video_set_streaming(struct ipu_isys_video *av,
 out_media_entity_stop_streaming:
 	mutex_lock(&mdev->graph_mutex);
 
-	media_graph_walk_start(&ip->graph,
-			       &av->vdev.entity);
+	media_graph_walk_start(&
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 5, 0)
+				      ip->
+#endif
+				      graph,
+				      &av->vdev.entity.pads[0]);
 
-	while (state && (entity2 = media_graph_walk_next(&ip->graph)) &&
+	while (state && (entity2 = media_graph_walk_next(&
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 5, 0)
+								ip->
+#endif
+								graph)) &&
 	       entity2 != entity) {
 		sd = media_entity_to_v4l2_subdev(entity2);
 
@@ -1601,6 +1764,27 @@ static long ipu_isys_compat_ioctl(struct file *file, unsigned int cmd,
 }
 #endif
 
+static const struct v4l2_ioctl_ops ioctl_ops_splane = {
+	.vidioc_querycap = ipu_isys_vidioc_querycap,
+	.vidioc_enum_fmt_vid_cap = ipu_isys_vidioc_enum_fmt,
+	.vidioc_g_fmt_vid_cap = vidioc_g_fmt_vid_cap,
+	.vidioc_s_fmt_vid_cap = vidioc_s_fmt_vid_cap,
+	.vidioc_try_fmt_vid_cap = vidioc_try_fmt_vid_cap,
+	.vidioc_reqbufs = vb2_ioctl_reqbufs,
+	.vidioc_create_bufs = vb2_ioctl_create_bufs,
+	.vidioc_prepare_buf = vb2_ioctl_prepare_buf,
+	.vidioc_querybuf = vb2_ioctl_querybuf,
+	.vidioc_qbuf = vb2_ioctl_qbuf,
+	.vidioc_dqbuf = vb2_ioctl_dqbuf,
+	.vidioc_streamon = vb2_ioctl_streamon,
+	.vidioc_streamoff = vb2_ioctl_streamoff,
+	.vidioc_expbuf = vb2_ioctl_expbuf,
+	.vidioc_default = ipu_isys_vidioc_private,
+	.vidioc_enum_input = vidioc_enum_input,
+	.vidioc_g_input = vidioc_g_input,
+	.vidioc_s_input = vidioc_s_input,
+};
+
 static const struct v4l2_ioctl_ops ioctl_ops_mplane = {
 	.vidioc_querycap = ipu_isys_vidioc_querycap,
 	.vidioc_enum_fmt_vid_cap = ipu_isys_vidioc_enum_fmt,
@@ -1657,28 +1841,26 @@ int ipu_isys_video_init(struct ipu_isys_video *av,
 	init_completion(&av->ip.stream_close_completion);
 	init_completion(&av->ip.stream_start_completion);
 	init_completion(&av->ip.stream_stop_completion);
+	init_completion(&av->ip.capture_ack_completion);
 	INIT_LIST_HEAD(&av->ip.queues);
 	spin_lock_init(&av->ip.short_packet_queue_lock);
 	av->ip.isys = av->isys;
+	av->ip.stream_id = 0;
+	av->ip.vc = 0;
 
-	if (!av->watermark) {
-		av->watermark = kzalloc(sizeof(*av->watermark), GFP_KERNEL);
-		if (!av->watermark) {
-			rval = -ENOMEM;
-			goto out_mutex_destroy;
-		}
-	}
-
-	av->vdev.device_caps = V4L2_CAP_STREAMING;
 	if (pad_flags & MEDIA_PAD_FL_SINK) {
-		av->aq.vbq.type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
-		ioctl_ops = &ioctl_ops_mplane;
-		av->vdev.device_caps |= V4L2_CAP_VIDEO_CAPTURE_MPLANE;
+		/* data_offset is available only for multi-plane buffers */
+		if (av->line_header_length) {
+			av->aq.vbq.type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
+			ioctl_ops = &ioctl_ops_mplane;
+		} else {
+			av->aq.vbq.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
+			ioctl_ops = &ioctl_ops_splane;
+		}
 		av->vdev.vfl_dir = VFL_DIR_RX;
 	} else {
 		av->aq.vbq.type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
 		av->vdev.vfl_dir = VFL_DIR_TX;
-		av->vdev.device_caps |= V4L2_CAP_VIDEO_OUTPUT_MPLANE;
 	}
 	rval = ipu_isys_queue_init(&av->aq);
 	if (rval)
@@ -1697,6 +1879,23 @@ int ipu_isys_video_init(struct ipu_isys_video *av,
 		av->vdev.ioctl_ops = ioctl_ops;
 	av->vdev.queue = &av->aq.vbq;
 	av->vdev.lock = &av->mutex;
+
+	av->vdev.device_caps = V4L2_CAP_STREAMING;
+
+	switch (av->aq.vbq.type) {
+	case V4L2_BUF_TYPE_VIDEO_CAPTURE:
+		av->vdev.device_caps |= V4L2_CAP_VIDEO_CAPTURE;
+		break;
+	case V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE:
+		av->vdev.device_caps |= V4L2_CAP_VIDEO_CAPTURE_MPLANE;
+		break;
+	case V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE:
+		av->vdev.device_caps |= V4L2_CAP_VIDEO_OUTPUT_MPLANE;
+		break;
+	default:
+		WARN_ON(1);
+	}
+
 	set_bit(V4L2_FL_USES_V4L2_FH, &av->vdev.flags);
 	video_set_drvdata(&av->vdev, av);
 
@@ -1732,7 +1931,6 @@ int ipu_isys_video_init(struct ipu_isys_video *av,
 	ipu_isys_queue_cleanup(&av->aq);
 
 out_mutex_destroy:
-	kfree(av->watermark);
 	mutex_destroy(&av->mutex);
 
 	return rval;
@@ -1740,7 +1938,6 @@ int ipu_isys_video_init(struct ipu_isys_video *av,
 
 void ipu_isys_video_cleanup(struct ipu_isys_video *av)
 {
-	kfree(av->watermark);
 	video_unregister_device(&av->vdev);
 	media_entity_cleanup(&av->vdev.entity);
 	mutex_destroy(&av->mutex);
diff --git a/drivers/media/pci/intel/ipu-isys-video.h b/drivers/media/pci/intel/ipu-isys-video.h
index 6ed17cb9e93d..c1375f70a897 100644
--- a/drivers/media/pci/intel/ipu-isys-video.h
+++ b/drivers/media/pci/intel/ipu-isys-video.h
@@ -1,5 +1,5 @@
 /* SPDX-License-Identifier: GPL-2.0 */
-/* Copyright (C) 2013 - 2020 Intel Corporation */
+/* Copyright (C) 2013 - 2018 Intel Corporation */
 
 #ifndef IPU_ISYS_VIDEO_H
 #define IPU_ISYS_VIDEO_H
@@ -37,7 +37,7 @@ struct sequence_info {
 
 struct output_pin_data {
 	void (*pin_ready)(struct ipu_isys_pipeline *ip,
-			  struct ipu_fw_isys_resp_info_abi *info);
+			   struct ipu_fw_isys_resp_info_abi *info);
 	struct ipu_isys_queue *aq;
 };
 
@@ -54,7 +54,7 @@ struct ipu_isys_pipeline {
 	struct ipu_isys_csi2_be *csi2_be;
 	struct ipu_isys_csi2_be_soc *csi2_be_soc;
 	struct ipu_isys_csi2 *csi2;
-
+	struct ipu_isys_tpg *tpg;
 	/*
 	 * Number of capture queues, write access serialised using struct
 	 * ipu_isys.stream_mutex
@@ -67,6 +67,7 @@ struct ipu_isys_pipeline {
 	struct completion stream_close_completion;
 	struct completion stream_start_completion;
 	struct completion stream_stop_completion;
+	struct completion capture_ack_completion;
 	struct ipu_isys *isys;
 
 	void (*capture_done[IPU_NUM_CAPTURE_DONE])
@@ -87,24 +88,21 @@ struct ipu_isys_pipeline {
 	spinlock_t short_packet_queue_lock;
 	struct list_head pending_interlaced_bufs;
 	unsigned int short_packet_trace_index;
+	unsigned int vc;
+	unsigned int stream_id;
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 5, 0)
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 14, 0)
 	struct media_graph graph;
+#else
+	struct media_entity_graph graph;
+#endif
+#endif
 	struct media_entity_enum entity_enum;
 };
 
 #define to_ipu_isys_pipeline(__pipe)				\
 	container_of((__pipe), struct ipu_isys_pipeline, pipe)
 
-struct video_stream_watermark {
-	u32 width;
-	u32 height;
-	u32 vblank;
-	u32 hblank;
-	u32 frame_rate;
-	u64 pixel_rate;
-	u64 stream_data_rate;
-	struct list_head stream_node;
-};
-
 struct ipu_isys_video {
 	/* Serialise access to other fields in the struct. */
 	struct mutex mutex;
@@ -118,20 +116,13 @@ struct ipu_isys_video {
 	struct ipu_isys_pipeline ip;
 	unsigned int streaming;
 	bool packed;
-	bool compression;
-	struct v4l2_ctrl_handler ctrl_handler;
-	struct v4l2_ctrl *compression_ctrl;
-	unsigned int ts_offsets[VIDEO_MAX_PLANES];
 	unsigned int line_header_length;	/* bits */
 	unsigned int line_footer_length;	/* bits */
-
-	struct video_stream_watermark *watermark;
-
-	const struct ipu_isys_pixelformat *
-		(*try_fmt_vid_mplane)(struct ipu_isys_video *av,
-				      struct v4l2_pix_format_mplane *mpix);
-	void (*prepare_fw_stream)(struct ipu_isys_video *av,
-				  struct ipu_fw_isys_stream_cfg_data_abi *cfg);
+	const struct ipu_isys_pixelformat *(*try_fmt_vid_mplane)(
+		struct ipu_isys_video *av,
+		struct v4l2_pix_format_mplane *mpix);
+	void (*prepare_firmware_stream_cfg)(struct ipu_isys_video *av,
+		struct ipu_fw_isys_stream_cfg_data_abi *cfg);
 };
 
 #define ipu_isys_queue_to_video(__aq) \
@@ -159,9 +150,9 @@ ipu_isys_video_try_fmt_vid_mplane(struct ipu_isys_video *av,
 				  struct v4l2_pix_format_mplane *mpix,
 				  int store_csi2_header);
 
-void
-ipu_isys_prepare_fw_cfg_default(struct ipu_isys_video *av,
-				struct ipu_fw_isys_stream_cfg_data_abi *cfg);
+void ipu_isys_prepare_firmware_stream_cfg_default(
+	struct ipu_isys_video *av,
+	struct ipu_fw_isys_stream_cfg_data_abi *cfg);
 int ipu_isys_video_prepare_streaming(struct ipu_isys_video *av,
 				     unsigned int state);
 int ipu_isys_video_set_streaming(struct ipu_isys_video *av, unsigned int state,
diff --git a/drivers/media/pci/intel/ipu-isys.c b/drivers/media/pci/intel/ipu-isys.c
index d1d24fd9e2d3..c131657a8961 100644
--- a/drivers/media/pci/intel/ipu-isys.c
+++ b/drivers/media/pci/intel/ipu-isys.c
@@ -1,5 +1,5 @@
 // SPDX-License-Identifier: GPL-2.0
-// Copyright (C) 2013 - 2021 Intel Corporation
+// Copyright (C) 2013 - 2018 Intel Corporation
 
 #include <linux/debugfs.h>
 #include <linux/delay.h>
@@ -14,14 +14,11 @@
 #include <linux/version.h>
 
 #include <media/ipu-isys.h>
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 6, 0)
 #include <media/v4l2-mc.h>
+#endif
 #include <media/v4l2-subdev.h>
-#include <media/v4l2-fwnode.h>
-#include <media/v4l2-ctrls.h>
-#include <media/v4l2-device.h>
-#include <media/v4l2-event.h>
-#include <media/v4l2-ioctl.h>
-#include <media/v4l2-async.h>
+
 #include "ipu.h"
 #include "ipu-bus.h"
 #include "ipu-cpd.h"
@@ -29,6 +26,7 @@
 #include "ipu-dma.h"
 #include "ipu-isys.h"
 #include "ipu-isys-csi2.h"
+#include "ipu-isys-tpg.h"
 #include "ipu-isys-video.h"
 #include "ipu-platform-regs.h"
 #include "ipu-buttress.h"
@@ -37,59 +35,301 @@
 
 #define ISYS_PM_QOS_VALUE	300
 
-#define IPU_BUTTRESS_FABIC_CONTROL	    0x68
-#define GDA_ENABLE_IWAKE_INDEX		    2
-#define GDA_IWAKE_THRESHOLD_INDEX           1
-#define GDA_IRQ_CRITICAL_THRESHOLD_INDEX    0
-
-/* LTR & DID value are 10 bit at most */
-#define LTR_DID_VAL_MAX		1023
-#define LTR_DEFAULT_VALUE	0x70503C19
-#define FILL_TIME_DEFAULT_VALUE 0xFFF0783C
-#define LTR_DID_PKGC_2R		20
-#define LTR_DID_PKGC_8		100
-#define LTR_SCALE_DEFAULT	5
-#define LTR_SCALE_1024NS	2
-#define REG_PKGC_PMON_CFG	0xB00
-
-#define VAL_PKGC_PMON_CFG_RESET 0x38
-#define VAL_PKGC_PMON_CFG_START 0x7
-
-#define IS_PIXEL_BUFFER_PAGES		0x80
-/* BIOS provides the driver the LTR and threshold information in IPU,
- * IS pixel buffer is 256KB, MaxSRAMSize is 200KB on IPU6.
+/*
+ * The param was passed from module to indicate if port
+ * could be optimized.
  */
-#define IPU6_MAX_SRAM_SIZE			(200 << 10)
-/* IS pixel buffer is 128KB, MaxSRAMSize is 96KB on IPU6SE.
+static bool csi2_port_optimized = true;
+module_param(csi2_port_optimized, bool, 0660);
+MODULE_PARM_DESC(csi2_port_optimized, "IPU CSI2 port optimization");
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 6, 0)
+/*
+ * BEGIN adapted code from drivers/media/platform/omap3isp/isp.c.
+ * FIXME: This (in terms of functionality if not code) should be most
+ * likely generalised in the framework, and use made optional for
+ * drivers.
  */
-#define IPU6SE_MAX_SRAM_SIZE			(96 << 10)
-/* When iwake mode is disabled the critical threshold is statically set to 75%
- * of the IS pixel buffer criticalThreshold = (128 * 3) / 4
+/*
+ * ipu_pipeline_pm_use_count - Count the number of users of a pipeline
+ * @entity: The entity
+ *
+ * Return the total number of users of all video device nodes in the pipeline.
  */
-#define CRITICAL_THRESHOLD_IWAKE_DISABLE	(IS_PIXEL_BUFFER_PAGES * 3 / 4)
-
-union fabric_ctrl {
-	struct {
-		u16 ltr_val   : 10;
-		u16 ltr_scale : 3;
-		u16 RSVD1     : 3;
-		u16 did_val   : 10;
-		u16 did_scale : 3;
-		u16 RSVD2     : 1;
-		u16 keep_power_in_D0   : 1;
-		u16 keep_power_override : 1;
-	} bits;
-	u32 value;
-};
+static int ipu_pipeline_pm_use_count(struct media_pad *pad)
+{
+	struct media_entity_graph graph;
+	struct media_entity *entity = pad->entity;
+	int use = 0;
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 5, 0)
+	media_graph_walk_init(&graph, entity->graph_obj.mdev);
+#endif
+	media_graph_walk_start(&graph, pad);
+
+	while ((entity = media_graph_walk_next(&graph))) {
+		if (is_media_entity_v4l2_io(entity))
+			use += entity->use_count;
+	}
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 5, 0)
+	media_graph_walk_cleanup(&graph);
+#endif
+	return use;
+}
+
+/*
+ * ipu_pipeline_pm_power_one - Apply power change to an entity
+ * @entity: The entity
+ * @change: Use count change
+ *
+ * Change the entity use count by @change. If the entity is a subdev update its
+ * power state by calling the core::s_power operation when the use count goes
+ * from 0 to != 0 or from != 0 to 0.
+ *
+ * Return 0 on success or a negative error code on failure.
+ */
+static int ipu_pipeline_pm_power_one(struct media_entity *entity, int change)
+{
+	struct v4l2_subdev *subdev;
+	int ret;
+
+	subdev = is_media_entity_v4l2_subdev(entity)
+	    ? media_entity_to_v4l2_subdev(entity) : NULL;
+
+	if (entity->use_count == 0 && change > 0 && subdev) {
+		ret = v4l2_subdev_call(subdev, core, s_power, 1);
+		if (ret < 0 && ret != -ENOIOCTLCMD)
+			return ret;
+	}
+
+	entity->use_count += change;
+	WARN_ON(entity->use_count < 0);
 
-enum ltr_did_type {
-	LTR_IWAKE_ON,
-	LTR_IWAKE_OFF,
-	LTR_ISYS_ON,
-	LTR_ISYS_OFF,
-	LTR_TYPE_MAX
+	if (entity->use_count == 0 && change < 0 && subdev)
+		v4l2_subdev_call(subdev, core, s_power, 0);
+
+	return 0;
+}
+
+/*
+ * ipu_get_linked_pad - Find internally connected pad for a given pad
+ * @entity: The entity
+ * @pad: Initial pad
+ *
+ * Return index of the linked pad.
+ */
+static int ipu_get_linked_pad(struct media_entity *entity,
+			      struct media_pad *pad)
+{
+	int i;
+
+	for (i = 0; i < entity->num_pads; i++) {
+		struct media_pad *opposite_pad = &entity->pads[i];
+
+		if (opposite_pad == pad)
+			continue;
+
+		if (media_entity_has_route(entity, pad->index,
+					   opposite_pad->index))
+			return opposite_pad->index;
+	}
+
+	return 0;
+}
+
+/*
+ * ipu_pipeline_pm_power - Apply power change to all entities
+ * in a pipeline
+ * @entity: The entity
+ * @change: Use count change
+ * @from_pad: Starting pad
+ *
+ * Walk the pipeline to update the use count and the power state of
+ * all non-node
+ * entities.
+ *
+ * Return 0 on success or a negative error code on failure.
+ */
+static int ipu_pipeline_pm_power(struct media_entity *entity,
+				 int change, int from_pad)
+{
+	struct media_entity_graph graph;
+	struct media_entity *first = entity;
+	int ret = 0;
+
+	if (!change)
+		return 0;
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 5, 0)
+	media_graph_walk_init(&graph, entity->graph_obj.mdev);
+#endif
+	media_graph_walk_start(&graph, &entity->pads[from_pad]);
+
+	while (!ret && (entity = media_graph_walk_next(&graph)))
+		if (!is_media_entity_v4l2_io(entity))
+			ret = ipu_pipeline_pm_power_one(entity, change);
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 5, 0)
+	media_graph_walk_cleanup(&graph);
+#endif
+	if (!ret)
+		return 0;
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 5, 0)
+	media_graph_walk_init(&graph, entity->graph_obj.mdev);
+#endif
+	media_graph_walk_start(&graph, &first->pads[from_pad]);
+
+	while ((first = media_graph_walk_next(&graph)) &&
+	       first != entity)
+		if (!is_media_entity_v4l2_io(first))
+			ipu_pipeline_pm_power_one(first, -change);
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 5, 0)
+	media_graph_walk_cleanup(&graph);
+#endif
+	return ret;
+}
+
+/*
+ * ipu_pipeline_pm_use - Update the use count of an entity
+ * @entity: The entity
+ * @use: Use (1) or stop using (0) the entity
+ *
+ * Update the use count of all entities in the pipeline and power entities
+ * on or off accordingly.
+ *
+ * Return 0 on success or a negative error code on failure. Powering entities
+ * off is assumed to never fail. No failure can occur when the use parameter is
+ * set to 0.
+ */
+int ipu_pipeline_pm_use(struct media_entity *entity, int use)
+{
+	int change = use ? 1 : -1;
+	int ret;
+
+	mutex_lock(&entity->
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 5, 0)
+		   parent
+#else
+		   graph_obj.mdev
+#endif
+		   ->graph_mutex);
+
+	/* Apply use count to node. */
+	entity->use_count += change;
+	WARN_ON(entity->use_count < 0);
+
+	/* Apply power change to connected non-nodes. */
+	ret = ipu_pipeline_pm_power(entity, change, 0);
+	if (ret < 0)
+		entity->use_count -= change;
+
+	mutex_unlock(&entity->
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 5, 0)
+		     parent
+#else
+		     graph_obj.mdev
+#endif
+		     ->graph_mutex);
+
+	return ret;
+}
+
+/*
+ * ipu_pipeline_link_notify - Link management notification callback
+ * @link: The link
+ * @flags: New link flags that will be applied
+ * @notification: The link's state change notification type
+ * (MEDIA_DEV_NOTIFY_*)
+ *
+ * React to link management on powered pipelines by updating the use count of
+ * all entities in the source and sink sides of the link. Entities are powered
+ * on or off accordingly.
+ *
+ * Return 0 on success or a negative error code on failure. Powering entities
+ * off is assumed to never fail. This function will not fail for disconnection
+ * events.
+ */
+static int ipu_pipeline_link_notify(struct media_link *link, u32 flags,
+				    unsigned int notification)
+{
+	struct media_entity *source = link->source->entity;
+	struct media_entity *sink = link->sink->entity;
+	int source_use = ipu_pipeline_pm_use_count(link->source);
+	int sink_use = ipu_pipeline_pm_use_count(link->sink);
+	int ret;
+
+	if (notification == MEDIA_DEV_NOTIFY_POST_LINK_CH &&
+	    !(flags & MEDIA_LNK_FL_ENABLED)) {
+		/* Powering off entities is assumed to never fail. */
+		ipu_pipeline_pm_power(source, -sink_use, 0);
+		ipu_pipeline_pm_power(sink, -source_use, 0);
+		return 0;
+	}
+
+	if (notification == MEDIA_DEV_NOTIFY_PRE_LINK_CH &&
+	    (flags & MEDIA_LNK_FL_ENABLED)) {
+		int from_pad = ipu_get_linked_pad(source, link->source);
+
+		ret = ipu_pipeline_pm_power(source, sink_use, from_pad);
+		if (ret < 0)
+			return ret;
+
+		ret = ipu_pipeline_pm_power(sink, source_use, 0);
+		if (ret < 0)
+			ipu_pipeline_pm_power(source, -sink_use, 0);
+
+		return ret;
+	}
+
+	return 0;
+}
+
+/* END adapted code from drivers/media/platform/omap3isp/isp.c */
+#endif /* < v4.6 */
+
+struct isys_i2c_test {
+	u8 bus_nr;
+	u16 addr;
+	struct i2c_client *client;
 };
 
+static int isys_i2c_test(struct device *dev, void *priv)
+{
+	struct i2c_client *client = i2c_verify_client(dev);
+	struct isys_i2c_test *test = priv;
+
+	if (!client)
+		return 0;
+
+	if (i2c_adapter_id(client->adapter) != test->bus_nr ||
+	    client->addr != test->addr)
+		return 0;
+
+	test->client = client;
+
+	return 0;
+}
+
+static struct
+i2c_client *isys_find_i2c_subdev(struct i2c_adapter *adapter,
+				 struct ipu_isys_subdev_info *sd_info)
+{
+	struct i2c_board_info *info = &sd_info->i2c.board_info;
+	struct isys_i2c_test test = {
+		.bus_nr = i2c_adapter_id(adapter),
+		.addr = info->addr,
+	};
+	int rval;
+
+	rval = i2c_for_each_dev(&test, isys_i2c_test);
+	if (rval || !test.client)
+		return NULL;
+	return test.client;
+}
+
 static int
 isys_complete_ext_device_registration(struct ipu_isys *isys,
 				      struct v4l2_subdev *sd,
@@ -128,14 +368,103 @@ isys_complete_ext_device_registration(struct ipu_isys *isys,
 	return rval;
 }
 
+static int isys_register_ext_subdev(struct ipu_isys *isys,
+				    struct ipu_isys_subdev_info *sd_info)
+{
+	struct i2c_adapter *adapter;
+	struct v4l2_subdev *sd;
+	struct i2c_client *client;
+	int rval;
+	int bus;
+
+#ifdef I2C_WA
+	bus = ipu_get_i2c_bus_id(sd_info->i2c.i2c_adapter_id);
+	if (bus < 0) {
+		dev_err(&isys->adev->dev, "Failed to find adapter!");
+		return -ENOENT;
+	}
+#else
+	bus = sd_info->i2c.i2c_adapter_id;
+#endif
+	adapter = i2c_get_adapter(bus);
+	if (!adapter) {
+		dev_warn(&isys->adev->dev, "can't find adapter\n");
+		return -ENOENT;
+	}
+
+	dev_info(&isys->adev->dev,
+		 "creating new i2c subdev for %s (address %2.2x, bus %d)",
+		 sd_info->i2c.board_info.type, sd_info->i2c.board_info.addr,
+		 bus);
+
+	if (sd_info->csi2) {
+		dev_info(&isys->adev->dev, "sensor device on CSI port: %d\n",
+			 sd_info->csi2->port);
+		if (sd_info->csi2->port >= isys->pdata->ipdata->csi2.nports ||
+		    !isys->csi2[sd_info->csi2->port].isys) {
+			dev_warn(&isys->adev->dev, "invalid csi2 port %u\n",
+				 sd_info->csi2->port);
+			rval = -EINVAL;
+			goto skip_put_adapter;
+		}
+	} else {
+		dev_info(&isys->adev->dev, "non camera subdevice\n");
+	}
+
+	client = isys_find_i2c_subdev(adapter, sd_info);
+	if (client) {
+		dev_dbg(&isys->adev->dev, "Device exists\n");
+		rval = 0;
+		goto skip_put_adapter;
+	}
+
+	sd = v4l2_i2c_new_subdev_board(&isys->v4l2_dev, adapter,
+				       &sd_info->i2c.board_info, NULL);
+	if (!sd) {
+		dev_warn(&isys->adev->dev, "can't create new i2c subdev\n");
+		rval = -EINVAL;
+		goto skip_put_adapter;
+	}
+
+	if (!sd_info->csi2)
+		return 0;
+
+	return isys_complete_ext_device_registration(isys, sd, sd_info->csi2);
+
+skip_put_adapter:
+	i2c_put_adapter(adapter);
+
+	return rval;
+}
+
+static void isys_register_ext_subdevs(struct ipu_isys *isys)
+{
+	struct ipu_isys_subdev_pdata *spdata = isys->pdata->spdata;
+	struct ipu_isys_subdev_info **sd_info;
+
+	if (!spdata) {
+		dev_info(&isys->adev->dev, "no subdevice info provided\n");
+		return;
+	}
+	for (sd_info = spdata->subdevs; *sd_info; sd_info++)
+		isys_register_ext_subdev(isys, *sd_info);
+}
+
 static void isys_unregister_subdevices(struct ipu_isys *isys)
 {
+	const struct ipu_isys_internal_tpg_pdata *tpg =
+	    &isys->pdata->ipdata->tpg;
 	const struct ipu_isys_internal_csi2_pdata *csi2 =
 	    &isys->pdata->ipdata->csi2;
 	unsigned int i;
 
-	for (i = 0; i < NR_OF_CSI2_BE_SOC_DEV; i++)
-		ipu_isys_csi2_be_soc_cleanup(&isys->csi2_be_soc[i]);
+	ipu_isys_csi2_be_cleanup(&isys->csi2_be);
+	ipu_isys_csi2_be_soc_cleanup(&isys->csi2_be_soc);
+
+	ipu_isys_isa_cleanup(&isys->isa);
+
+	for (i = 0; i < tpg->ntpgs; i++)
+		ipu_isys_tpg_cleanup(&isys->tpg[i]);
 
 	for (i = 0; i < csi2->nports; i++)
 		ipu_isys_csi2_cleanup(&isys->csi2[i]);
@@ -143,12 +472,38 @@ static void isys_unregister_subdevices(struct ipu_isys *isys)
 
 static int isys_register_subdevices(struct ipu_isys *isys)
 {
+	const struct ipu_isys_internal_tpg_pdata *tpg =
+	    &isys->pdata->ipdata->tpg;
 	const struct ipu_isys_internal_csi2_pdata *csi2 =
 	    &isys->pdata->ipdata->csi2;
-	struct ipu_isys_csi2_be_soc *csi2_be_soc;
-	unsigned int i, k;
+	struct ipu_isys_subdev_pdata *spdata = isys->pdata->spdata;
+	struct ipu_isys_subdev_info **sd_info;
+	DECLARE_BITMAP(csi2_enable, 32);
+	unsigned int i, j, k;
 	int rval;
 
+	/*
+	 * Here is somewhat a workaround, let each platform decide
+	 * if csi2 port can be optimized, which means only registered
+	 * port from pdata would be enabled.
+	 */
+	if (csi2_port_optimized && spdata) {
+		bitmap_zero(csi2_enable, 32);
+		for (sd_info = spdata->subdevs; *sd_info; sd_info++) {
+			if ((*sd_info)->csi2) {
+				i = (*sd_info)->csi2->port;
+				if (i >= csi2->nports) {
+					dev_warn(&isys->adev->dev,
+						 "invalid csi2 port %u\n", i);
+					continue;
+				}
+				bitmap_set(csi2_enable, i, 1);
+			}
+		}
+	} else {
+		bitmap_fill(csi2_enable, 32);
+	}
+
 	isys->csi2 = devm_kcalloc(&isys->adev->dev, csi2->nports,
 				  sizeof(*isys->csi2), GFP_KERNEL);
 	if (!isys->csi2) {
@@ -157,6 +512,9 @@ static int isys_register_subdevices(struct ipu_isys *isys)
 	}
 
 	for (i = 0; i < csi2->nports; i++) {
+		if (!test_bit(i, csi2_enable))
+			continue;
+
 		rval = ipu_isys_csi2_init(&isys->csi2[i], isys,
 					  isys->pdata->base +
 					  csi2->offsets[i], i);
@@ -166,380 +524,127 @@ static int isys_register_subdevices(struct ipu_isys *isys)
 		isys->isr_csi2_bits |= IPU_ISYS_UNISPART_IRQ_CSI2(i);
 	}
 
-	for (k = 0; k < NR_OF_CSI2_BE_SOC_DEV; k++) {
-		rval = ipu_isys_csi2_be_soc_init(&isys->csi2_be_soc[k],
-						 isys, k);
-		if (rval) {
-			dev_info(&isys->adev->dev,
-				 "can't register csi2 soc be device %d\n", k);
+	isys->tpg = devm_kcalloc(&isys->adev->dev, tpg->ntpgs,
+				 sizeof(*isys->tpg), GFP_KERNEL);
+	if (!isys->tpg) {
+		rval = -ENOMEM;
+		goto fail;
+	}
+
+	for (i = 0; i < tpg->ntpgs; i++) {
+		rval = ipu_isys_tpg_init(&isys->tpg[i], isys,
+					 isys->pdata->base +
+					 tpg->offsets[i],
+					 tpg->sels ? (isys->pdata->base +
+						      tpg->sels[i]) : NULL, i);
+		if (rval)
 			goto fail;
-		}
+	}
+
+	rval = ipu_isys_csi2_be_soc_init(&isys->csi2_be_soc, isys);
+	if (rval) {
+		dev_info(&isys->adev->dev,
+			 "can't register soc csi2 be device\n");
+		goto fail;
+	}
+
+	rval = ipu_isys_csi2_be_init(&isys->csi2_be, isys);
+	if (rval) {
+		dev_info(&isys->adev->dev,
+			 "can't register raw csi2 be device\n");
+		goto fail;
+	}
+	rval = ipu_isys_isa_init(&isys->isa, isys, NULL);
+	if (rval) {
+		dev_info(&isys->adev->dev, "can't register isa device\n");
+		goto fail;
 	}
 
 	for (i = 0; i < csi2->nports; i++) {
-		for (k = 0; k < NR_OF_CSI2_BE_SOC_DEV; k++) {
-			csi2_be_soc = &isys->csi2_be_soc[k];
+		if (!test_bit(i, csi2_enable))
+			continue;
+
+		for (j = CSI2_PAD_SOURCE(0);
+		     j < (NR_OF_CSI2_SOURCE_PADS + CSI2_PAD_SOURCE(0)); j++) {
 			rval =
 			    media_create_pad_link(&isys->csi2[i].asd.sd.entity,
-						  CSI2_PAD_SOURCE,
-						  &csi2_be_soc->asd.sd.entity,
-						  CSI2_BE_SOC_PAD_SINK, 0);
+						  j,
+						  &isys->csi2_be.asd.sd.entity,
+						  CSI2_BE_PAD_SINK, 0);
 			if (rval) {
 				dev_info(&isys->adev->dev,
-					 "can't create link csi2->be_soc\n");
+					 "can't create link csi2 <=> csi2_be\n");
 				goto fail;
 			}
-		}
-	}
-
-	return 0;
-
-fail:
-	isys_unregister_subdevices(isys);
-	return rval;
-}
-
-/* read ltrdid threshold values from BIOS or system configuration */
-static void get_lut_ltrdid(struct ipu_isys *isys, struct ltr_did *pltr_did)
-{
-	struct isys_iwake_watermark *iwake_watermark = isys->iwake_watermark;
-	/* default values*/
-	struct ltr_did ltrdid_default;
-
-	ltrdid_default.lut_ltr.value = LTR_DEFAULT_VALUE;
-	ltrdid_default.lut_fill_time.value = FILL_TIME_DEFAULT_VALUE;
-
-	if (iwake_watermark->ltrdid.lut_ltr.value)
-		*pltr_did = iwake_watermark->ltrdid;
-	else
-		*pltr_did = ltrdid_default;
-}
-
-static int set_iwake_register(struct ipu_isys *isys, u32 index, u32 value)
-{
-	int ret = 0;
-	u32 req_id = index;
-	u32 offset = 0;
-
-	ret = ipu_fw_isys_send_proxy_token(isys, req_id, index, offset, value);
-	if (ret)
-		dev_err(&isys->adev->dev, "write %d failed %d", index, ret);
-
-	return ret;
-}
-
-/*
- * When input system is powered up and before enabling any new sensor capture,
- * or after disabling any sensor capture the following values need to be set:
- * LTR_value = LTR(usec) from calculation;
- * LTR_scale = 2;
- * DID_value = DID(usec) from calculation;
- * DID_scale = 2;
- *
- * When input system is powered down, the LTR and DID values
- * must be returned to the default values:
- * LTR_value = 1023;
- * LTR_scale = 5;
- * DID_value = 1023;
- * DID_scale = 2;
- */
-static void set_iwake_ltrdid(struct ipu_isys *isys,
-			     u16 ltr,
-			     u16 did,
-			     enum ltr_did_type use)
-{
-	/* did_scale will set to 2= 1us */
-	u16 ltr_val, ltr_scale, did_val;
-	union fabric_ctrl fc;
-	struct ipu_device *isp = isys->adev->isp;
-
-	switch (use) {
-	case LTR_IWAKE_ON:
-		ltr_val = min_t(u16, ltr, (u16)LTR_DID_VAL_MAX);
-		did_val = min_t(u16, did, (u16)LTR_DID_VAL_MAX);
-		ltr_scale = (ltr == LTR_DID_VAL_MAX &&
-				did == LTR_DID_VAL_MAX) ?
-				LTR_SCALE_DEFAULT : LTR_SCALE_1024NS;
-		break;
-	case LTR_ISYS_ON:
-	case LTR_IWAKE_OFF:
-		ltr_val = LTR_DID_PKGC_2R;
-		did_val = LTR_DID_PKGC_2R;
-		ltr_scale = LTR_SCALE_1024NS;
-		break;
-	case LTR_ISYS_OFF:
-		ltr_val   = LTR_DID_VAL_MAX;
-		did_val   = LTR_DID_VAL_MAX;
-		ltr_scale = LTR_SCALE_DEFAULT;
-		break;
-	default:
-		return;
-	}
 
-	fc.value = readl(isp->base + IPU_BUTTRESS_FABIC_CONTROL);
-	fc.bits.ltr_val = ltr_val;
-	fc.bits.ltr_scale = ltr_scale;
-	fc.bits.did_val = did_val;
-	fc.bits.did_scale = 2;
-	dev_dbg(&isys->adev->dev,
-		"%s ltr: %d  did: %d", __func__, ltr_val, did_val);
-	writel(fc.value, isp->base + IPU_BUTTRESS_FABIC_CONTROL);
-}
-
-/* SW driver may clear register GDA_ENABLE_IWAKE before the FW configures the
- * stream for debug purposes. Otherwise SW should not access this register.
- */
-static int enable_iwake(struct ipu_isys *isys, bool enable)
-{
-	int ret = 0;
-	struct isys_iwake_watermark *iwake_watermark = isys->iwake_watermark;
-
-	mutex_lock(&iwake_watermark->mutex);
-	if (iwake_watermark->iwake_enabled == enable) {
-		mutex_unlock(&iwake_watermark->mutex);
-		return ret;
-	}
-	ret = set_iwake_register(isys, GDA_ENABLE_IWAKE_INDEX, enable);
-	if (!ret)
-		iwake_watermark->iwake_enabled = enable;
-	mutex_unlock(&iwake_watermark->mutex);
-	return ret;
-}
-
-void update_watermark_setting(struct ipu_isys *isys)
-{
-	struct isys_iwake_watermark *iwake_watermark = isys->iwake_watermark;
-	struct list_head *stream_node;
-	struct video_stream_watermark *p_watermark;
-	struct ltr_did ltrdid;
-	u16 calc_fill_time_us = 0;
-	u16 ltr = 0;
-	u16 did = 0;
-	u32 iwake_threshold, iwake_critical_threshold;
-	u64 threshold_bytes;
-	u64 isys_pb_datarate_mbs = 0;
-	u16 sram_granulrity_shift =
-		(ipu_ver == IPU_VER_6 || ipu_ver == IPU_VER_6EP) ?
-		IPU6_SRAM_GRANULRITY_SHIFT : IPU6SE_SRAM_GRANULRITY_SHIFT;
-	int max_sram_size =
-		(ipu_ver == IPU_VER_6 || ipu_ver == IPU_VER_6EP) ?
-		IPU6_MAX_SRAM_SIZE : IPU6SE_MAX_SRAM_SIZE;
-
-	mutex_lock(&iwake_watermark->mutex);
-	if (iwake_watermark->force_iwake_disable) {
-		set_iwake_ltrdid(isys, 0, 0, LTR_IWAKE_OFF);
-		set_iwake_register(isys, GDA_IRQ_CRITICAL_THRESHOLD_INDEX,
-				   CRITICAL_THRESHOLD_IWAKE_DISABLE);
-		mutex_unlock(&iwake_watermark->mutex);
-		return;
-	}
-
-	if (list_empty(&iwake_watermark->video_list)) {
-		isys_pb_datarate_mbs = 0;
-	} else {
-		list_for_each(stream_node, &iwake_watermark->video_list)
-		{
-			p_watermark = list_entry(stream_node,
-						 struct video_stream_watermark,
-						 stream_node);
-			isys_pb_datarate_mbs += p_watermark->stream_data_rate;
+			for (k = CSI2_BE_SOC_PAD_SINK(0);
+			     k < NR_OF_CSI2_BE_SOC_SINK_PADS; k++) {
+				rval =
+				    media_create_pad_link(&isys->csi2[i].asd.sd.
+							  entity, j,
+							  &isys->csi2_be_soc.
+							  asd.sd.entity, k,
+							  MEDIA_LNK_FL_DYNAMIC);
+				if (rval) {
+					dev_info(&isys->adev->dev,
+						 "can't create link csi2->be_soc\n");
+					goto fail;
+				}
+			}
 		}
 	}
-	mutex_unlock(&iwake_watermark->mutex);
-
-	if (!isys_pb_datarate_mbs) {
-		enable_iwake(isys, false);
-		set_iwake_ltrdid(isys, 0, 0, LTR_IWAKE_OFF);
-		mutex_lock(&iwake_watermark->mutex);
-		set_iwake_register(isys, GDA_IRQ_CRITICAL_THRESHOLD_INDEX,
-				   CRITICAL_THRESHOLD_IWAKE_DISABLE);
-		mutex_unlock(&iwake_watermark->mutex);
-	} else {
-		/* should enable iwake by default according to FW */
-		enable_iwake(isys, true);
-		calc_fill_time_us = (u16)(max_sram_size / isys_pb_datarate_mbs);
-		get_lut_ltrdid(isys, &ltrdid);
-
-		if (calc_fill_time_us <= ltrdid.lut_fill_time.bits.th0)
-			ltr = 0;
-		else if (calc_fill_time_us <= ltrdid.lut_fill_time.bits.th1)
-			ltr = ltrdid.lut_ltr.bits.val0;
-		else if (calc_fill_time_us <= ltrdid.lut_fill_time.bits.th2)
-			ltr = ltrdid.lut_ltr.bits.val1;
-		else if (calc_fill_time_us <= ltrdid.lut_fill_time.bits.th3)
-			ltr = ltrdid.lut_ltr.bits.val2;
-		else
-			ltr = ltrdid.lut_ltr.bits.val3;
-
-		did = calc_fill_time_us - ltr;
-
-		threshold_bytes = did * isys_pb_datarate_mbs;
-		/* calculate iwake threshold with 2KB granularity pages */
-		iwake_threshold =
-			max_t(u32, 1, threshold_bytes >> sram_granulrity_shift);
-
-		iwake_threshold = min_t(u32, iwake_threshold, max_sram_size);
-
-		/* set the critical threshold to halfway between
-		 * iwake threshold and the full buffer.
-		 */
-		iwake_critical_threshold = iwake_threshold +
-			(IS_PIXEL_BUFFER_PAGES - iwake_threshold) / 2;
-
-		dev_dbg(&isys->adev->dev, "%s threshold: %u  critical: %u",
-			__func__, iwake_threshold, iwake_critical_threshold);
-		set_iwake_ltrdid(isys, ltr, did, LTR_IWAKE_ON);
-		mutex_lock(&iwake_watermark->mutex);
-		set_iwake_register(isys,
-				   GDA_IWAKE_THRESHOLD_INDEX, iwake_threshold);
-
-		set_iwake_register(isys,
-				   GDA_IRQ_CRITICAL_THRESHOLD_INDEX,
-				   iwake_critical_threshold);
-		mutex_unlock(&iwake_watermark->mutex);
-
-		writel(VAL_PKGC_PMON_CFG_RESET,
-		       isys->adev->isp->base + REG_PKGC_PMON_CFG);
-		writel(VAL_PKGC_PMON_CFG_START,
-		       isys->adev->isp->base + REG_PKGC_PMON_CFG);
-	}
-}
-
-static int isys_iwake_watermark_init(struct ipu_isys *isys)
-{
-	struct isys_iwake_watermark *iwake_watermark;
 
-	if (isys->iwake_watermark)
-		return 0;
-
-	iwake_watermark = devm_kzalloc(&isys->adev->dev,
-				       sizeof(*iwake_watermark), GFP_KERNEL);
-	if (!iwake_watermark)
-		return -ENOMEM;
-	INIT_LIST_HEAD(&iwake_watermark->video_list);
-	mutex_init(&iwake_watermark->mutex);
-
-	iwake_watermark->ltrdid.lut_ltr.value = 0;
-	isys->iwake_watermark = iwake_watermark;
-	iwake_watermark->isys = isys;
-	iwake_watermark->iwake_enabled = false;
-	iwake_watermark->force_iwake_disable = false;
-	return 0;
-}
-
-static int isys_iwake_watermark_cleanup(struct ipu_isys *isys)
-{
-	struct isys_iwake_watermark *iwake_watermark = isys->iwake_watermark;
-
-	if (!iwake_watermark)
-		return -EINVAL;
-	mutex_lock(&iwake_watermark->mutex);
-	list_del(&iwake_watermark->video_list);
-	mutex_unlock(&iwake_watermark->mutex);
-	mutex_destroy(&iwake_watermark->mutex);
-	isys->iwake_watermark = NULL;
-	return 0;
-}
-
-/* The .bound() notifier callback when a match is found */
-static int isys_notifier_bound(struct v4l2_async_notifier *notifier,
-			       struct v4l2_subdev *sd,
-			       struct v4l2_async_subdev *asd)
-{
-	struct ipu_isys *isys = container_of(notifier,
-					struct ipu_isys, notifier);
-	struct sensor_async_subdev *s_asd = container_of(asd,
-					struct sensor_async_subdev, asd);
-
-	dev_info(&isys->adev->dev, "bind %s nlanes is %d port is %d\n",
-		 sd->name, s_asd->csi2.nlanes, s_asd->csi2.port);
-	isys_complete_ext_device_registration(isys, sd, &s_asd->csi2);
-
-	return v4l2_device_register_subdev_nodes(&isys->v4l2_dev);
-}
-
-static void isys_notifier_unbind(struct v4l2_async_notifier *notifier,
-				 struct v4l2_subdev *sd,
-				 struct v4l2_async_subdev *asd)
-{
-	struct ipu_isys *isys = container_of(notifier,
-					struct ipu_isys, notifier);
-
-	dev_info(&isys->adev->dev, "unbind %s\n", sd->name);
-}
-
-static int isys_notifier_complete(struct v4l2_async_notifier *notifier)
-{
-	struct ipu_isys *isys = container_of(notifier,
-					struct ipu_isys, notifier);
-
-	dev_info(&isys->adev->dev, "All sensor registration completed.\n");
-
-	return v4l2_device_register_subdev_nodes(&isys->v4l2_dev);
-}
-
-static const struct v4l2_async_notifier_operations isys_async_ops = {
-	.bound = isys_notifier_bound,
-	.unbind = isys_notifier_unbind,
-	.complete = isys_notifier_complete,
-};
-
-static int isys_fwnode_parse(struct device *dev,
-			     struct v4l2_fwnode_endpoint *vep,
-			     struct v4l2_async_subdev *asd)
-{
-	struct sensor_async_subdev *s_asd =
-			container_of(asd, struct sensor_async_subdev, asd);
-
-	s_asd->csi2.port = vep->base.port;
-	s_asd->csi2.nlanes = vep->bus.mipi_csi2.num_data_lanes;
-
-	return 0;
-}
-
-static int isys_notifier_init(struct ipu_isys *isys)
-{
-	struct ipu_device *isp = isys->adev->isp;
-	size_t asd_struct_size = sizeof(struct sensor_async_subdev);
-	int ret;
-
-	v4l2_async_notifier_init(&isys->notifier);
-	ret = v4l2_async_notifier_parse_fwnode_endpoints(&isp->pdev->dev,
-							 &isys->notifier,
-							 asd_struct_size,
-							 isys_fwnode_parse);
-
-	if (ret < 0) {
-		dev_err(&isys->adev->dev,
-			"v4l2 parse_fwnode_endpoints() failed: %d\n", ret);
-		return ret;
-	}
+	for (i = 0; i < tpg->ntpgs; i++) {
+		rval = media_create_pad_link(&isys->tpg[i].asd.sd.entity,
+					     TPG_PAD_SOURCE,
+					     &isys->csi2_be.asd.sd.entity,
+					     CSI2_BE_PAD_SINK, 0);
+		if (rval) {
+			dev_info(&isys->adev->dev,
+				 "can't create link between tpg and csi2_be\n");
+			goto fail;
+		}
 
-	if (list_empty(&isys->notifier.asd_list)) {
-		/* isys probe could continue with async subdevs missing */
-		dev_warn(&isys->adev->dev, "no subdev found in graph\n");
-		return 0;
+		for (k = CSI2_BE_SOC_PAD_SINK(0);
+		     k < NR_OF_CSI2_BE_SOC_SINK_PADS; k++) {
+			rval =
+			    media_create_pad_link(&isys->tpg[i].asd.sd.entity,
+						  TPG_PAD_SOURCE,
+						  &isys->csi2_be_soc.asd.sd.
+						  entity, k,
+						  MEDIA_LNK_FL_DYNAMIC);
+			if (rval) {
+				dev_info(&isys->adev->dev,
+					 "can't create link tpg->be_soc\n");
+				goto fail;
+			}
+		}
 	}
 
-	isys->notifier.ops = &isys_async_ops;
-	ret = v4l2_async_notifier_register(&isys->v4l2_dev, &isys->notifier);
-	if (ret) {
-		dev_err(&isys->adev->dev,
-			"failed to register async notifier : %d\n", ret);
-		v4l2_async_notifier_cleanup(&isys->notifier);
+	rval = media_create_pad_link(&isys->csi2_be.asd.sd.entity,
+				     CSI2_BE_PAD_SOURCE,
+				     &isys->isa.asd.sd.entity, ISA_PAD_SINK, 0);
+	if (rval) {
+		dev_info(&isys->adev->dev,
+			 "can't create link between CSI2 raw be and ISA\n");
+		goto fail;
 	}
+	return 0;
 
-	return ret;
-}
-
-static void isys_notifier_cleanup(struct ipu_isys *isys)
-{
-	v4l2_async_notifier_unregister(&isys->notifier);
-	v4l2_async_notifier_cleanup(&isys->notifier);
+fail:
+	isys_unregister_subdevices(isys);
+	return rval;
 }
 
 static struct media_device_ops isys_mdev_ops = {
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 6, 0)
+	.link_notify = ipu_pipeline_link_notify,
+#else
 	.link_notify = v4l2_pipeline_link_notify,
+#endif
+	.req_alloc = ipu_isys_req_alloc,
+	.req_free = ipu_isys_req_free,
+	.req_queue = ipu_isys_req_queue,
 };
 
 static int isys_register_devices(struct ipu_isys *isys)
@@ -547,15 +652,26 @@ static int isys_register_devices(struct ipu_isys *isys)
 	int rval;
 
 	isys->media_dev.dev = &isys->adev->dev;
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 9, 12)
 	isys->media_dev.ops = &isys_mdev_ops;
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(4, 6, 0)
+	isys->media_dev.link_notify = ipu_pipeline_link_notify;
+#else
+	isys->media_dev.link_notify = v4l2_pipeline_link_notify;
+#endif
 	strlcpy(isys->media_dev.model,
 		IPU_MEDIA_DEV_MODEL_NAME, sizeof(isys->media_dev.model));
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 14, 0)
+	isys->media_dev.driver_version = LINUX_VERSION_CODE;
+#endif
 	snprintf(isys->media_dev.bus_info, sizeof(isys->media_dev.bus_info),
 		 "pci:%s", dev_name(isys->adev->dev.parent->parent));
 	strlcpy(isys->v4l2_dev.name, isys->media_dev.model,
 		sizeof(isys->v4l2_dev.name));
 
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 5, 0)
 	media_device_init(&isys->media_dev);
+#endif
 
 	rval = media_device_register(&isys->media_dev);
 	if (rval < 0) {
@@ -575,19 +691,14 @@ static int isys_register_devices(struct ipu_isys *isys)
 	if (rval)
 		goto out_v4l2_device_unregister;
 
-	rval = isys_notifier_init(isys);
-	if (rval)
-		goto out_isys_unregister_subdevices;
+	isys_register_ext_subdevs(isys);
 
 	rval = v4l2_device_register_subdev_nodes(&isys->v4l2_dev);
 	if (rval)
-		goto out_isys_notifier_cleanup;
+		goto out_isys_unregister_subdevices;
 
 	return 0;
 
-out_isys_notifier_cleanup:
-	isys_notifier_cleanup(isys);
-
 out_isys_unregister_subdevices:
 	isys_unregister_subdevices(isys);
 
@@ -596,7 +707,9 @@ static int isys_register_devices(struct ipu_isys *isys)
 
 out_media_device_unregister:
 	media_device_unregister(&isys->media_dev);
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 5, 0)
 	media_device_cleanup(&isys->media_dev);
+#endif
 
 	return rval;
 }
@@ -606,7 +719,9 @@ static void isys_unregister_devices(struct ipu_isys *isys)
 	isys_unregister_subdevices(isys);
 	v4l2_device_unregister(&isys->v4l2_dev);
 	media_device_unregister(&isys->media_dev);
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 5, 0)
 	media_device_cleanup(&isys->media_dev);
+#endif
 }
 
 #ifdef CONFIG_PM
@@ -618,12 +733,10 @@ static int isys_runtime_pm_resume(struct device *dev)
 	unsigned long flags;
 	int ret;
 
-	if (!isys)
+	if (!isys) {
+		WARN(1, "%s called before probing. skipping.\n", __func__);
 		return 0;
-
-	ret = ipu_mmu_hw_init(adev->mmu);
-	if (ret)
-		return ret;
+	}
 
 	ipu_trace_restore(dev);
 
@@ -644,7 +757,6 @@ static int isys_runtime_pm_resume(struct device *dev)
 	}
 	isys_setup_hw(isys);
 
-	set_iwake_ltrdid(isys, 0, 0, LTR_ISYS_ON);
 	return 0;
 }
 
@@ -654,8 +766,10 @@ static int isys_runtime_pm_suspend(struct device *dev)
 	struct ipu_isys *isys = ipu_bus_get_drvdata(adev);
 	unsigned long flags;
 
-	if (!isys)
+	if (!isys) {
+		WARN(1, "%s called before probing. skipping.\n", __func__);
 		return 0;
+	}
 
 	spin_lock_irqsave(&isys->power_lock, flags);
 	isys->power = 0;
@@ -668,9 +782,6 @@ static int isys_runtime_pm_suspend(struct device *dev)
 
 	cpu_latency_qos_update_request(&isys->pm_qos, PM_QOS_DEFAULT_VALUE);
 
-	ipu_mmu_hw_cleanup(adev->mmu);
-
-	set_iwake_ltrdid(isys, 0, 0, LTR_ISYS_OFF);
 	return 0;
 }
 
@@ -710,30 +821,33 @@ static void isys_remove(struct ipu_bus_device *adev)
 	struct isys_fw_msgs *fwmsg, *safe;
 
 	dev_info(&adev->dev, "removed\n");
-#ifdef CONFIG_DEBUG_FS
 	if (isp->ipu_dir)
 		debugfs_remove_recursive(isys->debugfsdir);
-#endif
 
 	list_for_each_entry_safe(fwmsg, safe, &isys->framebuflist, head) {
 		dma_free_attrs(&adev->dev, sizeof(struct isys_fw_msgs),
 			       fwmsg, fwmsg->dma_addr,
-			       0);
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0)
+			       NULL
+#else
+			       0
+#endif
+		    );
 	}
 
 	list_for_each_entry_safe(fwmsg, safe, &isys->framebuflist_fw, head) {
 		dma_free_attrs(&adev->dev, sizeof(struct isys_fw_msgs),
 			       fwmsg, fwmsg->dma_addr,
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0)
+			       NULL
+#else
 			       0
+#endif
 		    );
 	}
 
-	isys_iwake_watermark_cleanup(isys);
-
 	ipu_trace_uninit(&adev->dev);
-	isys_notifier_cleanup(isys);
 	isys_unregister_devices(isys);
-
 	cpu_latency_qos_remove_request(&isys->pm_qos);
 
 	if (!isp->secure_mode) {
@@ -749,14 +863,28 @@ static void isys_remove(struct ipu_bus_device *adev)
 
 	if (isys->short_packet_source == IPU_ISYS_SHORT_PACKET_FROM_TUNIT) {
 		u32 trace_size = IPU_ISYS_SHORT_PACKET_TRACE_BUFFER_SIZE;
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0)
+		struct dma_attrs attrs;
+
+		init_dma_attrs(&attrs);
+		dma_set_attr(DMA_ATTR_NON_CONSISTENT, &attrs);
+		dma_free_attrs(&adev->dev, trace_size,
+			       isys->short_packet_trace_buffer,
+			       isys->short_packet_trace_buffer_dma_addr,
+			       &attrs);
+#else
+		unsigned long attrs = 0;
 
-		dma_free_coherent(&adev->dev, trace_size,
-				  isys->short_packet_trace_buffer,
-				  isys->short_packet_trace_buffer_dma_addr);
+#if LINUX_VERSION_CODE < KERNEL_VERSION(5, 10, 0)
+		attrs = DMA_ATTR_NON_CONSISTENT;
+#endif
+		dma_free_attrs(&adev->dev, trace_size,
+			       isys->short_packet_trace_buffer,
+			       isys->short_packet_trace_buffer_dma_addr, attrs);
+#endif
 	}
 }
 
-#ifdef CONFIG_DEBUG_FS
 static int ipu_isys_icache_prefetch_get(void *data, u64 *val)
 {
 	struct ipu_isys *isys = data;
@@ -777,50 +905,14 @@ static int ipu_isys_icache_prefetch_set(void *data, u64 val)
 	return 0;
 }
 
-static int isys_iwake_control_get(void *data, u64 *val)
-{
-	struct ipu_isys *isys = data;
-	struct isys_iwake_watermark *iwake_watermark = isys->iwake_watermark;
-
-	mutex_lock(&iwake_watermark->mutex);
-	*val = isys->iwake_watermark->force_iwake_disable;
-	mutex_unlock(&iwake_watermark->mutex);
-	return 0;
-}
-
-static int isys_iwake_control_set(void *data, u64 val)
-{
-	struct ipu_isys *isys = data;
-	struct isys_iwake_watermark *iwake_watermark;
-
-	if (val != !!val)
-		return -EINVAL;
-	/* If stream is open, refuse to set iwake */
-	if (isys->stream_opened)
-		return -EBUSY;
-
-	iwake_watermark = isys->iwake_watermark;
-	mutex_lock(&iwake_watermark->mutex);
-	isys->iwake_watermark->force_iwake_disable = !!val;
-	mutex_unlock(&iwake_watermark->mutex);
-	return 0;
-}
-
 DEFINE_SIMPLE_ATTRIBUTE(isys_icache_prefetch_fops,
 			ipu_isys_icache_prefetch_get,
 			ipu_isys_icache_prefetch_set, "%llu\n");
 
-DEFINE_SIMPLE_ATTRIBUTE(isys_iwake_control_fops,
-			isys_iwake_control_get,
-			isys_iwake_control_set, "%llu\n");
-
 static int ipu_isys_init_debugfs(struct ipu_isys *isys)
 {
 	struct dentry *file;
 	struct dentry *dir;
-#ifdef IPU_ISYS_GPC
-	int ret;
-#endif
 
 	dir = debugfs_create_dir("isys", isys->adev->isp->ipu_dir);
 	if (IS_ERR(dir))
@@ -831,27 +923,16 @@ static int ipu_isys_init_debugfs(struct ipu_isys *isys)
 	if (IS_ERR(file))
 		goto err;
 
-	file = debugfs_create_file("iwake_disable", 0600,
-				   dir, isys, &isys_iwake_control_fops);
-	if (IS_ERR(file))
-		goto err;
-
 	isys->debugfsdir = dir;
 
-#ifdef IPU_ISYS_GPC
-	ret = ipu_isys_gpc_init_debugfs(isys);
-	if (ret)
-		return ret;
-#endif
 
 	return 0;
 err:
 	debugfs_remove_recursive(dir);
 	return -ENOMEM;
 }
-#endif
 
-static int alloc_fw_msg_bufs(struct ipu_isys *isys, int amount)
+static int alloc_fw_msg_buffers(struct ipu_isys *isys, int amount)
 {
 	dma_addr_t dma_addr;
 	struct isys_fw_msgs *addr;
@@ -862,7 +943,12 @@ static int alloc_fw_msg_bufs(struct ipu_isys *isys, int amount)
 		addr = dma_alloc_attrs(&isys->adev->dev,
 				       sizeof(struct isys_fw_msgs),
 				       &dma_addr, GFP_KERNEL,
-				       0);
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0)
+				       NULL
+#else
+				       0
+#endif
+		    );
 		if (!addr)
 			break;
 		addr->dma_addr = dma_addr;
@@ -882,7 +968,12 @@ static int alloc_fw_msg_bufs(struct ipu_isys *isys, int amount)
 		dma_free_attrs(&isys->adev->dev,
 			       sizeof(struct isys_fw_msgs),
 			       addr, addr->dma_addr,
-			       0);
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0)
+			       NULL
+#else
+			       0
+#endif
+		    );
 		spin_lock_irqsave(&isys->listlock, flags);
 	}
 	spin_unlock_irqrestore(&isys->listlock, flags);
@@ -904,12 +995,12 @@ struct isys_fw_msgs *ipu_get_fw_msg_buf(struct ipu_isys_pipeline *ip)
 		spin_unlock_irqrestore(&isys->listlock, flags);
 		dev_dbg(&isys->adev->dev, "Frame list empty - Allocate more");
 
-		alloc_fw_msg_bufs(isys, 5);
+		alloc_fw_msg_buffers(isys, 5);
 
 		spin_lock_irqsave(&isys->listlock, flags);
 		if (list_empty(&isys->framebuflist)) {
-			spin_unlock_irqrestore(&isys->listlock, flags);
 			dev_err(&isys->adev->dev, "Frame list empty");
+			spin_unlock_irqrestore(&isys->listlock, flags);
 			return NULL;
 		}
 	}
@@ -932,88 +1023,76 @@ void ipu_cleanup_fw_msg_bufs(struct ipu_isys *isys)
 	spin_unlock_irqrestore(&isys->listlock, flags);
 }
 
-void ipu_put_fw_mgs_buf(struct ipu_isys *isys, u64 data)
+void ipu_put_fw_mgs_buffer(struct ipu_isys *isys, u64 data)
 {
 	struct isys_fw_msgs *msg;
-	unsigned long flags;
 	u64 *ptr = (u64 *)(unsigned long)data;
 
 	if (!ptr)
 		return;
 
-	spin_lock_irqsave(&isys->listlock, flags);
+	spin_lock(&isys->listlock);
 	msg = container_of(ptr, struct isys_fw_msgs, fw_msg.dummy);
 	list_move(&msg->head, &isys->framebuflist);
-	spin_unlock_irqrestore(&isys->listlock, flags);
+	spin_unlock(&isys->listlock);
 }
+EXPORT_SYMBOL_GPL(ipu_put_fw_mgs_buffer);
 
 static int isys_probe(struct ipu_bus_device *adev)
 {
 	struct ipu_isys *isys;
 	struct ipu_device *isp = adev->isp;
+#if defined(CONFIG_VIDEO_INTEL_IPU4) || defined(CONFIG_VIDEO_INTEL_IPU4P)
+	const u32 trace_size = IPU_ISYS_SHORT_PACKET_TRACE_BUFFER_SIZE;
+	dma_addr_t *trace_dma_addr;
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0)
+	struct dma_attrs attrs;
+#else
+	unsigned long attrs;
+#endif
+#endif
 	const struct firmware *fw;
 	int rval = 0;
 
+	trace_printk("B|%d|TMWK\n", current->pid);
+
+	/* Has the domain been attached? */
+	if (!isp->secure_mode && !isp->pkg_dir_dma_addr) {
+		trace_printk("E|TMWK\n");
+		return -EPROBE_DEFER;
+	}
+
 	isys = devm_kzalloc(&adev->dev, sizeof(*isys), GFP_KERNEL);
 	if (!isys)
 		return -ENOMEM;
 
-	rval = ipu_mmu_hw_init(adev->mmu);
-	if (rval)
-		return rval;
-
 	/* By default, short packet is captured from T-Unit. */
+#if defined(CONFIG_VIDEO_INTEL_IPU4) || defined(CONFIG_VIDEO_INTEL_IPU4P)
+	isys->short_packet_source = IPU_ISYS_SHORT_PACKET_FROM_TUNIT;
+	trace_dma_addr = &isys->short_packet_trace_buffer_dma_addr;
+	mutex_init(&isys->short_packet_tracing_mutex);
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0)
+	init_dma_attrs(&attrs);
+	dma_set_attr(DMA_ATTR_NON_CONSISTENT, &attrs);
+	isys->short_packet_trace_buffer =
+	    dma_alloc_attrs(&adev->dev, trace_size, trace_dma_addr,
+			    GFP_KERNEL, &attrs);
+#else
+#if LINUX_VERSION_CODE < KERNEL_VERSION(5, 10, 0)
+	attrs = DMA_ATTR_NON_CONSISTENT;
+#endif
+	isys->short_packet_trace_buffer =
+	    dma_alloc_attrs(&adev->dev, trace_size, trace_dma_addr,
+			    GFP_KERNEL, attrs);
+#endif
+	if (!isys->short_packet_trace_buffer)
+		return -ENOMEM;
+#else
 	isys->short_packet_source = IPU_ISYS_SHORT_PACKET_FROM_RECEIVER;
+#endif
 	isys->adev = adev;
 	isys->pdata = adev->pdata;
 
-	/* initial streamID for different sensor types */
-	if (ipu_ver == IPU_VER_6 || ipu_ver == IPU_VER_6EP) {
-		isys->sensor_info.vc1_data_start =
-			IPU6_FW_ISYS_VC1_SENSOR_DATA_START;
-		isys->sensor_info.vc1_data_end =
-			IPU6_FW_ISYS_VC1_SENSOR_DATA_END;
-		isys->sensor_info.vc0_data_start =
-			IPU6_FW_ISYS_VC0_SENSOR_DATA_START;
-		isys->sensor_info.vc0_data_end =
-			IPU6_FW_ISYS_VC0_SENSOR_DATA_END;
-		isys->sensor_info.vc1_pdaf_start =
-			IPU6_FW_ISYS_VC1_SENSOR_PDAF_START;
-		isys->sensor_info.vc1_pdaf_end =
-			IPU6_FW_ISYS_VC1_SENSOR_PDAF_END;
-		isys->sensor_info.sensor_metadata =
-			IPU6_FW_ISYS_SENSOR_METADATA;
-
-		isys->sensor_types[IPU_FW_ISYS_VC1_SENSOR_DATA] =
-			IPU6_FW_ISYS_VC1_SENSOR_DATA_START;
-		isys->sensor_types[IPU_FW_ISYS_VC1_SENSOR_PDAF] =
-			IPU6_FW_ISYS_VC1_SENSOR_PDAF_START;
-		isys->sensor_types[IPU_FW_ISYS_VC0_SENSOR_DATA] =
-			IPU6_FW_ISYS_VC0_SENSOR_DATA_START;
-	} else if (ipu_ver == IPU_VER_6SE) {
-		isys->sensor_info.vc1_data_start =
-			IPU6SE_FW_ISYS_VC1_SENSOR_DATA_START;
-		isys->sensor_info.vc1_data_end =
-			IPU6SE_FW_ISYS_VC1_SENSOR_DATA_END;
-		isys->sensor_info.vc0_data_start =
-			IPU6SE_FW_ISYS_VC0_SENSOR_DATA_START;
-		isys->sensor_info.vc0_data_end =
-			IPU6SE_FW_ISYS_VC0_SENSOR_DATA_END;
-		isys->sensor_info.vc1_pdaf_start =
-			IPU6SE_FW_ISYS_VC1_SENSOR_PDAF_START;
-		isys->sensor_info.vc1_pdaf_end =
-			IPU6SE_FW_ISYS_VC1_SENSOR_PDAF_END;
-		isys->sensor_info.sensor_metadata =
-			IPU6SE_FW_ISYS_SENSOR_METADATA;
-
-		isys->sensor_types[IPU_FW_ISYS_VC1_SENSOR_DATA] =
-			IPU6SE_FW_ISYS_VC1_SENSOR_DATA_START;
-		isys->sensor_types[IPU_FW_ISYS_VC1_SENSOR_PDAF] =
-			IPU6SE_FW_ISYS_VC1_SENSOR_PDAF_START;
-		isys->sensor_types[IPU_FW_ISYS_VC0_SENSOR_DATA] =
-			IPU6SE_FW_ISYS_VC0_SENSOR_DATA_START;
-	}
-
 	INIT_LIST_HEAD(&isys->requests);
 
 	spin_lock_init(&isys->lock);
@@ -1028,11 +1107,15 @@ static int isys_probe(struct ipu_bus_device *adev)
 	INIT_LIST_HEAD(&isys->framebuflist);
 	INIT_LIST_HEAD(&isys->framebuflist_fw);
 
-	dev_dbg(&adev->dev, "isys probe %p %p\n", adev, &adev->dev);
+	dev_info(&adev->dev, "isys probe %p %p\n", adev, &adev->dev);
 	ipu_bus_set_drvdata(adev, isys);
 
 	isys->line_align = IPU_ISYS_2600_MEM_LINE_ALIGN;
+#ifdef CONFIG_VIDEO_INTEL_IPU4
+	isys->icache_prefetch = is_ipu_hw_bxtp_e0(isp);
+#else
 	isys->icache_prefetch = 0;
+#endif
 
 #ifndef CONFIG_PM
 	isys_setup_hw(isys);
@@ -1044,42 +1127,37 @@ static int isys_probe(struct ipu_bus_device *adev)
 		if (rval)
 			goto release_firmware;
 
-		isys->pkg_dir =
-		    ipu_cpd_create_pkg_dir(adev, isp->cpd_fw->data,
-					   sg_dma_address(isys->fw_sgt.sgl),
-					   &isys->pkg_dir_dma_addr,
-					   &isys->pkg_dir_size);
+		isys->pkg_dir = ipu_cpd_create_pkg_dir(adev, isp->cpd_fw->data,
+						       sg_dma_address(isys->
+								      fw_sgt.
+								      sgl),
+						       &isys->pkg_dir_dma_addr,
+						       &isys->pkg_dir_size);
 		if (!isys->pkg_dir) {
 			rval = -ENOMEM;
 			goto remove_shared_buffer;
 		}
 	}
 
-#ifdef CONFIG_DEBUG_FS
 	/* Debug fs failure is not fatal. */
 	ipu_isys_init_debugfs(isys);
-#endif
 
 	ipu_trace_init(adev->isp, isys->pdata->base, &adev->dev,
 		       isys_trace_blocks);
 
 	cpu_latency_qos_add_request(&isys->pm_qos, PM_QOS_DEFAULT_VALUE);
-	alloc_fw_msg_bufs(isys, 20);
+	alloc_fw_msg_buffers(isys, 20);
+
+	pm_runtime_allow(&adev->dev);
+	pm_runtime_enable(&adev->dev);
 
 	rval = isys_register_devices(isys);
 	if (rval)
 		goto out_remove_pkg_dir_shared_buffer;
-	rval = isys_iwake_watermark_init(isys);
-	if (rval)
-		goto out_unregister_devices;
-
-	ipu_mmu_hw_cleanup(adev->mmu);
 
+	trace_printk("E|TMWK\n");
 	return 0;
 
-out_unregister_devices:
-	isys_iwake_watermark_cleanup(isys);
-	isys_unregister_devices(isys);
 out_remove_pkg_dir_shared_buffer:
 	if (!isp->secure_mode)
 		ipu_cpd_free_pkg_dir(adev, isys->pkg_dir,
@@ -1093,13 +1171,24 @@ static int isys_probe(struct ipu_bus_device *adev)
 		release_firmware(isys->fw);
 	ipu_trace_uninit(&adev->dev);
 
+	trace_printk("E|TMWK\n");
+
 	mutex_destroy(&isys->mutex);
 	mutex_destroy(&isys->stream_mutex);
 
-	if (isys->short_packet_source == IPU_ISYS_SHORT_PACKET_FROM_TUNIT)
+	if (isys->short_packet_source == IPU_ISYS_SHORT_PACKET_FROM_TUNIT) {
 		mutex_destroy(&isys->short_packet_tracing_mutex);
-
-	ipu_mmu_hw_cleanup(adev->mmu);
+#if defined(CONFIG_VIDEO_INTEL_IPU4) || defined(CONFIG_VIDEO_INTEL_IPU4P)
+		dma_free_attrs(&adev->dev, trace_size,
+			       isys->short_packet_trace_buffer,
+			       isys->short_packet_trace_buffer_dma_addr,
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0)
+			       &attrs);
+#else
+			       attrs);
+#endif
+#endif
+	}
 
 	return rval;
 }
@@ -1157,7 +1246,7 @@ int isys_isr_one(struct ipu_bus_device *adev)
 	if (!resp)
 		return 1;
 
-	ts = (u64)resp->timestamp[1] << 32 | resp->timestamp[0];
+	ts = (u64) resp->timestamp[1] << 32 | resp->timestamp[0];
 
 	if (resp->error_info.error == IPU_FW_ISYS_ERROR_STREAM_IN_SUSPENSION)
 		/* Suspension is kind of special case: not enough buffers */
@@ -1203,7 +1292,7 @@ int isys_isr_one(struct ipu_bus_device *adev)
 
 	switch (resp->type) {
 	case IPU_FW_ISYS_RESP_TYPE_STREAM_OPEN_DONE:
-		ipu_put_fw_mgs_buf(ipu_bus_get_drvdata(adev), resp->buf_id);
+		ipu_put_fw_mgs_buffer(ipu_bus_get_drvdata(adev), resp->buf_id);
 		complete(&pipe->stream_open_completion);
 		break;
 	case IPU_FW_ISYS_RESP_TYPE_STREAM_CLOSE_ACK:
@@ -1213,7 +1302,7 @@ int isys_isr_one(struct ipu_bus_device *adev)
 		complete(&pipe->stream_start_completion);
 		break;
 	case IPU_FW_ISYS_RESP_TYPE_STREAM_START_AND_CAPTURE_ACK:
-		ipu_put_fw_mgs_buf(ipu_bus_get_drvdata(adev), resp->buf_id);
+		ipu_put_fw_mgs_buffer(ipu_bus_get_drvdata(adev), resp->buf_id);
 		complete(&pipe->stream_start_completion);
 		break;
 	case IPU_FW_ISYS_RESP_TYPE_STREAM_STOP_ACK:
@@ -1230,11 +1319,10 @@ int isys_isr_one(struct ipu_bus_device *adev)
 			dev_err(&adev->dev,
 				"%d:No data pin ready handler for pin id %d\n",
 				resp->stream_handle, resp->pin_id);
-		if (pipe->csi2)
-			ipu_isys_csi2_error(pipe->csi2);
-
 		break;
 	case IPU_FW_ISYS_RESP_TYPE_STREAM_CAPTURE_ACK:
+		ipu_put_fw_mgs_buffer(ipu_bus_get_drvdata(adev), resp->buf_id);
+		complete(&pipe->capture_ack_completion);
 		break;
 	case IPU_FW_ISYS_RESP_TYPE_STREAM_START_AND_CAPTURE_DONE:
 	case IPU_FW_ISYS_RESP_TYPE_STREAM_CAPTURE_DONE:
@@ -1242,13 +1330,13 @@ int isys_isr_one(struct ipu_bus_device *adev)
 			struct ipu_isys_buffer *ib, *ib_safe;
 			struct list_head list;
 			unsigned long flags;
-			unsigned int *ts = resp->timestamp;
 
 			if (pipe->isys->short_packet_source ==
 			    IPU_ISYS_SHORT_PACKET_FROM_TUNIT)
 				pipe->cur_field =
-				    ipu_isys_csi2_get_current_field(pipe, ts);
-
+				    ipu_isys_csi2_get_current_field(pipe,
+								    resp->
+								    timestamp);
 			/*
 			 * Move the pending buffers to a local temp list.
 			 * Then we do not need to handle the lock during
@@ -1266,7 +1354,11 @@ int isys_isr_one(struct ipu_bus_device *adev)
 				struct vb2_buffer *vb;
 
 				vb = ipu_isys_buffer_to_vb2_buffer(ib);
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 4, 0)
+				vb->v4l2_buf.field = pipe->cur_field;
+#else
 				to_vb2_v4l2_buffer(vb)->field = pipe->cur_field;
+#endif
 				list_del(&ib->head);
 
 				ipu_isys_queue_buf_done(ib);
@@ -1278,9 +1370,6 @@ int isys_isr_one(struct ipu_bus_device *adev)
 
 		break;
 	case IPU_FW_ISYS_RESP_TYPE_FRAME_SOF:
-		if (pipe->csi2)
-			ipu_isys_csi2_sof_event(pipe->csi2);
-
 		pipe->seq[pipe->seq_index].sequence =
 		    atomic_read(&pipe->sequence) - 1;
 		pipe->seq[pipe->seq_index].timestamp = ts;
@@ -1292,8 +1381,7 @@ int isys_isr_one(struct ipu_bus_device *adev)
 		    % IPU_ISYS_MAX_PARALLEL_SOF;
 		break;
 	case IPU_FW_ISYS_RESP_TYPE_FRAME_EOF:
-		if (pipe->csi2)
-			ipu_isys_csi2_eof_event(pipe->csi2);
+
 
 		dev_dbg(&adev->dev,
 			"eof: handle %d: (index %u), timestamp 0x%16.16llx\n",
@@ -1313,6 +1401,34 @@ int isys_isr_one(struct ipu_bus_device *adev)
 	return 0;
 }
 
+static void isys_isr_poll(struct ipu_bus_device *adev)
+{
+	struct ipu_isys *isys = ipu_bus_get_drvdata(adev);
+
+	if (!isys->fwcom) {
+		dev_dbg(&isys->adev->dev,
+			"got interrupt but device not configured yet\n");
+		return;
+	}
+
+	mutex_lock(&isys->mutex);
+	isys_isr(adev);
+	mutex_unlock(&isys->mutex);
+}
+
+int ipu_isys_isr_run(void *ptr)
+{
+	struct ipu_isys *isys = ptr;
+
+	while (!kthread_should_stop()) {
+		usleep_range(500, 1000);
+		if (isys->stream_opened)
+			isys_isr_poll(isys->adev);
+	}
+
+	return 0;
+}
+
 static struct ipu_bus_driver isys_driver = {
 	.probe = isys_probe,
 	.remove = isys_remove,
@@ -1328,11 +1444,7 @@ static struct ipu_bus_driver isys_driver = {
 module_ipu_bus_driver(isys_driver);
 
 static const struct pci_device_id ipu_pci_tbl[] = {
-	{PCI_DEVICE(PCI_VENDOR_ID_INTEL, IPU6_PCI_ID)},
-	{PCI_DEVICE(PCI_VENDOR_ID_INTEL, IPU6SE_PCI_ID)},
-	{PCI_DEVICE(PCI_VENDOR_ID_INTEL, IPU6EP_ADL_P_PCI_ID)},
-	{PCI_DEVICE(PCI_VENDOR_ID_INTEL, IPU6EP_ADL_N_PCI_ID)},
-	{PCI_DEVICE(PCI_VENDOR_ID_INTEL, IPU6EP_RPL_P_PCI_ID)},
+	{PCI_DEVICE(PCI_VENDOR_ID_INTEL, IPU_PCI_ID)},
 	{0,}
 };
 MODULE_DEVICE_TABLE(pci, ipu_pci_tbl);
diff --git a/drivers/media/pci/intel/ipu-isys.h b/drivers/media/pci/intel/ipu-isys.h
index 8b1228febdf6..847961062c9f 100644
--- a/drivers/media/pci/intel/ipu-isys.h
+++ b/drivers/media/pci/intel/ipu-isys.h
@@ -1,5 +1,5 @@
 /* SPDX-License-Identifier: GPL-2.0 */
-/* Copyright (C) 2013 - 2020 Intel Corporation */
+/* Copyright (C) 2013 - 2018 Intel Corporation */
 
 #ifndef IPU_ISYS_H
 #define IPU_ISYS_H
@@ -16,6 +16,7 @@
 #include "ipu-isys-media.h"
 #include "ipu-isys-csi2.h"
 #include "ipu-isys-csi2-be.h"
+#include "ipu-isys-tpg.h"
 #include "ipu-isys-video.h"
 #include "ipu-pdata.h"
 #include "ipu-fw-isys.h"
@@ -56,58 +57,8 @@
 #define IPU_ISYS_MAX_WIDTH		16384U
 #define IPU_ISYS_MAX_HEIGHT		16384U
 
-#define NR_OF_CSI2_BE_SOC_DEV 1
-
-/* the threshold granularity is 2KB on IPU6 */
-#define IPU6_SRAM_GRANULRITY_SHIFT	11
-#define IPU6_SRAM_GRANULRITY_SIZE	2048
-/* the threshold granularity is 1KB on IPU6SE */
-#define IPU6SE_SRAM_GRANULRITY_SHIFT	10
-#define IPU6SE_SRAM_GRANULRITY_SIZE	1024
-
 struct task_struct;
 
-struct ltr_did {
-	union {
-		u32 value;
-		struct {
-			u8 val0;
-			u8 val1;
-			u8 val2;
-			u8 val3;
-		} bits;
-	} lut_ltr;
-	union {
-		u32 value;
-		struct {
-			u8 th0;
-			u8 th1;
-			u8 th2;
-			u8 th3;
-		} bits;
-	} lut_fill_time;
-};
-
-struct isys_iwake_watermark {
-	bool iwake_enabled;
-	bool force_iwake_disable;
-	u32 iwake_threshold;
-	u64 isys_pixelbuffer_datarate;
-	struct ltr_did ltrdid;
-	struct mutex mutex; /* protect whole struct */
-	struct ipu_isys *isys;
-	struct list_head video_list;
-};
-struct ipu_isys_sensor_info {
-	unsigned int vc1_data_start;
-	unsigned int vc1_data_end;
-	unsigned int vc0_data_start;
-	unsigned int vc0_data_end;
-	unsigned int vc1_pdaf_start;
-	unsigned int vc1_pdaf_end;
-	unsigned int sensor_metadata;
-};
-
 /*
  * struct ipu_isys
  *
@@ -130,7 +81,9 @@ struct ipu_isys_sensor_info {
  * @lib_mutex: optional external library mutex
  * @pdata: platform data pointer
  * @csi2: CSI-2 receivers
+ * @tpg: test pattern generators
  * @csi2_be: CSI-2 back-ends
+ * @isa: Input system accelerator
  * @fw: ISYS firmware binary (unsecure firmware)
  * @fw_sgt: fw scatterlist
  * @pkg_dir: host pointer to pkg_dir
@@ -156,12 +109,11 @@ struct ipu_isys {
 	bool csi2_cse_ipc_not_supported;
 	unsigned int video_opened;
 	unsigned int stream_opened;
-	struct ipu_isys_sensor_info sensor_info;
+#if !defined(CONFIG_VIDEO_INTEL_IPU4) && !defined(CONFIG_VIDEO_INTEL_IPU4P)
 	unsigned int sensor_types[N_IPU_FW_ISYS_SENSOR_TYPE];
+#endif
 
-#ifdef CONFIG_DEBUG_FS
 	struct dentry *debugfsdir;
-#endif
 	struct mutex mutex;	/* Serialise isys video open/release related */
 	struct mutex stream_mutex;	/* Stream start, stop, queueing reqs */
 	struct mutex lib_mutex;	/* Serialise optional external library mutex */
@@ -169,8 +121,11 @@ struct ipu_isys {
 	struct ipu_isys_pdata *pdata;
 
 	struct ipu_isys_csi2 *csi2;
+	struct ipu_isys_tpg *tpg;
+	struct ipu_isys_isa isa;
 	struct ipu_isys_csi2_be csi2_be;
-	struct ipu_isys_csi2_be_soc csi2_be_soc[NR_OF_CSI2_BE_SOC_DEV];
+	struct ipu_isys_csi2_be_soc csi2_be_soc;
+
 	const struct firmware *fw;
 	struct sg_table fw_sgt;
 
@@ -190,13 +145,8 @@ struct ipu_isys {
 	spinlock_t listlock;	/* Protect framebuflist */
 	struct list_head framebuflist;
 	struct list_head framebuflist_fw;
-	struct v4l2_async_notifier notifier;
-	struct isys_iwake_watermark *iwake_watermark;
-
 };
 
-void update_watermark_setting(struct ipu_isys *isys);
-
 struct isys_fw_msgs {
 	union {
 		u64 dummy;
@@ -211,17 +161,18 @@ struct isys_fw_msgs {
 #define to_stream_cfg_msg_buf(a) (&(a)->fw_msg.stream)
 #define to_dma_addr(a) ((a)->dma_addr)
 
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 6, 0)
+int ipu_pipeline_pm_use(struct media_entity *entity, int use);
+#endif
 struct isys_fw_msgs *ipu_get_fw_msg_buf(struct ipu_isys_pipeline *ip);
-void ipu_put_fw_mgs_buf(struct ipu_isys *isys, u64 data);
+void ipu_put_fw_mgs_buffer(struct ipu_isys *isys, u64 data);
 void ipu_cleanup_fw_msg_bufs(struct ipu_isys *isys);
 
 extern const struct v4l2_ioctl_ops ipu_isys_ioctl_ops;
 
 void isys_setup_hw(struct ipu_isys *isys);
 int isys_isr_one(struct ipu_bus_device *adev);
+int ipu_isys_isr_run(void *ptr);
 irqreturn_t isys_isr(struct ipu_bus_device *adev);
-#ifdef IPU_ISYS_GPC
-int ipu_isys_gpc_init_debugfs(struct ipu_isys *isys);
-#endif
 
 #endif /* IPU_ISYS_H */
diff --git a/drivers/media/pci/intel/ipu-mmu.c b/drivers/media/pci/intel/ipu-mmu.c
index 7d38529820b1..4fc81c03361f 100644
--- a/drivers/media/pci/intel/ipu-mmu.c
+++ b/drivers/media/pci/intel/ipu-mmu.c
@@ -1,15 +1,17 @@
 // SPDX-License-Identifier: GPL-2.0
-// Copyright (C) 2013 - 2021 Intel Corporation
+// Copyright (C) 2013 - 2018 Intel Corporation
 
 #include <asm/cacheflush.h>
 
 #include <linux/device.h>
 #include <linux/iova.h>
 #include <linux/module.h>
+#include <linux/pm_runtime.h>
 #include <linux/sizes.h>
 
 #include "ipu.h"
 #include "ipu-platform.h"
+#include "ipu-bus.h"
 #include "ipu-dma.h"
 #include "ipu-mmu.h"
 #include "ipu-platform-regs.h"
@@ -31,6 +33,10 @@
 
 #define REG_TLB_INVALIDATE	0x0000
 
+#define MMU0_TLB_INVALIDATE	1
+
+#define MMU1_TLB_INVALIDATE	0xffff
+
 #define REG_L1_PHYS		0x0004	/* 27-bit pfn */
 #define REG_INFO		0x0008
 
@@ -40,7 +46,87 @@
 /* The range of stream ID i in L2 cache is from 0 to 15 */
 #define MMUV2_REG_L2_STREAMID(i)	(0x4c + ((i) * 4))
 
+/* ZLW Enable for each stream in L1 MMU AT where i : 0..15 */
+#define MMUV2_AT_REG_L1_ZLW_EN_SID(i)		(0x100 + ((i) * 0x20))
+
+/* ZLW 1D mode Enable for each stream in L1 MMU AT where i : 0..15 */
+#define MMUV2_AT_REG_L1_ZLW_1DMODE_SID(i)	(0x100 + ((i) * 0x20) + 0x0004)
+
+/* Set ZLW insertion N pages ahead per stream 1D where i : 0..15 */
+#define MMUV2_AT_REG_L1_ZLW_INS_N_AHEAD_SID(i)	(0x100 + ((i) * 0x20) + 0x0008)
+
+/* ZLW 2D mode Enable for each stream in L1 MMU AT where i : 0..15 */
+#define MMUV2_AT_REG_L1_ZLW_2DMODE_SID(i)	(0x100 + ((i) * 0x20) + 0x0010)
+
+/* ZLW Insertion for each stream in L1 MMU AT where i : 0..15 */
+#define MMUV2_AT_REG_L1_ZLW_INSERTION(i)	(0x100 + ((i) * 0x20) + 0x000c)
+
+#define MMUV2_AT_REG_L1_FW_ZLW_FIFO		(0x100 + \
+			(IPU_MMU_MAX_TLB_L1_STREAMS * 0x20) + 0x003c)
+
+/* FW ZLW has prioty - needed for ZLW invalidations */
+#define MMUV2_AT_REG_L1_FW_ZLW_PRIO		(0x100 + \
+			(IPU_MMU_MAX_TLB_L1_STREAMS * 0x20))
+
 #define TBL_PHYS_ADDR(a)	((phys_addr_t)(a) << ISP_PADDR_SHIFT)
+#define TBL_VIRT_ADDR(a)	phys_to_virt(TBL_PHYS_ADDR(a))
+
+static void zlw_invalidate(struct ipu_mmu *mmu, struct ipu_mmu_hw *mmu_hw)
+{
+	unsigned int retry = 0;
+	unsigned int i, j;
+	int ret;
+
+	for (i = 0; i < mmu_hw->nr_l1streams; i++) {
+		/* We need to invalidate only the zlw enabled stream IDs */
+		if (mmu_hw->l1_zlw_en[i]) {
+			/*
+			 * Maximum 16 blocks per L1 stream
+			 * Write trash buffer iova offset to the FW_ZLW
+			 * register. This will trigger pre-fetching of next 16
+			 * pages from the page table. So we need to increment
+			 * iova address by 16 * 4K to trigger the next 16 pages.
+			 * Once this loop is completed, the L1 cache will be
+			 * filled with trash buffer translation.
+			 *
+			 * TODO: Instead of maximum 16 blocks, use the allocated
+			 * block size
+			 */
+			for (j = 0; j < mmu_hw->l1_block_sz[i]; j++)
+				writel(mmu->iova_addr_trash +
+					   j * MMUV2_TRASH_L1_BLOCK_OFFSET,
+					   mmu_hw->base +
+					   MMUV2_AT_REG_L1_ZLW_INSERTION(i));
+
+			/*
+			 * Now we need to fill the L2 cache entry. L2 cache
+			 * entries will be automatically updated, based on the
+			 * L1 entry. The above loop for L1 will update only one
+			 * of the two entries in L2 as the L1 is under 4MB
+			 * range. To force the other entry in L2 to update, we
+			 * just need to trigger another pre-fetch which is
+			 * outside the above 4MB range.
+			 */
+			writel(mmu->iova_addr_trash +
+				   MMUV2_TRASH_L2_BLOCK_OFFSET,
+				   mmu_hw->base +
+				   MMUV2_AT_REG_L1_ZLW_INSERTION(0));
+		}
+	}
+
+	/*
+	 * Wait until AT is ready. FIFO read should return 2 when AT is ready.
+	 * Retry value of 1000 is just by guess work to avoid the forever loop.
+	 */
+	do {
+		if (retry > 1000) {
+			dev_err(mmu->dev, "zlw invalidation failed\n");
+			return;
+		}
+		ret = readl(mmu_hw->base + MMUV2_AT_REG_L1_FW_ZLW_FIFO);
+		retry++;
+	} while (ret != 2);
+}
 
 static void tlb_invalidate(struct ipu_mmu *mmu)
 {
@@ -54,26 +140,35 @@ static void tlb_invalidate(struct ipu_mmu *mmu)
 	}
 
 	for (i = 0; i < mmu->nr_mmus; i++) {
+		u32 inv;
+
 		/*
-		 * To avoid the HW bug induced dead lock in some of the IPU
+		 * To avoid the HW bug induced dead lock in some of the IPU4
 		 * MMUs on successive invalidate calls, we need to first do a
 		 * read to the page table base before writing the invalidate
 		 * register. MMUs which need to implement this WA, will have
-		 * the insert_read_before_invalidate flags set as true.
+		 * the insert_read_before_invalidate flasg set as true.
 		 * Disregard the return value of the read.
 		 */
 		if (mmu->mmu_hw[i].insert_read_before_invalidate)
 			readl(mmu->mmu_hw[i].base + REG_L1_PHYS);
 
-		writel(0xffffffff, mmu->mmu_hw[i].base +
-		       REG_TLB_INVALIDATE);
-		/*
-		 * The TLB invalidation is a "single cycle" (IOMMU clock cycles)
-		 * When the actual MMIO write reaches the IPU TLB Invalidate
-		 * register, wmb() will force the TLB invalidate out if the CPU
-		 * attempts to update the IOMMU page table (or sooner).
-		 */
-		wmb();
+		/* Normal invalidate or zlw invalidate */
+		if (mmu->mmu_hw[i].zlw_invalidate) {
+			/* trash buffer must be mapped by now, just in case! */
+			WARN_ON(!mmu->iova_addr_trash);
+
+			zlw_invalidate(mmu, &mmu->mmu_hw[i]);
+		} else {
+			if (mmu->mmu_hw[i].nr_l1streams == 32)
+				inv = 0xffffffff;
+			else if (mmu->mmu_hw[i].nr_l1streams == 0)
+				inv = MMU0_TLB_INVALIDATE;
+			else
+				inv = MMU1_TLB_INVALIDATE;
+			writel(inv, mmu->mmu_hw[i].base +
+				   REG_TLB_INVALIDATE);
+		}
 	}
 	spin_unlock_irqrestore(&mmu->ready_lock, flags);
 }
@@ -83,162 +178,47 @@ static void page_table_dump(struct ipu_mmu_info *mmu_info)
 {
 	u32 l1_idx;
 
-	dev_dbg(mmu_info->dev, "begin IOMMU page table dump\n");
+	pr_debug("begin IOMMU page table dump\n");
 
 	for (l1_idx = 0; l1_idx < ISP_L1PT_PTES; l1_idx++) {
 		u32 l2_idx;
-		u32 iova = (phys_addr_t)l1_idx << ISP_L1PT_SHIFT;
+		u32 iova = (phys_addr_t) l1_idx << ISP_L1PT_SHIFT;
 
-		if (mmu_info->l1_pt[l1_idx] == mmu_info->dummy_l2_pteval)
+		if (mmu_info->pgtbl[l1_idx] == mmu_info->dummy_l2_tbl)
 			continue;
-		dev_dbg(mmu_info->dev,
-			"l1 entry %u; iovas 0x%8.8x-0x%8.8x, at %p\n",
-			l1_idx, iova, iova + ISP_PAGE_SIZE,
-			(void *)TBL_PHYS_ADDR(mmu_info->l1_pt[l1_idx]));
+		pr_debug("l1 entry %u; iovas 0x%8.8x--0x%8.8x, at %p\n",
+			 l1_idx, iova, iova + ISP_PAGE_SIZE,
+			 (void *)TBL_PHYS_ADDR(mmu_info->pgtbl[l1_idx]));
 
 		for (l2_idx = 0; l2_idx < ISP_L2PT_PTES; l2_idx++) {
-			u32 *l2_pt = mmu_info->l2_pts[l1_idx];
+			u32 *l2_pt = TBL_VIRT_ADDR(mmu_info->pgtbl[l1_idx]);
 			u32 iova2 = iova + (l2_idx << ISP_L2PT_SHIFT);
 
-			if (l2_pt[l2_idx] == mmu_info->dummy_page_pteval)
+			if (l2_pt[l2_idx] == mmu_info->dummy_page)
 				continue;
 
-			dev_dbg(mmu_info->dev,
-				"\tl2 entry %u; iova 0x%8.8x, phys %p\n",
-				l2_idx, iova2,
-				(void *)TBL_PHYS_ADDR(l2_pt[l2_idx]));
+			pr_debug("\tl2 entry %u; iova 0x%8.8x, phys %p\n",
+				 l2_idx, iova2,
+				 (void *)TBL_PHYS_ADDR(l2_pt[l2_idx]));
 		}
 	}
 
-	dev_dbg(mmu_info->dev, "end IOMMU page table dump\n");
+	pr_debug("end IOMMU page table dump\n");
 }
 #endif /* DEBUG */
 
-static dma_addr_t map_single(struct ipu_mmu_info *mmu_info, void *ptr)
-{
-	dma_addr_t dma;
-
-	dma = dma_map_single(mmu_info->dev, ptr, PAGE_SIZE, DMA_BIDIRECTIONAL);
-	if (dma_mapping_error(mmu_info->dev, dma))
-		return 0;
-
-	return dma;
-}
-
-static int get_dummy_page(struct ipu_mmu_info *mmu_info)
-{
-	dma_addr_t dma;
-	void *pt = (void *)get_zeroed_page(GFP_ATOMIC | GFP_DMA32);
-
-	if (!pt)
-		return -ENOMEM;
-
-	dev_dbg(mmu_info->dev, "%s get_zeroed_page() == %p\n", __func__, pt);
-
-	dma = map_single(mmu_info, pt);
-	if (!dma) {
-		dev_err(mmu_info->dev, "Failed to map dummy page\n");
-		goto err_free_page;
-	}
-
-	mmu_info->dummy_page = pt;
-	mmu_info->dummy_page_pteval = dma >> ISP_PAGE_SHIFT;
-
-	return 0;
-
-err_free_page:
-	free_page((unsigned long)pt);
-	return -ENOMEM;
-}
-
-static void free_dummy_page(struct ipu_mmu_info *mmu_info)
-{
-	dma_unmap_single(mmu_info->dev,
-			 TBL_PHYS_ADDR(mmu_info->dummy_page_pteval),
-			 PAGE_SIZE, DMA_BIDIRECTIONAL);
-	free_page((unsigned long)mmu_info->dummy_page);
-}
-
-static int alloc_dummy_l2_pt(struct ipu_mmu_info *mmu_info)
-{
-	dma_addr_t dma;
-	u32 *pt = (u32 *)get_zeroed_page(GFP_ATOMIC | GFP_DMA32);
-	int i;
-
-	if (!pt)
-		return -ENOMEM;
-
-	dev_dbg(mmu_info->dev, "%s get_zeroed_page() == %p\n", __func__, pt);
-
-	dma = map_single(mmu_info, pt);
-	if (!dma) {
-		dev_err(mmu_info->dev, "Failed to map l2pt page\n");
-		goto err_free_page;
-	}
-
-	for (i = 0; i < ISP_L2PT_PTES; i++)
-		pt[i] = mmu_info->dummy_page_pteval;
-
-	mmu_info->dummy_l2_pt = pt;
-	mmu_info->dummy_l2_pteval = dma >> ISP_PAGE_SHIFT;
-
-	return 0;
-
-err_free_page:
-	free_page((unsigned long)pt);
-	return -ENOMEM;
-}
-
-static void free_dummy_l2_pt(struct ipu_mmu_info *mmu_info)
-{
-	dma_unmap_single(mmu_info->dev,
-			 TBL_PHYS_ADDR(mmu_info->dummy_l2_pteval),
-			 PAGE_SIZE, DMA_BIDIRECTIONAL);
-	free_page((unsigned long)mmu_info->dummy_l2_pt);
-}
-
-static u32 *alloc_l1_pt(struct ipu_mmu_info *mmu_info)
-{
-	dma_addr_t dma;
-	u32 *pt = (u32 *)get_zeroed_page(GFP_ATOMIC | GFP_DMA32);
-	int i;
-
-	if (!pt)
-		return NULL;
-
-	dev_dbg(mmu_info->dev, "%s get_zeroed_page() == %p\n", __func__, pt);
-
-	for (i = 0; i < ISP_L1PT_PTES; i++)
-		pt[i] = mmu_info->dummy_l2_pteval;
-
-	dma = map_single(mmu_info, pt);
-	if (!dma) {
-		dev_err(mmu_info->dev, "Failed to map l1pt page\n");
-		goto err_free_page;
-	}
-
-	mmu_info->l1_pt_dma = dma >> ISP_PADDR_SHIFT;
-	dev_dbg(mmu_info->dev, "l1 pt %p mapped at %llx\n", pt, dma);
-
-	return pt;
-
-err_free_page:
-	free_page((unsigned long)pt);
-	return NULL;
-}
-
-static u32 *alloc_l2_pt(struct ipu_mmu_info *mmu_info)
+static u32 *alloc_page_table(struct ipu_mmu_info *mmu_info, bool l1)
 {
-	u32 *pt = (u32 *)get_zeroed_page(GFP_ATOMIC | GFP_DMA32);
+	u32 *pt = (u32 *) __get_free_page(GFP_KERNEL | GFP_DMA32);
 	int i;
 
 	if (!pt)
 		return NULL;
 
-	dev_dbg(mmu_info->dev, "%s get_zeroed_page() == %p\n", __func__, pt);
+	pr_debug("__get_free_page() == %p\n", pt);
 
 	for (i = 0; i < ISP_L1PT_PTES; i++)
-		pt[i] = mmu_info->dummy_page_pteval;
+		pt[i] = l1 ? mmu_info->dummy_l2_tbl : mmu_info->dummy_page;
 
 	return pt;
 }
@@ -247,82 +227,76 @@ static int l2_map(struct ipu_mmu_info *mmu_info, unsigned long iova,
 		  phys_addr_t paddr, size_t size)
 {
 	u32 l1_idx = iova >> ISP_L1PT_SHIFT;
-	u32 l1_entry;
-	u32 *l2_pt, *l2_virt;
+	u32 l1_entry = mmu_info->pgtbl[l1_idx];
+	u32 *l2_pt;
 	u32 iova_start = iova;
 	unsigned int l2_idx;
 	unsigned long flags;
-	dma_addr_t dma;
-
-	dev_dbg(mmu_info->dev,
-		"mapping l2 page table for l1 index %u (iova %8.8x)\n",
-		l1_idx, (u32)iova);
-
-	spin_lock_irqsave(&mmu_info->lock, flags);
-	l1_entry = mmu_info->l1_pt[l1_idx];
-	if (l1_entry == mmu_info->dummy_l2_pteval) {
-		l2_virt = mmu_info->l2_pts[l1_idx];
-		if (likely(!l2_virt)) {
-			l2_virt = alloc_l2_pt(mmu_info);
-			if (!l2_virt) {
-				spin_unlock_irqrestore(&mmu_info->lock, flags);
-				return -ENOMEM;
-			}
-		}
 
-		dma = map_single(mmu_info, l2_virt);
-		if (!dma) {
-			dev_err(mmu_info->dev, "Failed to map l2pt page\n");
-			free_page((unsigned long)l2_virt);
-			spin_unlock_irqrestore(&mmu_info->lock, flags);
-			return -EINVAL;
-		}
+	pr_debug("mapping l2 page table for l1 index %u (iova %8.8x)\n",
+		 l1_idx, (u32) iova);
 
-		l1_entry = dma >> ISP_PADDR_SHIFT;
+	if (l1_entry == mmu_info->dummy_l2_tbl) {
+		u32 *l2_virt = alloc_page_table(mmu_info, false);
 
-		dev_dbg(mmu_info->dev, "page for l1_idx %u %p allocated\n",
-			l1_idx, l2_virt);
-		mmu_info->l1_pt[l1_idx] = l1_entry;
-		mmu_info->l2_pts[l1_idx] = l2_virt;
-		clflush_cache_range(&mmu_info->l1_pt[l1_idx],
-				    sizeof(mmu_info->l1_pt[l1_idx]));
+		if (!l2_virt)
+			return -ENOMEM;
+
+		l1_entry = virt_to_phys(l2_virt) >> ISP_PADDR_SHIFT;
+		pr_debug("allocated page for l1_idx %u\n", l1_idx);
+
+		spin_lock_irqsave(&mmu_info->lock, flags);
+		if (mmu_info->pgtbl[l1_idx] == mmu_info->dummy_l2_tbl) {
+			mmu_info->pgtbl[l1_idx] = l1_entry;
+#ifdef CONFIG_X86
+			clflush_cache_range(&mmu_info->pgtbl[l1_idx],
+					    sizeof(mmu_info->pgtbl[l1_idx]));
+#endif /* CONFIG_X86 */
+		} else {
+			spin_unlock_irqrestore(&mmu_info->lock, flags);
+			free_page((unsigned long)TBL_VIRT_ADDR(l1_entry));
+			spin_lock_irqsave(&mmu_info->lock, flags);
+		}
+	} else {
+		spin_lock_irqsave(&mmu_info->lock, flags);
 	}
 
-	l2_pt = mmu_info->l2_pts[l1_idx];
+	l2_pt = TBL_VIRT_ADDR(mmu_info->pgtbl[l1_idx]);
 
-	dev_dbg(mmu_info->dev, "l2_pt at %p with dma 0x%x\n", l2_pt, l1_entry);
+	pr_debug("l2_pt at %p\n", l2_pt);
 
 	paddr = ALIGN(paddr, ISP_PAGE_SIZE);
 
 	l2_idx = (iova_start & ISP_L2PT_MASK) >> ISP_L2PT_SHIFT;
 
-	dev_dbg(mmu_info->dev, "l2_idx %u, phys 0x%8.8x\n", l2_idx,
-		l2_pt[l2_idx]);
-	if (l2_pt[l2_idx] != mmu_info->dummy_page_pteval) {
+	pr_debug("l2_idx %u, phys 0x%8.8x\n", l2_idx, l2_pt[l2_idx]);
+	if (l2_pt[l2_idx] != mmu_info->dummy_page) {
 		spin_unlock_irqrestore(&mmu_info->lock, flags);
-		return -EINVAL;
+		return -EBUSY;
 	}
 
 	l2_pt[l2_idx] = paddr >> ISP_PADDR_SHIFT;
 
-	clflush_cache_range(&l2_pt[l2_idx], sizeof(l2_pt[l2_idx]));
 	spin_unlock_irqrestore(&mmu_info->lock, flags);
 
-	dev_dbg(mmu_info->dev, "l2 index %u mapped as 0x%8.8x\n", l2_idx,
-		l2_pt[l2_idx]);
+#ifdef CONFIG_X86
+	clflush_cache_range(&l2_pt[l2_idx], sizeof(l2_pt[l2_idx]));
+#endif /* CONFIG_X86 */
+
+	pr_debug("l2 index %u mapped as 0x%8.8x\n", l2_idx, l2_pt[l2_idx]);
 
 	return 0;
 }
 
 static int __ipu_mmu_map(struct ipu_mmu_info *mmu_info, unsigned long iova,
-			 phys_addr_t paddr, size_t size)
+		       phys_addr_t paddr, size_t size)
 {
 	u32 iova_start = round_down(iova, ISP_PAGE_SIZE);
 	u32 iova_end = ALIGN(iova + size, ISP_PAGE_SIZE);
 
-	dev_dbg(mmu_info->dev,
-		"mapping iova 0x%8.8x--0x%8.8x, size %zu at paddr 0x%10.10llx\n",
-		iova_start, iova_end, size, paddr);
+	pr_debug
+	    ("mapping iova 0x%8.8x--0x%8.8x, size %zu at paddr 0x%10.10llx\n",
+	     iova_start, iova_end, size, paddr);
 
 	return l2_map(mmu_info, iova_start, paddr, size);
 }
@@ -331,74 +305,61 @@ static size_t l2_unmap(struct ipu_mmu_info *mmu_info, unsigned long iova,
 		       phys_addr_t dummy, size_t size)
 {
 	u32 l1_idx = iova >> ISP_L1PT_SHIFT;
-	u32 *l2_pt;
+	u32 *l2_pt = TBL_VIRT_ADDR(mmu_info->pgtbl[l1_idx]);
 	u32 iova_start = iova;
 	unsigned int l2_idx;
 	size_t unmapped = 0;
-	unsigned long flags;
 
-	dev_dbg(mmu_info->dev, "unmapping l2 page table for l1 index %u (iova 0x%8.8lx)\n",
-		l1_idx, iova);
+	pr_debug("unmapping l2 page table for l1 index %u (iova 0x%8.8lx)\n",
+		 l1_idx, iova);
 
-	spin_lock_irqsave(&mmu_info->lock, flags);
-	if (mmu_info->l1_pt[l1_idx] == mmu_info->dummy_l2_pteval) {
-		spin_unlock_irqrestore(&mmu_info->lock, flags);
-		dev_err(mmu_info->dev,
-			"unmap iova 0x%8.8lx l1 idx %u which was not mapped\n",
-			iova, l1_idx);
-		return 0;
-	}
+	if (mmu_info->pgtbl[l1_idx] == mmu_info->dummy_l2_tbl)
+		return -EINVAL;
+
+	pr_debug("l2_pt at %p\n", l2_pt);
 
 	for (l2_idx = (iova_start & ISP_L2PT_MASK) >> ISP_L2PT_SHIFT;
 	     (iova_start & ISP_L1PT_MASK) + (l2_idx << ISP_PAGE_SHIFT)
 	     < iova_start + size && l2_idx < ISP_L2PT_PTES; l2_idx++) {
-		l2_pt = mmu_info->l2_pts[l1_idx];
-		dev_dbg(mmu_info->dev,
-			"unmap l2 index %u with pteval 0x%10.10llx\n",
-			l2_idx, TBL_PHYS_ADDR(l2_pt[l2_idx]));
-		l2_pt[l2_idx] = mmu_info->dummy_page_pteval;
+		unsigned long flags;
 
+		pr_debug("l2 index %u unmapped, was 0x%10.10llx\n",
+			 l2_idx, TBL_PHYS_ADDR(l2_pt[l2_idx]));
+		spin_lock_irqsave(&mmu_info->lock, flags);
+		l2_pt[l2_idx] = mmu_info->dummy_page;
+		spin_unlock_irqrestore(&mmu_info->lock, flags);
+#ifdef CONFIG_X86
 		clflush_cache_range(&l2_pt[l2_idx], sizeof(l2_pt[l2_idx]));
+#endif /* CONFIG_X86 */
 		unmapped++;
 	}
-	spin_unlock_irqrestore(&mmu_info->lock, flags);
 
 	return unmapped << ISP_PAGE_SHIFT;
 }
 
 static size_t __ipu_mmu_unmap(struct ipu_mmu_info *mmu_info,
-			      unsigned long iova, size_t size)
+			    unsigned long iova, size_t size)
 {
 	return l2_unmap(mmu_info, iova, 0, size);
 }
 
-static int allocate_trash_buffer(struct ipu_mmu *mmu)
+static int allocate_trash_buffer(struct ipu_bus_device *adev)
 {
+	struct ipu_mmu *mmu = ipu_bus_get_drvdata(adev);
 	unsigned int n_pages = PAGE_ALIGN(IPU_MMUV2_TRASH_RANGE) >> PAGE_SHIFT;
 	struct iova *iova;
 	u32 iova_addr;
 	unsigned int i;
-	dma_addr_t dma;
 	int ret;
 
 	/* Allocate 8MB in iova range */
 	iova = alloc_iova(&mmu->dmap->iovad, n_pages,
-			  mmu->dmap->mmu_info->aperture_end >> PAGE_SHIFT, 0);
+			  dma_get_mask(mmu->dev) >> PAGE_SHIFT, 0);
 	if (!iova) {
-		dev_err(mmu->dev, "cannot allocate iova range for trash\n");
+		dev_err(&adev->dev, "cannot allocate iova range for trash\n");
 		return -ENOMEM;
 	}
 
-	dma = dma_map_page(mmu->dmap->mmu_info->dev, mmu->trash_page, 0,
-			   PAGE_SIZE, DMA_BIDIRECTIONAL);
-	if (dma_mapping_error(mmu->dmap->mmu_info->dev, dma)) {
-		dev_err(mmu->dmap->mmu_info->dev, "Failed to map trash page\n");
-		ret = -ENOMEM;
-		goto out_free_iova;
-	}
-
-	mmu->pci_trash_page = dma;
-
 	/*
 	 * Map the 8MB iova address range to the same physical trash page
 	 * mmu->trash_page which is already reserved at the probe
@@ -406,9 +367,9 @@ static int allocate_trash_buffer(struct ipu_mmu *mmu)
 	iova_addr = iova->pfn_lo;
 	for (i = 0; i < n_pages; i++) {
 		ret = ipu_mmu_map(mmu->dmap->mmu_info, iova_addr << PAGE_SHIFT,
-				  mmu->pci_trash_page, PAGE_SIZE);
+				page_to_phys(mmu->trash_page), PAGE_SIZE);
 		if (ret) {
-			dev_err(mmu->dev,
+			dev_err(&adev->dev,
 				"mapping trash buffer range failed\n");
 			goto out_unmap;
 		}
@@ -416,63 +377,111 @@ static int allocate_trash_buffer(struct ipu_mmu *mmu)
 		iova_addr++;
 	}
 
-	mmu->iova_trash_page = iova->pfn_lo << PAGE_SHIFT;
-	dev_dbg(mmu->dev, "iova trash buffer for MMUID: %d is %u\n",
-		mmu->mmid, (unsigned int)mmu->iova_trash_page);
+	/* save the address for the ZLW invalidation */
+	mmu->iova_addr_trash = iova->pfn_lo << PAGE_SHIFT;
+	dev_info(&adev->dev, "iova trash buffer for MMUID: %d is %u\n",
+		 mmu->mmid, (unsigned int)mmu->iova_addr_trash);
 	return 0;
 
 out_unmap:
 	ipu_mmu_unmap(mmu->dmap->mmu_info, iova->pfn_lo << PAGE_SHIFT,
-		      (iova->pfn_hi - iova->pfn_lo + 1) << PAGE_SHIFT);
-	dma_unmap_page(mmu->dmap->mmu_info->dev, mmu->pci_trash_page,
-		       PAGE_SIZE, DMA_BIDIRECTIONAL);
-out_free_iova:
+		    (iova->pfn_hi - iova->pfn_lo + 1) << PAGE_SHIFT);
 	__free_iova(&mmu->dmap->iovad, iova);
 	return ret;
 }
 
-int ipu_mmu_hw_init(struct ipu_mmu *mmu)
+static int ipu_mmu_hw_init(struct device *dev)
 {
+	struct ipu_bus_device *adev = to_ipu_bus_device(dev);
+	struct ipu_mmu *mmu = ipu_bus_get_drvdata(adev);
 	unsigned int i;
 	unsigned long flags;
 	struct ipu_mmu_info *mmu_info;
 
-	dev_dbg(mmu->dev, "mmu hw init\n");
+	dev_dbg(dev, "mmu hw init\n");
+	/*
+	 * FIXME: following fix for null pointer check is not a complete one.
+	 * if mmu is not powered cycled before being used, the page table
+	 * address will still not be set into HW.
+	 */
+	if (!mmu->dmap) {
+		dev_warn(dev, "mmu is not ready yet. skipping.\n");
+		return 0;
+	}
 
 	mmu_info = mmu->dmap->mmu_info;
 
 	/* Initialise the each MMU HW block */
 	for (i = 0; i < mmu->nr_mmus; i++) {
 		struct ipu_mmu_hw *mmu_hw = &mmu->mmu_hw[i];
+#if defined(CONFIG_VIDEO_INTEL_IPU4) || defined(CONFIG_VIDEO_INTEL_IPU4P)
+		bool zlw_invalidate = false;
+#endif
 		unsigned int j;
 		u16 block_addr;
 
 		/* Write page table address per MMU */
-		writel((phys_addr_t)mmu_info->l1_pt_dma,
-		       mmu->mmu_hw[i].base + REG_L1_PHYS);
+		writel((phys_addr_t) virt_to_phys(mmu_info->pgtbl)
+			   >> ISP_PADDR_SHIFT,
+			   mmu->mmu_hw[i].base + REG_L1_PHYS);
 
 		/* Set info bits per MMU */
 		writel(mmu->mmu_hw[i].info_bits,
-		       mmu->mmu_hw[i].base + REG_INFO);
+			   mmu->mmu_hw[i].base + REG_INFO);
 
 		/* Configure MMU TLB stream configuration for L1 */
 		for (j = 0, block_addr = 0; j < mmu_hw->nr_l1streams;
 		     block_addr += mmu->mmu_hw[i].l1_block_sz[j], j++) {
 			if (block_addr > IPU_MAX_LI_BLOCK_ADDR) {
-				dev_err(mmu->dev, "invalid L1 configuration\n");
+				dev_err(dev, "invalid L1 configuration\n");
 				return -EINVAL;
 			}
 
 			/* Write block start address for each streams */
 			writel(block_addr, mmu_hw->base +
 				   mmu_hw->l1_stream_id_reg_offset + 4 * j);
+
+#if defined(CONFIG_VIDEO_INTEL_IPU4) || defined(CONFIG_VIDEO_INTEL_IPU4P)
+			/* Enable ZLW for streams based on the init table */
+			writel(mmu->mmu_hw[i].l1_zlw_en[j],
+				   mmu_hw->base +
+				   MMUV2_AT_REG_L1_ZLW_EN_SID(j));
+
+			/* To track if zlw is enabled in any streams */
+			zlw_invalidate |= mmu->mmu_hw[i].l1_zlw_en[j];
+
+			/* Enable ZLW 1D mode for streams from the init table */
+			writel(mmu->mmu_hw[i].l1_zlw_1d_mode[j],
+				   mmu_hw->base +
+				   MMUV2_AT_REG_L1_ZLW_1DMODE_SID(j));
+
+			/* Set when the ZLW insertion will happen */
+			writel(mmu->mmu_hw[i].l1_ins_zlw_ahead_pages[j],
+				   mmu_hw->base +
+				   MMUV2_AT_REG_L1_ZLW_INS_N_AHEAD_SID(j));
+
+			/* Set if ZLW 2D mode active for each streams */
+			writel(mmu->mmu_hw[i].l1_zlw_2d_mode[j],
+				   mmu_hw->base +
+				   MMUV2_AT_REG_L1_ZLW_2DMODE_SID(j));
+#endif
 		}
 
+#if defined(CONFIG_VIDEO_INTEL_IPU4) || defined(CONFIG_VIDEO_INTEL_IPU4P)
+		/*
+		 * If ZLW invalidate is enabled even for one stream in a MMU1,
+		 * we need to set the FW ZLW operations have higher priority
+		 * on that MMU1
+		 */
+		if (zlw_invalidate)
+			writel(1, mmu_hw->base +
+				   MMUV2_AT_REG_L1_FW_ZLW_PRIO);
+#endif
 		/* Configure MMU TLB stream configuration for L2 */
 		for (j = 0, block_addr = 0; j < mmu_hw->nr_l2streams;
 		     block_addr += mmu->mmu_hw[i].l2_block_sz[j], j++) {
 			if (block_addr > IPU_MAX_L2_BLOCK_ADDR) {
-				dev_err(mmu->dev, "invalid L2 configuration\n");
+				dev_err(dev, "invalid L2 configuration\n");
 				return -EINVAL;
 			}
 
@@ -481,22 +490,21 @@ int ipu_mmu_hw_init(struct ipu_mmu *mmu)
 		}
 	}
 
-	if (!mmu->trash_page) {
+	/* Allocate trash buffer, if not allocated. Only once per MMU */
+	if (!mmu->iova_addr_trash) {
 		int ret;
 
-		mmu->trash_page = alloc_page(GFP_KERNEL);
-		if (!mmu->trash_page) {
-			dev_err(mmu->dev, "insufficient memory for trash buffer\n");
-			return -ENOMEM;
-		}
-
-		ret = allocate_trash_buffer(mmu);
+		ret = allocate_trash_buffer(adev);
 		if (ret) {
-			__free_page(mmu->trash_page);
-			mmu->trash_page = NULL;
-			dev_err(mmu->dev, "trash buffer allocation failed\n");
+			dev_err(dev, "trash buffer allocation failed\n");
 			return ret;
 		}
+
+		/*
+		 * Update the domain pointer to trash buffer to release it on
+		 * domain destroy
+		 */
+		mmu_info->iova_addr_trash = mmu->iova_addr_trash;
 	}
 
 	spin_lock_irqsave(&mmu->ready_lock, flags);
@@ -505,121 +513,35 @@ int ipu_mmu_hw_init(struct ipu_mmu *mmu)
 
 	return 0;
 }
-EXPORT_SYMBOL(ipu_mmu_hw_init);
-
-static struct ipu_mmu_info *ipu_mmu_alloc(struct ipu_device *isp)
-{
-	struct ipu_mmu_info *mmu_info;
-	int ret;
-
-	mmu_info = kzalloc(sizeof(*mmu_info), GFP_KERNEL);
-	if (!mmu_info)
-		return NULL;
-
-	mmu_info->aperture_start = 0;
-	mmu_info->aperture_end = DMA_BIT_MASK(isp->secure_mode ?
-					      IPU_MMU_ADDRESS_BITS :
-					      IPU_MMU_ADDRESS_BITS_NON_SECURE);
-	mmu_info->pgsize_bitmap = SZ_4K;
-	mmu_info->dev = &isp->pdev->dev;
-
-	ret = get_dummy_page(mmu_info);
-	if (ret)
-		goto err_free_info;
-
-	ret = alloc_dummy_l2_pt(mmu_info);
-	if (ret)
-		goto err_free_dummy_page;
-
-	mmu_info->l2_pts = vzalloc(ISP_L2PT_PTES * sizeof(*mmu_info->l2_pts));
-	if (!mmu_info->l2_pts)
-		goto err_free_dummy_l2_pt;
-
-	/*
-	 * We always map the L1 page table (a single page as well as
-	 * the L2 page tables).
-	 */
-	mmu_info->l1_pt = alloc_l1_pt(mmu_info);
-	if (!mmu_info->l1_pt)
-		goto err_free_l2_pts;
-
-	spin_lock_init(&mmu_info->lock);
-
-	dev_dbg(mmu_info->dev, "domain initialised\n");
-
-	return mmu_info;
-
-err_free_l2_pts:
-	vfree(mmu_info->l2_pts);
-err_free_dummy_l2_pt:
-	free_dummy_l2_pt(mmu_info);
-err_free_dummy_page:
-	free_dummy_page(mmu_info);
-err_free_info:
-	kfree(mmu_info);
-
-	return NULL;
-}
-
-int ipu_mmu_hw_cleanup(struct ipu_mmu *mmu)
-{
-	unsigned long flags;
-
-	spin_lock_irqsave(&mmu->ready_lock, flags);
-	mmu->ready = false;
-	spin_unlock_irqrestore(&mmu->ready_lock, flags);
-
-	return 0;
-}
-EXPORT_SYMBOL(ipu_mmu_hw_cleanup);
 
-static struct ipu_dma_mapping *alloc_dma_mapping(struct ipu_device *isp)
+static void set_mapping(struct ipu_mmu *mmu, struct ipu_dma_mapping *dmap)
 {
-	struct ipu_dma_mapping *dmap;
+	mmu->dmap = dmap;
 
-	dmap = kzalloc(sizeof(*dmap), GFP_KERNEL);
 	if (!dmap)
-		return NULL;
-
-	dmap->mmu_info = ipu_mmu_alloc(isp);
-	if (!dmap->mmu_info) {
-		kfree(dmap);
-		return NULL;
-	}
-	init_iova_domain(&dmap->iovad, SZ_4K, 1);
-	dmap->mmu_info->dmap = dmap;
-
-	kref_init(&dmap->ref);
-
-	dev_dbg(&isp->pdev->dev, "alloc mapping\n");
-
-	iova_cache_get();
+		return;
 
-	return dmap;
+	pm_runtime_get_sync(mmu->dev);
+	ipu_mmu_hw_init(mmu->dev);
+	pm_runtime_put(mmu->dev);
 }
 
 phys_addr_t ipu_mmu_iova_to_phys(struct ipu_mmu_info *mmu_info,
-				 dma_addr_t iova)
+					dma_addr_t iova)
 {
-	unsigned long flags;
-	u32 *l2_pt;
-	phys_addr_t phy_addr;
+	u32 *l2_pt = TBL_VIRT_ADDR(mmu_info->pgtbl[iova >> ISP_L1PT_SHIFT]);
 
-	spin_lock_irqsave(&mmu_info->lock, flags);
-	l2_pt = mmu_info->l2_pts[iova >> ISP_L1PT_SHIFT];
-	phy_addr = (phys_addr_t)l2_pt[(iova & ISP_L2PT_MASK) >> ISP_L2PT_SHIFT];
-	phy_addr <<= ISP_PAGE_SHIFT;
-	spin_unlock_irqrestore(&mmu_info->lock, flags);
-
-	return phy_addr;
+	return (phys_addr_t) l2_pt[(iova & ISP_L2PT_MASK) >> ISP_L2PT_SHIFT]
+	    << ISP_PAGE_SHIFT;
 }
+EXPORT_SYMBOL(ipu_mmu_iova_to_phys);
 
-/*
+/**
  * The following four functions are implemented based on iommu.c
- * drivers/iommu/iommu.c:iommu_pgsize().
+ * drivers/iommu/iommu.c/iommu_pgsize().
  */
 static size_t ipu_mmu_pgsize(unsigned long pgsize_bitmap,
-			     unsigned long addr_merge, size_t size)
+			      unsigned long addr_merge, size_t size)
 {
 	unsigned int pgsize_idx;
 	size_t pgsize;
@@ -651,9 +573,9 @@ static size_t ipu_mmu_pgsize(unsigned long pgsize_bitmap,
 	return pgsize;
 }
 
-/* drivers/iommu/iommu.c:iommu_unmap() */
+/* drivers/iommu/iommu.c/iommu_unmap() */
 size_t ipu_mmu_unmap(struct ipu_mmu_info *mmu_info, unsigned long iova,
-		     size_t size)
+		      size_t size)
 {
 	size_t unmapped_page, unmapped = 0;
 	unsigned int min_pagesz;
@@ -684,7 +606,7 @@ size_t ipu_mmu_unmap(struct ipu_mmu_info *mmu_info, unsigned long iova,
 		if (!unmapped_page)
 			break;
 
-		dev_dbg(mmu_info->dev, "unmapped: iova 0x%lx size 0x%zx\n",
+		dev_dbg(NULL, "unmapped: iova 0x%lx size 0x%zx\n",
 			iova, unmapped_page);
 
 		iova += unmapped_page;
@@ -693,10 +615,11 @@ size_t ipu_mmu_unmap(struct ipu_mmu_info *mmu_info, unsigned long iova,
 
 	return unmapped;
 }
+EXPORT_SYMBOL(ipu_mmu_unmap);
 
-/* drivers/iommu/iommu.c:iommu_map() */
+/* drivers/iommu/iommu.c/iommu_map() */
 int ipu_mmu_map(struct ipu_mmu_info *mmu_info, unsigned long iova,
-		phys_addr_t paddr, size_t size)
+	      phys_addr_t paddr, size_t size)
 {
 	unsigned long orig_iova = iova;
 	unsigned int min_pagesz;
@@ -715,22 +638,20 @@ int ipu_mmu_map(struct ipu_mmu_info *mmu_info, unsigned long iova,
 	 * size of the smallest page supported by the hardware
 	 */
 	if (!IS_ALIGNED(iova | paddr | size, min_pagesz)) {
-		dev_err(mmu_info->dev,
-			"unaligned: iova 0x%lx pa %pa size 0x%zx min_pagesz 0x%x\n",
-			iova, &paddr, size, min_pagesz);
+		pr_err("unaligned: iova 0x%lx pa %pa size 0x%zx min_pagesz 0x%x\n",
+		       iova, &paddr, size, min_pagesz);
 		return -EINVAL;
 	}
 
-	dev_dbg(mmu_info->dev, "map: iova 0x%lx pa %pa size 0x%zx\n",
-		iova, &paddr, size);
+	pr_debug("map: iova 0x%lx pa %pa size 0x%zx\n", iova, &paddr, size);
 
 	while (size) {
-		size_t pgsize = ipu_mmu_pgsize(mmu_info->pgsize_bitmap,
-					       iova | paddr, size);
+		size_t pgsize
+			= ipu_mmu_pgsize(mmu_info->pgsize_bitmap,
+					iova | paddr, size);
 
-		dev_dbg(mmu_info->dev,
-			"mapping: iova 0x%lx pa %pa pgsize 0x%zx\n",
-			iova, &paddr, pgsize);
+		pr_debug("mapping: iova 0x%lx pa %pa pgsize 0x%zx\n",
+			 iova, &paddr, pgsize);
 
 		ret = __ipu_mmu_map(mmu_info, iova, paddr, pgsize);
 		if (ret)
@@ -747,111 +668,199 @@ int ipu_mmu_map(struct ipu_mmu_info *mmu_info, unsigned long iova,
 
 	return ret;
 }
+EXPORT_SYMBOL(ipu_mmu_map);
+
+struct ipu_mmu_info *ipu_mmu_alloc(void)
+{
+	struct ipu_mmu_info *mmu_info;
+	void *ptr;
+
+	mmu_info = kzalloc(sizeof(*mmu_info), GFP_KERNEL);
+	if (!mmu_info)
+		return NULL;
+
+	mmu_info->aperture_start = 0;
+	mmu_info->aperture_end = DMA_BIT_MASK(IPU_MMU_ADDRESS_BITS);
+	mmu_info->pgsize_bitmap = SZ_4K;
+
+	ptr = (void *)__get_free_page(GFP_KERNEL | GFP_DMA32);
+	if (!ptr)
+		goto err_mem;
+
+	mmu_info->dummy_page = virt_to_phys(ptr) >> ISP_PAGE_SHIFT;
+
+	ptr = alloc_page_table(mmu_info, false);
+	if (!ptr)
+		goto err;
+
+	mmu_info->dummy_l2_tbl = virt_to_phys(ptr) >> ISP_PAGE_SHIFT;
+
+	/*
+	 * We always map the L1 page table (a single page as well as
+	 * the L2 page tables).
+	 */
+	mmu_info->pgtbl = alloc_page_table(mmu_info, true);
+	if (!mmu_info->pgtbl)
+		goto err;
+
+	spin_lock_init(&mmu_info->lock);
+
+	pr_debug("domain initialised\n");
+
+	return mmu_info;
+
+err:
+	free_page((unsigned long)TBL_VIRT_ADDR(mmu_info->dummy_page));
+	free_page((unsigned long)TBL_VIRT_ADDR(mmu_info->dummy_l2_tbl));
+err_mem:
+	kfree(mmu_info);
+
+	return NULL;
+}
+EXPORT_SYMBOL(ipu_mmu_alloc);
 
-static void ipu_mmu_destroy(struct ipu_mmu *mmu)
+void ipu_mmu_destroy(struct ipu_mmu_info *mmu_info)
 {
-	struct ipu_dma_mapping *dmap = mmu->dmap;
-	struct ipu_mmu_info *mmu_info = dmap->mmu_info;
 	struct iova *iova;
 	u32 l1_idx;
 
-	if (mmu->iova_trash_page) {
-		iova = find_iova(&dmap->iovad,
-				 mmu->iova_trash_page >> PAGE_SHIFT);
-		if (iova) {
-			/* unmap and free the trash buffer iova */
-			ipu_mmu_unmap(mmu_info, iova->pfn_lo << PAGE_SHIFT,
-				      (iova->pfn_hi - iova->pfn_lo + 1) <<
-				      PAGE_SHIFT);
-			__free_iova(&dmap->iovad, iova);
-		} else {
-			dev_err(mmu->dev, "trash buffer iova not found.\n");
-		}
+	if (mmu_info->iova_addr_trash) {
+		iova = find_iova(&mmu_info->dmap->iovad,
+				mmu_info->iova_addr_trash >> PAGE_SHIFT);
+		/* unmap and free the corresponding trash buffer iova */
+		ipu_mmu_unmap(mmu_info, iova->pfn_lo << PAGE_SHIFT,
+			    (iova->pfn_hi - iova->pfn_lo + 1) << PAGE_SHIFT);
+		__free_iova(&mmu_info->dmap->iovad, iova);
 
-		mmu->iova_trash_page = 0;
-		dma_unmap_page(mmu_info->dev, mmu->pci_trash_page,
-			       PAGE_SIZE, DMA_BIDIRECTIONAL);
-		mmu->pci_trash_page = 0;
-		__free_page(mmu->trash_page);
+		/*
+		 * Set iova_addr_trash in mmu to 0, so that on next HW init
+		 * this will be mapped again.
+		 */
+		mmu_info->iova_addr_trash = 0;
 	}
 
-	for (l1_idx = 0; l1_idx < ISP_L1PT_PTES; l1_idx++) {
-		if (mmu_info->l1_pt[l1_idx] != mmu_info->dummy_l2_pteval) {
-			dma_unmap_single(mmu_info->dev,
-					 TBL_PHYS_ADDR(mmu_info->l1_pt[l1_idx]),
-					 PAGE_SIZE, DMA_BIDIRECTIONAL);
-			free_page((unsigned long)mmu_info->l2_pts[l1_idx]);
-		}
-	}
+	for (l1_idx = 0; l1_idx < ISP_L1PT_PTES; l1_idx++)
+		if (mmu_info->pgtbl[l1_idx] != mmu_info->dummy_l2_tbl)
+			free_page((unsigned long)
+				  TBL_VIRT_ADDR(mmu_info->pgtbl[l1_idx]));
 
-	free_dummy_page(mmu_info);
-	dma_unmap_single(mmu_info->dev, mmu_info->l1_pt_dma << ISP_PADDR_SHIFT,
-			 PAGE_SIZE, DMA_BIDIRECTIONAL);
-	free_page((unsigned long)mmu_info->dummy_l2_pt);
-	free_page((unsigned long)mmu_info->l1_pt);
+	free_page((unsigned long)TBL_VIRT_ADDR(mmu_info->dummy_page));
+	free_page((unsigned long)TBL_VIRT_ADDR(mmu_info->dummy_l2_tbl));
+	free_page((unsigned long)mmu_info->pgtbl);
 	kfree(mmu_info);
 }
+EXPORT_SYMBOL(ipu_mmu_destroy);
 
-struct ipu_mmu *ipu_mmu_init(struct device *dev,
-			     void __iomem *base, int mmid,
-			     const struct ipu_hw_variants *hw)
+static int ipu_mmu_probe(struct ipu_bus_device *adev)
 {
-	struct ipu_mmu *mmu;
 	struct ipu_mmu_pdata *pdata;
-	struct ipu_device *isp = pci_get_drvdata(to_pci_dev(dev));
-	unsigned int i;
-
-	if (hw->nr_mmus > IPU_MMU_MAX_DEVICES)
-		return ERR_PTR(-EINVAL);
-
-	pdata = devm_kzalloc(dev, sizeof(*pdata), GFP_KERNEL);
-	if (!pdata)
-		return ERR_PTR(-ENOMEM);
+	struct ipu_mmu *mmu;
 
-	for (i = 0; i < hw->nr_mmus; i++) {
-		struct ipu_mmu_hw *pdata_mmu = &pdata->mmu_hw[i];
-		const struct ipu_mmu_hw *src_mmu = &hw->mmu_hw[i];
+	mmu = devm_kzalloc(&adev->dev, sizeof(*mmu), GFP_KERNEL);
+	if (!mmu)
+		return -ENOMEM;
 
-		if (src_mmu->nr_l1streams > IPU_MMU_MAX_TLB_L1_STREAMS ||
-		    src_mmu->nr_l2streams > IPU_MMU_MAX_TLB_L2_STREAMS)
-			return ERR_PTR(-EINVAL);
+	dev_dbg(&adev->dev, "mmu probe %p %p\n", adev, &adev->dev);
+	ipu_bus_set_drvdata(adev, mmu);
 
-		*pdata_mmu = *src_mmu;
-		pdata_mmu->base = base + src_mmu->offset;
-	}
+	pdata = adev->pdata;
 
-	mmu = devm_kzalloc(dev, sizeof(*mmu), GFP_KERNEL);
-	if (!mmu)
-		return ERR_PTR(-ENOMEM);
+	mmu->mmid = pdata->mmid;
 
-	mmu->mmid = mmid;
 	mmu->mmu_hw = pdata->mmu_hw;
-	mmu->nr_mmus = hw->nr_mmus;
+	mmu->nr_mmus = pdata->nr_mmus;
 	mmu->tlb_invalidate = tlb_invalidate;
+	mmu->set_mapping = set_mapping;
+	mmu->dev = &adev->dev;
 	mmu->ready = false;
-	INIT_LIST_HEAD(&mmu->vma_list);
 	spin_lock_init(&mmu->ready_lock);
 
-	mmu->dmap = alloc_dma_mapping(isp);
-	if (!mmu->dmap) {
-		dev_err(dev, "can't alloc dma mapping\n");
-		return ERR_PTR(-ENOMEM);
+	/*
+	 * Allocate 1 page of physical memory for the trash buffer
+	 *
+	 * TODO! Could be further optimized by allocating only one page per ipu
+	 * instance instead of per mmu
+	 */
+	mmu->trash_page = alloc_page(GFP_KERNEL);
+	if (!mmu->trash_page) {
+		dev_err(&adev->dev, "insufficient memory for trash buffer\n");
+		return -ENOMEM;
 	}
+	dev_info(&adev->dev, "MMU: %d, allocated page for trash: 0x%p\n",
+		 mmu->mmid, mmu->trash_page);
+
+	pm_runtime_allow(&adev->dev);
+	pm_runtime_enable(&adev->dev);
+
+	/*
+	 * FIXME: We can't unload this --- bus_set_iommu() will
+	 * register a notifier which must stay until the devices are
+	 * gone.
+	 */
+	__module_get(THIS_MODULE);
+
+	return 0;
+}
+
+/*
+ * Leave iommu ops as they were --- this means we must be called as
+ * the very last.
+ */
+static void ipu_mmu_remove(struct ipu_bus_device *adev)
+{
+	struct ipu_mmu *mmu = ipu_bus_get_drvdata(adev);
+
+	__free_page(mmu->trash_page);
+	dev_dbg(&adev->dev, "removed\n");
+}
 
-	return mmu;
+static irqreturn_t ipu_mmu_isr(struct ipu_bus_device *adev)
+{
+	dev_info(&adev->dev, "Yeah!\n");
+	return IRQ_NONE;
 }
 
-void ipu_mmu_cleanup(struct ipu_mmu *mmu)
+#ifdef CONFIG_PM
+static int ipu_mmu_suspend(struct device *dev)
 {
-	struct ipu_dma_mapping *dmap = mmu->dmap;
+	struct ipu_bus_device *adev = to_ipu_bus_device(dev);
+	struct ipu_mmu *mmu = ipu_bus_get_drvdata(adev);
+	unsigned long flags;
+
+	spin_lock_irqsave(&mmu->ready_lock, flags);
+	mmu->ready = false;
+	spin_unlock_irqrestore(&mmu->ready_lock, flags);
 
-	ipu_mmu_destroy(mmu);
-	mmu->dmap = NULL;
-	iova_cache_put();
-	put_iova_domain(&dmap->iovad);
-	kfree(dmap);
+	return 0;
 }
 
+static const struct dev_pm_ops ipu_mmu_pm_ops = {
+	.resume = ipu_mmu_hw_init,
+	.suspend = ipu_mmu_suspend,
+	.runtime_resume = ipu_mmu_hw_init,
+	.runtime_suspend = ipu_mmu_suspend,
+};
+
+#define IPU_MMU_PM_OPS	(&ipu_mmu_pm_ops)
+
+#else /* !CONFIG_PM */
+
+#define IPU_MMU_PM_OPS	NULL
+
+#endif /* !CONFIG_PM */
+
+struct ipu_bus_driver ipu_mmu_driver = {
+	.probe = ipu_mmu_probe,
+	.remove = ipu_mmu_remove,
+	.isr = ipu_mmu_isr,
+	.wanted = IPU_MMU_NAME,
+	.drv = {
+		.name = IPU_MMU_NAME,
+		.owner = THIS_MODULE,
+		.pm = IPU_MMU_PM_OPS,
+	},
+};
+
 MODULE_AUTHOR("Sakari Ailus <sakari.ailus@linux.intel.com>");
 MODULE_AUTHOR("Samu Onkalo <samu.onkalo@intel.com>");
 MODULE_LICENSE("GPL");
diff --git a/drivers/media/pci/intel/ipu-mmu.h b/drivers/media/pci/intel/ipu-mmu.h
index 5f55d6b831fa..f81a1e4c91e7 100644
--- a/drivers/media/pci/intel/ipu-mmu.h
+++ b/drivers/media/pci/intel/ipu-mmu.h
@@ -1,5 +1,5 @@
 /* SPDX-License-Identifier: GPL-2.0 */
-/* Copyright (C) 2013 - 2021 Intel Corporation */
+/* Copyright (C) 2013 - 2018 Intel Corporation */
 
 #ifndef IPU_MMU_H
 #define IPU_MMU_H
@@ -12,27 +12,24 @@
 #define ISYS_MMID 1
 #define PSYS_MMID 0
 
+extern struct ipu_bus_driver ipu_mmu_driver;
 /*
  * @pgtbl: virtual address of the l1 page table (one page)
  */
 struct ipu_mmu_info {
-	struct device *dev;
-
-	u32 __iomem *l1_pt;
-	u32 l1_pt_dma;
-	u32 **l2_pts;
-
-	u32 *dummy_l2_pt;
-	u32 dummy_l2_pteval;
-	void *dummy_page;
-	u32 dummy_page_pteval;
-
+	u32 __iomem *pgtbl;
 	dma_addr_t aperture_start;
 	dma_addr_t aperture_end;
 	unsigned long pgsize_bitmap;
 
 	spinlock_t lock;	/* Serialize access to users */
+	unsigned int users;
 	struct ipu_dma_mapping *dmap;
+	u32 dummy_l2_tbl;
+	u32 dummy_page;
+
+	/* Reference to the trash address to unmap on domain destroy */
+	dma_addr_t iova_addr_trash;
 };
 
 /*
@@ -40,6 +37,7 @@ struct ipu_mmu_info {
  */
 struct ipu_mmu {
 	struct list_head node;
+	unsigned int users;
 
 	struct ipu_mmu_hw *mmu_hw;
 	unsigned int nr_mmus;
@@ -49,28 +47,24 @@ struct ipu_mmu {
 	struct device *dev;
 
 	struct ipu_dma_mapping *dmap;
-	struct list_head vma_list;
 
 	struct page *trash_page;
-	dma_addr_t pci_trash_page; /* IOVA from PCI DMA services (parent) */
-	dma_addr_t iova_trash_page; /* IOVA for IPU child nodes to use */
+	dma_addr_t iova_addr_trash;
 
 	bool ready;
 	spinlock_t ready_lock;	/* Serialize access to bool ready */
 
 	void (*tlb_invalidate)(struct ipu_mmu *mmu);
+	void (*set_mapping)(struct ipu_mmu *mmu,
+			     struct ipu_dma_mapping *dmap);
 };
 
-struct ipu_mmu *ipu_mmu_init(struct device *dev,
-			     void __iomem *base, int mmid,
-			     const struct ipu_hw_variants *hw);
-void ipu_mmu_cleanup(struct ipu_mmu *mmu);
-int ipu_mmu_hw_init(struct ipu_mmu *mmu);
-int ipu_mmu_hw_cleanup(struct ipu_mmu *mmu);
+struct ipu_mmu_info *ipu_mmu_alloc(void);
+void ipu_mmu_destroy(struct ipu_mmu_info *mmu_info);
 int ipu_mmu_map(struct ipu_mmu_info *mmu_info, unsigned long iova,
-		phys_addr_t paddr, size_t size);
+	      phys_addr_t paddr, size_t size);
 size_t ipu_mmu_unmap(struct ipu_mmu_info *mmu_info, unsigned long iova,
-		     size_t size);
+		      size_t size);
 phys_addr_t ipu_mmu_iova_to_phys(struct ipu_mmu_info *mmu_info,
-				 dma_addr_t iova);
+				dma_addr_t iova);
 #endif
diff --git a/drivers/media/pci/intel/ipu-pdata.h b/drivers/media/pci/intel/ipu-pdata.h
index a8f21f81da6d..66f111266f05 100644
--- a/drivers/media/pci/intel/ipu-pdata.h
+++ b/drivers/media/pci/intel/ipu-pdata.h
@@ -1,5 +1,5 @@
 /* SPDX-License-Identifier: GPL-2.0 */
-/* Copyright (C) 2013 - 2021 Intel Corporation */
+/* Copyright (C) 2013 - 2018 Intel Corporation */
 
 #ifndef IPU_PDATA_H
 #define IPU_PDATA_H
@@ -15,10 +15,17 @@
 /* The firmware is accessible within the first 2 GiB only in non-secure mode. */
 #define IPU_MMU_ADDRESS_BITS_NON_SECURE	31
 
+#if defined(CONFIG_VIDEO_INTEL_IPU4) || defined(CONFIG_VIDEO_INTEL_IPU4P)
+#define IPU_MMU_MAX_TLB_L1_STREAMS	16
+#define IPU_MMU_MAX_TLB_L2_STREAMS	16
+#define IPU_MAX_LI_BLOCK_ADDR		64
+#define IPU_MAX_L2_BLOCK_ADDR		32
+#else
 #define IPU_MMU_MAX_TLB_L1_STREAMS	32
 #define IPU_MMU_MAX_TLB_L2_STREAMS	32
 #define IPU_MAX_LI_BLOCK_ADDR		128
 #define IPU_MAX_L2_BLOCK_ADDR		64
+#endif
 
 #define IPU_ISYS_MAX_CSI2_LEGACY_PORTS	4
 #define IPU_ISYS_MAX_CSI2_COMBO_PORTS	2
@@ -35,7 +42,7 @@
  * psys has 4 ports with IOSF interface for VC0, VC1w, VC1r and VC2
  *
  * Threshold values are pre-defined and are arrived at after performance
- * evaluations on a type of IPU
+ * evaluations on a type of IPU4
  */
 #define IPU_MAX_VC_IOSF_PORTS		4
 
@@ -60,7 +67,7 @@ struct ipu_isys_subdev_pdata;
 /*
  * MMU Invalidation HW bug workaround by ZLW mechanism
  *
- * Old IPU MMUV2 has a bug in the invalidation mechanism which might result in
+ * IPU4 MMUV2 has a bug in the invalidation mechanism which might result in
  * wrong translation or replication of the translation. This will cause data
  * corruption. So we cannot directly use the MMU V2 invalidation registers
  * to invalidate the MMU. Instead, whenever an invalidate is called, we need to
@@ -98,7 +105,7 @@ struct ipu_isys_subdev_pdata;
 #define MMUV2_TRASH_L2_BLOCK_OFFSET		IPU_MMUV2_L2_RANGE
 
 /*
- * In some of the IPU MMUs, there is provision to configure L1 and L2 page
+ * In some of the IPU4 MMUs, there is provision to configure L1 and L2 page
  * table caches. Both these L1 and L2 caches are divided into multiple sections
  * called streams. There is maximum 16 streams for both caches. Each of these
  * sections are subdivided into multiple blocks. When nr_l1streams = 0 and
@@ -154,7 +161,7 @@ struct ipu_isys_subdev_pdata;
  *
  * Currently L1/L2 streams, blocks, AT ZLW configurations etc. are pre-defined
  * as per the usecase specific calculations. Any change to this pre-defined
- * table has to happen in sync with IPU FW.
+ * table has to happen in sync with IPU4 FW.
  */
 struct ipu_mmu_hw {
 	union {
@@ -186,6 +193,8 @@ struct ipu_mmu_hw {
 	u8 l2_block_sz[IPU_MMU_MAX_TLB_L2_STREAMS];
 	/* flag to track if WA is needed for successive invalidate HW bug */
 	bool insert_read_before_invalidate;
+	/* flag to track if zlw based mmu invalidation is needed */
+	bool zlw_invalidate;
 };
 
 struct ipu_mmu_pdata {
@@ -200,9 +209,39 @@ struct ipu_isys_csi2_pdata {
 
 #define IPU_EV_AUTO 0xff
 
+struct ipu_combo_receiver_params {
+	u8 crc_val;
+	u8 drc_val;
+	u8 drc_val_combined;
+	u8 ctle_val;
+};
+
+struct ipu_receiver_electrical_params {
+	u64 min_freq;
+	u64 max_freq;
+	unsigned short device;	/* PCI DEVICE ID */
+	u8 revision;	/* PCI REVISION */
+	/* base settings at first receiver power on */
+	u8 rcomp_val_combo;
+	u8 rcomp_val_legacy;
+
+	/* Combo per receiver settings */
+	struct ipu_combo_receiver_params ports[2];
+};
+
 struct ipu_isys_internal_csi2_pdata {
 	unsigned int nports;
 	unsigned int *offsets;
+	struct ipu_receiver_electrical_params *evparams;
+	u32 evsetmask0;
+	u32 evsetmask1;
+	unsigned char *evlanecombine;
+};
+
+struct ipu_isys_internal_tpg_pdata {
+	unsigned int ntpgs;
+	unsigned int *offsets;
+	unsigned int *sels;
 };
 
 /*
@@ -220,6 +259,7 @@ struct ipu_hw_variants {
 
 struct ipu_isys_internal_pdata {
 	struct ipu_isys_internal_csi2_pdata csi2;
+	struct ipu_isys_internal_tpg_pdata tpg;
 	struct ipu_hw_variants hw_variant;
 	u32 num_parallel_streams;
 	u32 isys_dma_overshoot;
@@ -228,6 +268,7 @@ struct ipu_isys_internal_pdata {
 struct ipu_isys_pdata {
 	void __iomem *base;
 	const struct ipu_isys_internal_pdata *ipdata;
+	struct ipu_isys_subdev_pdata *spdata;
 };
 
 struct ipu_psys_internal_pdata {
diff --git a/drivers/media/pci/intel/ipu-psys-compat32.c b/drivers/media/pci/intel/ipu-psys-compat32.c
index 763ebc2c1a9f..0687f3f50690 100644
--- a/drivers/media/pci/intel/ipu-psys-compat32.c
+++ b/drivers/media/pci/intel/ipu-psys-compat32.c
@@ -1,5 +1,5 @@
 // SPDX-License-Identifier: GPL-2.0
-// Copyright (C) 2013 - 2020 Intel Corporation
+// Copyright (C) 2013 - 2018 Intel Corporation
 
 #include <linux/compat.h>
 #include <linux/errno.h>
@@ -58,10 +58,10 @@ get_ipu_psys_command32(struct ipu_psys_command *kp,
 		       struct ipu_psys_command32 __user *up)
 {
 	compat_uptr_t pgm, bufs;
-	bool access_ok;
 
-	access_ok = access_ok(up, sizeof(struct ipu_psys_command32));
-	if (!access_ok || get_user(kp->issue_id, &up->issue_id) ||
+	if (!access_ok(up,
+		       sizeof(struct ipu_psys_command32)) ||
+	    get_user(kp->issue_id, &up->issue_id) ||
 	    get_user(kp->user_token, &up->user_token) ||
 	    get_user(kp->priority, &up->priority) ||
 	    get_user(pgm, &up->pg_manifest) ||
@@ -69,13 +69,37 @@ get_ipu_psys_command32(struct ipu_psys_command *kp,
 	    get_user(kp->pg, &up->pg) ||
 	    get_user(kp->pg_manifest_size, &up->pg_manifest_size) ||
 	    get_user(kp->bufcount, &up->bufcount) ||
-	    get_user(kp->min_psys_freq, &up->min_psys_freq) ||
-	    get_user(kp->frame_counter, &up->frame_counter)
+	    get_user(kp->min_psys_freq, &up->min_psys_freq)
+	    || get_user(kp->frame_counter, &up->frame_counter)
 	    )
 		return -EFAULT;
 
 	kp->pg_manifest = compat_ptr(pgm);
 	kp->buffers = compat_ptr(bufs);
+	return 0;
+}
+
+static int
+put_ipu_psys_command32(struct ipu_psys_command *kp,
+		       struct ipu_psys_command32 __user *up)
+{
+	compat_uptr_t pgm = (u32)((unsigned long)kp->pg_manifest);
+	compat_uptr_t bufs = (u32)((unsigned long)kp->buffers);
+
+	if (!access_ok(up,
+		       sizeof(struct ipu_psys_command32)) ||
+	    put_user(kp->issue_id, &up->issue_id) ||
+	    put_user(kp->user_token, &up->user_token) ||
+	    put_user(kp->priority, &up->priority) ||
+	    put_user(pgm, &up->pg_manifest) ||
+	    put_user(bufs, &up->buffers) ||
+	    put_user(kp->pg, &up->pg) ||
+	    put_user(kp->pg_manifest_size, &up->pg_manifest_size) ||
+	    put_user(kp->bufcount, &up->bufcount) ||
+	    put_user(kp->min_psys_freq, &up->min_psys_freq)
+	    || put_user(kp->frame_counter, &up->frame_counter)
+	    )
+		return -EFAULT;
 
 	return 0;
 }
@@ -85,10 +109,10 @@ get_ipu_psys_buffer32(struct ipu_psys_buffer *kp,
 		      struct ipu_psys_buffer32 __user *up)
 {
 	compat_uptr_t ptr;
-	bool access_ok;
 
-	access_ok = access_ok(up, sizeof(struct ipu_psys_buffer32));
-	if (!access_ok || get_user(kp->len, &up->len) ||
+	if (!access_ok(up,
+		       sizeof(struct ipu_psys_buffer32)) ||
+	    get_user(kp->len, &up->len) ||
 	    get_user(ptr, &up->base.userptr) ||
 	    get_user(kp->data_offset, &up->data_offset) ||
 	    get_user(kp->bytes_used, &up->bytes_used) ||
@@ -104,10 +128,9 @@ static int
 put_ipu_psys_buffer32(struct ipu_psys_buffer *kp,
 		      struct ipu_psys_buffer32 __user *up)
 {
-	bool access_ok;
-
-	access_ok = access_ok(up, sizeof(struct ipu_psys_buffer32));
-	if (!access_ok || put_user(kp->len, &up->len) ||
+	if (!access_ok(up,
+		       sizeof(struct ipu_psys_buffer32)) ||
+	    put_user(kp->len, &up->len) ||
 	    put_user(kp->base.fd, &up->base.fd) ||
 	    put_user(kp->data_offset, &up->data_offset) ||
 	    put_user(kp->bytes_used, &up->bytes_used) ||
@@ -122,10 +145,10 @@ get_ipu_psys_manifest32(struct ipu_psys_manifest *kp,
 			struct ipu_psys_manifest32 __user *up)
 {
 	compat_uptr_t ptr;
-	bool access_ok;
 
-	access_ok = access_ok(up, sizeof(struct ipu_psys_manifest32));
-	if (!access_ok || get_user(kp->index, &up->index) ||
+	if (!access_ok(up,
+		       sizeof(struct ipu_psys_manifest32)) ||
+	    get_user(kp->index, &up->index) ||
 	    get_user(kp->size, &up->size) || get_user(ptr, &up->manifest))
 		return -EFAULT;
 
@@ -139,10 +162,10 @@ put_ipu_psys_manifest32(struct ipu_psys_manifest *kp,
 			struct ipu_psys_manifest32 __user *up)
 {
 	compat_uptr_t ptr = (u32)((unsigned long)kp->manifest);
-	bool access_ok;
 
-	access_ok = access_ok(up, sizeof(struct ipu_psys_manifest32));
-	if (!access_ok || put_user(kp->index, &up->index) ||
+	if (!access_ok(up,
+		       sizeof(struct ipu_psys_manifest32)) ||
+	    put_user(kp->index, &up->index) ||
 	    put_user(kp->size, &up->size) || put_user(ptr, &up->manifest))
 		return -EFAULT;
 
@@ -166,6 +189,7 @@ long ipu_psys_compat_ioctl32(struct file *file, unsigned int cmd,
 	} karg;
 	int compatible_arg = 1;
 	int err = 0;
+	int copy_to_user_size = 0;
 	void __user *up = compat_ptr(arg);
 
 	switch (cmd) {
@@ -191,10 +215,12 @@ long ipu_psys_compat_ioctl32(struct file *file, unsigned int cmd,
 		break;
 	case IPU_IOC_QCMD:
 		err = get_ipu_psys_command32(&karg.cmd, up);
+		copy_to_user_size = sizeof(struct ipu_psys_command32);
 		compatible_arg = 0;
 		break;
 	case IPU_IOC_GET_MANIFEST:
 		err = get_ipu_psys_manifest32(&karg.m, up);
+		copy_to_user_size = sizeof(struct ipu_psys_manifest32);
 		compatible_arg = 0;
 		break;
 	}
@@ -204,10 +230,14 @@ long ipu_psys_compat_ioctl32(struct file *file, unsigned int cmd,
 	if (compatible_arg) {
 		err = native_ioctl(file, cmd, (unsigned long)up);
 	} else {
-		mm_segment_t old_fs = force_uaccess_begin();
-
-		err = native_ioctl(file, cmd, (unsigned long)&karg);
-		force_uaccess_end(old_fs);
+		// This will lose 4/8 bytes from the end of the 64bit struct.
+		err = copy_to_user(up, &karg, copy_to_user_size ? copy_to_user_size : _IOC_SIZE(cmd));
+		if (err)
+			return err;
+		err = native_ioctl(file, cmd, (unsigned long)up);
+		if (err)
+			return err;
+		err = copy_from_user(&karg, up, _IOC_SIZE(cmd));
 	}
 
 	if (err)
@@ -220,6 +250,10 @@ long ipu_psys_compat_ioctl32(struct file *file, unsigned int cmd,
 	case IPU_IOC_GET_MANIFEST:
 		err = put_ipu_psys_manifest32(&karg.m, up);
 		break;
+	case IPU_IOC_QCMD:
+		err = put_ipu_psys_command32(&karg.cmd, up);
+		break;
 	}
 	return err;
 }
+EXPORT_SYMBOL_GPL(ipu_psys_compat_ioctl32);
diff --git a/drivers/media/pci/intel/ipu-psys.c b/drivers/media/pci/intel/ipu-psys.c
index 327d4f6c670d..f9bcc388875d 100644
--- a/drivers/media/pci/intel/ipu-psys.c
+++ b/drivers/media/pci/intel/ipu-psys.c
@@ -1,5 +1,5 @@
 // SPDX-License-Identifier: GPL-2.0
-// Copyright (C) 2013 - 2020 Intel Corporation
+// Copyright (C) 2013 - 2018 Intel Corporation
 
 #include <linux/debugfs.h>
 #include <linux/delay.h>
@@ -15,15 +15,22 @@
 #include <linux/pm_runtime.h>
 #include <linux/version.h>
 #include <linux/poll.h>
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 14, 0)
+#include <linux/sched.h>
+#else
 #include <uapi/linux/sched/types.h>
+#endif
 #include <linux/uaccess.h>
 #include <linux/vmalloc.h>
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0)
+#include <linux/dma-attrs.h>
+#else
 #include <linux/dma-mapping.h>
+#endif
 
 #include <uapi/linux/ipu-psys.h>
 
 #include "ipu.h"
-#include "ipu-mmu.h"
 #include "ipu-bus.h"
 #include "ipu-platform.h"
 #include "ipu-buttress.h"
@@ -32,6 +39,7 @@
 #include "ipu-psys.h"
 #include "ipu-platform-psys.h"
 #include "ipu-platform-regs.h"
+#include "ipu-fw-isys.h"
 #include "ipu-fw-com.h"
 
 static bool async_fw_init;
@@ -70,6 +78,11 @@ static struct bus_type ipu_psys_bus = {
 	.name = IPU_PSYS_NAME,
 };
 
+static struct ipu_psys_capability caps = {
+	.version = 1,
+	.driver = "ipu-psys",
+};
+
 struct ipu_psys_pg *__get_pg_buf(struct ipu_psys *psys, size_t pg_size)
 {
 	struct ipu_psys_pg *kpg;
@@ -90,7 +103,8 @@ struct ipu_psys_pg *__get_pg_buf(struct ipu_psys *psys, size_t pg_size)
 		return NULL;
 
 	kpg->pg = dma_alloc_attrs(&psys->adev->dev, pg_size,
-				  &kpg->pg_dma_addr, GFP_KERNEL, 0);
+				  &kpg->pg_dma_addr, GFP_KERNEL,
+				  0);
 	if (!kpg->pg) {
 		kfree(kpg);
 		return NULL;
@@ -105,15 +119,13 @@ struct ipu_psys_pg *__get_pg_buf(struct ipu_psys *psys, size_t pg_size)
 	return kpg;
 }
 
-static int ipu_psys_unmapbuf_locked(int fd, struct ipu_psys_fh *fh,
-				    struct ipu_psys_kbuffer *kbuf);
 struct ipu_psys_kbuffer *ipu_psys_lookup_kbuffer(struct ipu_psys_fh *fh, int fd)
 {
-	struct ipu_psys_kbuffer *kbuf;
+	struct ipu_psys_kbuffer *kbuffer;
 
-	list_for_each_entry(kbuf, &fh->bufmap, list) {
-		if (kbuf->fd == fd)
-			return kbuf;
+	list_for_each_entry(kbuffer, &fh->bufmap, list) {
+		if (kbuffer->fd == fd)
+			return kbuffer;
 	}
 
 	return NULL;
@@ -151,24 +163,28 @@ static int ipu_psys_get_userpages(struct ipu_dma_buf_attach *attach)
 	if (!sgt)
 		return -ENOMEM;
 
-	if (attach->npages != 0) {
-		pages = attach->pages;
-		npages = attach->npages;
-		attach->vma_is_io = 1;
-		goto skip_pages;
-	}
-
-	pages = kvzalloc(array_size, GFP_KERNEL);
+	if (array_size <= PAGE_SIZE)
+		pages = kzalloc(array_size, GFP_KERNEL);
+	else
+		pages = vzalloc(array_size);
 	if (!pages)
 		goto free_sgt;
 
-	mmap_read_lock(current->mm);
+	down_read(&current->mm->mmap_lock);
 	vma = find_vma(current->mm, start);
 	if (!vma) {
 		ret = -EFAULT;
 		goto error_up_read;
 	}
 
+	if (vma->vm_end < start + attach->len) {
+		dev_err(attach->dev,
+			"vma at %lu is too small for %llu bytes\n",
+			start, attach->len);
+		ret = -EFAULT;
+		goto error_up_read;
+	}
+
 	/*
 	 * For buffers from Gralloc, VM_PFNMAP is expected,
 	 * but VM_IO is set. Possibly bug in Gralloc.
@@ -178,14 +194,6 @@ static int ipu_psys_get_userpages(struct ipu_dma_buf_attach *attach)
 	if (attach->vma_is_io) {
 		unsigned long io_start = start;
 
-		if (vma->vm_end < start + attach->len) {
-			dev_err(attach->dev,
-				"vma at %lu is too small for %llu bytes\n",
-				start, attach->len);
-			ret = -EFAULT;
-			goto error_up_read;
-		}
-
 		for (nr = 0; nr < npages; nr++, io_start += PAGE_SIZE) {
 			unsigned long pfn;
 
@@ -195,18 +203,22 @@ static int ipu_psys_get_userpages(struct ipu_dma_buf_attach *attach)
 			pages[nr] = pfn_to_page(pfn);
 		}
 	} else {
-		nr = get_user_pages(start & PAGE_MASK, npages,
-				    FOLL_WRITE,
-				    pages, NULL);
+		nr = get_user_pages(
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 6, 0)
+				   current, current->mm,
+#endif
+				   start & PAGE_MASK, npages,
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 9, 0)
+				   1, 0,
+#else
+				   FOLL_WRITE,
+#endif
+				   pages, NULL);
 		if (nr < npages)
 			goto error_up_read;
 	}
-	mmap_read_unlock(current->mm);
+	up_read(&current->mm->mmap_lock);
 
-	attach->pages = pages;
-	attach->npages = npages;
-
-skip_pages:
 	ret = sg_alloc_table_from_pages(sgt, pages, npages,
 					start & ~PAGE_MASK, attach->len,
 					GFP_KERNEL);
@@ -214,11 +226,13 @@ static int ipu_psys_get_userpages(struct ipu_dma_buf_attach *attach)
 		goto error;
 
 	attach->sgt = sgt;
+	attach->pages = pages;
+	attach->npages = npages;
 
 	return 0;
 
 error_up_read:
-	mmap_read_unlock(current->mm);
+	up_read(&current->mm->mmap_lock);
 error:
 	if (!attach->vma_is_io)
 		while (nr > 0)
@@ -250,15 +264,22 @@ static void ipu_psys_put_userpages(struct ipu_dma_buf_attach *attach)
 		}
 	}
 
-	kvfree(attach->pages);
+	if (is_vmalloc_addr(attach->pages))
+		vfree(attach->pages);
+	else
+		kfree(attach->pages);
 
 	sg_free_table(attach->sgt);
 	kfree(attach->sgt);
 	attach->sgt = NULL;
 }
-
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 19, 0)
 static int ipu_dma_buf_attach(struct dma_buf *dbuf,
 			      struct dma_buf_attachment *attach)
+#else
+static int ipu_dma_buf_attach(struct dma_buf *dbuf, struct device *dev,
+			      struct dma_buf_attachment *attach)
+#endif
 {
 	struct ipu_psys_kbuffer *kbuf = dbuf->priv;
 	struct ipu_dma_buf_attach *ipu_attach;
@@ -267,6 +288,9 @@ static int ipu_dma_buf_attach(struct dma_buf *dbuf,
 	if (!ipu_attach)
 		return -ENOMEM;
 
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 19, 0)
+	ipu_attach->dev = dev;
+#endif
 	ipu_attach->len = kbuf->len;
 	ipu_attach->userptr = kbuf->userptr;
 
@@ -287,16 +311,26 @@ static struct sg_table *ipu_dma_buf_map(struct dma_buf_attachment *attach,
 					enum dma_data_direction dir)
 {
 	struct ipu_dma_buf_attach *ipu_attach = attach->priv;
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0)
+	DEFINE_DMA_ATTRS(attrs);
+#else
 	unsigned long attrs;
+#endif
 	int ret;
 
 	ret = ipu_psys_get_userpages(ipu_attach);
 	if (ret)
 		return NULL;
 
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0)
+	dma_set_attr(DMA_ATTR_SKIP_CPU_SYNC, &attrs);
+	ret = dma_map_sg_attrs(attach->dev, ipu_attach->sgt->sgl,
+			       ipu_attach->sgt->orig_nents, dir, &attrs);
+#else
 	attrs = DMA_ATTR_SKIP_CPU_SYNC;
 	ret = dma_map_sg_attrs(attach->dev, ipu_attach->sgt->sgl,
 			       ipu_attach->sgt->orig_nents, dir, attrs);
+#endif
 	if (ret < ipu_attach->sgt->orig_nents) {
 		ipu_psys_put_userpages(ipu_attach);
 		dev_dbg(attach->dev, "buf map failed\n");
@@ -328,6 +362,20 @@ static int ipu_dma_buf_mmap(struct dma_buf *dbuf, struct vm_area_struct *vma)
 	return -ENOTTY;
 }
 
+#if LINUX_VERSION_CODE < KERNEL_VERSION(5, 6, 0)
+static void *ipu_dma_buf_kmap(struct dma_buf *dbuf, unsigned long pgnum)
+{
+	return NULL;
+}
+#endif
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 19, 0)
+static void *ipu_dma_buf_kmap_atomic(struct dma_buf *dbuf, unsigned long pgnum)
+{
+	return NULL;
+}
+#endif
+
 static void ipu_dma_buf_release(struct dma_buf *buf)
 {
 	struct ipu_psys_kbuffer *kbuf = buf->priv;
@@ -344,7 +392,10 @@ static void ipu_dma_buf_release(struct dma_buf *buf)
 }
 
 static int ipu_dma_buf_begin_cpu_access(struct dma_buf *dma_buf,
-					enum dma_data_direction dir)
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 6, 0)
+				 size_t start, size_t len,
+#endif
+				 enum dma_data_direction dir)
 {
 	return -ENOTTY;
 }
@@ -353,23 +404,27 @@ static int ipu_dma_buf_vmap(struct dma_buf *dmabuf, struct dma_buf_map *map)
 {
 	struct dma_buf_attachment *attach;
 	struct ipu_dma_buf_attach *ipu_attach;
+    void *vaddr;
 
 	if (list_empty(&dmabuf->attachments))
-		return -EINVAL;
+		return -ENOMEM;
 
 	attach = list_last_entry(&dmabuf->attachments,
 				 struct dma_buf_attachment, node);
 	ipu_attach = attach->priv;
 
 	if (!ipu_attach || !ipu_attach->pages || !ipu_attach->npages)
-		return -EINVAL;
+		return -ENOMEM;
 
-	map->vaddr = vm_map_ram(ipu_attach->pages, ipu_attach->npages, 0);
-	map->is_iomem = false;
-	if (!map->vaddr)
-		return -EINVAL;
+	vaddr = vm_map_ram(ipu_attach->pages,
+			  ipu_attach->npages, 0);
 
-	return 0;
+    if (IS_ERR(vaddr))
+	return PTR_ERR(vaddr);
+
+    dma_buf_map_set_vaddr(map, vaddr);
+
+    return 0;
 }
 
 static void ipu_dma_buf_vunmap(struct dma_buf *dmabuf, struct dma_buf_map *map)
@@ -390,13 +445,22 @@ static void ipu_dma_buf_vunmap(struct dma_buf *dmabuf, struct dma_buf_map *map)
 	vm_unmap_ram(map->vaddr, ipu_attach->npages);
 }
 
-struct dma_buf_ops ipu_dma_buf_ops = {
+static struct dma_buf_ops ipu_dma_buf_ops = {
 	.attach = ipu_dma_buf_attach,
 	.detach = ipu_dma_buf_detach,
 	.map_dma_buf = ipu_dma_buf_map,
 	.unmap_dma_buf = ipu_dma_buf_unmap,
 	.release = ipu_dma_buf_release,
 	.begin_cpu_access = ipu_dma_buf_begin_cpu_access,
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 14, 0)
+	.kmap = ipu_dma_buf_kmap,
+	.kmap_atomic = ipu_dma_buf_kmap_atomic,
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(5, 6, 0)
+	.map = ipu_dma_buf_kmap,
+#endif
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 19, 0)
+	.map_atomic = ipu_dma_buf_kmap_atomic,
+#endif
 	.mmap = ipu_dma_buf_mmap,
 	.vmap = ipu_dma_buf_vmap,
 	.vunmap = ipu_dma_buf_vunmap,
@@ -412,12 +476,17 @@ static int ipu_psys_open(struct inode *inode, struct file *file)
 	if (isp->flr_done)
 		return -EIO;
 
+	rval = ipu_buttress_authenticate(isp);
+	if (rval) {
+		dev_err(&psys->adev->dev, "FW authentication failed\n");
+		return rval;
+	}
+
 	fh = kzalloc(sizeof(*fh), GFP_KERNEL);
 	if (!fh)
 		return -ENOMEM;
 
 	fh->psys = psys;
-
 	file->private_data = fh;
 
 	mutex_init(&fh->mutex);
@@ -440,52 +509,37 @@ static int ipu_psys_open(struct inode *inode, struct file *file)
 	return rval;
 }
 
-static inline void ipu_psys_kbuf_unmap(struct ipu_psys_kbuffer *kbuf)
-{
-	if (!kbuf)
-		return;
-
-	kbuf->valid = false;
-	if (kbuf->kaddr) {
-		struct dma_buf_map dmap;
-
-		dma_buf_map_set_vaddr(&dmap, kbuf->kaddr);
-		dma_buf_vunmap(kbuf->dbuf, &dmap);
-	}
-	if (kbuf->sgt)
-		dma_buf_unmap_attachment(kbuf->db_attach,
-					 kbuf->sgt,
-					 DMA_BIDIRECTIONAL);
-	if (kbuf->db_attach)
-		dma_buf_detach(kbuf->dbuf, kbuf->db_attach);
-	dma_buf_put(kbuf->dbuf);
-
-	kbuf->db_attach = NULL;
-	kbuf->dbuf = NULL;
-	kbuf->sgt = NULL;
-}
-
 static int ipu_psys_release(struct inode *inode, struct file *file)
 {
 	struct ipu_psys *psys = inode_to_ipu_psys(inode);
 	struct ipu_psys_fh *fh = file->private_data;
 	struct ipu_psys_kbuffer *kbuf, *kbuf0;
-	struct dma_buf_attachment *db_attach;
+    struct dma_buf_map map;
 
 	mutex_lock(&fh->mutex);
 	/* clean up buffers */
 	if (!list_empty(&fh->bufmap)) {
 		list_for_each_entry_safe(kbuf, kbuf0, &fh->bufmap, list) {
 			list_del(&kbuf->list);
-			db_attach = kbuf->db_attach;
-
-			/* Unmap and release buffers */
-			if (kbuf->dbuf && db_attach) {
-
-				ipu_psys_kbuf_unmap(kbuf);
+			   /* Unmap and release buffers */
+			if (kbuf->dbuf && kbuf->db_attach) {
+				struct dma_buf *dbuf;
+
+				map = (struct dma_buf_map)DMA_BUF_MAP_INIT_VADDR(kbuf->kaddr);
+				kbuf->valid = false;
+				dma_buf_vunmap(kbuf->dbuf, &map);
+				dma_buf_unmap_attachment(kbuf->db_attach,
+							 kbuf->sgt,
+							 DMA_BIDIRECTIONAL);
+				dma_buf_detach(kbuf->dbuf, kbuf->db_attach);
+				dbuf = kbuf->dbuf;
+				kbuf->dbuf = NULL;
+				kbuf->db_attach = NULL;
+				dma_buf_put(dbuf);
 			} else {
-				if (db_attach)
-					ipu_psys_put_userpages(db_attach->priv);
+				if (kbuf->db_attach)
+					ipu_psys_put_userpages(
+						kbuf->db_attach->priv);
 				kfree(kbuf);
 			}
 		}
@@ -496,12 +550,8 @@ static int ipu_psys_release(struct inode *inode, struct file *file)
 	list_del(&fh->list);
 
 	mutex_unlock(&psys->mutex);
-	ipu_psys_fh_deinit(fh);
 
-	mutex_lock(&psys->mutex);
-	if (list_empty(&psys->fhs))
-		psys->power_gating = 0;
-	mutex_unlock(&psys->mutex);
+	ipu_psys_fh_deinit(fh);
 	mutex_destroy(&fh->mutex);
 	kfree(fh);
 
@@ -513,7 +563,9 @@ static int ipu_psys_getbuf(struct ipu_psys_buffer *buf, struct ipu_psys_fh *fh)
 	struct ipu_psys_kbuffer *kbuf;
 	struct ipu_psys *psys = fh->psys;
 
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 1, 0)
 	DEFINE_DMA_BUF_EXPORT_INFO(exp_info);
+#endif
 	struct dma_buf *dbuf;
 	int ret;
 
@@ -530,12 +582,16 @@ static int ipu_psys_getbuf(struct ipu_psys_buffer *buf, struct ipu_psys_fh *fh)
 	kbuf->userptr = buf->base.userptr;
 	kbuf->flags = buf->flags;
 
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 1, 0)
 	exp_info.ops = &ipu_dma_buf_ops;
 	exp_info.size = kbuf->len;
 	exp_info.flags = O_RDWR;
 	exp_info.priv = kbuf;
 
 	dbuf = dma_buf_export(&exp_info);
+#else
+	dbuf = dma_buf_export(kbuf, &ipu_dma_buf_ops, kbuf->len, 0);
+#endif
 	if (IS_ERR(dbuf)) {
 		kfree(kbuf);
 		return PTR_ERR(dbuf);
@@ -544,21 +600,21 @@ static int ipu_psys_getbuf(struct ipu_psys_buffer *buf, struct ipu_psys_fh *fh)
 	ret = dma_buf_fd(dbuf, 0);
 	if (ret < 0) {
 		kfree(kbuf);
-		dma_buf_put(dbuf);
 		return ret;
 	}
 
+	dev_dbg(&psys->adev->dev, "IOC_GETBUF: userptr %p", buf->base.userptr);
+
 	kbuf->fd = ret;
 	buf->base.fd = ret;
 	kbuf->flags = buf->flags &= ~IPU_BUFFER_FLAG_USERPTR;
 	kbuf->flags = buf->flags |= IPU_BUFFER_FLAG_DMA_HANDLE;
 
 	mutex_lock(&fh->mutex);
-	list_add(&kbuf->list, &fh->bufmap);
+	list_add_tail(&kbuf->list, &fh->bufmap);
 	mutex_unlock(&fh->mutex);
 
-	dev_dbg(&psys->adev->dev, "IOC_GETBUF: userptr %p size %llu to fd %d",
-		buf->base.userptr, buf->len, buf->base.fd);
+	dev_dbg(&psys->adev->dev, "to %d\n", buf->base.fd);
 
 	return 0;
 }
@@ -568,17 +624,16 @@ static int ipu_psys_putbuf(struct ipu_psys_buffer *buf, struct ipu_psys_fh *fh)
 	return 0;
 }
 
-int ipu_psys_mapbuf_locked(int fd, struct ipu_psys_fh *fh,
-			   struct ipu_psys_kbuffer *kbuf)
+static long ipu_psys_mapbuf(int fd, struct ipu_psys_fh *fh)
 {
 	struct ipu_psys *psys = fh->psys;
+	struct ipu_psys_kbuffer *kbuf;
 	struct dma_buf *dbuf;
-	struct dma_buf_map dmap;
+    struct dma_buf_map map;
 	int ret;
 
-	dbuf = dma_buf_get(fd);
-	if (IS_ERR(dbuf))
-		return -EINVAL;
+	mutex_lock(&fh->mutex);
+	kbuf = ipu_psys_lookup_kbuffer(fh, fd);
 
 	if (!kbuf) {
 		/* This fd isn't generated by ipu_psys_getbuf, it
@@ -587,41 +642,27 @@ int ipu_psys_mapbuf_locked(int fd, struct ipu_psys_fh *fh,
 		 */
 		kbuf = kzalloc(sizeof(*kbuf), GFP_KERNEL);
 		if (!kbuf) {
-			ret = -ENOMEM;
-			goto mapbuf_fail;
+			mutex_unlock(&fh->mutex);
+			return -ENOMEM;
 		}
 
-		list_add(&kbuf->list, &fh->bufmap);
-	}
-
-	/* fd valid and found, need remap */
-	if (kbuf->dbuf && (kbuf->dbuf != dbuf || kbuf->len != dbuf->size)) {
-		dev_dbg(&psys->adev->dev,
-			"dmabuf fd %d with kbuf %p changed, need remap.\n",
-			fd, kbuf);
-		ret = ipu_psys_unmapbuf_locked(fd, fh, kbuf);
-		if (ret)
-			goto mapbuf_fail;
-
-		kbuf = ipu_psys_lookup_kbuffer(fh, fd);
-		/* changed external dmabuf */
-		if (!kbuf) {
-			kbuf = kzalloc(sizeof(*kbuf), GFP_KERNEL);
-			if (!kbuf) {
-				ret = -ENOMEM;
-				goto mapbuf_fail;
-			}
-			list_add(&kbuf->list, &fh->bufmap);
-		}
+		list_add_tail(&kbuf->list, &fh->bufmap);
 	}
 
 	if (kbuf->sgt) {
-		dev_dbg(&psys->adev->dev, "fd %d has been mapped!\n", fd);
-		dma_buf_put(dbuf);
+		dev_dbg(&psys->adev->dev, "has been mapped!\n");
 		goto mapbuf_end;
 	}
 
-	kbuf->dbuf = dbuf;
+	kbuf->dbuf = dma_buf_get(fd);
+	if (IS_ERR(kbuf->dbuf)) {
+		if (!kbuf->userptr) {
+			list_del(&kbuf->list);
+			kfree(kbuf);
+		}
+		mutex_unlock(&fh->mutex);
+		return -EINVAL;
+	}
 
 	if (kbuf->len == 0)
 		kbuf->len = kbuf->dbuf->size;
@@ -631,107 +672,95 @@ int ipu_psys_mapbuf_locked(int fd, struct ipu_psys_fh *fh,
 	kbuf->db_attach = dma_buf_attach(kbuf->dbuf, &psys->adev->dev);
 	if (IS_ERR(kbuf->db_attach)) {
 		ret = PTR_ERR(kbuf->db_attach);
-		dev_dbg(&psys->adev->dev, "dma buf attach failed\n");
-		goto kbuf_map_fail;
+		goto error_put;
 	}
 
 	kbuf->sgt = dma_buf_map_attachment(kbuf->db_attach, DMA_BIDIRECTIONAL);
 	if (IS_ERR_OR_NULL(kbuf->sgt)) {
 		ret = -EINVAL;
 		kbuf->sgt = NULL;
-		dev_dbg(&psys->adev->dev, "dma buf map attachment failed\n");
-		goto kbuf_map_fail;
+		dev_dbg(&psys->adev->dev, "map attachment failed\n");
+		goto error_detach;
 	}
 
 	kbuf->dma_addr = sg_dma_address(kbuf->sgt->sgl);
 
-	ret = dma_buf_vmap(kbuf->dbuf, &dmap);
+	ret = dma_buf_vmap(kbuf->dbuf, &map);
 	if (ret) {
-		dev_dbg(&psys->adev->dev, "dma buf vmap failed\n");
-		goto kbuf_map_fail;
+		ret = -EINVAL;
+		goto error_unmap;
 	}
-	kbuf->kaddr = dmap.vaddr;
+    kbuf->kaddr = map.vaddr;
 
-	dev_dbg(&psys->adev->dev, "%s kbuf %p fd %d with len %llu mapped\n",
-		__func__, kbuf, fd, kbuf->len);
 mapbuf_end:
 
 	kbuf->valid = true;
 
-	return 0;
+	mutex_unlock(&fh->mutex);
+
+	dev_dbg(&psys->adev->dev, "IOC_MAPBUF: mapped fd %d\n", fd);
 
-kbuf_map_fail:
-	ipu_psys_kbuf_unmap(kbuf);
+	return 0;
 
+error_unmap:
+	dma_buf_unmap_attachment(kbuf->db_attach, kbuf->sgt, DMA_BIDIRECTIONAL);
+error_detach:
+	dma_buf_detach(kbuf->dbuf, kbuf->db_attach);
+	kbuf->db_attach = NULL;
+error_put:
 	list_del(&kbuf->list);
+	dbuf = kbuf->dbuf;
+
 	if (!kbuf->userptr)
 		kfree(kbuf);
-	return ret;
 
-mapbuf_fail:
+	mutex_unlock(&fh->mutex);
 	dma_buf_put(dbuf);
 
-	dev_err(&psys->adev->dev, "%s failed for fd %d\n", __func__, fd);
 	return ret;
 }
 
-static long ipu_psys_mapbuf(int fd, struct ipu_psys_fh *fh)
+static long ipu_psys_unmapbuf(int fd, struct ipu_psys_fh *fh)
 {
-	long ret;
 	struct ipu_psys_kbuffer *kbuf;
+	struct ipu_psys *psys = fh->psys;
+	struct dma_buf *dmabuf;
+    struct dma_buf_map map;
 
 	mutex_lock(&fh->mutex);
 	kbuf = ipu_psys_lookup_kbuffer(fh, fd);
-	ret = ipu_psys_mapbuf_locked(fd, fh, kbuf);
-	mutex_unlock(&fh->mutex);
+	if (!kbuf) {
+		dev_dbg(&psys->adev->dev, "buffer %d not found\n", fd);
+		mutex_unlock(&fh->mutex);
+		return -EINVAL;
+	}
 
-	dev_dbg(&fh->psys->adev->dev, "IOC_MAPBUF ret %ld\n", ret);
+    map = (struct dma_buf_map)DMA_BUF_MAP_INIT_VADDR(kbuf->kaddr);
 
-	return ret;
-}
+	/* From now on it is not safe to use this kbuffer */
+	kbuf->valid = false;
 
-static int ipu_psys_unmapbuf_locked(int fd, struct ipu_psys_fh *fh,
-				    struct ipu_psys_kbuffer *kbuf)
-{
-	struct ipu_psys *psys = fh->psys;
+	dma_buf_vunmap(kbuf->dbuf, &map);
+	dma_buf_unmap_attachment(kbuf->db_attach, kbuf->sgt, DMA_BIDIRECTIONAL);
 
-	if (!kbuf || fd != kbuf->fd) {
-		dev_err(&psys->adev->dev, "invalid kbuffer\n");
-		return -EINVAL;
-	}
+	dma_buf_detach(kbuf->dbuf, kbuf->db_attach);
 
-	/* From now on it is not safe to use this kbuffer */
-	ipu_psys_kbuf_unmap(kbuf);
+	dmabuf = kbuf->dbuf;
+
+	kbuf->db_attach = NULL;
+	kbuf->dbuf = NULL;
 
 	list_del(&kbuf->list);
 
 	if (!kbuf->userptr)
 		kfree(kbuf);
 
-	dev_dbg(&psys->adev->dev, "%s fd %d unmapped\n", __func__, fd);
-
-	return 0;
-}
-
-static long ipu_psys_unmapbuf(int fd, struct ipu_psys_fh *fh)
-{
-	struct ipu_psys_kbuffer *kbuf;
-	long ret;
-
-	mutex_lock(&fh->mutex);
-	kbuf = ipu_psys_lookup_kbuffer(fh, fd);
-	if (!kbuf) {
-		dev_err(&fh->psys->adev->dev,
-			"buffer with fd %d not found\n", fd);
-		mutex_unlock(&fh->mutex);
-		return -EINVAL;
-	}
-	ret = ipu_psys_unmapbuf_locked(fd, fh, kbuf);
 	mutex_unlock(&fh->mutex);
+	dma_buf_put(dmabuf);
 
-	dev_dbg(&fh->psys->adev->dev, "IOC_UNMAPBUF\n");
+	dev_dbg(&psys->adev->dev, "IOC_UNMAPBUF: fd %d\n", fd);
 
-	return ret;
+	return 0;
 }
 
 static unsigned int ipu_psys_poll(struct file *file,
@@ -791,7 +820,7 @@ static long ipu_get_manifest(struct ipu_psys_manifest *manifest,
 		return 0;
 
 	if (copy_to_user(manifest->manifest,
-			 (uint8_t *)client_pkg + client_pkg->pg_manifest_offs,
+			 (uint8_t *) client_pkg + client_pkg->pg_manifest_offs,
 			 manifest->size)) {
 		return -EFAULT;
 	}
@@ -810,7 +839,7 @@ static long ipu_psys_ioctl(struct file *file, unsigned int cmd,
 		struct ipu_psys_manifest m;
 	} karg;
 	struct ipu_psys_fh *fh = file->private_data;
-	long err = 0;
+	int err = 0;
 	void __user *up = (void __user *)arg;
 	bool copy = (cmd != IPU_IOC_MAPBUF && cmd != IPU_IOC_UNMAPBUF);
 
@@ -833,7 +862,7 @@ static long ipu_psys_ioctl(struct file *file, unsigned int cmd,
 		err = ipu_psys_unmapbuf(arg, fh);
 		break;
 	case IPU_IOC_QUERYCAP:
-		karg.caps = fh->psys->caps;
+		karg.caps = caps;
 		break;
 	case IPU_IOC_GETBUF:
 		err = ipu_psys_getbuf(&karg.buf, fh);
@@ -888,23 +917,20 @@ static int psys_runtime_pm_resume(struct device *dev)
 	unsigned long flags;
 	int retval;
 
-	if (!psys)
+	if (!psys) {
+		WARN(1, "%s called before probing. skipping.\n", __func__);
 		return 0;
-
+	}
 	/*
 	 * In runtime autosuspend mode, if the psys is in power on state, no
 	 * need to resume again.
 	 */
-	spin_lock_irqsave(&psys->ready_lock, flags);
-	if (psys->ready) {
-		spin_unlock_irqrestore(&psys->ready_lock, flags);
+	spin_lock_irqsave(&psys->power_lock, flags);
+	if (psys->power) {
+		spin_unlock_irqrestore(&psys->power_lock, flags);
 		return 0;
 	}
-	spin_unlock_irqrestore(&psys->ready_lock, flags);
-
-	retval = ipu_mmu_hw_init(adev->mmu);
-	if (retval)
-		return retval;
+	spin_unlock_irqrestore(&psys->power_lock, flags);
 
 	if (async_fw_init && !psys->fwcom) {
 		dev_err(dev,
@@ -914,13 +940,12 @@ static int psys_runtime_pm_resume(struct device *dev)
 	}
 
 	if (!ipu_buttress_auth_done(adev->isp)) {
-		dev_dbg(dev, "%s: not yet authenticated, skipping\n", __func__);
+		dev_err(dev, "%s: not yet authenticated, skipping\n", __func__);
 		return 0;
 	}
 
 	ipu_psys_setup_hw(psys);
 
-	ipu_psys_subdomains_power(psys, 1);
 	ipu_trace_restore(&psys->adev->dev);
 
 	ipu_configure_spc(adev->isp,
@@ -935,9 +960,9 @@ static int psys_runtime_pm_resume(struct device *dev)
 		return retval;
 	}
 
-	spin_lock_irqsave(&psys->ready_lock, flags);
-	psys->ready = 1;
-	spin_unlock_irqrestore(&psys->ready_lock, flags);
+	spin_lock_irqsave(&psys->power_lock, flags);
+	psys->power = 1;
+	spin_unlock_irqrestore(&psys->power_lock, flags);
 
 	return 0;
 }
@@ -949,15 +974,17 @@ static int psys_runtime_pm_suspend(struct device *dev)
 	unsigned long flags;
 	int rval;
 
-	if (!psys)
+	if (!psys) {
+		WARN(1, "%s called before probing. skipping.\n", __func__);
 		return 0;
+	}
 
-	if (!psys->ready)
+	if (!psys->power)
 		return 0;
 
-	spin_lock_irqsave(&psys->ready_lock, flags);
-	psys->ready = 0;
-	spin_unlock_irqrestore(&psys->ready_lock, flags);
+	spin_lock_irqsave(&psys->power_lock, flags);
+	psys->power = 0;
+	spin_unlock_irqrestore(&psys->power_lock, flags);
 
 	/*
 	 * We can trace failure but better to not return an error.
@@ -968,32 +995,12 @@ static int psys_runtime_pm_suspend(struct device *dev)
 	if (rval)
 		dev_err(dev, "Device close failure: %d\n", rval);
 
-	ipu_psys_subdomains_power(psys, 0);
-
-	ipu_mmu_hw_cleanup(adev->mmu);
-
-	return 0;
-}
-
-/* The following PM callbacks are needed to enable runtime PM in IPU PCI
- * device resume, otherwise, runtime PM can't work in PCI resume from
- * S3 state.
- */
-static int psys_resume(struct device *dev)
-{
-	return 0;
-}
-
-static int psys_suspend(struct device *dev)
-{
 	return 0;
 }
 
 static const struct dev_pm_ops psys_pm_ops = {
 	.runtime_suspend = psys_runtime_pm_suspend,
 	.runtime_resume = psys_runtime_pm_resume,
-	.suspend = psys_suspend,
-	.resume = psys_resume,
 };
 
 #define PSYS_PM_OPS (&psys_pm_ops)
@@ -1024,10 +1031,10 @@ static int cpd_fw_reload(struct ipu_device *isp)
 	}
 
 	rval = request_cpd_fw(&isp->cpd_fw, isp->cpd_fw_name,
-			      &isp->pdev->dev);
+				&isp->pdev->dev);
 	if (rval) {
 		dev_err(&isp->pdev->dev, "Requesting firmware(%s) failed\n",
-			isp->cpd_fw_name);
+			IPU_CPD_FIRMWARE_NAME);
 		return rval;
 	}
 
@@ -1078,7 +1085,6 @@ static int cpd_fw_reload(struct ipu_device *isp)
 	return rval;
 }
 
-#ifdef CONFIG_DEBUG_FS
 static int ipu_psys_icache_prefetch_sp_get(void *data, u64 *val)
 {
 	struct ipu_psys *psys = data;
@@ -1148,17 +1154,12 @@ static int ipu_psys_init_debugfs(struct ipu_psys *psys)
 
 	psys->debugfsdir = dir;
 
-#ifdef IPU_PSYS_GPC
-	if (ipu_psys_gpc_init_debugfs(psys))
-		return -ENOMEM;
-#endif
 
 	return 0;
 err:
 	debugfs_remove_recursive(dir);
 	return -ENOMEM;
 }
-#endif
 
 static int ipu_psys_sched_cmd(void *ptr)
 {
@@ -1167,9 +1168,8 @@ static int ipu_psys_sched_cmd(void *ptr)
 
 	while (1) {
 		wait_event_interruptible(psys->sched_cmd_wq,
-					 (kthread_should_stop() ||
-					  (pending =
-					   atomic_read(&psys->wakeup_count))));
+			(kthread_should_stop() || (pending =
+			atomic_read(&psys->wakeup_sched_thread_count))));
 
 		if (kthread_should_stop())
 			break;
@@ -1178,7 +1178,7 @@ static int ipu_psys_sched_cmd(void *ptr)
 			continue;
 
 		mutex_lock(&psys->mutex);
-		atomic_set(&psys->wakeup_count, 0);
+		atomic_set(&psys->wakeup_sched_thread_count, 0);
 		ipu_psys_run_next(psys);
 		mutex_unlock(&psys->mutex);
 	}
@@ -1193,12 +1193,12 @@ static void start_sp(struct ipu_bus_device *adev)
 	    psys->pdata->ipdata->hw_variant.spc_offset;
 	u32 val = 0;
 
-	val |= IPU_PSYS_SPC_STATUS_START |
-	    IPU_PSYS_SPC_STATUS_RUN |
-	    IPU_PSYS_SPC_STATUS_CTRL_ICACHE_INVALIDATE;
+	val |= IPU_ISYS_SPC_STATUS_START |
+	    IPU_ISYS_SPC_STATUS_RUN |
+	    IPU_ISYS_SPC_STATUS_CTRL_ICACHE_INVALIDATE;
 	val |= psys->icache_prefetch_sp ?
-	    IPU_PSYS_SPC_STATUS_ICACHE_PREFETCH : 0;
-	writel(val, spc_regs_base + IPU_PSYS_REG_SPC_STATUS_CTRL);
+	    IPU_ISYS_SPC_STATUS_ICACHE_PREFETCH : 0;
+	writel(val, spc_regs_base + IPU_ISYS_REG_SPC_STATUS_CTRL);
 }
 
 static int query_sp(struct ipu_bus_device *adev)
@@ -1206,18 +1206,18 @@ static int query_sp(struct ipu_bus_device *adev)
 	struct ipu_psys *psys = ipu_bus_get_drvdata(adev);
 	void __iomem *spc_regs_base = psys->pdata->base +
 	    psys->pdata->ipdata->hw_variant.spc_offset;
-	u32 val = readl(spc_regs_base + IPU_PSYS_REG_SPC_STATUS_CTRL);
+	u32 val = readl(spc_regs_base + IPU_ISYS_REG_SPC_STATUS_CTRL);
 
 	/* return true when READY == 1, START == 0 */
-	val &= IPU_PSYS_SPC_STATUS_READY | IPU_PSYS_SPC_STATUS_START;
+	val &= IPU_ISYS_SPC_STATUS_READY | IPU_ISYS_SPC_STATUS_START;
 
-	return val == IPU_PSYS_SPC_STATUS_READY;
+	return val == IPU_ISYS_SPC_STATUS_READY;
 }
 
 static int ipu_psys_fw_init(struct ipu_psys *psys)
 {
-	unsigned int size;
-	struct ipu_fw_syscom_queue_config *queue_cfg;
+	struct ipu_fw_syscom_queue_config
+		fw_psys_cmd_queue_cfg[IPU_FW_PSYS_N_PSYS_CMD_QUEUE_ID];
 	struct ipu_fw_syscom_queue_config fw_psys_event_queue_cfg[] = {
 		{
 			IPU_FW_PSYS_EVENT_QUEUE_SIZE,
@@ -1232,34 +1232,34 @@ static int ipu_psys_fw_init(struct ipu_psys *psys)
 		.icache_prefetch_isp = psys->icache_prefetch_isp,
 	};
 	struct ipu_fw_com_cfg fwcom = {
+		.num_input_queues = IPU_FW_PSYS_N_PSYS_CMD_QUEUE_ID,
 		.num_output_queues = IPU_FW_PSYS_N_PSYS_EVENT_QUEUE_ID,
 		.output = fw_psys_event_queue_cfg,
 		.specific_addr = &server_init,
 		.specific_size = sizeof(server_init),
 		.cell_start = start_sp,
 		.cell_ready = query_sp,
-		.buttress_boot_offset = SYSCOM_BUTTRESS_FW_PARAMS_PSYS_OFFSET,
 	};
-	int i;
+	int rval, i;
 
-	size = IPU6SE_FW_PSYS_N_PSYS_CMD_QUEUE_ID;
-	if (ipu_ver == IPU_VER_6 || ipu_ver == IPU_VER_6EP)
-		size = IPU6_FW_PSYS_N_PSYS_CMD_QUEUE_ID;
-
-	queue_cfg = devm_kzalloc(&psys->adev->dev, sizeof(*queue_cfg) * size,
-				 GFP_KERNEL);
-	if (!queue_cfg)
-		return -ENOMEM;
-
-	for (i = 0; i < size; i++) {
-		queue_cfg[i].queue_size = IPU_FW_PSYS_CMD_QUEUE_SIZE;
-		queue_cfg[i].token_size = sizeof(struct ipu_fw_psys_cmd);
+	for (i = 0; i < IPU_FW_PSYS_N_PSYS_CMD_QUEUE_ID; i++) {
+		fw_psys_cmd_queue_cfg[i].queue_size =
+			IPU_FW_PSYS_CMD_QUEUE_SIZE;
+		fw_psys_cmd_queue_cfg[i].token_size =
+			sizeof(struct ipu_fw_psys_cmd);
 	}
 
-	fwcom.input = queue_cfg;
-	fwcom.num_input_queues = size;
+	fwcom.input = fw_psys_cmd_queue_cfg;
+
 	fwcom.dmem_addr = psys->pdata->ipdata->hw_variant.dmem_offset;
 
+	rval = ipu_buttress_authenticate(psys->adev->isp);
+	if (rval) {
+		dev_err(&psys->adev->dev, "FW authentication failed(%d)\n",
+			rval);
+		return rval;
+	}
+
 	psys->fwcom = ipu_fw_com_prepare(&fwcom, psys->adev, psys->pdata->base);
 	if (!psys->fwcom) {
 		dev_err(&psys->adev->dev, "psys fw com prepare failed\n");
@@ -1290,12 +1290,12 @@ static int ipu_psys_probe(struct ipu_bus_device *adev)
 	struct ipu_device *isp = adev->isp;
 	struct ipu_psys_pg *kpg, *kpg0;
 	struct ipu_psys *psys;
+	const struct firmware *fw;
 	unsigned int minor;
 	int i, rval = -E2BIG;
 
-	rval = ipu_mmu_hw_init(adev->mmu);
-	if (rval)
-		return rval;
+	trace_printk("B|%d|TMWK\n", current->pid);
+
 
 	mutex_lock(&ipu_psys_mutex);
 
@@ -1313,9 +1313,11 @@ static int ipu_psys_probe(struct ipu_bus_device *adev)
 
 	psys->adev = adev;
 	psys->pdata = adev->pdata;
+#ifdef CONFIG_VIDEO_INTEL_IPU4
+	psys->icache_prefetch_sp = is_ipu_hw_bxtp_e0(isp);
+#else
 	psys->icache_prefetch_sp = 0;
-
-	psys->power_gating = 0;
+#endif
 
 	ipu_trace_init(adev->isp, psys->pdata->base, &adev->dev,
 		       psys_trace_blocks);
@@ -1331,18 +1333,19 @@ static int ipu_psys_probe(struct ipu_bus_device *adev)
 
 	set_bit(minor, ipu_psys_devices);
 
-	spin_lock_init(&psys->ready_lock);
+	spin_lock_init(&psys->power_lock);
 	spin_lock_init(&psys->pgs_lock);
-	psys->ready = 0;
+	psys->power = 0;
 	psys->timeout = IPU_PSYS_CMD_TIMEOUT_MS;
 
 	mutex_init(&psys->mutex);
 	INIT_LIST_HEAD(&psys->fhs);
 	INIT_LIST_HEAD(&psys->pgs);
 	INIT_LIST_HEAD(&psys->started_kcmds_list);
+	INIT_WORK(&psys->watchdog_work, ipu_psys_watchdog_work);
 
 	init_waitqueue_head(&psys->sched_cmd_wq);
-	atomic_set(&psys->wakeup_count, 0);
+	atomic_set(&psys->wakeup_sched_thread_count, 0);
 	/*
 	 * Create a thread to schedule commands sent to IPU firmware.
 	 * The thread reduces the coupling between the command scheduler
@@ -1359,18 +1362,34 @@ static int ipu_psys_probe(struct ipu_bus_device *adev)
 
 	ipu_bus_set_drvdata(adev, psys);
 
-	rval = ipu_psys_resource_pool_init(&psys->resource_pool_running);
+	rval = ipu_psys_resource_pool_init(&psys->resource_pool_started);
 	if (rval < 0) {
 		dev_err(&psys->dev,
 			"unable to alloc process group resources\n");
 		goto out_mutex_destroy;
 	}
 
-	ipu6_psys_hw_res_variant_init();
-	psys->pkg_dir = isp->pkg_dir;
-	psys->pkg_dir_dma_addr = isp->pkg_dir_dma_addr;
-	psys->pkg_dir_size = isp->pkg_dir_size;
-	psys->fw_sgt = isp->fw_sgt;
+	rval = ipu_psys_resource_pool_init(&psys->resource_pool_running);
+	if (rval < 0) {
+		dev_err(&psys->dev,
+			"unable to alloc process group resources\n");
+		goto out_resources_started_free;
+	}
+
+	fw = adev->isp->cpd_fw;
+
+	rval = ipu_buttress_map_fw_image(adev, fw, &psys->fw_sgt);
+	if (rval)
+		goto out_resources_running_free;
+
+	psys->pkg_dir = ipu_cpd_create_pkg_dir(adev, fw->data,
+					       sg_dma_address(psys->fw_sgt.sgl),
+					       &psys->pkg_dir_dma_addr,
+					       &psys->pkg_dir_size);
+	if (!psys->pkg_dir) {
+		rval = -ENOMEM;
+		goto out_unmap_fw_image;
+	}
 
 	/* allocate and map memory for process groups */
 	for (i = 0; i < IPU_PSYS_PG_POOL_SIZE; i++) {
@@ -1389,9 +1408,13 @@ static int ipu_psys_probe(struct ipu_bus_device *adev)
 		list_add(&kpg->list, &psys->pgs);
 	}
 
-	psys->caps.pg_count = ipu_cpd_pkg_dir_get_num_entries(psys->pkg_dir);
+	isp->pkg_dir = psys->pkg_dir;
+	isp->pkg_dir_dma_addr = psys->pkg_dir_dma_addr;
+	isp->pkg_dir_size = psys->pkg_dir_size;
+
+	caps.pg_count = ipu_cpd_pkg_dir_get_num_entries(psys->pkg_dir);
 
-	dev_info(&adev->dev, "pkg_dir entry count:%d\n", psys->caps.pg_count);
+	dev_info(&adev->dev, "pkg_dir entry count:%d\n", caps.pg_count);
 	if (async_fw_init) {
 		INIT_DELAYED_WORK((struct delayed_work *)&fw_init_task,
 				  run_fw_init_work);
@@ -1418,8 +1441,11 @@ static int ipu_psys_probe(struct ipu_bus_device *adev)
 	}
 
 	/* Add the hw stepping information to caps */
-	strlcpy(psys->caps.dev_model, IPU_MEDIA_DEV_MODEL_NAME,
-		sizeof(psys->caps.dev_model));
+	strlcpy(caps.dev_model, IPU_MEDIA_DEV_MODEL_NAME,
+		sizeof(caps.dev_model));
+
+	pm_runtime_allow(&adev->dev);
+	pm_runtime_enable(&adev->dev);
 
 	pm_runtime_set_autosuspend_delay(&psys->adev->dev,
 					 IPU_PSYS_AUTOSUSPEND_DELAY);
@@ -1428,17 +1454,14 @@ static int ipu_psys_probe(struct ipu_bus_device *adev)
 
 	mutex_unlock(&ipu_psys_mutex);
 
-#ifdef CONFIG_DEBUG_FS
 	/* Debug fs failure is not fatal. */
 	ipu_psys_init_debugfs(psys);
-#endif
 
 	adev->isp->cpd_fw_reload = &cpd_fw_reload;
 
 	dev_info(&adev->dev, "psys probe minor: %d\n", minor);
 
-	ipu_mmu_hw_cleanup(adev->mmu);
-
+	trace_printk("E|TMWK\n");
 	return 0;
 
 out_release_fw_com:
@@ -1450,7 +1473,16 @@ static int ipu_psys_probe(struct ipu_bus_device *adev)
 		kfree(kpg);
 	}
 
+	if (!isp->secure_mode)
+		ipu_cpd_free_pkg_dir(adev, psys->pkg_dir,
+				     psys->pkg_dir_dma_addr,
+				     psys->pkg_dir_size);
+out_unmap_fw_image:
+	ipu_buttress_unmap_fw_image(adev, &psys->fw_sgt);
+out_resources_running_free:
 	ipu_psys_resource_pool_cleanup(&psys->resource_pool_running);
+out_resources_started_free:
+	ipu_psys_resource_pool_cleanup(&psys->resource_pool_started);
 out_mutex_destroy:
 	mutex_destroy(&psys->mutex);
 	cdev_del(&psys->cdev);
@@ -1463,8 +1495,7 @@ static int ipu_psys_probe(struct ipu_bus_device *adev)
 	ipu_trace_uninit(&adev->dev);
 	mutex_unlock(&ipu_psys_mutex);
 
-	ipu_mmu_hw_cleanup(adev->mmu);
-
+	trace_printk("E|TMWK\n");
 	return rval;
 }
 
@@ -1474,10 +1505,8 @@ static void ipu_psys_remove(struct ipu_bus_device *adev)
 	struct ipu_psys *psys = ipu_bus_get_drvdata(adev);
 	struct ipu_psys_pg *kpg, *kpg0;
 
-#ifdef CONFIG_DEBUG_FS
 	if (isp->ipu_dir)
 		debugfs_remove_recursive(psys->debugfsdir);
-#endif
 
 	flush_workqueue(IPU_PSYS_WORK_QUEUE);
 
@@ -1499,11 +1528,21 @@ static void ipu_psys_remove(struct ipu_bus_device *adev)
 	if (psys->fwcom && ipu_fw_com_release(psys->fwcom, 1))
 		dev_err(&adev->dev, "fw com release failed.\n");
 
+	isp->pkg_dir = NULL;
+	isp->pkg_dir_dma_addr = 0;
+	isp->pkg_dir_size = 0;
+
+	ipu_cpd_free_pkg_dir(adev, psys->pkg_dir,
+			     psys->pkg_dir_dma_addr, psys->pkg_dir_size);
+
+	ipu_buttress_unmap_fw_image(adev, &psys->fw_sgt);
+
 	kfree(psys->server_init);
 	kfree(psys->syscom_config);
 
 	ipu_trace_uninit(&adev->dev);
 
+	ipu_psys_resource_pool_cleanup(&psys->resource_pool_started);
 	ipu_psys_resource_pool_cleanup(&psys->resource_pool_running);
 
 	device_unregister(&psys->dev);
@@ -1527,8 +1566,14 @@ static irqreturn_t psys_isr_threaded(struct ipu_bus_device *adev)
 
 	mutex_lock(&psys->mutex);
 #ifdef CONFIG_PM
-	r = pm_runtime_get_if_in_use(&psys->adev->dev);
-	if (!r || WARN_ON_ONCE(r < 0)) {
+	if (!READ_ONCE(psys->power)) {
+		mutex_unlock(&psys->mutex);
+		return IRQ_NONE;
+	}
+
+	r = pm_runtime_get_sync(&psys->adev->dev);
+	if (r < 0) {
+		pm_runtime_put(&psys->adev->dev);
 		mutex_unlock(&psys->mutex);
 		return IRQ_NONE;
 	}
@@ -1549,6 +1594,7 @@ static irqreturn_t psys_isr_threaded(struct ipu_bus_device *adev)
 	return status ? IRQ_HANDLED : IRQ_NONE;
 }
 
+
 static struct ipu_bus_driver ipu_psys_driver = {
 	.probe = ipu_psys_probe,
 	.remove = ipu_psys_remove,
@@ -1595,11 +1641,7 @@ static void __exit ipu_psys_exit(void)
 }
 
 static const struct pci_device_id ipu_pci_tbl[] = {
-	{PCI_DEVICE(PCI_VENDOR_ID_INTEL, IPU6_PCI_ID)},
-	{PCI_DEVICE(PCI_VENDOR_ID_INTEL, IPU6SE_PCI_ID)},
-	{PCI_DEVICE(PCI_VENDOR_ID_INTEL, IPU6EP_ADL_P_PCI_ID)},
-	{PCI_DEVICE(PCI_VENDOR_ID_INTEL, IPU6EP_ADL_N_PCI_ID)},
-	{PCI_DEVICE(PCI_VENDOR_ID_INTEL, IPU6EP_RPL_P_PCI_ID)},
+	{PCI_DEVICE(PCI_VENDOR_ID_INTEL, IPU_PCI_ID)},
 	{0,}
 };
 MODULE_DEVICE_TABLE(pci, ipu_pci_tbl);
diff --git a/drivers/media/pci/intel/ipu-psys.h b/drivers/media/pci/intel/ipu-psys.h
index 80d70f2ef3ce..bf888b38b2fd 100644
--- a/drivers/media/pci/intel/ipu-psys.h
+++ b/drivers/media/pci/intel/ipu-psys.h
@@ -1,5 +1,5 @@
 /* SPDX-License-Identifier: GPL-2.0 */
-/* Copyright (C) 2013 - 2020 Intel Corporation */
+/* Copyright (C) 2013 - 2018 Intel Corporation */
 
 #ifndef IPU_PSYS_H
 #define IPU_PSYS_H
@@ -13,7 +13,7 @@
 #include "ipu-platform-psys.h"
 
 #define IPU_PSYS_PG_POOL_SIZE 16
-#define IPU_PSYS_PG_MAX_SIZE 8192
+#define IPU_PSYS_PG_MAX_SIZE 2048
 #define IPU_MAX_PSYS_CMD_BUFFERS 32
 #define IPU_PSYS_EVENT_CMD_COMPLETE IPU_FW_PSYS_EVENT_TYPE_SUCCESS
 #define IPU_PSYS_EVENT_FRAGMENT_COMPLETE IPU_FW_PSYS_EVENT_TYPE_SUCCESS
@@ -50,24 +50,22 @@ struct ipu_resource_alloc {
  * resources for the next set of PGs to be run on IPU
  * (ie. those PGs which are not yet being run and which don't
  * yet reserve real IPU resources).
- * Use larger array to cover existing resource quantity
  */
-
-/* resource size may need expand for new resource model */
+#define IPU_PSYS_RESOURCE_OVERALLOC 2	/* Some room for ABI / ext lib delta */
 struct ipu_psys_resource_pool {
 	u32 cells;	/* Bitmask of cells allocated */
-	struct ipu_resource dev_channels[16];
-	struct ipu_resource ext_memory[32];
-	struct ipu_resource dfms[16];
-	DECLARE_BITMAP(cmd_queues, 32);
-	/* Protects cmd_queues bitmap */
-	spinlock_t queues_lock;
+	struct ipu_resource dev_channels[IPU_FW_PSYS_N_DEV_CHN_ID +
+					 IPU_PSYS_RESOURCE_OVERALLOC];
+	struct ipu_resource ext_memory[IPU_FW_PSYS_N_MEM_ID +
+				       IPU_PSYS_RESOURCE_OVERALLOC];
+	struct ipu_resource dfms[IPU_FW_PSYS_N_DEV_DFM_ID +
+				 IPU_PSYS_RESOURCE_OVERALLOC];
 };
 
 /*
  * This struct keeps book of the resources allocated for a specific PG.
  * It is used for freeing up resources from struct ipu_psys_resources
- * when the PG is released from IPU (or model of IPU).
+ * when the PG is released from IPU4 (or model of IPU4).
  */
 struct ipu_psys_resource_alloc {
 	u32 cells;	/* Bitmask of cells needed */
@@ -78,15 +76,14 @@ struct ipu_psys_resource_alloc {
 
 struct task_struct;
 struct ipu_psys {
-	struct ipu_psys_capability caps;
 	struct cdev cdev;
 	struct device dev;
 
 	struct mutex mutex;	/* Psys various */
-	int ready; /* psys fw status */
+	int power;
 	bool icache_prefetch_sp;
 	bool icache_prefetch_isp;
-	spinlock_t ready_lock;	/* protect psys firmware state */
+	spinlock_t power_lock;	/* Serialize access to power */
 	spinlock_t pgs_lock;	/* Protect pgs list access */
 	struct list_head fhs;
 	struct list_head pgs;
@@ -97,14 +94,14 @@ struct ipu_psys {
 	struct ia_css_syscom_config *syscom_config;
 	struct ia_css_psys_server_init *server_init;
 	struct task_struct *sched_cmd_thread;
+	struct work_struct watchdog_work;
 	wait_queue_head_t sched_cmd_wq;
-	atomic_t wakeup_count;  /* Psys schedule thread wakeup count */
-#ifdef CONFIG_DEBUG_FS
+	atomic_t wakeup_sched_thread_count;
 	struct dentry *debugfsdir;
-#endif
 
 	/* Resources needed to be managed for process groups */
 	struct ipu_psys_resource_pool resource_pool_running;
+	struct ipu_psys_resource_pool resource_pool_started;
 
 	const struct firmware *fw;
 	struct sg_table fw_sgt;
@@ -115,8 +112,6 @@ struct ipu_psys {
 
 	int active_kcmds, started_kcmds;
 	void *fwcom;
-
-	int power_gating;
 };
 
 struct ipu_psys_fh {
@@ -140,7 +135,7 @@ struct ipu_psys_pg {
 struct ipu_psys_kcmd {
 	struct ipu_psys_fh *fh;
 	struct list_head list;
-	struct ipu_psys_buffer_set *kbuf_set;
+	struct list_head started_list;
 	enum ipu_psys_cmd_state state;
 	void *pg_manifest;
 	size_t pg_manifest_size;
@@ -152,10 +147,6 @@ struct ipu_psys_kcmd {
 	u64 user_token;
 	u64 issue_id;
 	u32 priority;
-	u32 kernel_enable_bitmap[4];
-	u32 terminal_enable_bitmap[4];
-	u32 routing_enable_bitmap[4];
-	u32 rbm[5];
 	struct ipu_buttress_constraint constraint;
 	struct ipu_psys_event ev;
 	struct timer_list watchdog;
@@ -194,20 +185,15 @@ long ipu_psys_compat_ioctl32(struct file *file, unsigned int cmd,
 #endif
 
 void ipu_psys_setup_hw(struct ipu_psys *psys);
-void ipu_psys_subdomains_power(struct ipu_psys *psys, bool on);
 void ipu_psys_handle_events(struct ipu_psys *psys);
 int ipu_psys_kcmd_new(struct ipu_psys_command *cmd, struct ipu_psys_fh *fh);
 void ipu_psys_run_next(struct ipu_psys *psys);
+void ipu_psys_watchdog_work(struct work_struct *work);
 struct ipu_psys_pg *__get_pg_buf(struct ipu_psys *psys, size_t pg_size);
 struct ipu_psys_kbuffer *
 ipu_psys_lookup_kbuffer(struct ipu_psys_fh *fh, int fd);
-int ipu_psys_mapbuf_locked(int fd, struct ipu_psys_fh *fh,
-			   struct ipu_psys_kbuffer *kbuf);
 struct ipu_psys_kbuffer *
 ipu_psys_lookup_kbuffer_by_kaddr(struct ipu_psys_fh *fh, void *kaddr);
-#ifdef IPU_PSYS_GPC
-int ipu_psys_gpc_init_debugfs(struct ipu_psys *psys);
-#endif
 int ipu_psys_resource_pool_init(struct ipu_psys_resource_pool *pool);
 void ipu_psys_resource_pool_cleanup(struct ipu_psys_resource_pool *pool);
 struct ipu_psys_kcmd *ipu_get_completed_kcmd(struct ipu_psys_fh *fh);
diff --git a/drivers/media/pci/intel/ipu-trace-event.h b/drivers/media/pci/intel/ipu-trace-event.h
new file mode 100644
index 000000000000..39df80e3a4d4
--- /dev/null
+++ b/drivers/media/pci/intel/ipu-trace-event.h
@@ -0,0 +1,99 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/* Copyright (C) 2015 - 2018 Intel Corporation */
+
+#undef TRACE_SYSTEM
+#define TRACE_SYSTEM ipu
+
+#if !defined(IPU_TRACE_EVENT_H) || defined(TRACE_HEADER_MULTI_READ)
+#define IPU_EVENT_H
+
+#include <linux/tracepoint.h>
+
+#ifdef IPU_SOF_SEQID_TRACE
+TRACE_EVENT(ipu_sof_seqid,
+	    TP_PROTO(unsigned int seqid, unsigned int csiport,
+		     unsigned int csivc),
+	    TP_ARGS(seqid, csiport, csivc),
+	    TP_STRUCT__entry(__field(unsigned int, seqid)
+			     __field(unsigned int, csiport)
+			     __field(unsigned int, csivc)
+	    ),
+	    TP_fast_assign(__entry->seqid = seqid;
+			   __entry->csiport = csiport;
+			   __entry->csivc = csivc;),
+	    TP_printk("seqid<%u>,csiport<%u>,csivc<%u>", __entry->seqid,
+		      __entry->csiport, __entry->csivc)
+	);
+#endif
+
+#ifdef IPU_EOF_SEQID_TRACE
+TRACE_EVENT(ipu_eof_seqid,
+	    TP_PROTO(unsigned int seqid, unsigned int csiport,
+		     unsigned int csivc),
+	    TP_ARGS(seqid, csiport, csivc),
+	    TP_STRUCT__entry(__field(unsigned int, seqid)
+			     __field(unsigned int, csiport)
+			     __field(unsigned int, csivc)
+	    ),
+	    TP_fast_assign(__entry->seqid = seqid;
+			   __entry->csiport = csiport;
+			   __entry->csivc = csivc;),
+	    TP_printk("seqid<%u>,csiport<%u>,csivc<%u>", __entry->seqid,
+		      __entry->csiport, __entry->csivc)
+	);
+#endif
+
+#ifdef IPU_PERF_REG_TRACE
+TRACE_EVENT(ipu_perf_reg,
+	    TP_PROTO(unsigned int addr, unsigned int val),
+	    TP_ARGS(addr, val), TP_STRUCT__entry(__field(unsigned int, addr)
+						 __field(unsigned int, val)
+	    ),
+	    TP_fast_assign(__entry->addr = addr;
+			   __entry->val = val;),
+	    TP_printk("addr=%u,val=%u", __entry->addr, __entry->val)
+	);
+#endif
+
+#ifdef IPU_PG_KCMD_TRACE
+TRACE_EVENT(ipu_pg_kcmd,
+	    TP_PROTO(const char *func, unsigned int id,
+		     unsigned long long issue_id, unsigned int pri,
+		     unsigned int pg_id, unsigned int load_cycles,
+		     unsigned int init_cycles,
+		     unsigned int processing_cycles),
+	    TP_ARGS(func, id, issue_id, pri, pg_id, load_cycles, init_cycles,
+		    processing_cycles),
+	    TP_STRUCT__entry(__field(const char *, func)
+			     __field(unsigned int, id)
+			     __field(unsigned long long, issue_id)
+			     __field(unsigned int, pri)
+			     __field(unsigned int, pg_id)
+			     __field(unsigned int, load_cycles)
+			     __field(unsigned int, init_cycles)
+			     __field(unsigned int, processing_cycles)
+	    ),
+	    TP_fast_assign(__entry->func = func;
+			   __entry->id = id;
+			   __entry->issue_id = issue_id;
+			   __entry->pri = pri;
+			   __entry->pg_id = pg_id;
+			   __entry->load_cycles = load_cycles;
+			   __entry->init_cycles = init_cycles;
+			   __entry->processing_cycles = processing_cycles;),
+	    TP_printk
+	    ("pg-kcmd: func=%s,id=%u,issue_id=0x%llx,pri=%u,pg_id=%d,load_cycles=%u,init_cycles=%u,processing_cycles=%u",
+	     __entry->func, __entry->id, __entry->issue_id, __entry->pri,
+	     __entry->pg_id, __entry->load_cycles, __entry->init_cycles,
+	     __entry->processing_cycles)
+	);
+
+#endif
+#endif
+
+#undef TRACE_INCLUDE_PATH
+#undef TRACE_INCLUDE_FILE
+#define TRACE_INCLUDE_PATH .
+#define TRACE_INCLUDE_FILE  ipu-trace-event
+/* This part must be outside protection */
+#include <trace/define_trace.h>
diff --git a/drivers/media/pci/intel/ipu-trace.c b/drivers/media/pci/intel/ipu-trace.c
index 4e7ee02a423b..824515a66ac1 100644
--- a/drivers/media/pci/intel/ipu-trace.c
+++ b/drivers/media/pci/intel/ipu-trace.c
@@ -1,5 +1,5 @@
 // SPDX-License-Identifier: GPL-2.0
-// Copyright (C) 2014 - 2021 Intel Corporation
+// Copyright (C) 2014 - 2018 Intel Corporation
 
 #include <linux/debugfs.h>
 #include <linux/delay.h>
@@ -15,12 +15,57 @@
 #include "ipu-platform-regs.h"
 #include "ipu-trace.h"
 
+/* Input data processing states */
+enum config_file_parse_states {
+	STATE_FILL = 0,
+	STATE_COMMENT,
+	STATE_COMPLETE,
+};
+
 struct trace_register_range {
 	u32 start;
 	u32 end;
 };
 
-#define MEMORY_RING_BUFFER_SIZE		(SZ_1M * 32)
+static u16 trace_unit_template[] = TRACE_REG_CREATE_TUN_REGISTER_LIST;
+static u16 trace_monitor_template[] = TRACE_REG_CREATE_TM_REGISTER_LIST;
+static u16 trace_gpc_template[] = TRACE_REG_CREATE_GPC_REGISTER_LIST;
+
+static struct trace_register_range trace_csi2_range_template[] = {
+	{
+	 .start = TRACE_REG_CSI2_TM_RESET_REG_IDX,
+	 .end = TRACE_REG_CSI2_TM_IRQ_ENABLE_REG_IDn(7)
+	},
+	{
+	 .start = TRACE_REG_END_MARK,
+	 .end = TRACE_REG_END_MARK
+	}
+};
+
+static struct trace_register_range trace_csi2_3ph_range_template[] = {
+	{
+	 .start = TRACE_REG_CSI2_3PH_TM_RESET_REG_IDX,
+	 .end = TRACE_REG_CSI2_3PH_TM_IRQ_ENABLE_REG_IDn(7)
+	},
+	{
+	 .start = TRACE_REG_END_MARK,
+	 .end = TRACE_REG_END_MARK
+	}
+};
+
+static struct trace_register_range trace_sig2cio_range_template[] = {
+	{
+	 .start = TRACE_REG_SIG2CIO_ADDRESS,
+	 .end = (TRACE_REG_SIG2CIO_STATUS + 8 * TRACE_REG_SIG2CIO_SIZE_OF)
+	},
+	{
+	 .start = TRACE_REG_END_MARK,
+	 .end = TRACE_REG_END_MARK
+	}
+};
+
+#define LINE_MAX_LEN			128
+#define MEMORY_RING_BUFFER_SIZE		(SZ_1M * 10)
 #define TRACE_MESSAGE_SIZE		16
 /*
  * It looks that the trace unit sometimes writes outside the given buffer.
@@ -31,8 +76,8 @@ struct trace_register_range {
 #define MEMORY_RING_BUFFER_OVERREAD	MEMORY_RING_BUFFER_GUARD
 #define MAX_TRACE_REGISTERS		200
 #define TRACE_CONF_DUMP_BUFFER_SIZE	(MAX_TRACE_REGISTERS * 2 * 32)
-#define TRACE_CONF_DATA_MAX_LEN		(1024 * 4)
-#define WPT_TRACE_CONF_DATA_MAX_LEN	(1024 * 64)
+
+#define IPU_TRACE_TIME_RETRY	5
 
 struct config_value {
 	u32 reg;
@@ -44,14 +89,6 @@ struct ipu_trace_buffer {
 	void *memory_buffer;
 };
 
-struct ipu_subsystem_wptrace_config {
-	bool open;
-	char *conf_dump_buffer;
-	int size_conf_dump;
-	unsigned int fill_level;
-	struct config_value config[MAX_TRACE_REGISTERS];
-};
-
 struct ipu_subsystem_trace_config {
 	u32 offset;
 	void __iomem *base;
@@ -62,20 +99,64 @@ struct ipu_subsystem_trace_config {
 	bool running;
 	/* Cached register values  */
 	struct config_value config[MAX_TRACE_REGISTERS];
-	/* watchpoint trace info */
-	struct ipu_subsystem_wptrace_config wpt;
+};
+
+/*
+ * State of the input data processing is kept in this structure.
+ * Only one user is supported at time.
+ */
+struct buf_state {
+	char line_buffer[LINE_MAX_LEN];
+	enum config_file_parse_states state;
+	int offset;	/* Offset to line_buffer */
 };
 
 struct ipu_trace {
-	struct mutex lock; /* Protect ipu trace operations */
+	struct mutex lock;
 	bool open;
 	char *conf_dump_buffer;
 	int size_conf_dump;
+	struct buf_state buffer_state;
 
 	struct ipu_subsystem_trace_config isys;
 	struct ipu_subsystem_trace_config psys;
 };
 
+int ipu_trace_get_timer(struct device *dev, u64 *timer)
+{
+	struct ipu_bus_device *adev = to_ipu_bus_device(dev);
+	struct ipu_subsystem_trace_config *sys = adev->trace_cfg;
+	struct ipu_trace_block *blocks;
+	void __iomem *addr = NULL;
+	uint32_t time_hi1, time_hi2, time_lo, retry;
+
+	if (!sys)
+		return -ENODEV;
+	/* Find trace unit base address */
+	blocks = sys->blocks;
+	while (blocks->type != IPU_TRACE_BLOCK_END) {
+		if (blocks->type == IPU_TRACE_BLOCK_TUN) {
+			addr = sys->base + blocks->offset;
+			break;
+		}
+		blocks++;
+	}
+	if (!addr)
+		return -ENODEV;
+
+	for (retry = 0; retry < IPU_TRACE_TIME_RETRY; retry++) {
+		time_hi1 = readl(addr + TRACE_REG_TUN_LOCAL_TIMER1);
+		time_lo = readl(addr + TRACE_REG_TUN_LOCAL_TIMER0);
+		time_hi2 = readl(addr + TRACE_REG_TUN_LOCAL_TIMER1);
+		*timer = (((u64) time_hi1) << 32) | time_lo;
+		if (time_hi1 == time_hi2)
+			return 0;
+	}
+
+	return -EINVAL;
+}
+EXPORT_SYMBOL_GPL(ipu_trace_get_timer);
+
 static void __ipu_trace_restore(struct device *dev)
 {
 	struct ipu_bus_device *adev = to_ipu_bus_device(dev);
@@ -84,7 +165,7 @@ static void __ipu_trace_restore(struct device *dev)
 	struct config_value *config;
 	struct ipu_subsystem_trace_config *sys = adev->trace_cfg;
 	struct ipu_trace_block *blocks;
-	u32 mapped_trace_buffer;
+	uint32_t mapped_trace_buffer;
 	void __iomem *addr = NULL;
 	int i;
 
@@ -114,10 +195,10 @@ static void __ipu_trace_restore(struct device *dev)
 
 	if (!sys->memory.memory_buffer) {
 		sys->memory.memory_buffer =
-		    dma_alloc_coherent(dev, MEMORY_RING_BUFFER_SIZE +
-				       MEMORY_RING_BUFFER_GUARD,
-				       &sys->memory.dma_handle,
-				       GFP_KERNEL);
+		    dma_alloc_attrs(dev, MEMORY_RING_BUFFER_SIZE +
+				    MEMORY_RING_BUFFER_GUARD,
+				    &sys->memory.dma_handle,
+				    GFP_KERNEL, 0);
 	}
 
 	if (!sys->memory.memory_buffer) {
@@ -137,7 +218,7 @@ static void __ipu_trace_restore(struct device *dev)
 
 	/* Infobits for ddr trace */
 	writel(IPU_INFO_REQUEST_DESTINATION_PRIMARY,
-	       addr + TRACE_REG_TUN_DDR_INFO_VAL);
+		   addr + TRACE_REG_TUN_DDR_INFO_VAL);
 
 	/* Find trace timer reset address */
 	addr = NULL;
@@ -165,13 +246,6 @@ static void __ipu_trace_restore(struct device *dev)
 		writel(config[i].value, isp->base + config[i].reg);
 	}
 
-	/* Register wpt config received from userspace, and only psys has wpt */
-	config = sys->wpt.config;
-	for (i = 0; i < sys->wpt.fill_level; i++) {
-		dev_dbg(dev, "Trace restore: reg 0x%08x, value 0x%08x\n",
-			config[i].reg, config[i].value);
-		writel(config[i].value, isp->base + config[i].reg);
-	}
 	sys->running = true;
 }
 
@@ -250,19 +324,60 @@ void ipu_trace_stop(struct device *dev)
 }
 EXPORT_SYMBOL_GPL(ipu_trace_stop);
 
+static int validate_register(u32 base, u32 reg, u16 *template)
+{
+	int i = 0;
+
+	while (template[i] != TRACE_REG_END_MARK) {
+		if (template[i] + base != reg) {
+			i++;
+			continue;
+		}
+		/* This is a valid register */
+		return 0;
+	}
+	return -EINVAL;
+}
+
+static int validate_register_range(u32 base, u32 reg,
+				   struct trace_register_range *template)
+{
+	unsigned int i = 0;
+
+	if (!IS_ALIGNED(reg, sizeof(u32)))
+		return -EINVAL;
+
+	while (template[i].start != TRACE_REG_END_MARK) {
+		if ((reg < template[i].start + base) ||
+		    (reg > template[i].end + base)) {
+			i++;
+			continue;
+		}
+		/* This is a valid register */
+		return 0;
+	}
+	return -EINVAL;
+}
+
 static int update_register_cache(struct ipu_device *isp, u32 reg, u32 value)
 {
 	struct ipu_trace *dctrl = isp->trace;
+	const struct ipu_trace_block *blocks;
 	struct ipu_subsystem_trace_config *sys;
+	struct device *dev;
+	u32 base = 0;
+	u16 *template = NULL;
+	struct trace_register_range *template_range = NULL;
+	int i, range;
 	int rval = -EINVAL;
 
 	if (dctrl->isys.offset == dctrl->psys.offset) {
 		/* For the IPU with uniform address space */
 		if (reg >= IPU_ISYS_OFFSET &&
-		    reg < IPU_ISYS_OFFSET + TRACE_REG_MAX_ISYS_OFFSET)
+			reg < IPU_ISYS_OFFSET + TRACE_REG_MAX_ISYS_OFFSET)
 			sys = &dctrl->isys;
 		else if (reg >= IPU_PSYS_OFFSET &&
-			 reg < IPU_PSYS_OFFSET + TRACE_REG_MAX_PSYS_OFFSET)
+			reg < IPU_PSYS_OFFSET + TRACE_REG_MAX_PSYS_OFFSET)
 			sys = &dctrl->psys;
 		else
 			goto error;
@@ -279,8 +394,55 @@ static int update_register_cache(struct ipu_device *isp, u32 reg, u32 value)
 			goto error;
 	}
 
+	blocks = sys->blocks;
+	dev = sys->dev;
+
+	/* Check registers block by block */
+	i = 0;
+	while (blocks[i].type != IPU_TRACE_BLOCK_END) {
+		base = blocks[i].offset + sys->offset;
+		if ((reg >= base && reg < base + TRACE_REG_MAX_BLOCK_SIZE))
+			break;
+		i++;
+	}
+
+	range = 0;
+	switch (blocks[i].type) {
+	case IPU_TRACE_BLOCK_TUN:
+		template = trace_unit_template;
+		break;
+	case IPU_TRACE_BLOCK_TM:
+		template = trace_monitor_template;
+		break;
+	case IPU_TRACE_BLOCK_GPC:
+		template = trace_gpc_template;
+		break;
+	case IPU_TRACE_CSI2:
+		range = 1;
+		template_range = trace_csi2_range_template;
+		break;
+	case IPU_TRACE_CSI2_3PH:
+		range = 1;
+		template_range = trace_csi2_3ph_range_template;
+		break;
+	case IPU_TRACE_SIG2CIOS:
+		range = 1;
+		template_range = trace_sig2cio_range_template;
+		break;
+	default:
+		goto error;
+	}
+
+	if (range)
+		rval = validate_register_range(base, reg, template_range);
+	else
+		rval = validate_register(base, reg, template);
+
+	if (rval)
+		goto error;
+
 	if (sys->fill_level < MAX_TRACE_REGISTERS) {
-		dev_dbg(sys->dev,
+		dev_dbg(dev,
 			"Trace reg addr 0x%08x value 0x%08x\n", reg, value);
 		sys->config[sys->fill_level].reg = reg;
 		sys->config[sys->fill_level].value = value;
@@ -297,6 +459,79 @@ static int update_register_cache(struct ipu_device *isp, u32 reg, u32 value)
 	return rval;
 }
 
+/*
+ * We don't know how much data is received this time. Process given data
+ * character by character.
+ * Fill the line buffer until either
+ * 1) new line is got -> go to decode
+ * or
+ * 2) line_buffer is full -> ignore rest of line and then try to decode
+ * or
+ * 3) Comment mark is found -> ignore rest of the line and then try to decode
+ *    the data which was received before the comment mark
+ *
+ * Decode phase tries to find "reg = value" pairs and validates those
+ */
+static int process_buffer(struct ipu_device *isp,
+			  char *buffer, int size, struct buf_state *state)
+{
+	int i, ret;
+	int curr_state = state->state;
+	u32 reg, value;
+
+	for (i = 0; i < size; i++) {
+		/*
+		 * Comment mark in any position turns on comment mode
+		 * until end of line
+		 */
+		if (curr_state != STATE_COMMENT && buffer[i] == '#') {
+			state->line_buffer[state->offset] = '\0';
+			curr_state = STATE_COMMENT;
+			continue;
+		}
+
+		switch (curr_state) {
+		case STATE_COMMENT:
+			/* Only new line can break this mode */
+			if (buffer[i] == '\n')
+				curr_state = STATE_COMPLETE;
+			break;
+		case STATE_FILL:
+			state->line_buffer[state->offset] = buffer[i];
+			state->offset++;
+
+			if (state->offset >= sizeof(state->line_buffer) - 1) {
+				/* Line buffer full - ignore rest */
+				state->line_buffer[state->offset] = '\0';
+				curr_state = STATE_COMMENT;
+				break;
+			}
+
+			if (buffer[i] == '\n') {
+				state->line_buffer[state->offset] = '\0';
+				curr_state = STATE_COMPLETE;
+			}
+			break;
+		default:
+			state->offset = 0;
+			state->line_buffer[state->offset] = '\0';
+			curr_state = STATE_COMMENT;
+		}
+
+		if (curr_state == STATE_COMPLETE) {
+			ret = sscanf(state->line_buffer, "%x = %x",
+				     &reg, &value);
+			if (ret == 2)
+				update_register_cache(isp, reg, value);
+
+			state->offset = 0;
+			curr_state = STATE_FILL;
+		}
+	}
+	state->state = curr_state;
+	return 0;
+}
+
 static void traceconf_dump(struct ipu_device *isp)
 {
 	struct ipu_subsystem_trace_config *sys[2] = {
@@ -368,7 +603,6 @@ static int traceconf_open(struct inode *inode, struct file *file)
 		/* Forget old config if opened for write */
 		isp->trace->isys.fill_level = 0;
 		isp->trace->psys.fill_level = 0;
-		isp->trace->psys.wpt.fill_level = 0;
 	}
 
 	if (file->f_mode & FMODE_READ) {
@@ -398,52 +632,26 @@ static ssize_t traceconf_read(struct file *file, char __user *buf,
 static ssize_t traceconf_write(struct file *file, const char __user *buf,
 			       size_t len, loff_t *ppos)
 {
-	int i;
 	struct ipu_device *isp = file->private_data;
-	ssize_t bytes = 0;
-	char *ipu_trace_buffer = NULL;
-	size_t buffer_size = 0;
-	u32 ipu_trace_number = 0;
-	struct config_value *cfg_buffer = NULL;
-
-	if ((*ppos < 0) || (len > TRACE_CONF_DATA_MAX_LEN) ||
-	    (len < sizeof(ipu_trace_number))) {
-		dev_info(&isp->pdev->dev,
-			"length is error, len:%ld, loff:%lld\n",
-			len, *ppos);
-		return -EINVAL;
-	}
-
-	ipu_trace_buffer = vzalloc(len);
-	if (!ipu_trace_buffer)
-		return -ENOMEM;
+	char buffer[64];
+	ssize_t bytes, count;
+	loff_t pos = *ppos;
 
-	bytes = copy_from_user(ipu_trace_buffer, buf, len);
-	if (bytes != 0) {
-		vfree(ipu_trace_buffer);
-		return -EFAULT;
-	}
+	if (*ppos < 0)
+		return -EINVAL;
 
-	memcpy(&ipu_trace_number, ipu_trace_buffer, sizeof(u32));
-	buffer_size = ipu_trace_number * sizeof(struct config_value);
-	if ((buffer_size + sizeof(ipu_trace_number)) != len) {
-		dev_info(&isp->pdev->dev,
-			"File size is not right, len:%ld, buffer_size:%zu\n",
-			len, buffer_size);
-		vfree(ipu_trace_buffer);
+	count = min(len, sizeof(buffer));
+	bytes = copy_from_user(buffer, buf, count);
+	if (bytes == count)
 		return -EFAULT;
-	}
 
+	count -= bytes;
 	mutex_lock(&isp->trace->lock);
-	cfg_buffer = (struct config_value *)(ipu_trace_buffer + sizeof(u32));
-	for (i = 0; i < ipu_trace_number; i++) {
-		update_register_cache(isp, cfg_buffer[i].reg,
-			cfg_buffer[i].value);
-	}
+	process_buffer(isp, buffer, count, &isp->trace->buffer_state);
 	mutex_unlock(&isp->trace->lock);
-	vfree(ipu_trace_buffer);
+	*ppos = pos + count;
 
-	return len;
+	return count;
 }
 
 static int traceconf_release(struct inode *inode, struct file *file)
@@ -522,162 +730,6 @@ static const struct file_operations ipu_traceconf_fops = {
 	.llseek = no_llseek,
 };
 
-static void wptraceconf_dump(struct ipu_device *isp)
-{
-	struct ipu_subsystem_wptrace_config *sys = &isp->trace->psys.wpt;
-	int i, rem_size;
-	char *out;
-
-	sys->size_conf_dump = 0;
-	out = sys->conf_dump_buffer;
-	rem_size = TRACE_CONF_DUMP_BUFFER_SIZE;
-
-	for (i = 0; i < sys->fill_level && rem_size > 0; i++) {
-		int bytes_print;
-		int n = snprintf(out, rem_size, "0x%08x = 0x%08x\n",
-				 sys->config[i].reg,
-				 sys->config[i].value);
-
-		bytes_print = min(n, rem_size - 1);
-		rem_size -= bytes_print;
-		out += bytes_print;
-	}
-	sys->size_conf_dump = out - sys->conf_dump_buffer;
-}
-
-static int wptraceconf_open(struct inode *inode, struct file *file)
-{
-	int ret;
-	struct ipu_device *isp;
-
-	if (!inode->i_private)
-		return -EACCES;
-
-	isp = inode->i_private;
-	ret = mutex_trylock(&isp->trace->lock);
-	if (!ret)
-		return -EBUSY;
-
-	if (isp->trace->psys.wpt.open) {
-		mutex_unlock(&isp->trace->lock);
-		return -EBUSY;
-	}
-
-	file->private_data = isp;
-	if (file->f_mode & FMODE_WRITE) {
-		/* TBD: Allocate temp buffer for processing.
-		 * Push validated buffer to active config
-		 */
-		/* Forget old config if opened for write */
-		isp->trace->psys.wpt.fill_level = 0;
-	}
-
-	if (file->f_mode & FMODE_READ) {
-		isp->trace->psys.wpt.conf_dump_buffer =
-		    vzalloc(TRACE_CONF_DUMP_BUFFER_SIZE);
-		if (!isp->trace->psys.wpt.conf_dump_buffer) {
-			mutex_unlock(&isp->trace->lock);
-			return -ENOMEM;
-		}
-		wptraceconf_dump(isp);
-	}
-	mutex_unlock(&isp->trace->lock);
-	return 0;
-}
-
-static ssize_t wptraceconf_read(struct file *file, char __user *buf,
-			      size_t len, loff_t *ppos)
-{
-	struct ipu_device *isp = file->private_data;
-
-	return simple_read_from_buffer(buf, len, ppos,
-				       isp->trace->psys.wpt.conf_dump_buffer,
-				       isp->trace->psys.wpt.size_conf_dump);
-}
-
-static ssize_t wptraceconf_write(struct file *file, const char __user *buf,
-			       size_t len, loff_t *ppos)
-{
-	int i;
-	struct ipu_device *isp = file->private_data;
-	ssize_t bytes = 0;
-	char *wpt_info_buffer = NULL;
-	size_t buffer_size = 0;
-	u32 wp_node_number = 0;
-	struct config_value *wpt_buffer = NULL;
-	struct ipu_subsystem_wptrace_config *wpt = &isp->trace->psys.wpt;
-
-	if ((*ppos < 0) || (len > WPT_TRACE_CONF_DATA_MAX_LEN) ||
-	    (len < sizeof(wp_node_number))) {
-		dev_info(&isp->pdev->dev,
-			"length is error, len:%ld, loff:%lld\n",
-			len, *ppos);
-		return -EINVAL;
-	}
-
-	wpt_info_buffer = vzalloc(len);
-	if (!wpt_info_buffer)
-		return -ENOMEM;
-
-	bytes = copy_from_user(wpt_info_buffer, buf, len);
-	if (bytes != 0) {
-		vfree(wpt_info_buffer);
-		return -EFAULT;
-	}
-
-	memcpy(&wp_node_number, wpt_info_buffer, sizeof(u32));
-	buffer_size = wp_node_number * sizeof(struct config_value);
-	if ((buffer_size + sizeof(wp_node_number)) != len) {
-		dev_info(&isp->pdev->dev,
-			"File size is not right, len:%ld, buffer_size:%zu\n",
-			len, buffer_size);
-		vfree(wpt_info_buffer);
-		return -EFAULT;
-	}
-
-	mutex_lock(&isp->trace->lock);
-	wpt_buffer = (struct config_value *)(wpt_info_buffer + sizeof(u32));
-	for (i = 0; i < wp_node_number; i++) {
-		if (wpt->fill_level < MAX_TRACE_REGISTERS) {
-			wpt->config[wpt->fill_level].reg = wpt_buffer[i].reg;
-			wpt->config[wpt->fill_level].value =
-				wpt_buffer[i].value;
-			wpt->fill_level++;
-		} else {
-			dev_info(&isp->pdev->dev,
-				 "Address 0x%08x ignored as invalid register\n",
-				 wpt_buffer[i].reg);
-			break;
-		}
-	}
-	mutex_unlock(&isp->trace->lock);
-	vfree(wpt_info_buffer);
-
-	return len;
-}
-
-static int wptraceconf_release(struct inode *inode, struct file *file)
-{
-	struct ipu_device *isp = file->private_data;
-
-	mutex_lock(&isp->trace->lock);
-	isp->trace->open = 0;
-	vfree(isp->trace->psys.wpt.conf_dump_buffer);
-	isp->trace->psys.wpt.conf_dump_buffer = NULL;
-	mutex_unlock(&isp->trace->lock);
-
-	return 0;
-}
-
-static const struct file_operations ipu_wptraceconf_fops = {
-	.owner = THIS_MODULE,
-	.open = wptraceconf_open,
-	.release = wptraceconf_release,
-	.read = wptraceconf_read,
-	.write = wptraceconf_write,
-	.llseek = no_llseek,
-};
-
 static int gettrace_open(struct inode *inode, struct file *file)
 {
 	struct ipu_subsystem_trace_config *sys = inode->i_private;
@@ -793,11 +845,11 @@ void ipu_trace_uninit(struct device *dev)
 	mutex_lock(&trace->lock);
 
 	if (sys->memory.memory_buffer)
-		dma_free_coherent(sys->dev,
-				  MEMORY_RING_BUFFER_SIZE +
-				  MEMORY_RING_BUFFER_GUARD,
-				  sys->memory.memory_buffer,
-				  sys->memory.dma_handle);
+		dma_free_attrs(sys->dev,
+			       MEMORY_RING_BUFFER_SIZE +
+			       MEMORY_RING_BUFFER_GUARD,
+			       sys->memory.memory_buffer,
+			       sys->memory.dma_handle, 0);
 
 	sys->dev = NULL;
 	sys->memory.memory_buffer = NULL;
@@ -808,7 +860,7 @@ EXPORT_SYMBOL_GPL(ipu_trace_uninit);
 
 int ipu_trace_debugfs_add(struct ipu_device *isp, struct dentry *dir)
 {
-	struct dentry *files[4];
+	struct dentry *files[3];
 	int i = 0;
 
 	files[i] = debugfs_create_file("traceconf", 0644,
@@ -817,12 +869,6 @@ int ipu_trace_debugfs_add(struct ipu_device *isp, struct dentry *dir)
 		return -ENOMEM;
 	i++;
 
-	files[i] = debugfs_create_file("wptraceconf", 0644,
-				       dir, isp, &ipu_wptraceconf_fops);
-	if (!files[i])
-		goto error;
-	i++;
-
 	files[i] = debugfs_create_file("getisystrace", 0444,
 				       dir,
 				       &isp->trace->isys, &ipu_gettrace_fops);
diff --git a/drivers/media/pci/intel/ipu-trace.h b/drivers/media/pci/intel/ipu-trace.h
index f1233a306519..9167c0400273 100644
--- a/drivers/media/pci/intel/ipu-trace.h
+++ b/drivers/media/pci/intel/ipu-trace.h
@@ -1,10 +1,19 @@
 /* SPDX-License-Identifier: GPL-2.0 */
-/* Copyright (C) 2014 - 2021 Intel Corporation */
+/* Copyright (C) 2014 - 2018 Intel Corporation */
 
 #ifndef IPU_TRACE_H
 #define IPU_TRACE_H
 #include <linux/debugfs.h>
 
+#define TRACE_REG_MAX_BLOCK_SIZE	0x0fff
+
+#define TRACE_REG_END_MARK 0xffff
+
+#define TRACE_REG_CMD_TYPE_D64		0x0
+#define TRACE_REG_CMD_TYPE_D64M		0x1
+#define TRACE_REG_CMD_TYPE_D64TS	0x2
+#define TRACE_REG_CMD_TYPE_D64MTS	0x3
+
 /* Trace unit register offsets */
 #define TRACE_REG_TUN_DDR_ENABLE        0x000
 #define TRACE_REG_TUN_NPK_ENABLE	0x004
@@ -17,6 +26,13 @@
 #define TRACE_REG_TUN_WR_PTR		0x020
 #define TRACE_REG_TUN_RD_PTR		0x024
 
+#define TRACE_REG_CREATE_TUN_REGISTER_LIST {	\
+	TRACE_REG_TUN_DDR_ENABLE,		\
+	TRACE_REG_TUN_NPK_ENABLE,		\
+	TRACE_REG_TUN_DDR_INFO_VAL,	        \
+	TRACE_REG_TUN_NPK_ADDR,			\
+	TRACE_REG_END_MARK			\
+}
 /*
  * Following registers are left out on purpose:
  * TUN_LOCAL_TIMER0, TUN_LOCAL_TIMER1, TUN_DRAM_BASE_ADDR
@@ -52,6 +68,34 @@
 #define TRACE_REG_TM_FWTRACE_MIDDLE		0x0A04
 #define TRACE_REG_TM_FWTRACE_LAST		0x0A08
 
+#define TRACE_REG_CREATE_TM_REGISTER_LIST {	\
+	TRACE_REG_TM_TRACE_ADDR_A,		\
+	TRACE_REG_TM_TRACE_ADDR_B,		\
+	TRACE_REG_TM_TRACE_ADDR_C,		\
+	TRACE_REG_TM_TRACE_ADDR_D,		\
+	TRACE_REG_TM_TRACE_ENABLE_NPK,		\
+	TRACE_REG_TM_TRACE_ENABLE_DDR,		\
+	TRACE_REG_TM_TRACE_PER_PC,		\
+	TRACE_REG_TM_TRACE_PER_BRANCH,		\
+	TRACE_REG_TM_TRACE_HEADER,		\
+	TRACE_REG_TM_TRACE_CFG,			\
+	TRACE_REG_TM_TRACE_LOST_PACKETS,	\
+	TRACE_REG_TM_TRACE_LP_CLEAR,		\
+	TRACE_REG_TM_TRACE_LMRUN_MASK,		\
+	TRACE_REG_TM_TRACE_LMRUN_PC_LOW,	\
+	TRACE_REG_TM_TRACE_LMRUN_PC_HIGH,	\
+	TRACE_REG_TM_TRACE_MMIO_SEL,		\
+	TRACE_REG_TM_TRACE_MMIO_WP0_LOW,	\
+	TRACE_REG_TM_TRACE_MMIO_WP1_LOW,	\
+	TRACE_REG_TM_TRACE_MMIO_WP2_LOW,	\
+	TRACE_REG_TM_TRACE_MMIO_WP3_LOW,	\
+	TRACE_REG_TM_TRACE_MMIO_WP0_HIGH,	\
+	TRACE_REG_TM_TRACE_MMIO_WP1_HIGH,	\
+	TRACE_REG_TM_TRACE_MMIO_WP2_HIGH,	\
+	TRACE_REG_TM_TRACE_MMIO_WP3_HIGH,	\
+	TRACE_REG_END_MARK			\
+}
+
 /*
  * Following exists only in (I)SP address space:
  * TM_FWTRACE_FIRST, TM_FWTRACE_MIDDLE, TM_FWTRACE_LAST
@@ -116,6 +160,127 @@
 #define TRACE_REG_GPC_IRQ_ENABLE_ID2		0x0b8
 #define TRACE_REG_GPC_IRQ_ENABLE_ID3		0x0bc
 
+#define TRACE_REG_CREATE_GPC_REGISTER_LIST {	\
+	TRACE_REG_GPC_RESET,			\
+	TRACE_REG_GPC_OVERALL_ENABLE,		\
+	TRACE_REG_GPC_TRACE_HEADER,		\
+	TRACE_REG_GPC_TRACE_ADDRESS,		\
+	TRACE_REG_GPC_TRACE_NPK_EN,		\
+	TRACE_REG_GPC_TRACE_DDR_EN,		\
+	TRACE_REG_GPC_TRACE_LPKT_CLEAR,		\
+	TRACE_REG_GPC_TRACE_LPKT,		\
+	TRACE_REG_GPC_ENABLE_ID0,		\
+	TRACE_REG_GPC_ENABLE_ID1,		\
+	TRACE_REG_GPC_ENABLE_ID2,		\
+	TRACE_REG_GPC_ENABLE_ID3,		\
+	TRACE_REG_GPC_VALUE_ID0,		\
+	TRACE_REG_GPC_VALUE_ID1,		\
+	TRACE_REG_GPC_VALUE_ID2,		\
+	TRACE_REG_GPC_VALUE_ID3,		\
+	TRACE_REG_GPC_CNT_INPUT_SELECT_ID0,	\
+	TRACE_REG_GPC_CNT_INPUT_SELECT_ID1,	\
+	TRACE_REG_GPC_CNT_INPUT_SELECT_ID2,	\
+	TRACE_REG_GPC_CNT_INPUT_SELECT_ID3,	\
+	TRACE_REG_GPC_CNT_START_SELECT_ID0,	\
+	TRACE_REG_GPC_CNT_START_SELECT_ID1,	\
+	TRACE_REG_GPC_CNT_START_SELECT_ID2,	\
+	TRACE_REG_GPC_CNT_START_SELECT_ID3,	\
+	TRACE_REG_GPC_CNT_STOP_SELECT_ID0,	\
+	TRACE_REG_GPC_CNT_STOP_SELECT_ID1,	\
+	TRACE_REG_GPC_CNT_STOP_SELECT_ID2,	\
+	TRACE_REG_GPC_CNT_STOP_SELECT_ID3,	\
+	TRACE_REG_GPC_CNT_MSG_SELECT_ID0,	\
+	TRACE_REG_GPC_CNT_MSG_SELECT_ID1,	\
+	TRACE_REG_GPC_CNT_MSG_SELECT_ID2,	\
+	TRACE_REG_GPC_CNT_MSG_SELECT_ID3,	\
+	TRACE_REG_GPC_CNT_MSG_PLOAD_SELECT_ID0,	\
+	TRACE_REG_GPC_CNT_MSG_PLOAD_SELECT_ID1,	\
+	TRACE_REG_GPC_CNT_MSG_PLOAD_SELECT_ID2,	\
+	TRACE_REG_GPC_CNT_MSG_PLOAD_SELECT_ID3,	\
+	TRACE_REG_GPC_IRQ_TRIGGER_VALUE_ID0,	\
+	TRACE_REG_GPC_IRQ_TRIGGER_VALUE_ID1,	\
+	TRACE_REG_GPC_IRQ_TRIGGER_VALUE_ID2,	\
+	TRACE_REG_GPC_IRQ_TRIGGER_VALUE_ID3,	\
+	TRACE_REG_GPC_IRQ_TIMER_SELECT_ID0,	\
+	TRACE_REG_GPC_IRQ_TIMER_SELECT_ID1,	\
+	TRACE_REG_GPC_IRQ_TIMER_SELECT_ID2,	\
+	TRACE_REG_GPC_IRQ_TIMER_SELECT_ID3,	\
+	TRACE_REG_GPC_IRQ_ENABLE_ID0,		\
+	TRACE_REG_GPC_IRQ_ENABLE_ID1,		\
+	TRACE_REG_GPC_IRQ_ENABLE_ID2,		\
+	TRACE_REG_GPC_IRQ_ENABLE_ID3,		\
+	TRACE_REG_END_MARK			\
+}
+
+/* CSI2 legacy receiver trace registers */
+#define TRACE_REG_CSI2_TM_RESET_REG_IDX			   0x0000
+#define TRACE_REG_CSI2_TM_OVERALL_ENABLE_REG_IDX	   0x0004
+#define TRACE_REG_CSI2_TM_TRACE_HEADER_REG_IDX		   0x0008
+#define TRACE_REG_CSI2_TM_TRACE_ADDRESS_REG_IDX		   0x000c
+#define TRACE_REG_CSI2_TM_TRACE_HEADER_VAL		   0xf
+#define TRACE_REG_CSI2_TM_TRACE_ADDRESS_VAL		   0x100218
+#define TRACE_REG_CSI2_TM_MONITOR_ID			   0x8
+
+/* 0 <= n <= 3 */
+#define TRACE_REG_CSI2_TM_TRACE_NPK_EN_REG_IDX_P(n)	   (0x0010 + (n) * 4)
+#define TRACE_REG_CSI2_TM_TRACE_DDR_EN_REG_IDX_P(n)	   (0x0020 + (n) * 4)
+#define TRACE_CSI2_TM_EVENT_FE(vc)			   (BIT(0) << (vc * 6))
+#define TRACE_CSI2_TM_EVENT_FS(vc)			   (BIT(1) << (vc * 6))
+#define TRACE_CSI2_TM_EVENT_PE(vc)			   (BIT(2) << (vc * 6))
+#define TRACE_CSI2_TM_EVENT_PS(vc)			   (BIT(3) << (vc * 6))
+#define TRACE_CSI2_TM_EVENT_LE(vc)			   (BIT(4) << (vc * 6))
+#define TRACE_CSI2_TM_EVENT_LS(vc)			   (BIT(5) << (vc * 6))
+
+#define TRACE_REG_CSI2_TM_TRACE_LPKT_CLEAR_REG_IDX	   0x0030
+#define TRACE_REG_CSI2_TM_TRACE_LPKT_REG_IDX		   0x0034
+
+/* 0 <= n <= 7 */
+#define TRACE_REG_CSI2_TM_ENABLE_REG_IDn(n)		   (0x0038 + (n) * 4)
+#define TRACE_REG_CSI2_TM_VALUE_REG_IDn(n)		   (0x0058 + (n) * 4)
+#define TRACE_REG_CSI2_TM_CNT_INPUT_SELECT_REG_IDn(n)	   (0x0078 + (n) * 4)
+#define TRACE_REG_CSI2_TM_CNT_START_SELECT_REG_IDn(n)	   (0x0098 + (n) * 4)
+#define TRACE_REG_CSI2_TM_CNT_STOP_SELECT_REG_IDn(n)	   (0x00b8 + (n) * 4)
+#define TRACE_REG_CSI2_TM_IRQ_TRIGGER_VALUE_REG_IDn(n)	   (0x00d8 + (n) * 4)
+#define TRACE_REG_CSI2_TM_IRQ_TIMER_SELECT_REG_IDn(n)	   (0x00f8 + (n) * 4)
+#define TRACE_REG_CSI2_TM_IRQ_ENABLE_REG_IDn(n)		   (0x0118 + (n) * 4)
+
+/* CSI2_3PH combo receiver trace registers */
+#define TRACE_REG_CSI2_3PH_TM_RESET_REG_IDX		   0x0000
+#define TRACE_REG_CSI2_3PH_TM_OVERALL_ENABLE_REG_IDX	   0x0004
+#define TRACE_REG_CSI2_3PH_TM_TRACE_HEADER_REG_IDX	   0x0008
+#define TRACE_REG_CSI2_3PH_TM_TRACE_ADDRESS_REG_IDX	   0x000c
+#define TRACE_REG_CSI2_3PH_TM_TRACE_ADDRESS_VAL		   0x100258
+#define TRACE_REG_CSI2_3PH_TM_MONITOR_ID		   0x9
+
+/* 0 <= n <= 5 */
+#define TRACE_REG_CSI2_3PH_TM_TRACE_NPK_EN_REG_IDX_P(n)   (0x0010 + (n) * 4)
+#define TRACE_REG_CSI2_3PH_TM_TRACE_DDR_EN_REG_IDX_P(n)   (0x0028 + (n) * 4)
+
+#define TRACE_REG_CSI2_3PH_TM_TRACE_LPKT_CLEAR_REG_IDX	   0x0040
+#define TRACE_REG_CSI2_3PH_TM_TRACE_LPKT_REG_IDX	   0x0044
+
+/* 0 <= n <= 7 */
+#define TRACE_REG_CSI2_3PH_TM_ENABLE_REG_IDn(n)		   (0x0048 + (n) * 4)
+#define TRACE_REG_CSI2_3PH_TM_VALUE_REG_IDn(n)		   (0x0068 + (n) * 4)
+#define TRACE_REG_CSI2_3PH_TM_CNT_INPUT_SELECT_REG_IDn(n)  (0x0088 + (n) * 4)
+#define TRACE_REG_CSI2_3PH_TM_CNT_START_SELECT_REG_IDn(n)  (0x00a8 + (n) * 4)
+#define TRACE_REG_CSI2_3PH_TM_CNT_STOP_SELECT_REG_IDn(n)   (0x00c8 + (n) * 4)
+#define TRACE_REG_CSI2_3PH_TM_IRQ_TRIGGER_VALUE_REG_IDn(n) (0x00e8 + (n) * 4)
+#define TRACE_REG_CSI2_3PH_TM_IRQ_TIMER_SELECT_REG_IDn(n)  (0x0108 + (n) * 4)
+#define TRACE_REG_CSI2_3PH_TM_IRQ_ENABLE_REG_IDn(n)	   (0x0128 + (n) * 4)
+
+/* SIG2CIO trace monitors */
+#define TRACE_REG_SIG2CIO_ADDRESS			   0x0000
+#define TRACE_REG_SIG2CIO_WDATA				   0x0004
+#define TRACE_REG_SIG2CIO_MASK				   0x0008
+#define TRACE_REG_SIG2CIO_GROUP_CFG			   0x000c
+#define TRACE_REG_SIG2CIO_STICKY			   0x0010
+#define TRACE_REG_SIG2CIO_RST_STICKY			   0x0014
+#define TRACE_REG_SIG2CIO_MANUAL_RST_STICKY		   0x0018
+#define TRACE_REG_SIG2CIO_STATUS			   0x001c
+/* Size of on SIG2CIO block */
+#define TRACE_REG_SIG2CIO_SIZE_OF			   0x0020
+
 struct ipu_trace;
 struct ipu_subsystem_trace_config;
 
@@ -143,4 +308,5 @@ int ipu_trace_init(struct ipu_device *isp, void __iomem *base,
 void ipu_trace_restore(struct device *dev);
 void ipu_trace_uninit(struct device *dev);
 void ipu_trace_stop(struct device *dev);
+int ipu_trace_get_timer(struct device *dev, u64 *timer);
 #endif
diff --git a/drivers/media/pci/intel/ipu-wrapper.c b/drivers/media/pci/intel/ipu-wrapper.c
new file mode 100644
index 000000000000..2f09c3ed9102
--- /dev/null
+++ b/drivers/media/pci/intel/ipu-wrapper.c
@@ -0,0 +1,547 @@
+// SPDX-License-Identifier: GPL-2.0
+// Copyright (C) 2013 - 2018 Intel Corporation
+
+#include <asm/cacheflush.h>
+#include <linux/io.h>
+
+#include <linux/delay.h>
+#include <linux/dma-mapping.h>
+#include <linux/module.h>
+#include <linux/slab.h>
+#include <linux/spinlock.h>
+
+#include "ipu-bus.h"
+#include "ipu-dma.h"
+#include "ipu-mmu.h"
+#include "ipu-wrapper.h"
+#include "vied_subsystem_access.h"
+#include "vied_subsystem_access_initialization.h"
+#include "shared_memory_map.h"
+#include "shared_memory_access.h"
+
+struct wrapper_base {
+	void __iomem *sys_base;
+	const struct dma_map_ops *ops;
+	/* Protect shared memory buffers */
+	spinlock_t lock;
+	struct list_head buffers;
+	u32 css_map_done;
+	struct device *dev;
+};
+
+static struct wrapper_base isys;
+static struct wrapper_base psys;
+
+struct my_css_memory_buffer_item {
+	struct list_head list;
+	dma_addr_t iova;
+	unsigned long *addr;
+	size_t bytes;
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0)
+	struct dma_attrs attrs;
+#else
+	unsigned long attrs;
+#endif
+};
+
+static struct wrapper_base *get_mem_sub_system(int mmid)
+{
+	if (mmid == ISYS_MMID)
+		return &isys;
+
+	if (mmid == PSYS_MMID)
+		return &psys;
+	WARN(1, "Invalid mem subsystem");
+	return NULL;
+}
+
+static struct wrapper_base *get_sub_system(int ssid)
+{
+	if (ssid == ISYS_SSID)
+		return &isys;
+
+	if (ssid == PSYS_SSID)
+		return &psys;
+	WARN(1, "Invalid subsystem");
+	return NULL;
+}
+
+/*
+ * Subsystem access functions to access IUNIT MMIO space
+ */
+static void *host_addr(int ssid, u32 addr)
+{
+	if (ssid == ISYS_SSID)
+		return isys.sys_base + addr;
+	else if (ssid == PSYS_SSID)
+		return psys.sys_base + addr;
+	/*
+	 * Calling WARN_ON is a bit brutal but better to capture wrong register
+	 * accesses immediately. We have no way to return an error here.
+	 */
+	WARN_ON(1);
+
+	return NULL;
+}
+
+void vied_subsystem_store_32(unsigned int ssid, u32 addr, u32 data)
+{
+	writel(data, host_addr(ssid, addr));
+}
+
+void vied_subsystem_store_16(unsigned int ssid, u32 addr, u16 data)
+{
+	writew(data, host_addr(ssid, addr));
+}
+
+void vied_subsystem_store_8(unsigned int ssid, u32 addr, u8 data)
+{
+	writeb(data, host_addr(ssid, addr));
+}
+
+void vied_subsystem_store(unsigned int ssid,
+			  u32 addr, const void *data, unsigned int size)
+{
+	void *dst = host_addr(ssid, addr);
+
+	dev_dbg(get_sub_system(ssid)->dev, "access: %s 0x%x size: %d\n",
+		__func__, addr, size);
+
+	for (; size >= sizeof(u32); size -= sizeof(u32),
+	     dst += sizeof(u32), data += sizeof(u32)) {
+		writel(*(u32 *) data, dst);
+	}
+	if (size >= sizeof(u16)) {
+		writew(*(u16 *) data, dst);
+		size -= sizeof(u16), dst += sizeof(u16), data += sizeof(u16);
+	}
+	if (size)
+		writeb(*(u8 *) data, dst);
+}
+
+u32 vied_subsystem_load_32(unsigned int ssid, u32 addr)
+{
+	return readl(host_addr(ssid, addr));
+}
+
+u16 vied_subsystem_load_16(unsigned int ssid, u32 addr)
+{
+	return readw(host_addr(ssid, addr));
+}
+
+u8 vied_subsystem_load_8(unsigned int ssid, u32 addr)
+{
+	return readb(host_addr(ssid, addr));
+}
+
+void vied_subsystem_load(unsigned int ssid, u32 addr,
+			 void *data, unsigned int size)
+{
+	void *src = host_addr(ssid, addr);
+
+	dev_dbg(get_sub_system(ssid)->dev, "access: %s 0x%x size: %d\n",
+		__func__, addr, size);
+
+	for (; size >= sizeof(u32); size -= sizeof(u32),
+	     src += sizeof(u32), data += sizeof(u32))
+		*(u32 *) data = readl(src);
+	if (size >= sizeof(u16)) {
+		*(u16 *) data = readw(src);
+		size -= sizeof(u16), src += sizeof(u16), data += sizeof(u16);
+	}
+	if (size)
+		*(u8 *) data = readb(src);
+}
+
+/*
+ * Initialize base address for subsystem
+ */
+void vied_subsystem_access_initialize(unsigned int system)
+{
+}
+
+/*
+ * Shared memory access codes written by Dash Biswait,
+ * copied from FPGA environment
+ */
+
+/**
+ * \brief Initialize the shared memory interface administration on the host.
+ * \param mmid: id of ddr memory
+ * \param host_ddr_addr: physical address of memory as seen from host
+ * \param memory_size: size of ddr memory in bytes
+ * \param ps: size of page in bytes (for instance 4096)
+ */
+int shared_memory_allocation_initialize(unsigned int mmid, u64 host_ddr_addr,
+					size_t memory_size, size_t ps)
+{
+	return 0;
+}
+
+/**
+ * \brief De-initialize the shared memory interface administration on the host.
+ *
+ */
+void shared_memory_allocation_uninitialize(unsigned int mmid)
+{
+}
+
+/**
+ * \brief Initialize the shared memory interface administration on the host.
+ * \param ssid: id of subsystem
+ * \param mmid: id of ddr memory
+ * \param mmu_ps: size of page in bits
+ * \param mmu_pnrs: page numbers
+ * \param ddr_addr: base address
+ * \param inv_tlb: invalidate tbl
+ * \param sbt: set l1 base address
+ */
+int shared_memory_map_initialize(unsigned int ssid, unsigned int mmid,
+				 size_t mmu_ps, size_t mmu_pnrs, u64 ddr_addr,
+				 shared_memory_invalidate_mmu_tlb inv_tlb,
+				 shared_memory_set_page_table_base_address sbt)
+{
+	return 0;
+}
+
+/**
+ * \brief De-initialize the shared memory interface administration on the host.
+ */
+void shared_memory_map_uninitialize(unsigned int ssid, unsigned int mmid)
+{
+}
+
+static u8 alloc_cookie;
+
+/**
+ * \brief Allocate (DDR) shared memory space and return a host virtual address.
+ * \Returns NULL when insufficient memory available
+ */
+u64 shared_memory_alloc(unsigned int mmid, size_t bytes)
+{
+	struct wrapper_base *mine = get_mem_sub_system(mmid);
+	struct my_css_memory_buffer_item *buf;
+	unsigned long flags;
+
+	if (!mine) {
+	pr_err("Invalid mem subsystem, return. mmid=%d", mmid);
+	return 0;
+    }
+
+	dev_dbg(mine->dev, "%s: in, size: %zu\n", __func__, bytes);
+
+	if (!bytes)
+		return (unsigned long)&alloc_cookie;
+
+	might_sleep();
+
+	buf = kzalloc(sizeof(*buf), GFP_KERNEL);
+	if (!buf)
+		return 0;
+
+	/*alloc using ipu dma driver */
+	buf->bytes = PAGE_ALIGN(bytes);
+
+	buf->addr = dma_alloc_attrs(mine->dev, buf->bytes, &buf->iova,
+				    GFP_KERNEL,
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0)
+				    NULL
+#else
+				    0
+#endif
+	    );
+	if (!buf->addr) {
+		kfree(buf);
+		return 0;
+	}
+
+	spin_lock_irqsave(&mine->lock, flags);
+	list_add(&buf->list, &mine->buffers);
+	spin_unlock_irqrestore(&mine->lock, flags);
+
+	return (unsigned long)buf->addr;
+}
+
+/**
+ * \brief Free (DDR) shared memory space.
+ */
+void shared_memory_free(unsigned int mmid, u64 addr)
+{
+	struct wrapper_base *mine = get_mem_sub_system(mmid);
+	struct my_css_memory_buffer_item *buf = NULL;
+	unsigned long flags;
+
+	if (!mine) {
+	pr_err("Invalid mem subsystem, return. mmid=%d", mmid);
+	return;
+    }
+
+	if ((void *)(unsigned long)addr == &alloc_cookie)
+		return;
+
+	might_sleep();
+
+	dev_dbg(mine->dev, "looking for iova %8.8llx\n", addr);
+
+	spin_lock_irqsave(&mine->lock, flags);
+	list_for_each_entry(buf, &mine->buffers, list) {
+		dev_dbg(mine->dev, "buffer addr %8.8lx\n", (long)buf->addr);
+		if ((long)buf->addr != addr)
+			continue;
+
+		dev_dbg(mine->dev, "found it!\n");
+		list_del(&buf->list);
+		spin_unlock_irqrestore(&mine->lock, flags);
+		dma_free_attrs(mine->dev, buf->bytes, buf->addr, buf->iova,
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 8, 0)
+			       &buf->attrs
+#else
+			       buf->attrs
+#endif
+		    );
+		kfree(buf);
+		return;
+	}
+	dev_warn(mine->dev, "Can't find mem object %8.8llx\n", addr);
+	spin_unlock_irqrestore(&mine->lock, flags);
+}
+
+/**
+ * \brief Convert a host virtual address to a CSS virtual address and
+ * \update the MMU.
+ */
+u32 shared_memory_map(unsigned int ssid, unsigned int mmid, u64 addr)
+{
+	struct wrapper_base *mine = get_mem_sub_system(mmid);
+	struct my_css_memory_buffer_item *buf = NULL;
+	unsigned long flags;
+
+	if (!mine) {
+		pr_err("Invalid mem subsystem, return NULL. mmid=%d", mmid);
+		return 0;
+	}
+
+	if ((void *)(unsigned long)addr == &alloc_cookie)
+		return 0;
+
+	spin_lock_irqsave(&mine->lock, flags);
+	list_for_each_entry(buf, &mine->buffers, list) {
+		dev_dbg(mine->dev, "%s %8.8lx\n", __func__, (long)buf->addr);
+		if ((long)buf->addr != addr)
+			continue;
+
+		dev_dbg(mine->dev, "mapped!!\n");
+		spin_unlock_irqrestore(&mine->lock, flags);
+		return buf->iova;
+	}
+	dev_err(mine->dev, "Can't find mapped object %8.8llx\n", addr);
+	spin_unlock_irqrestore(&mine->lock, flags);
+	return 0;
+}
+
+/**
+ * \brief Free a CSS virtual address and update the MMU.
+ */
+void shared_memory_unmap(unsigned int ssid, unsigned int mmid, u32 addr)
+{
+}
+
+/**
+ * \brief Store a byte into (DDR) shared memory space using a host
+ * \virtual address
+ */
+void shared_memory_store_8(unsigned int mmid, u64 addr, u8 data)
+{
+	if (get_mem_sub_system(mmid))
+		dev_dbg(get_mem_sub_system(mmid)->dev,
+			"access: %s: Enter addr = 0x%llx data = 0x%x\n",
+			__func__, addr, data);
+
+	*((u8 *)(unsigned long) addr) = data;
+	/*Invalidate the cache lines to flush the content to ddr. */
+	clflush_cache_range((void *)(unsigned long)addr, sizeof(u8));
+}
+
+/**
+ * \brief Store a 16-bit word into (DDR) shared memory space using a host
+ * \virtual address
+ */
+void shared_memory_store_16(unsigned int mmid, u64 addr, u16 data)
+{
+	if (get_mem_sub_system(mmid))
+		dev_dbg(get_mem_sub_system(mmid)->dev,
+			"access: %s: Enter addr = 0x%llx data = 0x%x\n",
+			__func__, addr, data);
+
+	*((u16 *)(unsigned long) addr) = data;
+	/*Invalidate the cache lines to flush the content to ddr. */
+	clflush_cache_range((void *)(unsigned long) addr, sizeof(u16));
+}
+
+/**
+ * \brief Store a 32-bit word into (DDR) shared memory space using a host
+ * \virtual address
+ */
+void shared_memory_store_32(unsigned int mmid, u64 addr, u32 data)
+{
+	if (get_mem_sub_system(mmid))
+		dev_dbg(get_mem_sub_system(mmid)->dev,
+			"access: %s: Enter addr = 0x%llx data = 0x%x\n",
+			__func__, addr, data);
+
+	*((u32 *)(unsigned long) addr) = data;
+	/* Invalidate the cache lines to flush the content to ddr. */
+	clflush_cache_range((void *)(unsigned long) addr, sizeof(u32));
+}
+
+/**
+ * \brief Store a number of bytes into (DDR) shared memory space using a host
+ * \virtual address
+ */
+void shared_memory_store(unsigned int mmid, u64 addr, const void *data,
+			 size_t bytes)
+{
+	dev_dbg(get_mem_sub_system(mmid)->dev,
+		"access: %s: Enter addr = 0x%lx bytes = 0x%zx\n", __func__,
+		(unsigned long)addr, bytes);
+
+	if (!data) {
+		if (get_mem_sub_system(mmid))
+			dev_err(get_mem_sub_system(mmid)->dev,
+				"%s: data ptr is null\n", __func__);
+		else
+			pr_err("data ptr is null. mmid=%d\n", mmid);
+
+		return;
+	} else {
+		const u8 *pdata = data;
+		u8 *paddr = (u8 *)(unsigned long)addr;
+		size_t i = 0;
+
+		for (; i < bytes; ++i)
+			*paddr++ = *pdata++;
+
+		/* Invalidate the cache lines to flush the content to ddr. */
+		clflush_cache_range((void *)(unsigned long) addr, bytes);
+	}
+}
+
+/**
+ * \brief Set a number of bytes of (DDR) shared memory space to 0 using a host
+ * \virtual address
+ */
+void shared_memory_zero(unsigned int mmid, u64 addr, size_t bytes)
+{
+	if (get_mem_sub_system(mmid))
+		dev_dbg(get_mem_sub_system(mmid)->dev,
+			"access: %s: Enter addr = 0x%llx data = 0x%zx\n",
+			__func__, (unsigned long long)addr, bytes);
+
+	memset((void *)(unsigned long)addr, 0, bytes);
+	clflush_cache_range((void *)(unsigned long)addr, bytes);
+}
+
+/**
+ * \brief Load a byte from (DDR) shared memory space using a host
+ * \virtual address
+ */
+u8 shared_memory_load_8(unsigned int mmid, u64 addr)
+{
+	u8 data = 0;
+
+	if (get_mem_sub_system(mmid))
+		dev_dbg(get_mem_sub_system(mmid)->dev,
+			"access: %s: Enter addr = 0x%llx\n", __func__, addr);
+
+	/* Invalidate the cache lines to flush the content to ddr. */
+	clflush_cache_range((void *)(unsigned long)addr, sizeof(u8));
+	data = *(u8 *)(unsigned long) addr;
+	return data;
+}
+
+/**
+ * \brief Load a 16-bit word from (DDR) shared memory space using a host
+ * \virtual address
+ */
+u16 shared_memory_load_16(unsigned int mmid, u64 addr)
+{
+	u16 data = 0;
+
+	if (get_mem_sub_system(mmid))
+		dev_dbg(get_mem_sub_system(mmid)->dev,
+			"access: %s: Enter addr = 0x%llx\n", __func__, addr);
+
+	/* Invalidate the cache lines to flush the content to ddr. */
+	clflush_cache_range((void *)(unsigned long)addr, sizeof(u16));
+	data = *(u16 *)(unsigned long)addr;
+	return data;
+}
+
+/**
+ * \brief Load a 32-bit word from (DDR) shared memory space using a host
+ * \virtual address
+ */
+u32 shared_memory_load_32(unsigned int mmid, u64 addr)
+{
+	u32 data = 0;
+
+	if (get_mem_sub_system(mmid))
+		dev_dbg(get_mem_sub_system(mmid)->dev,
+			"access: %s: Enter addr = 0x%llx\n", __func__, addr);
+
+	/* Invalidate the cache lines to flush the content to ddr. */
+	clflush_cache_range((void *)(unsigned long)addr, sizeof(u32));
+	data = *(u32 *)(unsigned long)addr;
+	return data;
+}
+
+/**
+ * \brief Load a number of bytes from (DDR) shared memory space using a host
+ * \virtual address
+ */
+void shared_memory_load(unsigned int mmid, u64 addr, void *data, size_t bytes)
+{
+	if (get_mem_sub_system(mmid))
+		dev_dbg(get_mem_sub_system(mmid)->dev,
+			"access: %s: Enter addr = 0x%lx bytes = 0x%zx\n", __func__,
+			(unsigned long)addr, bytes);
+
+	if (!data && get_mem_sub_system(mmid)) {
+		dev_err(get_mem_sub_system(mmid)->dev,
+			"%s: data ptr is null\n", __func__);
+
+	} else {
+		u8 *pdata = data;
+		u8 *paddr = (u8 *)(unsigned long)addr;
+		size_t i = 0;
+
+		/* Invalidate the cache lines to flush the content to ddr. */
+		clflush_cache_range((void *)(unsigned long)addr, bytes);
+		for (; i < bytes; ++i)
+			*pdata++ = *paddr++;
+	}
+}
+
+static int init_wrapper(struct wrapper_base *sys)
+{
+	INIT_LIST_HEAD(&sys->buffers);
+	spin_lock_init(&sys->lock);
+	return 0;
+}
+
+/*
+ * Wrapper driver set base address for library use
+ */
+void ipu_wrapper_init(int mmid, struct device *dev, void __iomem *base)
+{
+	struct wrapper_base *sys = get_mem_sub_system(mmid);
+
+	if (!sys) {
+	pr_err("Invalid mem subsystem, return. mmid=%d", mmid);
+	return;
+    }
+	init_wrapper(sys);
+	sys->dev = dev;
+	sys->sys_base = base;
+}
+
diff --git a/drivers/media/pci/intel/ipu-wrapper.h b/drivers/media/pci/intel/ipu-wrapper.h
new file mode 100644
index 000000000000..52ca2d1593cd
--- /dev/null
+++ b/drivers/media/pci/intel/ipu-wrapper.h
@@ -0,0 +1,16 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/* Copyright (C) 2013 - 2018 Intel Corporation */
+
+#ifndef IPU_WRAPPER_H
+#define IPU_WRAPPER_H
+
+#define ISYS_SSID 1
+#define PSYS_SSID 0
+
+#define ISYS_MMID 1
+#define PSYS_MMID 0
+struct device;
+
+void ipu_wrapper_init(int mmid, struct device *dev, void __iomem *base);
+
+#endif /* IPU_WRAPPER_H */
diff --git a/drivers/media/pci/intel/ipu.c b/drivers/media/pci/intel/ipu.c
index 235d1f528bf2..720e80239579 100644
--- a/drivers/media/pci/intel/ipu.c
+++ b/drivers/media/pci/intel/ipu.c
@@ -1,7 +1,6 @@
 // SPDX-License-Identifier: GPL-2.0
-// Copyright (C) 2013 - 2020 Intel Corporation
+// Copyright (C) 2013 - 2018 Intel Corporation
 
-#include <linux/acpi.h>
 #include <linux/debugfs.h>
 #include <linux/device.h>
 #include <linux/interrupt.h>
@@ -27,76 +26,83 @@
 #include "ipu-trace.h"
 
 #define IPU_PCI_BAR		0
-enum ipu_version ipu_ver;
-EXPORT_SYMBOL(ipu_ver);
+
+static struct ipu_bus_device *ipu_mmu_init(struct pci_dev *pdev,
+					   struct device *parent,
+					   struct ipu_buttress_ctrl *ctrl,
+					   void __iomem *base,
+					   const struct ipu_hw_variants *hw,
+					   unsigned int nr, int mmid)
+{
+	struct ipu_mmu_pdata *pdata =
+	    devm_kzalloc(&pdev->dev, sizeof(*pdata), GFP_KERNEL);
+	unsigned int i;
+
+	if (!pdata)
+		return ERR_PTR(-ENOMEM);
+
+	if (hw->nr_mmus > IPU_MMU_MAX_DEVICES)
+		return ERR_PTR(-EINVAL);
+
+	for (i = 0; i < hw->nr_mmus; i++) {
+		struct ipu_mmu_hw *pdata_mmu = &pdata->mmu_hw[i];
+		const struct ipu_mmu_hw *src_mmu = &hw->mmu_hw[i];
+
+		if (src_mmu->nr_l1streams > IPU_MMU_MAX_TLB_L1_STREAMS ||
+		    src_mmu->nr_l2streams > IPU_MMU_MAX_TLB_L2_STREAMS)
+			return ERR_PTR(-EINVAL);
+
+		*pdata_mmu = *src_mmu;
+		pdata_mmu->base = base + src_mmu->offset;
+	}
+
+	pdata->nr_mmus = hw->nr_mmus;
+	pdata->mmid = mmid;
+
+	return ipu_bus_add_device(pdev, parent, pdata, NULL, ctrl,
+				  IPU_MMU_NAME, nr);
+}
 
 static struct ipu_bus_device *ipu_isys_init(struct pci_dev *pdev,
 					    struct device *parent,
-					    struct ipu_buttress_ctrl *ctrl,
+					    struct device *iommu,
 					    void __iomem *base,
 					    const struct ipu_isys_internal_pdata
 					    *ipdata,
-					    unsigned int nr)
+					    struct ipu_isys_subdev_pdata
+					    *spdata, unsigned int nr)
 {
-	struct ipu_bus_device *isys;
-	struct ipu_isys_pdata *pdata;
+	struct ipu_isys_pdata *pdata =
+	    devm_kzalloc(&pdev->dev, sizeof(*pdata), GFP_KERNEL);
 
-	pdata = devm_kzalloc(&pdev->dev, sizeof(*pdata), GFP_KERNEL);
 	if (!pdata)
 		return ERR_PTR(-ENOMEM);
 
 	pdata->base = base;
 	pdata->ipdata = ipdata;
+	pdata->spdata = spdata;
 
-	/* Use 250MHz for ipu6 se */
-	if (ipu_ver == IPU_VER_6SE)
-		ctrl->ratio = IPU6SE_IS_FREQ_CTL_DEFAULT_RATIO;
-
-	isys = ipu_bus_add_device(pdev, parent, pdata, ctrl,
+	return ipu_bus_add_device(pdev, parent, pdata, iommu, NULL,
 				  IPU_ISYS_NAME, nr);
-	if (IS_ERR(isys))
-		return ERR_PTR(-ENOMEM);
-
-	isys->mmu = ipu_mmu_init(&pdev->dev, base, ISYS_MMID,
-				 &ipdata->hw_variant);
-	if (IS_ERR(isys->mmu))
-		return ERR_PTR(-ENOMEM);
-
-	isys->mmu->dev = &isys->dev;
-
-	return isys;
 }
 
 static struct ipu_bus_device *ipu_psys_init(struct pci_dev *pdev,
 					    struct device *parent,
-					    struct ipu_buttress_ctrl *ctrl,
+					    struct device *iommu,
 					    void __iomem *base,
 					    const struct ipu_psys_internal_pdata
 					    *ipdata, unsigned int nr)
 {
-	struct ipu_bus_device *psys;
-	struct ipu_psys_pdata *pdata;
+	struct ipu_psys_pdata *pdata =
+	    devm_kzalloc(&pdev->dev, sizeof(*pdata), GFP_KERNEL);
 
-	pdata = devm_kzalloc(&pdev->dev, sizeof(*pdata), GFP_KERNEL);
 	if (!pdata)
 		return ERR_PTR(-ENOMEM);
 
 	pdata->base = base;
 	pdata->ipdata = ipdata;
-
-	psys = ipu_bus_add_device(pdev, parent, pdata, ctrl,
+	return ipu_bus_add_device(pdev, parent, pdata, iommu, NULL,
 				  IPU_PSYS_NAME, nr);
-	if (IS_ERR(psys))
-		return ERR_PTR(-ENOMEM);
-
-	psys->mmu = ipu_mmu_init(&pdev->dev, base, PSYS_MMID,
-				 &ipdata->hw_variant);
-	if (IS_ERR(psys->mmu))
-		return ERR_PTR(-ENOMEM);
-
-	psys->mmu->dev = &psys->dev;
-
-	return psys;
 }
 
 int ipu_fw_authenticate(void *data, u64 val)
@@ -113,21 +119,7 @@ int ipu_fw_authenticate(void *data, u64 val)
 		return ret;
 	}
 
-	ret = pm_runtime_get_sync(&isp->psys->dev);
-	if (ret < 0) {
-		dev_err(&isp->pdev->dev, "Runtime PM failed (%d)\n", ret);
-		return ret;
-	}
-
-	ret = ipu_buttress_authenticate(isp);
-	if (ret) {
-		dev_err(&isp->pdev->dev, "FW authentication failed\n");
-		return ret;
-	}
-
-	pm_runtime_put(&isp->psys->dev);
-
-	return 0;
+	return ipu_buttress_authenticate(isp);
 }
 EXPORT_SYMBOL(ipu_fw_authenticate);
 DEFINE_SIMPLE_ATTRIBUTE(authenticate_fops, NULL, ipu_fw_authenticate, "%llu\n");
@@ -175,12 +167,12 @@ static int force_suspend_set(void *data, u64 val)
 
 	if (val) {
 		b->force_suspend = 1;
-		ret = suspend_ipu_bus_device(isp->psys);
+		ret = suspend_ipu_bus_device(isp->psys_iommu);
 		if (ret) {
 			dev_err(&isp->pdev->dev, "Failed to suspend psys\n");
 			return ret;
 		}
-		ret = suspend_ipu_bus_device(isp->isys);
+		ret = suspend_ipu_bus_device(isp->isys_iommu);
 		if (ret) {
 			dev_err(&isp->pdev->dev, "Failed to suspend isys\n");
 			return ret;
@@ -198,12 +190,12 @@ static int force_suspend_set(void *data, u64 val)
 				"Failed to suspend IUnit PCI device\n");
 			return ret;
 		}
-		ret = resume_ipu_bus_device(isp->isys);
+		ret = resume_ipu_bus_device(isp->isys_iommu);
 		if (ret) {
 			dev_err(&isp->pdev->dev, "Failed to resume isys\n");
 			return ret;
 		}
-		ret = resume_ipu_bus_device(isp->psys);
+		ret = resume_ipu_bus_device(isp->psys_iommu);
 		if (ret) {
 			dev_err(&isp->pdev->dev, "Failed to resume psys\n");
 			return ret;
@@ -227,14 +219,19 @@ static int cpd_fw_reload(void *data, u64 val)
 
 	if (isp->cpd_fw_reload)
 		rval = isp->cpd_fw_reload(isp);
+	if (!rval && isp->isys_fw_reload)
+		rval = isp->isys_fw_reload(isp);
 
 	return rval;
 }
 
 DEFINE_SIMPLE_ATTRIBUTE(cpd_fw_fops, NULL, cpd_fw_reload, "%llu\n");
 
+#endif /* CONFIG_DEBUG_FS */
+
 static int ipu_init_debugfs(struct ipu_device *isp)
 {
+#ifdef CONFIG_DEBUG_FS
 	struct dentry *file;
 	struct dentry *dir;
 
@@ -268,6 +265,9 @@ static int ipu_init_debugfs(struct ipu_device *isp)
 err:
 	debugfs_remove_recursive(dir);
 	return -ENOMEM;
+#else
+	return 0;
+#endif /* CONFIG_DEBUG_FS */
 }
 
 static void ipu_remove_debugfs(struct ipu_device *isp)
@@ -279,27 +279,23 @@ static void ipu_remove_debugfs(struct ipu_device *isp)
 	debugfs_remove_recursive(isp->ipu_dir);
 	isp->ipu_dir = NULL;
 }
-#endif /* CONFIG_DEBUG_FS */
 
 static int ipu_pci_config_setup(struct pci_dev *dev)
 {
 	u16 pci_command;
-	int rval;
+	int rval = pci_enable_msi(dev);
 
-	pci_read_config_word(dev, PCI_COMMAND, &pci_command);
-	pci_command |= PCI_COMMAND_MEMORY | PCI_COMMAND_MASTER;
-	pci_write_config_word(dev, PCI_COMMAND, pci_command);
-	if (ipu_ver == IPU_VER_6EP) {
-		/* likely do nothing as msi not enabled by default */
-		pci_disable_msi(dev);
-		return 0;
+	if (rval) {
+		dev_err(&dev->dev, "Failed to enable msi (%d)\n", rval);
+		return rval;
 	}
 
-	rval = pci_enable_msi(dev);
-	if (rval)
-		dev_err(&dev->dev, "Failed to enable msi (%d)\n", rval);
+	pci_read_config_word(dev, PCI_COMMAND, &pci_command);
+	pci_command |= PCI_COMMAND_MEMORY | PCI_COMMAND_MASTER |
+	    PCI_COMMAND_INTX_DISABLE;
+	pci_write_config_word(dev, PCI_COMMAND, pci_command);
 
-	return rval;
+	return 0;
 }
 
 static void ipu_configure_vc_mechanism(struct ipu_device *isp)
@@ -320,7 +316,7 @@ static void ipu_configure_vc_mechanism(struct ipu_device *isp)
 }
 
 int request_cpd_fw(const struct firmware **firmware_p, const char *name,
-		   struct device *device)
+		 struct device *device)
 {
 	const struct firmware *fw;
 	struct firmware *tmp;
@@ -333,7 +329,7 @@ int request_cpd_fw(const struct firmware **firmware_p, const char *name,
 	if (is_vmalloc_addr(fw->data)) {
 		*firmware_p = fw;
 	} else {
-		tmp = kzalloc(sizeof(*tmp), GFP_KERNEL);
+		tmp = (struct firmware *)kzalloc(sizeof(struct firmware), GFP_KERNEL);
 		if (!tmp) {
 			release_firmware(fw);
 			return -ENOMEM;
@@ -361,14 +357,11 @@ static int ipu_pci_probe(struct pci_dev *pdev, const struct pci_device_id *id)
 	void __iomem *const *iomap;
 	void __iomem *isys_base = NULL;
 	void __iomem *psys_base = NULL;
-	struct ipu_buttress_ctrl *isys_ctrl = NULL, *psys_ctrl = NULL;
+	struct ipu_buttress_ctrl *isys_ctrl, *psys_ctrl;
 	unsigned int dma_mask = IPU_DMA_MASK;
-	struct fwnode_handle *fwnode = dev_fwnode(&pdev->dev);
-	u32 is_es;
 	int rval;
 
-	if (!fwnode || fwnode_property_read_u32(fwnode, "is_es", &is_es))
-		is_es = 0;
+	trace_printk("B|%d|TMWK\n", current->pid);
 
 	isp = devm_kzalloc(&pdev->dev, sizeof(*isp), GFP_KERNEL);
 	if (!isp)
@@ -382,6 +375,7 @@ static int ipu_pci_probe(struct pci_dev *pdev, const struct pci_device_id *id)
 	if (rval) {
 		dev_err(&pdev->dev, "Failed to enable CI ISP device (%d)\n",
 			rval);
+		trace_printk("E|TMWK\n");
 		return rval;
 	}
 
@@ -396,6 +390,7 @@ static int ipu_pci_probe(struct pci_dev *pdev, const struct pci_device_id *id)
 	if (rval) {
 		dev_err(&pdev->dev, "Failed to I/O memory remapping (%d)\n",
 			rval);
+		trace_printk("E|TMWK\n");
 		return rval;
 	}
 	dev_info(&pdev->dev, "physical base address 0x%llx\n", phys);
@@ -403,6 +398,7 @@ static int ipu_pci_probe(struct pci_dev *pdev, const struct pci_device_id *id)
 	iomap = pcim_iomap_table(pdev);
 	if (!iomap) {
 		dev_err(&pdev->dev, "Failed to iomap table (%d)\n", rval);
+		trace_printk("E|TMWK\n");
 		return -ENODEV;
 	}
 
@@ -412,48 +408,26 @@ static int ipu_pci_probe(struct pci_dev *pdev, const struct pci_device_id *id)
 	pci_set_drvdata(pdev, isp);
 	pci_set_master(pdev);
 
-	switch (id->device) {
-	case IPU6_PCI_ID:
-		ipu_ver = IPU_VER_6;
-		isp->cpd_fw_name = IPU6_FIRMWARE_NAME;
-		break;
-	case IPU6SE_PCI_ID:
-		ipu_ver = IPU_VER_6SE;
-		isp->cpd_fw_name = IPU6SE_FIRMWARE_NAME;
-		break;
-	case IPU6EP_ADL_P_PCI_ID:
-	case IPU6EP_ADL_N_PCI_ID:
-	case IPU6EP_RPL_P_PCI_ID:
-		ipu_ver = IPU_VER_6EP;
-		isp->cpd_fw_name = is_es ? IPU6EPES_FIRMWARE_NAME : IPU6EP_FIRMWARE_NAME;
-		break;
-	default:
-		WARN(1, "Unsupported IPU device");
-		return -ENODEV;
-	}
-
-	ipu_internal_pdata_init();
+	isp->cpd_fw_name = IPU_CPD_FIRMWARE_NAME;
 
 	isys_base = isp->base + isys_ipdata.hw_variant.offset;
 	psys_base = isp->base + psys_ipdata.hw_variant.offset;
 
-	dev_dbg(&pdev->dev, "isys_base: 0x%lx\n", (unsigned long)isys_base);
-	dev_dbg(&pdev->dev, "psys_base: 0x%lx\n", (unsigned long)psys_base);
-
 	rval = pci_set_dma_mask(pdev, DMA_BIT_MASK(dma_mask));
 	if (!rval)
 		rval = pci_set_consistent_dma_mask(pdev,
 						   DMA_BIT_MASK(dma_mask));
 	if (rval) {
 		dev_err(&pdev->dev, "Failed to set DMA mask (%d)\n", rval);
+		trace_printk("E|TMWK\n");
 		return rval;
 	}
 
-	dma_set_max_seg_size(&pdev->dev, UINT_MAX);
-
 	rval = ipu_pci_config_setup(pdev);
-	if (rval)
+	if (rval) {
+		trace_printk("E|TMWK\n");
 		return rval;
+	}
 
 	rval = devm_request_threaded_irq(&pdev->dev, pdev->irq,
 					 ipu_buttress_isr,
@@ -461,18 +435,22 @@ static int ipu_pci_probe(struct pci_dev *pdev, const struct pci_device_id *id)
 					 IRQF_SHARED, IPU_NAME, isp);
 	if (rval) {
 		dev_err(&pdev->dev, "Requesting irq failed(%d)\n", rval);
+		trace_printk("E|TMWK\n");
 		return rval;
 	}
 
 	rval = ipu_buttress_init(isp);
-	if (rval)
+	if (rval) {
+		trace_printk("E|TMWK\n");
 		return rval;
+	}
 
 	dev_info(&pdev->dev, "cpd file name: %s\n", isp->cpd_fw_name);
 
 	rval = request_cpd_fw(&isp->cpd_fw, isp->cpd_fw_name, &pdev->dev);
 	if (rval) {
 		dev_err(&isp->pdev->dev, "Requesting signed firmware failed\n");
+		trace_printk("E|TMWK\n");
 		return rval;
 	}
 
@@ -487,16 +465,13 @@ static int ipu_pci_probe(struct pci_dev *pdev, const struct pci_device_id *id)
 	if (rval)
 		dev_err(&pdev->dev, "Trace support not available\n");
 
-	pm_runtime_put_noidle(&pdev->dev);
-	pm_runtime_allow(&pdev->dev);
-
 	/*
 	 * NOTE Device hierarchy below is important to ensure proper
 	 * runtime suspend and resume order.
 	 * Also registration order is important to ensure proper
 	 * suspend and resume order during system
 	 * suspend. Registration order is as follows:
-	 * isys->psys
+	 * isys_iommu->isys->psys_iommu->psys
 	 */
 	isys_ctrl = devm_kzalloc(&pdev->dev, sizeof(*isys_ctrl), GFP_KERNEL);
 	if (!isys_ctrl) {
@@ -507,15 +482,23 @@ static int ipu_pci_probe(struct pci_dev *pdev, const struct pci_device_id *id)
 	/* Init butress control with default values based on the HW */
 	memcpy(isys_ctrl, &isys_buttress_ctrl, sizeof(*isys_ctrl));
 
-	isp->isys = ipu_isys_init(pdev, &pdev->dev,
-				  isys_ctrl, isys_base,
-				  &isys_ipdata,
-				  0);
-	if (IS_ERR(isp->isys)) {
-		rval = PTR_ERR(isp->isys);
+	isp->isys_iommu = ipu_mmu_init(pdev, &pdev->dev, isys_ctrl,
+				       isys_base,
+				       &isys_ipdata.hw_variant, 0, ISYS_MMID);
+	rval = PTR_ERR(isp->isys_iommu);
+	if (IS_ERR(isp->isys_iommu)) {
+		dev_err(&pdev->dev, "can't create isys iommu device\n");
+		rval = -ENOMEM;
 		goto out_ipu_bus_del_devices;
 	}
 
+	isp->isys = ipu_isys_init(pdev, &isp->isys_iommu->dev,
+				  &isp->isys_iommu->dev, isys_base,
+				  &isys_ipdata, pdev->dev.platform_data, 0);
+	rval = PTR_ERR(isp->isys);
+	if (IS_ERR(isp->isys))
+		goto out_ipu_bus_del_devices;
+
 	psys_ctrl = devm_kzalloc(&pdev->dev, sizeof(*psys_ctrl), GFP_KERNEL);
 	if (!psys_ctrl) {
 		rval = -ENOMEM;
@@ -525,88 +508,48 @@ static int ipu_pci_probe(struct pci_dev *pdev, const struct pci_device_id *id)
 	/* Init butress control with default values based on the HW */
 	memcpy(psys_ctrl, &psys_buttress_ctrl, sizeof(*psys_ctrl));
 
-	isp->psys = ipu_psys_init(pdev, &isp->isys->dev,
-				  psys_ctrl, psys_base,
-				  &psys_ipdata, 0);
-	if (IS_ERR(isp->psys)) {
-		rval = PTR_ERR(isp->psys);
+	isp->psys_iommu = ipu_mmu_init(pdev,
+				       isp->isys_iommu ?
+				       &isp->isys_iommu->dev :
+				       &pdev->dev, psys_ctrl, psys_base,
+				       &psys_ipdata.hw_variant, 1, PSYS_MMID);
+	rval = PTR_ERR(isp->psys_iommu);
+	if (IS_ERR(isp->psys_iommu)) {
+		dev_err(&pdev->dev, "can't create psys iommu device\n");
 		goto out_ipu_bus_del_devices;
 	}
 
-	rval = pm_runtime_get_sync(&isp->psys->dev);
-	if (rval < 0) {
-		dev_err(&isp->psys->dev, "Failed to get runtime PM\n");
-		goto out_ipu_bus_del_devices;
-	}
-
-	rval = ipu_mmu_hw_init(isp->psys->mmu);
-	if (rval) {
-		dev_err(&isp->pdev->dev, "Failed to set mmu hw\n");
-		goto out_ipu_bus_del_devices;
-	}
-
-	rval = ipu_buttress_map_fw_image(isp->psys, isp->cpd_fw,
-					 &isp->fw_sgt);
-	if (rval) {
-		dev_err(&isp->pdev->dev, "failed to map fw image\n");
-		goto out_ipu_bus_del_devices;
-	}
-
-	isp->pkg_dir = ipu_cpd_create_pkg_dir(isp->psys,
-					      isp->cpd_fw->data,
-					      sg_dma_address(isp->fw_sgt.sgl),
-					      &isp->pkg_dir_dma_addr,
-					      &isp->pkg_dir_size);
-	if (!isp->pkg_dir) {
-		rval = -ENOMEM;
-		dev_err(&isp->pdev->dev, "failed to create pkg dir\n");
-		goto out_ipu_bus_del_devices;
-	}
-
-	rval = ipu_buttress_authenticate(isp);
-	if (rval) {
-		dev_err(&isp->pdev->dev, "FW authentication failed(%d)\n",
-			rval);
+	isp->psys = ipu_psys_init(pdev, &isp->psys_iommu->dev,
+				  &isp->psys_iommu->dev, psys_base,
+				  &psys_ipdata, 0);
+	rval = PTR_ERR(isp->psys);
+	if (IS_ERR(isp->psys))
 		goto out_ipu_bus_del_devices;
-	}
-
-	ipu_mmu_hw_cleanup(isp->psys->mmu);
-	pm_runtime_put(&isp->psys->dev);
 
-#ifdef CONFIG_DEBUG_FS
 	rval = ipu_init_debugfs(isp);
 	if (rval) {
 		dev_err(&pdev->dev, "Failed to initialize debugfs");
 		goto out_ipu_bus_del_devices;
 	}
-#endif
 
 	/* Configure the arbitration mechanisms for VC requests */
 	ipu_configure_vc_mechanism(isp);
 
-	dev_info(&pdev->dev, "IPU driver version %d.%d\n", IPU_MAJOR_VERSION,
+	pm_runtime_put_noidle(&pdev->dev);
+	pm_runtime_allow(&pdev->dev);
+
+	dev_info(&pdev->dev, "IPU driver verion %d.%d\n", IPU_MAJOR_VERSION,
 		 IPU_MINOR_VERSION);
 
+	trace_printk("E|TMWK\n");
 	return 0;
 
 out_ipu_bus_del_devices:
-	if (isp->pkg_dir) {
-		ipu_cpd_free_pkg_dir(isp->psys, isp->pkg_dir,
-				     isp->pkg_dir_dma_addr,
-				     isp->pkg_dir_size);
-		ipu_buttress_unmap_fw_image(isp->psys, &isp->fw_sgt);
-		isp->pkg_dir = NULL;
-	}
-	if (isp->psys && isp->psys->mmu)
-		ipu_mmu_cleanup(isp->psys->mmu);
-	if (isp->isys && isp->isys->mmu)
-		ipu_mmu_cleanup(isp->isys->mmu);
-	if (isp->psys)
-		pm_runtime_put(&isp->psys->dev);
 	ipu_bus_del_devices(pdev);
 	ipu_buttress_exit(isp);
 	release_firmware(isp->cpd_fw);
 
+	trace_printk("E|TMWK\n");
 	return rval;
 }
 
@@ -614,20 +557,9 @@ static void ipu_pci_remove(struct pci_dev *pdev)
 {
 	struct ipu_device *isp = pci_get_drvdata(pdev);
 
-#ifdef CONFIG_DEBUG_FS
 	ipu_remove_debugfs(isp);
-#endif
 	ipu_trace_release(isp);
 
-	ipu_cpd_free_pkg_dir(isp->psys, isp->pkg_dir, isp->pkg_dir_dma_addr,
-			     isp->pkg_dir_size);
-
-	ipu_buttress_unmap_fw_image(isp->psys, &isp->fw_sgt);
-
-	isp->pkg_dir = NULL;
-	isp->pkg_dir_dma_addr = 0;
-	isp->pkg_dir_size = 0;
-
 	ipu_bus_del_devices(pdev);
 
 	pm_runtime_forbid(&pdev->dev);
@@ -639,11 +571,31 @@ static void ipu_pci_remove(struct pci_dev *pdev)
 	ipu_buttress_exit(isp);
 
 	release_firmware(isp->cpd_fw);
-
-	ipu_mmu_cleanup(isp->psys->mmu);
-	ipu_mmu_cleanup(isp->isys->mmu);
 }
 
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 13, 0)
+static void ipu_pci_reset_notify(struct pci_dev *pdev, bool prepare)
+{
+	struct ipu_device *isp = pci_get_drvdata(pdev);
+
+	if (prepare) {
+		dev_err(&pdev->dev, "FLR prepare\n");
+		pm_runtime_forbid(&isp->pdev->dev);
+		isp->flr_done = true;
+		return;
+	}
+
+	ipu_buttress_restore(isp);
+	if (isp->secure_mode)
+		ipu_buttress_reset_authentication(isp);
+
+	ipu_bus_flr_recovery();
+	isp->ipc_reinit = true;
+	pm_runtime_allow(&isp->pdev->dev);
+
+	dev_err(&pdev->dev, "FLR completed\n");
+}
+#else
 static void ipu_pci_reset_prepare(struct pci_dev *pdev)
 {
 	struct ipu_device *isp = pci_get_drvdata(pdev);
@@ -667,6 +619,7 @@ static void ipu_pci_reset_done(struct pci_dev *pdev)
 
 	dev_warn(&pdev->dev, "FLR completed\n");
 }
+#endif
 
 #ifdef CONFIG_PM
 
@@ -705,19 +658,6 @@ static int ipu_resume(struct device *dev)
 	if (rval)
 		dev_err(&isp->pdev->dev, "IPC reset protocol failed!\n");
 
-	rval = pm_runtime_get_sync(&isp->psys->dev);
-	if (rval < 0) {
-		dev_err(&isp->psys->dev, "Failed to get runtime PM\n");
-		return 0;
-	}
-
-	rval = ipu_buttress_authenticate(isp);
-	if (rval)
-		dev_err(&isp->pdev->dev, "FW authentication failed(%d)\n",
-			rval);
-
-	pm_runtime_put(&isp->psys->dev);
-
 	return 0;
 }
 
@@ -756,18 +696,18 @@ static const struct dev_pm_ops ipu_pm_ops = {
 #endif
 
 static const struct pci_device_id ipu_pci_tbl[] = {
-	{PCI_DEVICE(PCI_VENDOR_ID_INTEL, IPU6_PCI_ID)},
-	{PCI_DEVICE(PCI_VENDOR_ID_INTEL, IPU6SE_PCI_ID)},
-	{PCI_DEVICE(PCI_VENDOR_ID_INTEL, IPU6EP_ADL_P_PCI_ID)},
-	{PCI_DEVICE(PCI_VENDOR_ID_INTEL, IPU6EP_ADL_N_PCI_ID)},
-	{PCI_DEVICE(PCI_VENDOR_ID_INTEL, IPU6EP_RPL_P_PCI_ID)},
+	{PCI_DEVICE(PCI_VENDOR_ID_INTEL, IPU_PCI_ID)},
 	{0,}
 };
 MODULE_DEVICE_TABLE(pci, ipu_pci_tbl);
 
 static const struct pci_error_handlers pci_err_handlers = {
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4, 13, 0)
+	.reset_notify = ipu_pci_reset_notify,
+#else
 	.reset_prepare = ipu_pci_reset_prepare,
 	.reset_done = ipu_pci_reset_done,
+#endif
 };
 
 static struct pci_driver ipu_pci_driver = {
@@ -796,6 +736,8 @@ static int __init ipu_init(void)
 		goto out_pci_register_driver;
 	}
 
+	ipu_bus_register_driver(&ipu_mmu_driver);
+
 	return 0;
 
 out_pci_register_driver:
@@ -806,6 +748,7 @@ static int __init ipu_init(void)
 
 static void __exit ipu_exit(void)
 {
+	ipu_bus_unregister_driver(&ipu_mmu_driver);
 	pci_unregister_driver(&ipu_pci_driver);
 	ipu_bus_unregister();
 }
diff --git a/drivers/media/pci/intel/ipu.h b/drivers/media/pci/intel/ipu.h
index 10397c64681b..96e9a2144133 100644
--- a/drivers/media/pci/intel/ipu.h
+++ b/drivers/media/pci/intel/ipu.h
@@ -1,5 +1,5 @@
 /* SPDX-License-Identifier: GPL-2.0 */
-/* Copyright (C) 2013 - 2020 Intel Corporation */
+/* Copyright (C) 2013 - 2018 Intel Corporation */
 
 #ifndef IPU_H
 #define IPU_H
@@ -14,19 +14,11 @@
 #include "ipu-buttress.h"
 #include "ipu-trace.h"
 
-#define IPU6_PCI_ID	0x9a19
-#define IPU6SE_PCI_ID	0x4e19
-#define IPU6EP_ADL_P_PCI_ID	0x465d
-#define IPU6EP_ADL_N_PCI_ID	0x462e
-#define IPU6EP_RPL_P_PCI_ID	0xa75d
-#define IPU6EP_MTL_PCI_ID	0x7d19
-
-enum ipu_version {
-	IPU_VER_INVALID = 0,
-	IPU_VER_6,
-	IPU_VER_6SE,
-	IPU_VER_6EP,
-};
+#if defined(CONFIG_VIDEO_INTEL_IPU4)
+#define IPU_PCI_ID	0x5a88
+#elif defined(CONFIG_VIDEO_INTEL_IPU4P)
+#define IPU_PCI_ID	0x8a19
+#endif
 
 /*
  * IPU version definitions to reflect the IPU driver changes.
@@ -51,14 +43,20 @@ enum ipu_version {
 #define IPU_ISYS_OVERALLOC_MIN		1024
 
 /*
- * Physical pages in GDA is 128, page size is 2K for IPU6, 1K for others.
+ * Physical pages in GDA 128 * 1K pages.
  */
 #define IPU_DEVICE_GDA_NR_PAGES		128
 
 /*
  * Virtualization factor to calculate the available virtual pages.
  */
+#if defined(CONFIG_VIDEO_INTEL_IPU4)
+#define IPU_DEVICE_GDA_VIRT_FACTOR	8
+#elif defined(CONFIG_VIDEO_INTEL_IPU4P)
 #define IPU_DEVICE_GDA_VIRT_FACTOR	32
+#else
+#define IPU_DEVICE_GDA_VIRT_FACTOR	8
+#endif
 
 struct pci_dev;
 struct list_head;
@@ -69,8 +67,8 @@ struct firmware;
 struct ipu_device {
 	struct pci_dev *pdev;
 	struct list_head devices;
-	struct ipu_bus_device *isys;
-	struct ipu_bus_device *psys;
+	struct ipu_bus_device *isys_iommu, *isys;
+	struct ipu_bus_device *psys_iommu, *psys;
 	struct ipu_buttress buttress;
 
 	const struct firmware *cpd_fw;
@@ -78,17 +76,16 @@ struct ipu_device {
 	u64 *pkg_dir;
 	dma_addr_t pkg_dir_dma_addr;
 	unsigned int pkg_dir_size;
-	struct sg_table fw_sgt;
 
 	void __iomem *base;
-#ifdef CONFIG_DEBUG_FS
+	void __iomem *base2;
 	struct dentry *ipu_dir;
-#endif
 	struct ipu_trace *trace;
 	bool flr_done;
 	bool ipc_reinit;
 	bool secure_mode;
 
+	int (*isys_fw_reload)(struct ipu_device *isp);
 	int (*cpd_fw_reload)(struct ipu_device *isp);
 };
 
@@ -105,7 +102,4 @@ void ipu_configure_spc(struct ipu_device *isp,
 		       dma_addr_t pkg_dir_dma_addr);
 int request_cpd_fw(const struct firmware **firmware_p, const char *name,
 		   struct device *device);
-extern enum ipu_version ipu_ver;
-void ipu_internal_pdata_init(void);
-
 #endif /* IPU_H */
diff --git a/drivers/media/pci/intel/ipu3/ipu3-cio2-main.c b/drivers/media/pci/intel/ipu3/ipu3-cio2-main.c
index dfb2be0b9625..5a8778030d19 100644
--- a/drivers/media/pci/intel/ipu3/ipu3-cio2-main.c
+++ b/drivers/media/pci/intel/ipu3/ipu3-cio2-main.c
@@ -1760,7 +1760,7 @@ static int cio2_pci_probe(struct pci_dev *pci_dev,
 
 	pci_set_master(pci_dev);
 
-	r = pci_set_dma_mask(pci_dev, CIO2_DMA_MASK);
+	r = dma_set_mask(&pci_dev->dev, CIO2_DMA_MASK);
 	if (r) {
 		dev_err(dev, "failed to set DMA mask (%d)\n", r);
 		return -ENODEV;
diff --git a/drivers/media/pci/intel/ipu6/Makefile b/drivers/media/pci/intel/ipu6/Makefile
deleted file mode 100644
index 11464fd482d5..000000000000
--- a/drivers/media/pci/intel/ipu6/Makefile
+++ /dev/null
@@ -1,58 +0,0 @@
-# SPDX-License-Identifier: GPL-2.0
-# Copyright (c) 2017 - 2020 Intel Corporation.
-
-ifneq ($(EXTERNAL_BUILD), 1)
-srcpath := $(srctree)
-endif
-
-ccflags-y += -DIPU_TPG_FRAME_SYNC -DIPU_PSYS_GPC \
-		-DIPU_ISYS_GPC
-
-intel-ipu6-objs				+= ../ipu.o \
-					   ../ipu-bus.o \
-					   ../ipu-dma.o \
-					   ../ipu-mmu.o \
-					   ../ipu-buttress.o \
-					   ../ipu-trace.o \
-					   ../ipu-cpd.o \
-					   ipu6.o \
-					   ../ipu-fw-com.o
-
-obj-$(CONFIG_VIDEO_INTEL_IPU6)		+= intel-ipu6.o
-
-intel-ipu6-isys-objs			+= ../ipu-isys.o \
-					   ../ipu-isys-csi2.o \
-					   ipu6-isys.o \
-					   ipu6-isys-phy.o \
-					   ipu6-isys-csi2.o \
-					   ipu6-isys-gpc.o \
-					   ../ipu-isys-csi2-be-soc.o \
-					   ../ipu-fw-isys.o \
-					   ../ipu-isys-video.o \
-					   ../ipu-isys-queue.o \
-					   ../ipu-isys-subdev.o
-
-obj-$(CONFIG_VIDEO_INTEL_IPU6)		+= intel-ipu6-isys.o
-
-intel-ipu6-psys-objs			+= ../ipu-psys.o \
-					   ipu6-psys.o \
-					   ipu-resources.o \
-					   ipu6-psys-gpc.o \
-					   ipu6-l-scheduler.o \
-					   ipu6-ppg.o
-
-intel-ipu6-psys-objs			+= ipu-fw-resources.o \
-					   ipu6-fw-resources.o \
-					   ipu6se-fw-resources.o \
-					   ipu6ep-fw-resources.o \
-					   ../ipu-fw-psys.o
-
-ifeq ($(CONFIG_COMPAT),y)
-intel-ipu6-psys-objs			+= ../ipu-psys-compat32.o
-endif
-
-obj-$(CONFIG_VIDEO_INTEL_IPU6)		+= intel-ipu6-psys.o
-
-ccflags-y += -I$(srcpath)/$(src)/../../../../../include/
-ccflags-y += -I$(srcpath)/$(src)/../
-ccflags-y += -I$(srcpath)/$(src)/
diff --git a/drivers/media/pci/intel/ipu6/ipu-fw-resources.c b/drivers/media/pci/intel/ipu6/ipu-fw-resources.c
deleted file mode 100644
index ab663ead07ad..000000000000
--- a/drivers/media/pci/intel/ipu6/ipu-fw-resources.c
+++ /dev/null
@@ -1,103 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0
-// Copyright (C) 2015 - 2019 Intel Corporation
-
-#include <linux/err.h>
-#include <linux/string.h>
-
-#include "ipu-psys.h"
-#include "ipu-fw-psys.h"
-#include "ipu6-platform-resources.h"
-#include "ipu6se-platform-resources.h"
-
-/********** Generic resource handling **********/
-
-/*
- * Extension library gives byte offsets to its internal structures.
- * use those offsets to update fields. Without extension lib access
- * structures directly.
- */
-const struct ipu6_psys_hw_res_variant *var = &hw_var;
-
-int ipu_fw_psys_set_process_cell_id(struct ipu_fw_psys_process *ptr, u8 index,
-				    u8 value)
-{
-	struct ipu_fw_psys_process_group *parent =
-		(struct ipu_fw_psys_process_group *)((char *)ptr +
-						      ptr->parent_offset);
-
-	ptr->cells[index] = value;
-	parent->resource_bitmap |= 1 << value;
-
-	return 0;
-}
-
-u8 ipu_fw_psys_get_process_cell_id(struct ipu_fw_psys_process *ptr, u8 index)
-{
-	return ptr->cells[index];
-}
-
-int ipu_fw_psys_clear_process_cell(struct ipu_fw_psys_process *ptr)
-{
-	struct ipu_fw_psys_process_group *parent;
-	u8 cell_id = ipu_fw_psys_get_process_cell_id(ptr, 0);
-	int retval = -1;
-	u8 value;
-
-	parent = (struct ipu_fw_psys_process_group *)((char *)ptr +
-						       ptr->parent_offset);
-
-	value = var->cell_num;
-	if ((1 << cell_id) != 0 &&
-	    ((1 << cell_id) & parent->resource_bitmap)) {
-		ipu_fw_psys_set_process_cell_id(ptr, 0, value);
-		parent->resource_bitmap &= ~(1 << cell_id);
-		retval = 0;
-	}
-
-	return retval;
-}
-
-int ipu_fw_psys_set_proc_dev_chn(struct ipu_fw_psys_process *ptr, u16 offset,
-				 u16 value)
-{
-	if (var->set_proc_dev_chn)
-		return var->set_proc_dev_chn(ptr, offset, value);
-
-	WARN(1, "ipu6 psys res var is not initialised correctly.");
-	return 0;
-}
-
-int ipu_fw_psys_set_proc_dfm_bitmap(struct ipu_fw_psys_process *ptr,
-				    u16 id, u32 bitmap,
-				    u32 active_bitmap)
-{
-	if (var->set_proc_dfm_bitmap)
-		return var->set_proc_dfm_bitmap(ptr, id, bitmap,
-						active_bitmap);
-
-	WARN(1, "ipu6 psys res var is not initialised correctly.");
-	return 0;
-}
-
-int ipu_fw_psys_set_process_ext_mem(struct ipu_fw_psys_process *ptr,
-				    u16 type_id, u16 mem_id, u16 offset)
-{
-	if (var->set_proc_ext_mem)
-		return var->set_proc_ext_mem(ptr, type_id, mem_id, offset);
-
-	WARN(1, "ipu6 psys res var is not initialised correctly.");
-	return 0;
-}
-
-int ipu_fw_psys_get_program_manifest_by_process(
-	struct ipu_fw_generic_program_manifest *gen_pm,
-	const struct ipu_fw_psys_program_group_manifest *pg_manifest,
-	struct ipu_fw_psys_process *process)
-{
-	if (var->get_pgm_by_proc)
-		return var->get_pgm_by_proc(gen_pm, pg_manifest, process);
-
-	WARN(1, "ipu6 psys res var is not initialised correctly.");
-	return 0;
-}
-
diff --git a/drivers/media/pci/intel/ipu6/ipu-platform-buttress-regs.h b/drivers/media/pci/intel/ipu6/ipu-platform-buttress-regs.h
deleted file mode 100644
index 3c8b8eab838e..000000000000
--- a/drivers/media/pci/intel/ipu6/ipu-platform-buttress-regs.h
+++ /dev/null
@@ -1,318 +0,0 @@
-/* SPDX-License-Identifier: GPL-2.0 */
-/* Copyright (C) 2020 Intel Corporation */
-
-#ifndef IPU_PLATFORM_BUTTRESS_REGS_H
-#define IPU_PLATFORM_BUTTRESS_REGS_H
-
-/* IS_WORKPOINT_REQ */
-#define IPU_BUTTRESS_REG_IS_FREQ_CTL		0x34
-/* PS_WORKPOINT_REQ */
-#define IPU_BUTTRESS_REG_PS_FREQ_CTL		0x38
-
-#define IPU_BUTTRESS_IS_FREQ_RATIO_MASK	0xff
-#define IPU_BUTTRESS_PS_FREQ_RATIO_MASK	0xff
-
-#define IPU_IS_FREQ_MAX		533
-#define IPU_IS_FREQ_MIN		200
-#define IPU_PS_FREQ_MAX		450
-#define IPU_IS_FREQ_RATIO_BASE		25
-#define IPU_PS_FREQ_RATIO_BASE		25
-#define IPU_BUTTRESS_IS_FREQ_CTL_DIVISOR_MASK	0xff
-#define IPU_BUTTRESS_PS_FREQ_CTL_DIVISOR_MASK	0xff
-
-/* should be tuned for real silicon */
-#define IPU_IS_FREQ_CTL_DEFAULT_RATIO		0x08
-#define IPU6SE_IS_FREQ_CTL_DEFAULT_RATIO	0x0a
-#define IPU_PS_FREQ_CTL_DEFAULT_RATIO		0x0d
-
-#define IPU_IS_FREQ_CTL_DEFAULT_QOS_FLOOR_RATIO	0x10
-#define IPU_PS_FREQ_CTL_DEFAULT_QOS_FLOOR_RATIO	0x0708
-
-#define IPU_BUTTRESS_PWR_STATE_IS_PWR_SHIFT	3
-#define IPU_BUTTRESS_PWR_STATE_IS_PWR_MASK	\
-	(0x3 << IPU_BUTTRESS_PWR_STATE_IS_PWR_SHIFT)
-
-#define IPU_BUTTRESS_PWR_STATE_PS_PWR_SHIFT	6
-#define IPU_BUTTRESS_PWR_STATE_PS_PWR_MASK	\
-	(0x3 << IPU_BUTTRESS_PWR_STATE_PS_PWR_SHIFT)
-
-#define IPU_BUTTRESS_PWR_STATE_DN_DONE		0x0
-#define IPU_BUTTRESS_PWR_STATE_UP_PROCESS	0x1
-#define IPU_BUTTRESS_PWR_STATE_DN_PROCESS	0x2
-#define IPU_BUTTRESS_PWR_STATE_UP_DONE		0x3
-
-#define IPU_BUTTRESS_REG_FPGA_SUPPORT_0	0x270
-#define IPU_BUTTRESS_REG_FPGA_SUPPORT_1	0x274
-#define IPU_BUTTRESS_REG_FPGA_SUPPORT_2	0x278
-#define IPU_BUTTRESS_REG_FPGA_SUPPORT_3	0x27c
-#define IPU_BUTTRESS_REG_FPGA_SUPPORT_4	0x280
-#define IPU_BUTTRESS_REG_FPGA_SUPPORT_5	0x284
-#define IPU_BUTTRESS_REG_FPGA_SUPPORT_6	0x288
-#define IPU_BUTTRESS_REG_FPGA_SUPPORT_7	0x28c
-
-#define BUTTRESS_REG_WDT			0x8
-#define BUTTRESS_REG_BTRS_CTRL			0xc
-#define BUTTRESS_REG_BTRS_CTRL_STALL_MODE_VC0	BIT(0)
-#define BUTTRESS_REG_BTRS_CTRL_STALL_MODE_VC1	BIT(1)
-#define BUTTRESS_REG_BTRS_CTRL_REF_CLK_IND	GENMASK(9, 8)
-
-#define BUTTRESS_REG_FW_RESET_CTL	0x30
-#define BUTTRESS_FW_RESET_CTL_START	BIT(0)
-#define BUTTRESS_FW_RESET_CTL_DONE	BIT(1)
-
-#define BUTTRESS_REG_IS_FREQ_CTL	0x34
-
-#define BUTTRESS_IS_FREQ_CTL_DIVISOR_MASK	0xf
-
-#define BUTTRESS_REG_PS_FREQ_CTL	0x38
-
-#define BUTTRESS_PS_FREQ_CTL_RATIO_MASK		0xff
-
-#define BUTTRESS_FREQ_CTL_START		BIT(31)
-#define BUTTRESS_FREQ_CTL_START_SHIFT		31
-#define BUTTRESS_FREQ_CTL_QOS_FLOOR_SHIFT	8
-#define BUTTRESS_FREQ_CTL_ICCMAX_LEVEL		(GENMASK(19, 16))
-#define BUTTRESS_FREQ_CTL_QOS_FLOOR_MASK	(0xff << 8)
-
-#define BUTTRESS_REG_PWR_STATE	0x5c
-
-#define BUTTRESS_PWR_STATE_IS_PWR_SHIFT	3
-#define BUTTRESS_PWR_STATE_IS_PWR_MASK	(0x3 << 3)
-
-#define BUTTRESS_PWR_STATE_PS_PWR_SHIFT	6
-#define BUTTRESS_PWR_STATE_PS_PWR_MASK	(0x3 << 6)
-
-#define BUTTRESS_PWR_STATE_RESET		0x0
-#define BUTTRESS_PWR_STATE_PWR_ON_DONE		0x1
-#define BUTTRESS_PWR_STATE_PWR_RDY		0x3
-#define BUTTRESS_PWR_STATE_PWR_IDLE		0x4
-
-#define BUTTRESS_PWR_STATE_HH_STATUS_SHIFT	11
-#define BUTTRESS_PWR_STATE_HH_STATUS_MASK	(0x3 << 11)
-
-enum {
-	BUTTRESS_PWR_STATE_HH_STATE_IDLE,
-	BUTTRESS_PWR_STATE_HH_STATE_IN_PRGS,
-	BUTTRESS_PWR_STATE_HH_STATE_DONE,
-	BUTTRESS_PWR_STATE_HH_STATE_ERR,
-};
-
-#define BUTTRESS_PWR_STATE_IS_PWR_FSM_SHIFT	19
-#define BUTTRESS_PWR_STATE_IS_PWR_FSM_MASK	(0xf << 19)
-
-#define BUTTRESS_PWR_STATE_IS_PWR_FSM_IDLE			0x0
-#define BUTTRESS_PWR_STATE_IS_PWR_FSM_WAIT_4_PLL_CMP		0x1
-#define BUTTRESS_PWR_STATE_IS_PWR_FSM_WAIT_4_CLKACK		0x2
-#define BUTTRESS_PWR_STATE_IS_PWR_FSM_WAIT_4_PG_ACK		0x3
-#define BUTTRESS_PWR_STATE_IS_PWR_FSM_RST_ASSRT_CYCLES		0x4
-#define BUTTRESS_PWR_STATE_IS_PWR_FSM_STOP_CLK_CYCLES1		0x5
-#define BUTTRESS_PWR_STATE_IS_PWR_FSM_STOP_CLK_CYCLES2		0x6
-#define BUTTRESS_PWR_STATE_IS_PWR_FSM_RST_DEASSRT_CYCLES	0x7
-#define BUTTRESS_PWR_STATE_IS_PWR_FSM_WAIT_4_FUSE_WR_CMP	0x8
-#define BUTTRESS_PWR_STATE_IS_PWR_FSM_BRK_POINT			0x9
-#define BUTTRESS_PWR_STATE_IS_PWR_FSM_IS_RDY			0xa
-#define BUTTRESS_PWR_STATE_IS_PWR_FSM_HALT_HALTED		0xb
-#define BUTTRESS_PWR_STATE_IS_PWR_FSM_RST_DURATION_CNT3		0xc
-#define BUTTRESS_PWR_STATE_IS_PWR_FSM_WAIT_4_CLKACK_PD		0xd
-#define BUTTRESS_PWR_STATE_IS_PWR_FSM_PD_BRK_POINT		0xe
-#define BUTTRESS_PWR_STATE_IS_PWR_FSM_WAIT_4_PD_PG_ACK0		0xf
-
-#define BUTTRESS_PWR_STATE_PS_PWR_FSM_SHIFT	24
-#define BUTTRESS_PWR_STATE_PS_PWR_FSM_MASK	(0x1f << 24)
-
-#define BUTTRESS_PWR_STATE_PS_PWR_FSM_IDLE			0x0
-#define BUTTRESS_PWR_STATE_PS_PWR_FSM_WAIT_PU_PLL_IP_RDY	0x1
-#define BUTTRESS_PWR_STATE_PS_PWR_FSM_WAIT_RO_PRE_CNT_EXH	0x2
-#define BUTTRESS_PWR_STATE_PS_PWR_FSM_WAIT_PU_VGI_PWRGOOD	0x3
-#define BUTTRESS_PWR_STATE_PS_PWR_FSM_WAIT_RO_POST_CNT_EXH	0x4
-#define BUTTRESS_PWR_STATE_PS_PWR_FSM_WR_PLL_RATIO		0x5
-#define BUTTRESS_PWR_STATE_PS_PWR_FSM_WAIT_PU_PLL_CMP		0x6
-#define BUTTRESS_PWR_STATE_PS_PWR_FSM_WAIT_PU_CLKACK		0x7
-#define BUTTRESS_PWR_STATE_PS_PWR_FSM_RST_ASSRT_CYCLES		0x8
-#define BUTTRESS_PWR_STATE_PS_PWR_FSM_STOP_CLK_CYCLES1		0x9
-#define BUTTRESS_PWR_STATE_PS_PWR_FSM_STOP_CLK_CYCLES2		0xa
-#define BUTTRESS_PWR_STATE_PS_PWR_FSM_RST_DEASSRT_CYCLES	0xb
-#define BUTTRESS_PWR_STATE_PS_PWR_FSM_PU_BRK_PNT		0xc
-#define BUTTRESS_PWR_STATE_PS_PWR_FSM_WAIT_FUSE_ACCPT		0xd
-#define BUTTRESS_PWR_STATE_PS_PWR_FSM_PS_PWR_UP			0xf
-#define BUTTRESS_PWR_STATE_PS_PWR_FSM_WAIT_4_HALTED		0x10
-#define BUTTRESS_PWR_STATE_PS_PWR_FSM_RESET_CNT3		0x11
-#define BUTTRESS_PWR_STATE_PS_PWR_FSM_WAIT_PD_CLKACK		0x12
-#define BUTTRESS_PWR_STATE_PS_PWR_FSM_WAIT_PD_OFF_IND		0x13
-#define BUTTRESS_PWR_STATE_PS_PWR_FSM_WAIT_DVFS_PH4		0x14
-#define BUTTRESS_PWR_STATE_PS_PWR_FSM_WAIT_DVFS_PLL_CMP		0x15
-#define BUTTRESS_PWR_STATE_PS_PWR_FSM_WAIT_DVFS_CLKACK		0x16
-
-#define BUTTRESS_REG_SECURITY_CTL	0x300
-
-#define BUTTRESS_SECURITY_CTL_FW_SECURE_MODE	BIT(16)
-#define BUTTRESS_SECURITY_CTL_FW_SETUP_SHIFT		0
-#define BUTTRESS_SECURITY_CTL_FW_SETUP_MASK		0x1f
-
-#define BUTTRESS_SECURITY_CTL_FW_SETUP_DONE		0x1
-#define BUTTRESS_SECURITY_CTL_AUTH_DONE			0x2
-#define BUTTRESS_SECURITY_CTL_AUTH_FAILED			0x8
-
-#define BUTTRESS_REG_SENSOR_FREQ_CTL	0x16c
-
-#define BUTTRESS_SENSOR_FREQ_CTL_OSC_OUT_FREQ_DEFAULT(i) \
-					(0x1b << ((i) * 10))
-#define BUTTRESS_SENSOR_FREQ_CTL_OSC_OUT_FREQ_SHIFT(i)	((i) * 10)
-#define BUTTRESS_SENSOR_FREQ_CTL_OSC_OUT_FREQ_MASK(i) \
-					(0x1ff << ((i) * 10))
-
-#define BUTTRESS_SENSOR_CLK_FREQ_6P75MHZ	0x176
-#define BUTTRESS_SENSOR_CLK_FREQ_8MHZ		0x164
-#define BUTTRESS_SENSOR_CLK_FREQ_9P6MHZ		0x2
-#define BUTTRESS_SENSOR_CLK_FREQ_12MHZ		0x1b2
-#define BUTTRESS_SENSOR_CLK_FREQ_13P6MHZ	0x1ac
-#define BUTTRESS_SENSOR_CLK_FREQ_14P4MHZ	0x1cc
-#define BUTTRESS_SENSOR_CLK_FREQ_15P8MHZ	0x1a6
-#define BUTTRESS_SENSOR_CLK_FREQ_16P2MHZ	0xca
-#define BUTTRESS_SENSOR_CLK_FREQ_17P3MHZ	0x12e
-#define BUTTRESS_SENSOR_CLK_FREQ_18P6MHZ	0x1c0
-#define BUTTRESS_SENSOR_CLK_FREQ_19P2MHZ	0x0
-#define BUTTRESS_SENSOR_CLK_FREQ_24MHZ		0xb2
-#define BUTTRESS_SENSOR_CLK_FREQ_26MHZ		0xae
-#define BUTTRESS_SENSOR_CLK_FREQ_27MHZ		0x196
-
-#define BUTTRESS_SENSOR_FREQ_CTL_LJPLL_FB_RATIO_MASK		0xff
-#define BUTTRESS_SENSOR_FREQ_CTL_SEL_MIPICLK_A_SHIFT		8
-#define BUTTRESS_SENSOR_FREQ_CTL_SEL_MIPICLK_A_MASK		(0x2 << 8)
-#define BUTTRESS_SENSOR_FREQ_CTL_SEL_MIPICLK_C_SHIFT		10
-#define BUTTRESS_SENSOR_FREQ_CTL_SEL_MIPICLK_C_MASK		(0x2 << 10)
-#define BUTTRESS_SENSOR_FREQ_CTL_LJPLL_FORCE_OFF_SHIFT		12
-#define BUTTRESS_SENSOR_FREQ_CTL_LJPLL_REF_RATIO_SHIFT		14
-#define BUTTRESS_SENSOR_FREQ_CTL_LJPLL_REF_RATIO_MASK		(0x2 << 14)
-#define BUTTRESS_SENSOR_FREQ_CTL_LJPLL_PVD_RATIO_SHIFT		16
-#define BUTTRESS_SENSOR_FREQ_CTL_LJPLL_PVD_RATIO_MASK		(0x2 << 16)
-#define BUTTRESS_SENSOR_FREQ_CTL_LJPLL_OUTPUT_RATIO_SHIFT	18
-#define BUTTRESS_SENSOR_FREQ_CTL_LJPLL_OUTPUT_RATIO_MASK	(0x2 << 18)
-#define BUTTRESS_SENSOR_FREQ_CTL_START_SHIFT			31
-
-#define BUTTRESS_REG_SENSOR_CLK_CTL	0x170
-
-/* 0 <= i <= 2 */
-#define BUTTRESS_SENSOR_CLK_CTL_OSC_CLK_OUT_EN_SHIFT(i)		((i) * 2)
-#define BUTTRESS_SENSOR_CLK_CTL_OSC_CLK_OUT_SEL_SHIFT(i)	((i) * 2 + 1)
-
-#define BUTTRESS_REG_FW_SOURCE_BASE_LO	0x78
-#define BUTTRESS_REG_FW_SOURCE_BASE_HI	0x7C
-#define BUTTRESS_REG_FW_SOURCE_SIZE	0x80
-
-#define BUTTRESS_REG_ISR_STATUS		0x90
-#define BUTTRESS_REG_ISR_ENABLED_STATUS	0x94
-#define BUTTRESS_REG_ISR_ENABLE		0x98
-#define BUTTRESS_REG_ISR_CLEAR		0x9C
-
-#define BUTTRESS_ISR_IS_IRQ			BIT(0)
-#define BUTTRESS_ISR_PS_IRQ			BIT(1)
-#define BUTTRESS_ISR_IPC_EXEC_DONE_BY_CSE	BIT(2)
-#define BUTTRESS_ISR_IPC_EXEC_DONE_BY_ISH	BIT(3)
-#define BUTTRESS_ISR_IPC_FROM_CSE_IS_WAITING	BIT(4)
-#define BUTTRESS_ISR_IPC_FROM_ISH_IS_WAITING	BIT(5)
-#define BUTTRESS_ISR_CSE_CSR_SET		BIT(6)
-#define BUTTRESS_ISR_ISH_CSR_SET		BIT(7)
-#define BUTTRESS_ISR_SPURIOUS_CMP		BIT(8)
-#define BUTTRESS_ISR_WATCHDOG_EXPIRED		BIT(9)
-#define BUTTRESS_ISR_PUNIT_2_IUNIT_IRQ		BIT(10)
-#define BUTTRESS_ISR_SAI_VIOLATION		BIT(11)
-#define BUTTRESS_ISR_HW_ASSERTION		BIT(12)
-
-#define BUTTRESS_REG_IU2CSEDB0	0x100
-
-#define BUTTRESS_IU2CSEDB0_BUSY		BIT(31)
-#define BUTTRESS_IU2CSEDB0_SHORT_FORMAT_SHIFT	27
-#define BUTTRESS_IU2CSEDB0_CLIENT_ID_SHIFT	10
-#define BUTTRESS_IU2CSEDB0_IPC_CLIENT_ID_VAL	2
-
-#define BUTTRESS_REG_IU2CSEDATA0	0x104
-
-#define BUTTRESS_IU2CSEDATA0_IPC_BOOT_LOAD		1
-#define BUTTRESS_IU2CSEDATA0_IPC_AUTH_RUN		2
-#define BUTTRESS_IU2CSEDATA0_IPC_AUTH_REPLACE		3
-#define BUTTRESS_IU2CSEDATA0_IPC_UPDATE_SECURE_TOUCH	16
-
-#define BUTTRESS_CSE2IUDATA0_IPC_BOOT_LOAD_DONE			1
-#define BUTTRESS_CSE2IUDATA0_IPC_AUTH_RUN_DONE			2
-#define BUTTRESS_CSE2IUDATA0_IPC_AUTH_REPLACE_DONE		4
-#define BUTTRESS_CSE2IUDATA0_IPC_UPDATE_SECURE_TOUCH_DONE	16
-
-#define BUTTRESS_REG_IU2CSECSR		0x108
-
-#define BUTTRESS_IU2CSECSR_IPC_PEER_COMP_ACTIONS_RST_PHASE1		BIT(0)
-#define BUTTRESS_IU2CSECSR_IPC_PEER_COMP_ACTIONS_RST_PHASE2		BIT(1)
-#define BUTTRESS_IU2CSECSR_IPC_PEER_QUERIED_IP_COMP_ACTIONS_RST_PHASE	BIT(2)
-#define BUTTRESS_IU2CSECSR_IPC_PEER_ASSERTED_REG_VALID_REQ		BIT(3)
-#define BUTTRESS_IU2CSECSR_IPC_PEER_ACKED_REG_VALID			BIT(4)
-#define BUTTRESS_IU2CSECSR_IPC_PEER_DEASSERTED_REG_VALID_REQ		BIT(5)
-
-#define BUTTRESS_REG_CSE2IUDB0		0x304
-#define BUTTRESS_REG_CSE2IUCSR		0x30C
-#define BUTTRESS_REG_CSE2IUDATA0	0x308
-
-/* 0x20 == NACK, 0xf == unknown command */
-#define BUTTRESS_CSE2IUDATA0_IPC_NACK      0xf20
-#define BUTTRESS_CSE2IUDATA0_IPC_NACK_MASK 0xffff
-
-#define BUTTRESS_REG_ISH2IUCSR		0x50
-#define BUTTRESS_REG_ISH2IUDB0		0x54
-#define BUTTRESS_REG_ISH2IUDATA0	0x58
-
-#define BUTTRESS_REG_IU2ISHDB0		0x10C
-#define BUTTRESS_REG_IU2ISHDATA0	0x110
-#define BUTTRESS_REG_IU2ISHDATA1	0x114
-#define BUTTRESS_REG_IU2ISHCSR		0x118
-
-#define BUTTRESS_REG_ISH_START_DETECT		0x198
-#define BUTTRESS_REG_ISH_START_DETECT_MASK	0x19C
-
-#define BUTTRESS_REG_FABRIC_CMD	0x88
-
-#define BUTTRESS_FABRIC_CMD_START_TSC_SYNC	BIT(0)
-#define BUTTRESS_FABRIC_CMD_IS_DRAIN		BIT(4)
-
-#define BUTTRESS_REG_TSW_CTL		0x120
-#define BUTTRESS_TSW_CTL_SOFT_RESET	BIT(8)
-
-#define BUTTRESS_REG_TSC_LO	0x164
-#define BUTTRESS_REG_TSC_HI	0x168
-
-#define BUTTRESS_REG_CSI2_PORT_CONFIG_AB		0x200
-#define BUTTRESS_CSI2_PORT_CONFIG_AB_MUX_MASK		0x1f
-#define BUTTRESS_CSI2_PORT_CONFIG_AB_COMBO_SHIFT_B0	16
-
-#define BUTTRESS_REG_PS_FREQ_CAPABILITIES			0xf7498
-
-#define BUTTRESS_PS_FREQ_CAPABILITIES_LAST_RESOLVED_RATIO_SHIFT	24
-#define BUTTRESS_PS_FREQ_CAPABILITIES_LAST_RESOLVED_RATIO_MASK	(0xff << 24)
-#define BUTTRESS_PS_FREQ_CAPABILITIES_MAX_RATIO_SHIFT		16
-#define BUTTRESS_PS_FREQ_CAPABILITIES_MAX_RATIO_MASK		(0xff << 16)
-#define BUTTRESS_PS_FREQ_CAPABILITIES_EFFICIENT_RATIO_SHIFT	8
-#define BUTTRESS_PS_FREQ_CAPABILITIES_EFFICIENT_RATIO_MASK	(0xff << 8)
-#define BUTTRESS_PS_FREQ_CAPABILITIES_MIN_RATIO_SHIFT		0
-#define BUTTRESS_PS_FREQ_CAPABILITIES_MIN_RATIO_MASK		(0xff)
-
-#define BUTTRESS_IRQS		(BUTTRESS_ISR_IPC_FROM_CSE_IS_WAITING |	\
-				 BUTTRESS_ISR_IPC_EXEC_DONE_BY_CSE |	\
-				 BUTTRESS_ISR_IS_IRQ |			\
-				 BUTTRESS_ISR_PS_IRQ)
-
-#define IPU6SE_ISYS_PHY_0_BASE		0x10000
-
-/* only use BB0, BB2, BB4, and BB6 on PHY0 */
-#define IPU6SE_ISYS_PHY_BB_NUM		4
-
-/* offset from PHY base */
-#define PHY_CSI_CFG			0xc0
-#define PHY_CSI_RCOMP_CONTROL		0xc8
-#define PHY_CSI_BSCAN_EXCLUDE		0xd8
-
-#define PHY_CPHY_DLL_OVRD(x)		(0x100 + 0x100 * (x))
-#define PHY_DPHY_DLL_OVRD(x)		(0x14c + 0x100 * (x))
-#define PHY_CPHY_RX_CONTROL1(x)		(0x110 + 0x100 * (x))
-#define PHY_CPHY_RX_CONTROL2(x)		(0x114 + 0x100 * (x))
-#define PHY_DPHY_CFG(x)			(0x148 + 0x100 * (x))
-#define PHY_BB_AFE_CONFIG(x)		(0x174 + 0x100 * (x))
-
-#endif /* IPU_PLATFORM_BUTTRESS_REGS_H */
diff --git a/drivers/media/pci/intel/ipu6/ipu-platform-isys-csi2-reg.h b/drivers/media/pci/intel/ipu6/ipu-platform-isys-csi2-reg.h
deleted file mode 100644
index 80f7ac0b0c7f..000000000000
--- a/drivers/media/pci/intel/ipu6/ipu-platform-isys-csi2-reg.h
+++ /dev/null
@@ -1,277 +0,0 @@
-/* SPDX-License-Identifier: GPL-2.0 */
-/* Copyright (C) 2020 Intel Corporation */
-
-#ifndef IPU_PLATFORM_ISYS_CSI2_REG_H
-#define IPU_PLATFORM_ISYS_CSI2_REG_H
-
-#define CSI_REG_BASE			0x220000
-#define CSI_REG_BASE_PORT(id)		((id) * 0x1000)
-
-#define IPU_CSI_PORT_A_ADDR_OFFSET	\
-		(CSI_REG_BASE + CSI_REG_BASE_PORT(0))
-#define IPU_CSI_PORT_B_ADDR_OFFSET	\
-		(CSI_REG_BASE + CSI_REG_BASE_PORT(1))
-#define IPU_CSI_PORT_C_ADDR_OFFSET	\
-		(CSI_REG_BASE + CSI_REG_BASE_PORT(2))
-#define IPU_CSI_PORT_D_ADDR_OFFSET	\
-		(CSI_REG_BASE + CSI_REG_BASE_PORT(3))
-#define IPU_CSI_PORT_E_ADDR_OFFSET	\
-		(CSI_REG_BASE + CSI_REG_BASE_PORT(4))
-#define IPU_CSI_PORT_F_ADDR_OFFSET	\
-		(CSI_REG_BASE + CSI_REG_BASE_PORT(5))
-#define IPU_CSI_PORT_G_ADDR_OFFSET	\
-		(CSI_REG_BASE + CSI_REG_BASE_PORT(6))
-#define IPU_CSI_PORT_H_ADDR_OFFSET	\
-		(CSI_REG_BASE + CSI_REG_BASE_PORT(7))
-
-/* CSI Port Genral Purpose Registers */
-#define CSI_REG_PORT_GPREG_SRST                 0x0
-#define CSI_REG_PORT_GPREG_CSI2_SLV_REG_SRST    0x4
-#define CSI_REG_PORT_GPREG_CSI2_PORT_CONTROL    0x8
-
-/*
- * Port IRQs mapping events:
- * IRQ0 - CSI_FE event
- * IRQ1 - CSI_SYNC
- * IRQ2 - S2M_SIDS0TO7
- * IRQ3 - S2M_SIDS8TO15
- */
-#define CSI_PORT_REG_BASE_IRQ_CSI               0x80
-#define CSI_PORT_REG_BASE_IRQ_CSI_SYNC          0xA0
-#define CSI_PORT_REG_BASE_IRQ_S2M_SIDS0TOS7     0xC0
-#define CSI_PORT_REG_BASE_IRQ_S2M_SIDS8TOS15    0xE0
-
-#define CSI_PORT_REG_BASE_IRQ_EDGE_OFFSET	0x0
-#define CSI_PORT_REG_BASE_IRQ_MASK_OFFSET	0x4
-#define CSI_PORT_REG_BASE_IRQ_STATUS_OFFSET	0x8
-#define CSI_PORT_REG_BASE_IRQ_CLEAR_OFFSET	0xc
-#define CSI_PORT_REG_BASE_IRQ_ENABLE_OFFSET	0x10
-#define CSI_PORT_REG_BASE_IRQ_LEVEL_NOT_PULSE_OFFSET	0x14
-
-#define IPU6SE_CSI_RX_ERROR_IRQ_MASK		0x7ffff
-#define IPU6_CSI_RX_ERROR_IRQ_MASK		0xfffff
-
-#define CSI_RX_NUM_ERRORS_IN_IRQ		20
-#define CSI_RX_NUM_IRQ				32
-
-#define IPU_CSI_RX_IRQ_FS_VC		1
-#define IPU_CSI_RX_IRQ_FE_VC		2
-
-/* PPI2CSI */
-#define CSI_REG_PPI2CSI_ENABLE                  0x200
-#define CSI_REG_PPI2CSI_CONFIG_PPI_INTF         0x204
-#define PPI_INTF_CONFIG_NOF_ENABLED_DATALANES_SHIFT	3
-#define PPI_INTF_CONFIG_RX_AUTO_CLKGATING_SHIFT		5
-#define CSI_REG_PPI2CSI_CONFIG_CSI_FEATURE      0x208
-
-enum CSI_PPI2CSI_CTRL {
-	CSI_PPI2CSI_DISABLE = 0,
-	CSI_PPI2CSI_ENABLE = 1,
-};
-
-/* CSI_FE */
-#define CSI_REG_CSI_FE_ENABLE                   0x280
-#define CSI_REG_CSI_FE_MODE                     0x284
-#define CSI_REG_CSI_FE_MUX_CTRL                 0x288
-#define CSI_REG_CSI_FE_SYNC_CNTR_SEL            0x290
-
-enum CSI_FE_ENABLE_TYPE {
-	CSI_FE_DISABLE = 0,
-	CSI_FE_ENABLE = 1,
-};
-
-enum CSI_FE_MODE_TYPE {
-	CSI_FE_DPHY_MODE = 0,
-	CSI_FE_CPHY_MODE = 1,
-};
-
-enum CSI_FE_INPUT_SELECTOR {
-	CSI_SENSOR_INPUT = 0,
-	CSI_MIPIGEN_INPUT = 1,
-};
-
-enum CSI_FE_SYNC_CNTR_SEL_TYPE {
-	CSI_CNTR_SENSOR_LINE_ID = (1 << 0),
-	CSI_CNTR_INT_LINE_PKT_ID = ~CSI_CNTR_SENSOR_LINE_ID,
-	CSI_CNTR_SENSOR_FRAME_ID = (1 << 1),
-	CSI_CNTR_INT_FRAME_PKT_ID = ~CSI_CNTR_SENSOR_FRAME_ID,
-};
-
-/* MIPI_PKT_GEN */
-#define CSI_REG_PIXGEN_COM_BASE_OFFSET		0x300
-
-#define IPU_CSI_PORT_A_PIXGEN_ADDR_OFFSET	\
-	(CSI_REG_BASE + CSI_REG_BASE_PORT(0) + CSI_REG_PIXGEN_COM_BASE_OFFSET)
-#define IPU_CSI_PORT_B_PIXGEN_ADDR_OFFSET	\
-	(CSI_REG_BASE + CSI_REG_BASE_PORT(1) + CSI_REG_PIXGEN_COM_BASE_OFFSET)
-#define IPU_CSI_PORT_C_PIXGEN_ADDR_OFFSET	\
-	(CSI_REG_BASE + CSI_REG_BASE_PORT(2) + CSI_REG_PIXGEN_COM_BASE_OFFSET)
-#define IPU_CSI_PORT_D_PIXGEN_ADDR_OFFSET	\
-	(CSI_REG_BASE + CSI_REG_BASE_PORT(3) + CSI_REG_PIXGEN_COM_BASE_OFFSET)
-#define IPU_CSI_PORT_E_PIXGEN_ADDR_OFFSET	\
-	(CSI_REG_BASE + CSI_REG_BASE_PORT(4) + CSI_REG_PIXGEN_COM_BASE_OFFSET)
-#define IPU_CSI_PORT_F_PIXGEN_ADDR_OFFSET	\
-	(CSI_REG_BASE + CSI_REG_BASE_PORT(5) + CSI_REG_PIXGEN_COM_BASE_OFFSET)
-#define IPU_CSI_PORT_G_PIXGEN_ADDR_OFFSET	\
-	(CSI_REG_BASE + CSI_REG_BASE_PORT(6) + CSI_REG_PIXGEN_COM_BASE_OFFSET)
-#define IPU_CSI_PORT_H_PIXGEN_ADDR_OFFSET	\
-	(CSI_REG_BASE + CSI_REG_BASE_PORT(7) + CSI_REG_PIXGEN_COM_BASE_OFFSET)
-
-#define CSI_REG_PIXGEN_COM_ENABLE_REG_IDX(id)	\
-	(CSI_REG_BASE_PORT(id) + 0x300)
-#define CSI_REG_PIXGEN_COM_DTYPE_REG_IDX(id)	\
-	(CSI_REG_BASE_PORT(id) + 0x304)
-#define CSI_REG_PIXGEN_COM_VTYPE_REG_IDX(id)	\
-	(CSI_REG_BASE_PORT(id) + 0x308)
-#define CSI_REG_PIXGEN_COM_VCHAN_REG_IDX(id)	\
-	(CSI_REG_BASE_PORT(id) + 0x30C)
-#define CSI_REG_PIXGEN_COM_WCOUNT_REG_IDX(id)	\
-	(CSI_REG_BASE_PORT(id) + 0x310)
-/* PRBS */
-#define CSI_REG_PIXGEN_PRBS_RSTVAL_REG0_IDX(id)	\
-	(CSI_REG_BASE_PORT(id) + 0x314)
-#define CSI_REG_PIXGEN_PRBS_RSTVAL_REG1_IDX(id)	\
-	(CSI_REG_BASE_PORT(id) + 0x318)
-/* SYNC_GENERATOR_CONFIG */
-#define CSI_REG_PIXGEN_SYNG_FREE_RUN_REG_IDX(id)	\
-	(CSI_REG_BASE_PORT(id) + 0x31C)
-#define CSI_REG_PIXGEN_SYNG_PAUSE_REG_IDX(id)		\
-	(CSI_REG_BASE_PORT(id) + 0x320)
-#define CSI_REG_PIXGEN_SYNG_NOF_FRAME_REG_IDX(id)	\
-	(CSI_REG_BASE_PORT(id) + 0x324)
-#define CSI_REG_PIXGEN_SYNG_NOF_PIXEL_REG_IDX(id)	\
-	(CSI_REG_BASE_PORT(id) + 0x328)
-#define CSI_REG_PIXGEN_SYNG_NOF_LINE_REG_IDX(id)	\
-	(CSI_REG_BASE_PORT(id) + 0x32C)
-#define CSI_REG_PIXGEN_SYNG_HBLANK_CYC_REG_IDX(id)	\
-	(CSI_REG_BASE_PORT(id) + 0x330)
-#define CSI_REG_PIXGEN_SYNG_VBLANK_CYC_REG_IDX(id)	\
-	(CSI_REG_BASE_PORT(id) + 0x334)
-#define CSI_REG_PIXGEN_SYNG_STAT_HCNT_REG_IDX(id)	\
-	(CSI_REG_BASE_PORT(id) + 0x338)
-#define CSI_REG_PIXGEN_SYNG_STAT_VCNT_REG_IDX(id)	\
-	(CSI_REG_BASE_PORT(id) + 0x33C)
-#define CSI_REG_PIXGEN_SYNG_STAT_FCNT_REG_IDX(id)	\
-	(CSI_REG_BASE_PORT(id) + 0x340)
-#define CSI_REG_PIXGEN_SYNG_STAT_DONE_REG_IDX(id)	\
-	(CSI_REG_BASE_PORT(id) + 0x344)
-/* TPG */
-#define CSI_REG_PIXGEN_TPG_MODE_REG_IDX(id)		\
-	(CSI_REG_BASE_PORT(id) + 0x348)
-/* TPG: mask_cfg */
-#define CSI_REG_PIXGEN_TPG_HCNT_MASK_REG_IDX(id)	\
-	(CSI_REG_BASE_PORT(id) + 0x34C)
-#define CSI_REG_PIXGEN_TPG_VCNT_MASK_REG_IDX(id)	\
-	(CSI_REG_BASE_PORT(id) + 0x350)
-#define CSI_REG_PIXGEN_TPG_XYCNT_MASK_REG_IDX(id)	\
-	(CSI_REG_BASE_PORT(id) + 0x354)
-/* TPG: delta_cfg */
-#define CSI_REG_PIXGEN_TPG_HCNT_DELTA_REG_IDX(id)	\
-	(CSI_REG_BASE_PORT(id) + 0x358)
-#define CSI_REG_PIXGEN_TPG_VCNT_DELTA_REG_IDX(id)	\
-	(CSI_REG_BASE_PORT(id) + 0x35C)
-/* TPG: color_cfg */
-#define CSI_REG_PIXGEN_TPG_R1_REG_IDX(id)	(CSI_REG_BASE_PORT(id) + 0x360)
-#define CSI_REG_PIXGEN_TPG_G1_REG_IDX(id)	(CSI_REG_BASE_PORT(id) + 0x364)
-#define CSI_REG_PIXGEN_TPG_B1_REG_IDX(id)	(CSI_REG_BASE_PORT(id) + 0x368)
-#define CSI_REG_PIXGEN_TPG_R2_REG_IDX(id)	(CSI_REG_BASE_PORT(id) + 0x36C)
-#define CSI_REG_PIXGEN_TPG_G2_REG_IDX(id)	(CSI_REG_BASE_PORT(id) + 0x370)
-#define CSI_REG_PIXGEN_TPG_B2_REG_IDX(id)	(CSI_REG_BASE_PORT(id) + 0x374)
-
-#define CSI_REG_PIXGEN_PRBS_RSTVAL_REG0	CSI_REG_PIXGEN_PRBS_RSTVAL_REG0_IDX(0)
-#define CSI_REG_PIXGEN_PRBS_RSTVAL_REG1	CSI_REG_PIXGEN_PRBS_RSTVAL_REG1_IDX(0)
-#define CSI_REG_PIXGEN_COM_ENABLE_REG	CSI_REG_PIXGEN_COM_ENABLE_REG_IDX(0)
-#define CSI_REG_PIXGEN_TPG_MODE_REG	CSI_REG_PIXGEN_TPG_MODE_REG_IDX(0)
-#define CSI_REG_PIXGEN_TPG_R1_REG	CSI_REG_PIXGEN_TPG_R1_REG_IDX(0)
-#define CSI_REG_PIXGEN_TPG_G1_REG	CSI_REG_PIXGEN_TPG_G1_REG_IDX(0)
-#define CSI_REG_PIXGEN_TPG_B1_REG	CSI_REG_PIXGEN_TPG_B1_REG_IDX(0)
-#define CSI_REG_PIXGEN_TPG_R2_REG	CSI_REG_PIXGEN_TPG_R2_REG_IDX(0)
-#define CSI_REG_PIXGEN_TPG_G2_REG	CSI_REG_PIXGEN_TPG_G2_REG_IDX(0)
-#define CSI_REG_PIXGEN_TPG_B2_REG	CSI_REG_PIXGEN_TPG_B2_REG_IDX(0)
-#define CSI_REG_PIXGEN_TPG_HCNT_MASK_REG CSI_REG_PIXGEN_TPG_HCNT_MASK_REG_IDX(0)
-#define CSI_REG_PIXGEN_TPG_VCNT_MASK_REG CSI_REG_PIXGEN_TPG_VCNT_MASK_REG_IDX(0)
-#define CSI_REG_PIXGEN_TPG_XYCNT_MASK_REG	\
-	CSI_REG_PIXGEN_TPG_XYCNT_MASK_REG_IDX(0)
-
-#define CSI_REG_PIXGEN_SYNG_NOF_FRAME_REG	\
-	CSI_REG_PIXGEN_SYNG_NOF_FRAME_REG_IDX(0)
-#define CSI_REG_PIXGEN_SYNG_NOF_LINE_REG	\
-	CSI_REG_PIXGEN_SYNG_NOF_LINE_REG_IDX(0)
-#define CSI_REG_PIXGEN_SYNG_HBLANK_CYC_REG	\
-	CSI_REG_PIXGEN_SYNG_HBLANK_CYC_REG_IDX(0)
-#define CSI_REG_PIXGEN_SYNG_VBLANK_CYC_REG	\
-	CSI_REG_PIXGEN_SYNG_VBLANK_CYC_REG_IDX(0)
-#define CSI_REG_PIXGEN_SYNG_NOF_PIXEL_REG	\
-	CSI_REG_PIXGEN_SYNG_NOF_PIXEL_REG_IDX(0)
-#define CSI_REG_PIXGEN_COM_WCOUNT_REG	CSI_REG_PIXGEN_COM_WCOUNT_REG_IDX(0)
-#define CSI_REG_PIXGEN_COM_DTYPE_REG	CSI_REG_PIXGEN_COM_DTYPE_REG_IDX(0)
-#define CSI_REG_PIXGEN_COM_VTYPE_REG	CSI_REG_PIXGEN_COM_VTYPE_REG_IDX(0)
-#define CSI_REG_PIXGEN_COM_VCHAN_REG	CSI_REG_PIXGEN_COM_VCHAN_REG_IDX(0)
-#define CSI_REG_PIXGEN_TPG_HCNT_DELTA_REG	\
-	CSI_REG_PIXGEN_TPG_HCNT_DELTA_REG_IDX(0)
-#define CSI_REG_PIXGEN_TPG_VCNT_DELTA_REG	\
-	CSI_REG_PIXGEN_TPG_VCNT_DELTA_REG_IDX(0)
-
-/* CSI HUB General Purpose Registers */
-#define CSI_REG_HUB_GPREG_SRST			(CSI_REG_BASE + 0x18000)
-#define CSI_REG_HUB_GPREG_SLV_REG_SRST		(CSI_REG_BASE + 0x18004)
-#define CSI_REG_HUB_GPREG_PHY_CONTROL(id)	\
-	(CSI_REG_BASE + 0x18008 + (id) * 0x8)
-#define CSI_REG_HUB_GPREG_PHY_CONTROL_RESET		BIT(4)
-#define CSI_REG_HUB_GPREG_PHY_CONTROL_PWR_EN		BIT(0)
-#define CSI_REG_HUB_GPREG_PHY_STATUS(id)	\
-	(CSI_REG_BASE + 0x1800c + (id) * 0x8)
-#define CSI_REG_HUB_GPREG_PHY_STATUS_POWER_ACK		BIT(0)
-#define CSI_REG_HUB_GPREG_PHY_STATUS_PHY_READY		BIT(4)
-
-#define CSI_REG_HUB_DRV_ACCESS_PORT(id)	(CSI_REG_BASE + 0x18018 + (id) * 4)
-#define CSI_REG_HUB_FW_ACCESS_PORT(id)	(CSI_REG_BASE + 0x17000 + (id) * 4)
-
-enum CSI_PORT_CLK_GATING_SWITCH {
-	CSI_PORT_CLK_GATING_OFF = 0,
-	CSI_PORT_CLK_GATING_ON = 1,
-};
-
-#define CSI_REG_BASE_HUB_IRQ                        0x18200
-
-#define IPU_NUM_OF_DLANE_REG_PORT0      2
-#define IPU_NUM_OF_DLANE_REG_PORT1      4
-#define IPU_NUM_OF_DLANE_REG_PORT2      4
-#define IPU_NUM_OF_DLANE_REG_PORT3      2
-#define IPU_NUM_OF_DLANE_REG_PORT4      2
-#define IPU_NUM_OF_DLANE_REG_PORT5      4
-#define IPU_NUM_OF_DLANE_REG_PORT6      4
-#define IPU_NUM_OF_DLANE_REG_PORT7      2
-
-/* ipu6se support 2 SIPs, 2 port per SIP, 4 ports 0..3
- * sip0 - 0, 1
- * sip1 - 2, 3
- * 0 and 2 support 4 data lanes, 1 and 3 support 2 data lanes
- * all offset are base from isys base address
- */
-
-#define CSI2_HUB_GPREG_SIP_SRST(sip)			(0x238038 + (sip) * 4)
-#define CSI2_HUB_GPREG_SIP_FB_PORT_CFG(sip)		(0x238050 + (sip) * 4)
-
-#define CSI2_HUB_GPREG_DPHY_TIMER_INCR			(0x238040)
-#define CSI2_HUB_GPREG_HPLL_FREQ			(0x238044)
-#define CSI2_HUB_GPREG_IS_CLK_RATIO			(0x238048)
-#define CSI2_HUB_GPREG_HPLL_FREQ_ISCLK_RATE_OVERRIDE	(0x23804c)
-#define CSI2_HUB_GPREG_PORT_CLKGATING_DISABLE		(0x238058)
-#define CSI2_HUB_GPREG_SIP0_CSI_RX_A_CONTROL		(0x23805c)
-#define CSI2_HUB_GPREG_SIP0_CSI_RX_B_CONTROL		(0x238088)
-#define CSI2_HUB_GPREG_SIP1_CSI_RX_A_CONTROL		(0x2380a4)
-#define CSI2_HUB_GPREG_SIP1_CSI_RX_B_CONTROL		(0x2380d0)
-
-#define CSI2_SIP_TOP_CSI_RX_BASE(sip)		(0x23805c + (sip) * 0x48)
-#define CSI2_SIP_TOP_CSI_RX_PORT_BASE_0(port)	(0x23805c + ((port) / 2) * 0x48)
-#define CSI2_SIP_TOP_CSI_RX_PORT_BASE_1(port)	(0x238088 + ((port) / 2) * 0x48)
-
-/* offset from port base */
-#define CSI2_SIP_TOP_CSI_RX_PORT_CONTROL		(0x0)
-#define CSI2_SIP_TOP_CSI_RX_DLY_CNT_TERMEN_CLANE	(0x4)
-#define CSI2_SIP_TOP_CSI_RX_DLY_CNT_SETTLE_CLANE	(0x8)
-#define CSI2_SIP_TOP_CSI_RX_DLY_CNT_TERMEN_DLANE(lane)	(0xc + (lane) * 8)
-#define CSI2_SIP_TOP_CSI_RX_DLY_CNT_SETTLE_DLANE(lane)	(0x10 + (lane) * 8)
-
-#endif /* IPU6_ISYS_CSI2_REG_H */
diff --git a/drivers/media/pci/intel/ipu6/ipu-platform-isys.h b/drivers/media/pci/intel/ipu6/ipu-platform-isys.h
deleted file mode 100644
index 82ca971cd996..000000000000
--- a/drivers/media/pci/intel/ipu6/ipu-platform-isys.h
+++ /dev/null
@@ -1,26 +0,0 @@
-/* SPDX-License-Identifier: GPL-2.0 */
-/* Copyright (C) 2020 Intel Corporation */
-
-#ifndef IPU_PLATFORM_ISYS_H
-#define IPU_PLATFORM_ISYS_H
-
-#define IPU_ISYS_ENTITY_PREFIX		"Intel IPU6"
-
-/*
- * FW support max 16 streams
- */
-#define IPU_ISYS_MAX_STREAMS		16
-
-#define ISYS_UNISPART_IRQS	(IPU_ISYS_UNISPART_IRQ_SW |	\
-				 IPU_ISYS_UNISPART_IRQ_CSI0 |	\
-				 IPU_ISYS_UNISPART_IRQ_CSI1)
-
-/* IPU6 ISYS compression alignment */
-#define IPU_ISYS_COMPRESSION_LINE_ALIGN		512
-#define IPU_ISYS_COMPRESSION_HEIGHT_ALIGN	1
-#define IPU_ISYS_COMPRESSION_TILE_SIZE_BYTES	512
-#define IPU_ISYS_COMPRESSION_PAGE_ALIGN		0x1000
-#define IPU_ISYS_COMPRESSION_TILE_STATUS_BITS	4
-#define IPU_ISYS_COMPRESSION_MAX		3
-
-#endif
diff --git a/drivers/media/pci/intel/ipu6/ipu-platform-psys.h b/drivers/media/pci/intel/ipu6/ipu-platform-psys.h
deleted file mode 100644
index e44eaf3b580f..000000000000
--- a/drivers/media/pci/intel/ipu6/ipu-platform-psys.h
+++ /dev/null
@@ -1,78 +0,0 @@
-/* SPDX-License-Identifier: GPL-2.0 */
-/* Copyright (C) 2020 Intel Corporation */
-
-#ifndef IPU_PLATFORM_PSYS_H
-#define IPU_PLATFORM_PSYS_H
-
-#include "ipu-psys.h"
-#include <uapi/linux/ipu-psys.h>
-
-#define IPU_PSYS_BUF_SET_POOL_SIZE 8
-#define IPU_PSYS_BUF_SET_MAX_SIZE 1024
-
-struct ipu_fw_psys_buffer_set;
-
-enum ipu_psys_cmd_state {
-	KCMD_STATE_PPG_NEW,
-	KCMD_STATE_PPG_START,
-	KCMD_STATE_PPG_ENQUEUE,
-	KCMD_STATE_PPG_STOP,
-	KCMD_STATE_PPG_COMPLETE
-};
-
-struct ipu_psys_scheduler {
-	struct list_head ppgs;
-	struct mutex bs_mutex;  /* Protects buf_set field */
-	struct list_head buf_sets;
-};
-
-enum ipu_psys_ppg_state {
-	PPG_STATE_START = (1 << 0),
-	PPG_STATE_STARTING = (1 << 1),
-	PPG_STATE_STARTED = (1 << 2),
-	PPG_STATE_RUNNING = (1 << 3),
-	PPG_STATE_SUSPEND = (1 << 4),
-	PPG_STATE_SUSPENDING = (1 << 5),
-	PPG_STATE_SUSPENDED = (1 << 6),
-	PPG_STATE_RESUME = (1 << 7),
-	PPG_STATE_RESUMING = (1 << 8),
-	PPG_STATE_RESUMED = (1 << 9),
-	PPG_STATE_STOP = (1 << 10),
-	PPG_STATE_STOPPING = (1 << 11),
-	PPG_STATE_STOPPED = (1 << 12),
-};
-
-struct ipu_psys_ppg {
-	struct ipu_psys_pg *kpg;
-	struct ipu_psys_fh *fh;
-	struct list_head list;
-	struct list_head sched_list;
-	u64 token;
-	void *manifest;
-	struct mutex mutex;     /* Protects kcmd and ppg state field */
-	struct list_head kcmds_new_list;
-	struct list_head kcmds_processing_list;
-	struct list_head kcmds_finished_list;
-	enum ipu_psys_ppg_state state;
-	u32 pri_base;
-	int pri_dynamic;
-};
-
-struct ipu_psys_buffer_set {
-	struct list_head list;
-	struct ipu_fw_psys_buffer_set *buf_set;
-	size_t size;
-	size_t buf_set_size;
-	dma_addr_t dma_addr;
-	void *kaddr;
-	struct ipu_psys_kcmd *kcmd;
-};
-
-int ipu_psys_kcmd_start(struct ipu_psys *psys, struct ipu_psys_kcmd *kcmd);
-void ipu_psys_kcmd_complete(struct ipu_psys_ppg *kppg,
-			    struct ipu_psys_kcmd *kcmd,
-			    int error);
-int ipu_psys_fh_init(struct ipu_psys_fh *fh);
-int ipu_psys_fh_deinit(struct ipu_psys_fh *fh);
-
-#endif /* IPU_PLATFORM_PSYS_H */
diff --git a/drivers/media/pci/intel/ipu6/ipu-platform-regs.h b/drivers/media/pci/intel/ipu6/ipu-platform-regs.h
deleted file mode 100644
index be6c7f298e6d..000000000000
--- a/drivers/media/pci/intel/ipu6/ipu-platform-regs.h
+++ /dev/null
@@ -1,333 +0,0 @@
-/* SPDX-License-Identifier: GPL-2.0 */
-/* Copyright (C) 2018 - 2020 Intel Corporation */
-
-#ifndef IPU_PLATFORM_REGS_H
-#define IPU_PLATFORM_REGS_H
-
-/*
- * IPU6 uses uniform address within IPU, therefore all subsystem registers
- * locates in one signle space starts from 0 but in different sctions with
- * different addresses, the subsystem offsets are defined to 0 as the
- * register definition will have the address offset to 0.
- */
-#define IPU_UNIFIED_OFFSET			0
-
-#define IPU_ISYS_IOMMU0_OFFSET		0x2E0000
-#define IPU_ISYS_IOMMU1_OFFSET		0x2E0500
-#define IPU_ISYS_IOMMUI_OFFSET		0x2E0A00
-
-#define IPU_PSYS_IOMMU0_OFFSET		0x1B0000
-#define IPU_PSYS_IOMMU1_OFFSET		0x1B0700
-#define IPU_PSYS_IOMMU1R_OFFSET		0x1B0E00
-#define IPU_PSYS_IOMMUI_OFFSET		0x1B1500
-
-/* the offset from IOMMU base register */
-#define IPU_MMU_L1_STREAM_ID_REG_OFFSET	0x0c
-#define IPU_MMU_L2_STREAM_ID_REG_OFFSET	0x4c
-#define IPU_PSYS_MMU1W_L2_STREAM_ID_REG_OFFSET	0x8c
-
-#define IPU_MMU_INFO_OFFSET		0x8
-
-#define IPU_ISYS_SPC_OFFSET		0x210000
-
-#define IPU6SE_PSYS_SPC_OFFSET		0x110000
-#define IPU6_PSYS_SPC_OFFSET		0x118000
-
-#define IPU_ISYS_DMEM_OFFSET		0x200000
-#define IPU_PSYS_DMEM_OFFSET		0x100000
-
-#define IPU_REG_ISYS_CSI_TOP_CTRL0_IRQ_EDGE		0x238200
-#define IPU_REG_ISYS_CSI_TOP_CTRL0_IRQ_MASK		0x238204
-#define IPU_REG_ISYS_CSI_TOP_CTRL0_IRQ_STATUS		0x238208
-#define IPU_REG_ISYS_CSI_TOP_CTRL0_IRQ_CLEAR		0x23820c
-#define IPU_REG_ISYS_CSI_TOP_CTRL0_IRQ_ENABLE		0x238210
-#define IPU_REG_ISYS_CSI_TOP_CTRL0_IRQ_LEVEL_NOT_PULSE	0x238214
-
-#define IPU_REG_ISYS_CSI_TOP_CTRL1_IRQ_EDGE		0x238220
-#define IPU_REG_ISYS_CSI_TOP_CTRL1_IRQ_MASK		0x238224
-#define IPU_REG_ISYS_CSI_TOP_CTRL1_IRQ_STATUS		0x238228
-#define IPU_REG_ISYS_CSI_TOP_CTRL1_IRQ_CLEAR		0x23822c
-#define IPU_REG_ISYS_CSI_TOP_CTRL1_IRQ_ENABLE		0x238230
-#define IPU_REG_ISYS_CSI_TOP_CTRL1_IRQ_LEVEL_NOT_PULSE	0x238234
-
-#define IPU_REG_ISYS_UNISPART_IRQ_EDGE			0x27c000
-#define IPU_REG_ISYS_UNISPART_IRQ_MASK			0x27c004
-#define IPU_REG_ISYS_UNISPART_IRQ_STATUS		0x27c008
-#define IPU_REG_ISYS_UNISPART_IRQ_CLEAR			0x27c00c
-#define IPU_REG_ISYS_UNISPART_IRQ_ENABLE			0x27c010
-#define IPU_REG_ISYS_UNISPART_IRQ_LEVEL_NOT_PULSE	0x27c014
-#define IPU_REG_ISYS_UNISPART_SW_IRQ_REG			0x27c414
-#define IPU_REG_ISYS_UNISPART_SW_IRQ_MUX_REG		0x27c418
-#define IPU_ISYS_UNISPART_IRQ_CSI0			BIT(2)
-#define IPU_ISYS_UNISPART_IRQ_CSI1			BIT(3)
-#define IPU_ISYS_UNISPART_IRQ_SW			BIT(22)
-
-#define IPU_REG_ISYS_ISL_TOP_IRQ_EDGE			0x2b0200
-#define IPU_REG_ISYS_ISL_TOP_IRQ_MASK			0x2b0204
-#define IPU_REG_ISYS_ISL_TOP_IRQ_STATUS			0x2b0208
-#define IPU_REG_ISYS_ISL_TOP_IRQ_CLEAR			0x2b020c
-#define IPU_REG_ISYS_ISL_TOP_IRQ_ENABLE			0x2b0210
-#define IPU_REG_ISYS_ISL_TOP_IRQ_LEVEL_NOT_PULSE	0x2b0214
-
-#define IPU_REG_ISYS_CMPR_TOP_IRQ_EDGE			0x2d2100
-#define IPU_REG_ISYS_CMPR_TOP_IRQ_MASK			0x2d2104
-#define IPU_REG_ISYS_CMPR_TOP_IRQ_STATUS		0x2d2108
-#define IPU_REG_ISYS_CMPR_TOP_IRQ_CLEAR			0x2d210c
-#define IPU_REG_ISYS_CMPR_TOP_IRQ_ENABLE		0x2d2110
-#define IPU_REG_ISYS_CMPR_TOP_IRQ_LEVEL_NOT_PULSE	0x2d2114
-
-/* CDC Burst collector thresholds for isys - 3 FIFOs i = 0..2 */
-#define IPU_REG_ISYS_CDC_THRESHOLD(i)		(0x27c400 + ((i) * 4))
-
-#define IPU_ISYS_CSI_PHY_NUM				2
-#define IPU_CSI_IRQ_NUM_PER_PIPE			4
-#define IPU6SE_ISYS_CSI_PORT_NUM			4
-#define IPU6_ISYS_CSI_PORT_NUM				8
-
-#define IPU_ISYS_CSI_PORT_IRQ(irq_num)		(1 << (irq_num))
-
-/* PSYS Info bits*/
-#define IPU_REG_PSYS_INFO_SEG_CMEM_MASTER(a)	(0x2C + ((a) * 12))
-#define IPU_REG_PSYS_INFO_SEG_XMEM_MASTER(a)	(0x5C + ((a) * 12))
-
-/* PKG DIR OFFSET in IMR in secure mode */
-#define IPU_PKG_DIR_IMR_OFFSET			0x40
-
-#define IPU_ISYS_REG_SPC_STATUS_CTRL		0x0
-
-#define IPU_ISYS_SPC_STATUS_START			BIT(1)
-#define IPU_ISYS_SPC_STATUS_RUN				BIT(3)
-#define IPU_ISYS_SPC_STATUS_READY			BIT(5)
-#define IPU_ISYS_SPC_STATUS_CTRL_ICACHE_INVALIDATE	BIT(12)
-#define IPU_ISYS_SPC_STATUS_ICACHE_PREFETCH		BIT(13)
-
-#define IPU_PSYS_REG_SPC_STATUS_CTRL		0x0
-#define IPU_PSYS_REG_SPC_START_PC		0x4
-#define IPU_PSYS_REG_SPC_ICACHE_BASE		0x10
-#define IPU_REG_PSYS_INFO_SEG_0_CONFIG_ICACHE_MASTER	0x14
-
-#define IPU_PSYS_SPC_STATUS_START			BIT(1)
-#define IPU_PSYS_SPC_STATUS_RUN				BIT(3)
-#define IPU_PSYS_SPC_STATUS_READY			BIT(5)
-#define IPU_PSYS_SPC_STATUS_CTRL_ICACHE_INVALIDATE	BIT(12)
-#define IPU_PSYS_SPC_STATUS_ICACHE_PREFETCH		BIT(13)
-
-#define IPU_PSYS_REG_SPP0_STATUS_CTRL			0x20000
-
-#define IPU_INFO_ENABLE_SNOOP			BIT(0)
-#define IPU_INFO_DEC_FORCE_FLUSH		BIT(1)
-#define IPU_INFO_DEC_PASS_THRU			BIT(2)
-#define IPU_INFO_ZLW                            BIT(3)
-#define IPU_INFO_STREAM_ID_SET(id)		(((id) & 0x1F) << 4)
-#define IPU_INFO_REQUEST_DESTINATION_IOSF	BIT(9)
-#define IPU_INFO_IMR_BASE			BIT(10)
-#define IPU_INFO_IMR_DESTINED			BIT(11)
-
-#define IPU_INFO_REQUEST_DESTINATION_PRIMARY IPU_INFO_REQUEST_DESTINATION_IOSF
-
-/* Trace unit related register definitions */
-#define TRACE_REG_MAX_ISYS_OFFSET	0xfffff
-#define TRACE_REG_MAX_PSYS_OFFSET	0xfffff
-#define IPU_ISYS_OFFSET			IPU_ISYS_DMEM_OFFSET
-#define IPU_PSYS_OFFSET			IPU_PSYS_DMEM_OFFSET
-/* ISYS trace unit registers */
-/* Trace unit base offset */
-#define IPU_TRACE_REG_IS_TRACE_UNIT_BASE		0x27d000
-/* Trace monitors */
-#define IPU_TRACE_REG_IS_SP_EVQ_BASE		0x211000
-/* GPC blocks */
-#define IPU_TRACE_REG_IS_SP_GPC_BASE		0x210800
-#define IPU_TRACE_REG_IS_ISL_GPC_BASE		0x2b0a00
-#define IPU_TRACE_REG_IS_MMU_GPC_BASE		0x2e0f00
-/* each CSI2 port has a dedicated trace monitor, index 0..7 */
-#define IPU_TRACE_REG_CSI2_TM_BASE(port)	(0x220400 + 0x1000 * (port))
-
-/* Trace timers */
-#define IPU_TRACE_REG_IS_GPREG_TRACE_TIMER_RST_N		0x27c410
-#define TRACE_REG_GPREG_TRACE_TIMER_RST_OFF		BIT(0)
-
-/* SIG2CIO */
-#define IPU_TRACE_REG_CSI2_PORT_SIG2SIO_GR_BASE(port)		\
-			(0x220e00 + (port) * 0x1000)
-
-/* PSYS trace unit registers */
-/* Trace unit base offset */
-#define IPU_TRACE_REG_PS_TRACE_UNIT_BASE		0x1b4000
-/* Trace monitors */
-#define IPU_TRACE_REG_PS_SPC_EVQ_BASE			0x119000
-#define IPU_TRACE_REG_PS_SPP0_EVQ_BASE			0x139000
-
-/* GPC blocks */
-#define IPU_TRACE_REG_PS_SPC_GPC_BASE			0x118800
-#define IPU_TRACE_REG_PS_SPP0_GPC_BASE			0x138800
-#define IPU_TRACE_REG_PS_MMU_GPC_BASE			0x1b1b00
-
-/* Trace timers */
-#define IPU_TRACE_REG_PS_GPREG_TRACE_TIMER_RST_N	0x1aa714
-
-/*
- * s2m_pixel_soc_pixel_remapping is dedicated for the enableing of the
- * pixel s2m remp ability.Remap here  means that s2m rearange the order
- * of the pixels in each 4 pixels group.
- * For examle, mirroring remping means that if input's 4 first pixels
- * are 1 2 3 4 then in output we should see 4 3 2 1 in this 4 first pixels.
- * 0xE4 is from s2m MAS document. It means no remaping.
- */
-#define S2M_PIXEL_SOC_PIXEL_REMAPPING_FLAG_NO_REMAPPING 0xE4
-/*
- * csi_be_soc_pixel_remapping is for the enabling of the csi\mipi be pixel
- * remapping feature. This remapping is exactly like the stream2mmio remapping.
- */
-#define CSI_BE_SOC_PIXEL_REMAPPING_FLAG_NO_REMAPPING    0xE4
-
-#define IPU_REG_DMA_TOP_AB_GROUP1_BASE_ADDR         0x1AE000
-#define IPU_REG_DMA_TOP_AB_GROUP2_BASE_ADDR         0x1AF000
-#define IPU_REG_DMA_TOP_AB_RING_MIN_OFFSET(n)       (0x4 + (n) * 0xC)
-#define IPU_REG_DMA_TOP_AB_RING_MAX_OFFSET(n)       (0x8 + (n) * 0xC)
-#define IPU_REG_DMA_TOP_AB_RING_ACCESS_OFFSET(n)    (0xC + (n) * 0xC)
-
-enum ipu_device_ab_group1_target_id {
-	IPU_DEVICE_AB_GROUP1_TARGET_ID_R0_SPC_DMEM,
-	IPU_DEVICE_AB_GROUP1_TARGET_ID_R1_SPC_DMEM,
-	IPU_DEVICE_AB_GROUP1_TARGET_ID_R2_SPC_DMEM,
-	IPU_DEVICE_AB_GROUP1_TARGET_ID_R3_SPC_STATUS_REG,
-	IPU_DEVICE_AB_GROUP1_TARGET_ID_R4_SPC_MASTER_BASE_ADDR,
-	IPU_DEVICE_AB_GROUP1_TARGET_ID_R5_SPC_PC_STALL,
-	IPU_DEVICE_AB_GROUP1_TARGET_ID_R6_SPC_EQ,
-	IPU_DEVICE_AB_GROUP1_TARGET_ID_R7_SPC_RESERVED,
-	IPU_DEVICE_AB_GROUP1_TARGET_ID_R8_SPC_RESERVED,
-	IPU_DEVICE_AB_GROUP1_TARGET_ID_R9_SPP0,
-	IPU_DEVICE_AB_GROUP1_TARGET_ID_R10_SPP1,
-	IPU_DEVICE_AB_GROUP1_TARGET_ID_R11_CENTRAL_R1,
-	IPU_DEVICE_AB_GROUP1_TARGET_ID_R12_IRQ,
-	IPU_DEVICE_AB_GROUP1_TARGET_ID_R13_CENTRAL_R2,
-	IPU_DEVICE_AB_GROUP1_TARGET_ID_R14_DMA,
-	IPU_DEVICE_AB_GROUP1_TARGET_ID_R15_DMA,
-	IPU_DEVICE_AB_GROUP1_TARGET_ID_R16_GP,
-	IPU_DEVICE_AB_GROUP1_TARGET_ID_R17_ZLW_INSERTER,
-	IPU_DEVICE_AB_GROUP1_TARGET_ID_R18_AB,
-};
-
-enum nci_ab_access_mode {
-	NCI_AB_ACCESS_MODE_RW,	/* read & write */
-	NCI_AB_ACCESS_MODE_RO,	/* read only */
-	NCI_AB_ACCESS_MODE_WO,	/* write only */
-	NCI_AB_ACCESS_MODE_NA	/* No access at all */
-};
-
-/*
- * 3:0 CSI_PORT.irq_out[3:0] CSI_PORT_CTRL0 IRQ outputs (4bits)
- * [0] CSI_PORT.IRQ_CTRL0_csi
- * [1] CSI_PORT.IRQ_CTRL1_csi_sync
- * [2] CSI_PORT.IRQ_CTRL2_s2m_sids0to7
- * [3] CSI_PORT.IRQ_CTRL3_s2m_sids8to15
- */
-#define IPU_ISYS_UNISPART_IRQ_CSI2(port)		\
-				   (0x3 << ((port) * IPU_CSI_IRQ_NUM_PER_PIPE))
-
-/* IRQ-related registers in PSYS */
-#define IPU_REG_PSYS_GPDEV_IRQ_EDGE		0x1aa200
-#define IPU_REG_PSYS_GPDEV_IRQ_MASK		0x1aa204
-#define IPU_REG_PSYS_GPDEV_IRQ_STATUS		0x1aa208
-#define IPU_REG_PSYS_GPDEV_IRQ_CLEAR		0x1aa20c
-#define IPU_REG_PSYS_GPDEV_IRQ_ENABLE		0x1aa210
-#define IPU_REG_PSYS_GPDEV_IRQ_LEVEL_NOT_PULSE	0x1aa214
-/* There are 8 FW interrupts, n = 0..7 */
-#define IPU_PSYS_GPDEV_FWIRQ0			5
-#define IPU_PSYS_GPDEV_FWIRQ1			6
-#define IPU_PSYS_GPDEV_FWIRQ2			7
-#define IPU_PSYS_GPDEV_FWIRQ3			8
-#define IPU_PSYS_GPDEV_FWIRQ4			9
-#define IPU_PSYS_GPDEV_FWIRQ5			10
-#define IPU_PSYS_GPDEV_FWIRQ6			11
-#define IPU_PSYS_GPDEV_FWIRQ7			12
-#define IPU_PSYS_GPDEV_IRQ_FWIRQ(n)		(1 << (n))
-#define IPU_REG_PSYS_GPDEV_FWIRQ(n)		(4 * (n) + 0x1aa100)
-
-/*
- * ISYS GPC (Gerneral Performance Counters) Registers
- */
-#define IPU_ISYS_GPC_BASE			0x2E0000
-#define IPU_ISYS_GPREG_TRACE_TIMER_RST		0x27C410
-enum ipu_isf_cdc_mmu_gpc_registers {
-	IPU_ISF_CDC_MMU_GPC_SOFT_RESET  = 0x0F00,
-	IPU_ISF_CDC_MMU_GPC_OVERALL_ENABLE  = 0x0F04,
-	IPU_ISF_CDC_MMU_GPC_ENABLE0  = 0x0F20,
-	IPU_ISF_CDC_MMU_GPC_VALUE0  = 0x0F60,
-	IPU_ISF_CDC_MMU_GPC_CNT_SEL0 = 0x0FA0,
-};
-
-/*
- * GPC (Gerneral Performance Counters) Registers
- */
-#define IPU_GPC_BASE 0x1B0000
-#define IPU_GPREG_TRACE_TIMER_RST	0x1AA714
-enum ipu_cdc_mmu_gpc_registers {
-	IPU_CDC_MMU_GPC_SOFT_RESET  = 0x1B00,
-	IPU_CDC_MMU_GPC_OVERALL_ENABLE  = 0x1B04,
-	IPU_CDC_MMU_GPC_TRACE_HEADER  = 0x1B08,
-	IPU_CDC_MMU_GPC_TRACE_ADDR  = 0x1B0C,
-	IPU_CDC_MMU_GPC_TRACE_ENABLE_NPK  = 0x1B10,
-	IPU_CDC_MMU_GPC_TRACE_ENABLE_DDR  = 0x1B14,
-	IPU_CDC_MMU_GPC_LP_CLEAR  = 0x1B18,
-	IPU_CDC_MMU_GPC_LOST_PACKET  = 0x1B1C,
-	IPU_CDC_MMU_GPC_ENABLE0  = 0x1B20,
-	IPU_CDC_MMU_GPC_VALUE0  = 0x1B60,
-	IPU_CDC_MMU_GPC_CNT_SEL0 = 0x1BA0,
-	IPU_CDC_MMU_GPC_START_SEL0 = 0x1BE0,
-	IPU_CDC_MMU_GPC_STOP_SEL0 = 0x1C20,
-	IPU_CDC_MMU_GPC_MSG_SEL0 = 0x1C60,
-	IPU_CDC_MMU_GPC_PLOAD_SEL0 = 0x1CA0,
-	IPU_CDC_MMU_GPC_IRQ_TRIGGER_VALUE0 = 0x1CE0,
-	IPU_CDC_MMU_GPC_IRQ_TIMER_SEL0 = 0x1D20,
-	IPU_CDC_MMU_GPC_IRQ_ENABLE0 = 0x1D60,
-	IPU_CDC_MMU_GPC_END = 0x1D9C
-};
-
-#define IPU_GPC_SENSE_OFFSET		7
-#define IPU_GPC_ROUTE_OFFSET		5
-#define IPU_GPC_SOURCE_OFFSET		0
-
-/*
- * Signals monitored by GPC
- */
-#define IPU_GPC_TRACE_TLB_MISS_MMU_LB_IDX		0
-#define IPU_GPC_TRACE_FULL_WRITE_LB_IDX			1
-#define IPU_GPC_TRACE_NOFULL_WRITE_LB_IDX		2
-#define IPU_GPC_TRACE_FULL_READ_LB_IDX			3
-#define IPU_GPC_TRACE_NOFULL_READ_LB_IDX		4
-#define IPU_GPC_TRACE_STALL_LB_IDX			5
-#define IPU_GPC_TRACE_ZLW_LB_IDX			6
-#define IPU_GPC_TRACE_TLB_MISS_MMU_HBTX_IDX		7
-#define IPU_GPC_TRACE_FULL_WRITE_HBTX_IDX		8
-#define IPU_GPC_TRACE_NOFULL_WRITE_HBTX_IDX		9
-#define IPU_GPC_TRACE_FULL_READ_HBTX_IDX		10
-#define IPU_GPC_TRACE_STALL_HBTX_IDX			11
-#define IPU_GPC_TRACE_ZLW_HBTX_IDX			12
-#define IPU_GPC_TRACE_TLB_MISS_MMU_HBFRX_IDX		13
-#define IPU_GPC_TRACE_FULL_READ_HBFRX_IDX		14
-#define IPU_GPC_TRACE_NOFULL_READ_HBFRX_IDX		15
-#define IPU_GPC_TRACE_STALL_HBFRX_IDX			16
-#define IPU_GPC_TRACE_ZLW_HBFRX_IDX			17
-#define IPU_GPC_TRACE_TLB_MISS_ICACHE_IDX		18
-#define IPU_GPC_TRACE_FULL_READ_ICACHE_IDX		19
-#define IPU_GPC_TRACE_STALL_ICACHE_IDX			20
-/*
- * psys subdomains power request regs
- */
-enum ipu_device_buttress_psys_domain_pos {
-	IPU_PSYS_SUBDOMAIN_ISA		= 0,
-	IPU_PSYS_SUBDOMAIN_PSA		= 1,
-	IPU_PSYS_SUBDOMAIN_BB		= 2,
-	IPU_PSYS_SUBDOMAIN_IDSP1	= 3, /* only in IPU6M */
-	IPU_PSYS_SUBDOMAIN_IDSP2	= 4, /* only in IPU6M */
-};
-
-#define IPU_PSYS_SUBDOMAINS_POWER_MASK  (BIT(IPU_PSYS_SUBDOMAIN_ISA) | \
-					 BIT(IPU_PSYS_SUBDOMAIN_PSA) | \
-					 BIT(IPU_PSYS_SUBDOMAIN_BB))
-
-#define IPU_PSYS_SUBDOMAINS_POWER_REQ                   0xa0
-#define IPU_PSYS_SUBDOMAINS_POWER_STATUS                0xa4
-
-#endif /* IPU_PLATFORM_REGS_H */
diff --git a/drivers/media/pci/intel/ipu6/ipu-platform-resources.h b/drivers/media/pci/intel/ipu6/ipu-platform-resources.h
deleted file mode 100644
index 1f3554c0e5af..000000000000
--- a/drivers/media/pci/intel/ipu6/ipu-platform-resources.h
+++ /dev/null
@@ -1,103 +0,0 @@
-/* SPDX-License-Identifier: GPL-2.0 */
-/* Copyright (C) 2018 - 2020 Intel Corporation */
-
-#ifndef IPU_PLATFORM_RESOURCES_COMMON_H
-#define IPU_PLATFORM_RESOURCES_COMMON_H
-
-#define IPU_FW_PSYS_N_PADDING_UINT8_IN_PROGRAM_MANIFEST                 0
-
-#define	IPU_FW_PSYS_N_PADDING_UINT8_IN_PROCESS_STRUCT			0
-#define	IPU_FW_PSYS_N_PADDING_UINT8_IN_PROCESS_GROUP_STRUCT		2
-#define	IPU_FW_PSYS_N_PADDING_UINT8_IN_PROGRAM_MANIFEST_EXT		2
-
-#define IPU_FW_PSYS_N_PADDING_UINT8_IN_TERMINAL_STRUCT			5
-
-#define IPU_FW_PSYS_N_PADDING_UINT8_IN_PARAM_TERMINAL_STRUCT		6
-
-#define	IPU_FW_PSYS_N_PADDING_UINT8_IN_DATA_TERMINAL_STRUCT		3
-
-#define	IPU_FW_PSYS_N_PADDING_UINT8_IN_FRAME_DESC_STRUCT		3
-#define IPU_FW_PSYS_N_FRAME_PLANES					6
-#define IPU_FW_PSYS_N_PADDING_UINT8_IN_FRAME_STRUCT			4
-
-#define IPU_FW_PSYS_N_PADDING_UINT8_IN_BUFFER_SET_STRUCT		1
-
-#define IPU_FW_PSYS_MAX_INPUT_DEC_RESOURCES		4
-#define IPU_FW_PSYS_MAX_OUTPUT_DEC_RESOURCES		4
-
-#define IPU_FW_PSYS_PROCESS_MAX_CELLS			1
-#define IPU_FW_PSYS_KERNEL_BITMAP_NOF_ELEMS		4
-#define IPU_FW_PSYS_RBM_NOF_ELEMS			5
-#define IPU_FW_PSYS_KBM_NOF_ELEMS			4
-
-struct ipu_fw_psys_process {
-	s16 parent_offset;
-	u8 size;
-	u8 cell_dependencies_offset;
-	u8 terminal_dependencies_offset;
-	u8 process_extension_offset;
-	u8 ID;
-	u8 program_idx;
-	u8 state;
-	u8 cells[IPU_FW_PSYS_PROCESS_MAX_CELLS];
-	u8 cell_dependency_count;
-	u8 terminal_dependency_count;
-};
-
-struct ipu_fw_psys_program_manifest {
-	u32 kernel_bitmap[IPU_FW_PSYS_KERNEL_BITMAP_NOF_ELEMS];
-	s16 parent_offset;
-	u8  program_dependency_offset;
-	u8  terminal_dependency_offset;
-	u8  size;
-	u8  program_extension_offset;
-	u8 program_type;
-	u8 ID;
-	u8 cells[IPU_FW_PSYS_PROCESS_MAX_CELLS];
-	u8 cell_type_id;
-	u8 program_dependency_count;
-	u8 terminal_dependency_count;
-};
-
-/* platform specific resource interface */
-struct ipu_psys_resource_pool;
-struct ipu_psys_resource_alloc;
-struct ipu_fw_psys_process_group;
-int ipu_psys_allocate_resources(const struct device *dev,
-				struct ipu_fw_psys_process_group *pg,
-				void *pg_manifest,
-				struct ipu_psys_resource_alloc *alloc,
-				struct ipu_psys_resource_pool *pool);
-int ipu_psys_move_resources(const struct device *dev,
-			    struct ipu_psys_resource_alloc *alloc,
-			    struct ipu_psys_resource_pool *source_pool,
-			    struct ipu_psys_resource_pool *target_pool);
-
-void ipu_psys_resource_copy(struct ipu_psys_resource_pool *src,
-			    struct ipu_psys_resource_pool *dest);
-
-int ipu_psys_try_allocate_resources(struct device *dev,
-				    struct ipu_fw_psys_process_group *pg,
-				    void *pg_manifest,
-				    struct ipu_psys_resource_pool *pool);
-
-void ipu_psys_reset_process_cell(const struct device *dev,
-				 struct ipu_fw_psys_process_group *pg,
-				 void *pg_manifest,
-				 int process_count);
-void ipu_psys_free_resources(struct ipu_psys_resource_alloc *alloc,
-			     struct ipu_psys_resource_pool *pool);
-
-int ipu_fw_psys_set_proc_dfm_bitmap(struct ipu_fw_psys_process *ptr,
-				    u16 id, u32 bitmap,
-				    u32 active_bitmap);
-
-int ipu_psys_allocate_cmd_queue_resource(struct ipu_psys_resource_pool *pool);
-void ipu_psys_free_cmd_queue_resource(struct ipu_psys_resource_pool *pool,
-				      u8 queue_id);
-
-extern const struct ipu_fw_resource_definitions *ipu6_res_defs;
-extern const struct ipu_fw_resource_definitions *ipu6se_res_defs;
-extern const struct ipu_fw_resource_definitions *ipu6ep_res_defs;
-extern struct ipu6_psys_hw_res_variant hw_var;
-#endif /* IPU_PLATFORM_RESOURCES_COMMON_H */
diff --git a/drivers/media/pci/intel/ipu6/ipu-platform.h b/drivers/media/pci/intel/ipu6/ipu-platform.h
deleted file mode 100644
index 2e9cb163feb8..000000000000
--- a/drivers/media/pci/intel/ipu6/ipu-platform.h
+++ /dev/null
@@ -1,35 +0,0 @@
-/* SPDX-License-Identifier: GPL-2.0 */
-/* Copyright (C) 2013 - 2020 Intel Corporation */
-
-#ifndef IPU_PLATFORM_H
-#define IPU_PLATFORM_H
-
-#define IPU_NAME			"intel-ipu6"
-
-#define IPU6SE_FIRMWARE_NAME		"intel/ipu6se_fw.bin"
-#define IPU6EP_FIRMWARE_NAME		"intel/ipu6ep_fw.bin"
-#define IPU6EPES_FIRMWARE_NAME		"intel/ipu6epes_fw.bin"
-#define IPU6_FIRMWARE_NAME		"intel/ipu6_fw.bin"
-
-/*
- * The following definitions are encoded to the media_device's model field so
- * that the software components which uses IPU driver can get the hw stepping
- * information.
- */
-#define IPU_MEDIA_DEV_MODEL_NAME		"ipu6"
-
-#define IPU6SE_ISYS_NUM_STREAMS          IPU6SE_NONSECURE_STREAM_ID_MAX
-#define IPU6_ISYS_NUM_STREAMS            IPU6_NONSECURE_STREAM_ID_MAX
-
-/* declearations, definitions in ipu6.c */
-extern struct ipu_isys_internal_pdata isys_ipdata;
-extern struct ipu_psys_internal_pdata psys_ipdata;
-extern const struct ipu_buttress_ctrl isys_buttress_ctrl;
-extern const struct ipu_buttress_ctrl psys_buttress_ctrl;
-
-/* definitions in ipu6-isys.c */
-extern struct ipu_trace_block isys_trace_blocks[];
-/* definitions in ipu6-psys.c */
-extern struct ipu_trace_block psys_trace_blocks[];
-
-#endif
diff --git a/drivers/media/pci/intel/ipu6/ipu-resources.c b/drivers/media/pci/intel/ipu6/ipu-resources.c
deleted file mode 100644
index 07d5aff3b6ce..000000000000
--- a/drivers/media/pci/intel/ipu6/ipu-resources.c
+++ /dev/null
@@ -1,860 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0
-// Copyright (C) 2015 - 2020 Intel Corporation
-
-#include <linux/bitmap.h>
-#include <linux/errno.h>
-#include <linux/gfp.h>
-#include <linux/slab.h>
-#include <linux/device.h>
-
-#include <uapi/linux/ipu-psys.h>
-
-#include "ipu-fw-psys.h"
-#include "ipu-psys.h"
-
-struct ipu6_psys_hw_res_variant hw_var;
-void ipu6_psys_hw_res_variant_init(void)
-{
-	if (ipu_ver == IPU_VER_6SE) {
-		hw_var.queue_num = IPU6SE_FW_PSYS_N_PSYS_CMD_QUEUE_ID;
-		hw_var.cell_num = IPU6SE_FW_PSYS_N_CELL_ID;
-	} else if (ipu_ver == IPU_VER_6) {
-		hw_var.queue_num = IPU6_FW_PSYS_N_PSYS_CMD_QUEUE_ID;
-		hw_var.cell_num = IPU6_FW_PSYS_N_CELL_ID;
-	} else if (ipu_ver == IPU_VER_6EP) {
-		hw_var.queue_num = IPU6_FW_PSYS_N_PSYS_CMD_QUEUE_ID;
-		hw_var.cell_num = IPU6EP_FW_PSYS_N_CELL_ID;
-	} else {
-		WARN(1, "ipu6 psys res var is not initialised correctly.");
-	}
-
-	hw_var.set_proc_dev_chn = ipu6_fw_psys_set_proc_dev_chn;
-	hw_var.set_proc_dfm_bitmap = ipu6_fw_psys_set_proc_dfm_bitmap;
-	hw_var.set_proc_ext_mem = ipu6_fw_psys_set_process_ext_mem;
-	hw_var.get_pgm_by_proc =
-		ipu6_fw_psys_get_program_manifest_by_process;
-	return;
-}
-
-static const struct ipu_fw_resource_definitions *get_res(void)
-{
-	if (ipu_ver == IPU_VER_6SE)
-		return ipu6se_res_defs;
-
-	if (ipu_ver == IPU_VER_6EP)
-		return ipu6ep_res_defs;
-
-	return ipu6_res_defs;
-}
-
-static int ipu_resource_init(struct ipu_resource *res, u32 id, int elements)
-{
-	if (elements <= 0) {
-		res->bitmap = NULL;
-		return 0;
-	}
-
-	res->bitmap = bitmap_zalloc(elements, GFP_KERNEL);
-	if (!res->bitmap)
-		return -ENOMEM;
-	res->elements = elements;
-	res->id = id;
-	return 0;
-}
-
-static unsigned long
-ipu_resource_alloc_with_pos(struct ipu_resource *res, int n,
-			    int pos,
-			    struct ipu_resource_alloc *alloc,
-			    enum ipu_resource_type type)
-{
-	unsigned long p;
-
-	if (n <= 0) {
-		alloc->elements = 0;
-		return 0;
-	}
-
-	if (!res->bitmap || pos >= res->elements)
-		return (unsigned long)(-ENOSPC);
-
-	p = bitmap_find_next_zero_area(res->bitmap, res->elements, pos, n, 0);
-	alloc->resource = NULL;
-
-	if (p != pos)
-		return (unsigned long)(-ENOSPC);
-	bitmap_set(res->bitmap, p, n);
-	alloc->resource = res;
-	alloc->elements = n;
-	alloc->pos = p;
-	alloc->type = type;
-
-	return pos;
-}
-
-static unsigned long
-ipu_resource_alloc(struct ipu_resource *res, int n,
-		   struct ipu_resource_alloc *alloc,
-		   enum ipu_resource_type type)
-{
-	unsigned long p;
-
-	if (n <= 0) {
-		alloc->elements = 0;
-		return 0;
-	}
-
-	if (!res->bitmap)
-		return (unsigned long)(-ENOSPC);
-
-	p = bitmap_find_next_zero_area(res->bitmap, res->elements, 0, n, 0);
-	alloc->resource = NULL;
-
-	if (p >= res->elements)
-		return (unsigned long)(-ENOSPC);
-	bitmap_set(res->bitmap, p, n);
-	alloc->resource = res;
-	alloc->elements = n;
-	alloc->pos = p;
-	alloc->type = type;
-
-	return p;
-}
-
-static void ipu_resource_free(struct ipu_resource_alloc *alloc)
-{
-	if (alloc->elements <= 0)
-		return;
-
-	if (alloc->type == IPU_RESOURCE_DFM)
-		*alloc->resource->bitmap &= ~(unsigned long)(alloc->elements);
-	else
-		bitmap_clear(alloc->resource->bitmap, alloc->pos,
-			     alloc->elements);
-	alloc->resource = NULL;
-}
-
-static void ipu_resource_cleanup(struct ipu_resource *res)
-{
-	bitmap_free(res->bitmap);
-	res->bitmap = NULL;
-}
-
-/********** IPU PSYS-specific resource handling **********/
-int ipu_psys_resource_pool_init(struct ipu_psys_resource_pool *pool)
-{
-	int i, j, k, ret;
-	const struct ipu_fw_resource_definitions *res_defs;
-
-	res_defs = get_res();
-
-	spin_lock_init(&pool->queues_lock);
-	pool->cells = 0;
-
-	for (i = 0; i < res_defs->num_dev_channels; i++) {
-		ret = ipu_resource_init(&pool->dev_channels[i], i,
-					res_defs->dev_channels[i]);
-		if (ret)
-			goto error;
-	}
-
-	for (j = 0; j < res_defs->num_ext_mem_ids; j++) {
-		ret = ipu_resource_init(&pool->ext_memory[j], j,
-					res_defs->ext_mem_ids[j]);
-		if (ret)
-			goto memory_error;
-	}
-
-	for (k = 0; k < res_defs->num_dfm_ids; k++) {
-		ret = ipu_resource_init(&pool->dfms[k], k, res_defs->dfms[k]);
-		if (ret)
-			goto dfm_error;
-	}
-
-	spin_lock(&pool->queues_lock);
-	if (ipu_ver == IPU_VER_6SE)
-		bitmap_zero(pool->cmd_queues,
-			    IPU6SE_FW_PSYS_N_PSYS_CMD_QUEUE_ID);
-	else
-		bitmap_zero(pool->cmd_queues,
-			    IPU6_FW_PSYS_N_PSYS_CMD_QUEUE_ID);
-	spin_unlock(&pool->queues_lock);
-
-	return 0;
-
-dfm_error:
-	for (k--; k >= 0; k--)
-		ipu_resource_cleanup(&pool->dfms[k]);
-
-memory_error:
-	for (j--; j >= 0; j--)
-		ipu_resource_cleanup(&pool->ext_memory[j]);
-
-error:
-	for (i--; i >= 0; i--)
-		ipu_resource_cleanup(&pool->dev_channels[i]);
-	return ret;
-}
-
-void ipu_psys_resource_copy(struct ipu_psys_resource_pool *src,
-			    struct ipu_psys_resource_pool *dest)
-{
-	int i;
-	const struct ipu_fw_resource_definitions *res_defs;
-
-	res_defs = get_res();
-
-	dest->cells = src->cells;
-	for (i = 0; i < res_defs->num_dev_channels; i++)
-		*dest->dev_channels[i].bitmap = *src->dev_channels[i].bitmap;
-
-	for (i = 0; i < res_defs->num_ext_mem_ids; i++)
-		*dest->ext_memory[i].bitmap = *src->ext_memory[i].bitmap;
-
-	for (i = 0; i < res_defs->num_dfm_ids; i++)
-		*dest->dfms[i].bitmap = *src->dfms[i].bitmap;
-}
-
-void ipu_psys_resource_pool_cleanup(struct ipu_psys_resource_pool
-				    *pool)
-{
-	u32 i;
-	const struct ipu_fw_resource_definitions *res_defs;
-
-	res_defs = get_res();
-	for (i = 0; i < res_defs->num_dev_channels; i++)
-		ipu_resource_cleanup(&pool->dev_channels[i]);
-
-	for (i = 0; i < res_defs->num_ext_mem_ids; i++)
-		ipu_resource_cleanup(&pool->ext_memory[i]);
-
-	for (i = 0; i < res_defs->num_dfm_ids; i++)
-		ipu_resource_cleanup(&pool->dfms[i]);
-}
-
-static int __alloc_one_resrc(const struct device *dev,
-			     struct ipu_fw_psys_process *process,
-			     struct ipu_resource *resource,
-			     struct ipu_fw_generic_program_manifest *pm,
-			     u32 resource_id,
-			     struct ipu_psys_resource_alloc *alloc)
-{
-	const u16 resource_req = pm->dev_chn_size[resource_id];
-	const u16 resource_offset_req = pm->dev_chn_offset[resource_id];
-	unsigned long retl;
-
-	if (resource_req <= 0)
-		return -ENXIO;
-
-	if (alloc->resources >= IPU_MAX_RESOURCES) {
-		dev_err(dev, "out of resource handles\n");
-		return -ENOSPC;
-	}
-	if (resource_offset_req != (u16)(-1))
-		retl = ipu_resource_alloc_with_pos
-		    (resource,
-		     resource_req,
-		     resource_offset_req,
-		     &alloc->resource_alloc[alloc->resources],
-		     IPU_RESOURCE_DEV_CHN);
-	else
-		retl = ipu_resource_alloc
-		    (resource, resource_req,
-		     &alloc->resource_alloc[alloc->resources],
-		     IPU_RESOURCE_DEV_CHN);
-	if (IS_ERR_VALUE(retl)) {
-		dev_dbg(dev, "out of device channel resources\n");
-		return (int)retl;
-	}
-	alloc->resources++;
-
-	return 0;
-}
-
-static int ipu_psys_allocate_one_dfm(const struct device *dev,
-				     struct ipu_fw_psys_process *process,
-				     struct ipu_resource *resource,
-				     struct ipu_fw_generic_program_manifest *pm,
-				     u32 resource_id,
-				     struct ipu_psys_resource_alloc *alloc)
-{
-	u32 dfm_bitmap_req = pm->dfm_port_bitmap[resource_id];
-	u32 active_dfm_bitmap_req = pm->dfm_active_port_bitmap[resource_id];
-	const u8 is_relocatable = pm->is_dfm_relocatable[resource_id];
-	struct ipu_resource_alloc *alloc_resource;
-	unsigned long p = 0;
-
-	if (dfm_bitmap_req == 0)
-		return -ENXIO;
-
-	if (alloc->resources >= IPU_MAX_RESOURCES) {
-		dev_err(dev, "out of resource handles\n");
-		return -ENOSPC;
-	}
-
-	if (!resource->bitmap)
-		return -ENOSPC;
-
-	if (!is_relocatable) {
-		if (*resource->bitmap & dfm_bitmap_req) {
-			dev_warn(dev,
-				 "out of dfm resources, req 0x%x, get 0x%lx\n",
-				 dfm_bitmap_req, *resource->bitmap);
-			return -ENOSPC;
-		}
-		*resource->bitmap |= dfm_bitmap_req;
-	} else {
-		unsigned int n = hweight32(dfm_bitmap_req);
-
-		p = bitmap_find_next_zero_area(resource->bitmap,
-					       resource->elements, 0, n, 0);
-
-		if (p >= resource->elements)
-			return -ENOSPC;
-
-		bitmap_set(resource->bitmap, p, n);
-		dfm_bitmap_req = dfm_bitmap_req << p;
-		active_dfm_bitmap_req = active_dfm_bitmap_req << p;
-	}
-
-	alloc_resource = &alloc->resource_alloc[alloc->resources];
-	alloc_resource->resource = resource;
-	/* Using elements to indicate the bitmap */
-	alloc_resource->elements = dfm_bitmap_req;
-	alloc_resource->pos = p;
-	alloc_resource->type = IPU_RESOURCE_DFM;
-
-	alloc->resources++;
-
-	return 0;
-}
-
-/*
- * ext_mem_type_id is a generic type id for memory (like DMEM, VMEM)
- * ext_mem_bank_id is detailed type id for  memory (like DMEM0, DMEM1 etc.)
- */
-static int __alloc_mem_resrc(const struct device *dev,
-			     struct ipu_fw_psys_process *process,
-			     struct ipu_resource *resource,
-			     struct ipu_fw_generic_program_manifest *pm,
-			     u32 ext_mem_type_id, u32 ext_mem_bank_id,
-			     struct ipu_psys_resource_alloc *alloc)
-{
-	const u16 memory_resource_req = pm->ext_mem_size[ext_mem_type_id];
-	const u16 memory_offset_req = pm->ext_mem_offset[ext_mem_type_id];
-
-	unsigned long retl;
-
-	if (memory_resource_req <= 0)
-		return -ENXIO;
-
-	if (alloc->resources >= IPU_MAX_RESOURCES) {
-		dev_err(dev, "out of resource handles\n");
-		return -ENOSPC;
-	}
-	if (memory_offset_req != (u16)(-1))
-		retl = ipu_resource_alloc_with_pos
-		    (resource,
-		     memory_resource_req, memory_offset_req,
-		     &alloc->resource_alloc[alloc->resources],
-		     IPU_RESOURCE_EXT_MEM);
-	else
-		retl = ipu_resource_alloc
-		    (resource, memory_resource_req,
-		     &alloc->resource_alloc[alloc->resources],
-		     IPU_RESOURCE_EXT_MEM);
-	if (IS_ERR_VALUE(retl)) {
-		dev_dbg(dev, "out of memory resources\n");
-		return (int)retl;
-	}
-
-	alloc->resources++;
-
-	return 0;
-}
-
-int ipu_psys_allocate_cmd_queue_resource(struct ipu_psys_resource_pool *pool)
-{
-	unsigned long p;
-	int size, start;
-
-	size = IPU6_FW_PSYS_N_PSYS_CMD_QUEUE_ID;
-	start = IPU6_FW_PSYS_CMD_QUEUE_PPG0_COMMAND_ID;
-
-	if (ipu_ver == IPU_VER_6SE) {
-		size = IPU6SE_FW_PSYS_N_PSYS_CMD_QUEUE_ID;
-		start = IPU6SE_FW_PSYS_CMD_QUEUE_PPG0_COMMAND_ID;
-	}
-
-	spin_lock(&pool->queues_lock);
-	/* find available cmd queue from ppg0_cmd_id */
-	p = bitmap_find_next_zero_area(pool->cmd_queues, size, start, 1, 0);
-
-	if (p >= size) {
-		spin_unlock(&pool->queues_lock);
-		return -ENOSPC;
-	}
-
-	bitmap_set(pool->cmd_queues, p, 1);
-	spin_unlock(&pool->queues_lock);
-
-	return p;
-}
-
-void ipu_psys_free_cmd_queue_resource(struct ipu_psys_resource_pool *pool,
-				      u8 queue_id)
-{
-	spin_lock(&pool->queues_lock);
-	bitmap_clear(pool->cmd_queues, queue_id, 1);
-	spin_unlock(&pool->queues_lock);
-}
-
-int ipu_psys_try_allocate_resources(struct device *dev,
-				    struct ipu_fw_psys_process_group *pg,
-				    void *pg_manifest,
-				    struct ipu_psys_resource_pool *pool)
-{
-	u32 id, idx;
-	u32 mem_type_id;
-	int ret, i;
-	u16 *process_offset_table;
-	u8 processes;
-	u32 cells = 0;
-	struct ipu_psys_resource_alloc *alloc;
-	const struct ipu_fw_resource_definitions *res_defs;
-
-	if (!pg)
-		return -EINVAL;
-	process_offset_table = (u16 *)((u8 *)pg + pg->processes_offset);
-	processes = pg->process_count;
-
-	alloc = kzalloc(sizeof(*alloc), GFP_KERNEL);
-	if (!alloc)
-		return -ENOMEM;
-
-	res_defs = get_res();
-	for (i = 0; i < processes; i++) {
-		u32 cell;
-		struct ipu_fw_psys_process *process =
-			(struct ipu_fw_psys_process *)
-			((char *)pg + process_offset_table[i]);
-		struct ipu_fw_generic_program_manifest pm;
-
-		memset(&pm, 0, sizeof(pm));
-
-		if (!process) {
-			dev_err(dev, "can not get process\n");
-			ret = -ENOENT;
-			goto free_out;
-		}
-
-		ret = ipu_fw_psys_get_program_manifest_by_process
-			(&pm, pg_manifest, process);
-		if (ret < 0) {
-			dev_err(dev, "can not get manifest\n");
-			goto free_out;
-		}
-
-		if (pm.cell_id == res_defs->num_cells &&
-		    pm.cell_type_id == res_defs->num_cells_type) {
-			cell = res_defs->num_cells;
-		} else if ((pm.cell_id != res_defs->num_cells &&
-			    pm.cell_type_id == res_defs->num_cells_type)) {
-			cell = pm.cell_id;
-		} else {
-			/* Find a free cell of desired type */
-			u32 type = pm.cell_type_id;
-
-			for (cell = 0; cell < res_defs->num_cells; cell++)
-				if (res_defs->cells[cell] == type &&
-				    ((pool->cells | cells) & (1 << cell)) == 0)
-					break;
-			if (cell >= res_defs->num_cells) {
-				dev_dbg(dev, "no free cells of right type\n");
-				ret = -ENOSPC;
-				goto free_out;
-			}
-		}
-		if (cell < res_defs->num_cells)
-			cells |= 1 << cell;
-		if (pool->cells & cells) {
-			dev_dbg(dev, "out of cell resources\n");
-			ret = -ENOSPC;
-			goto free_out;
-		}
-
-		if (pm.dev_chn_size) {
-			for (id = 0; id < res_defs->num_dev_channels; id++) {
-				ret = __alloc_one_resrc(dev, process,
-							&pool->dev_channels[id],
-							&pm, id, alloc);
-				if (ret && ret != -ENXIO)
-					goto free_out;
-			}
-		}
-
-		if (pm.dfm_port_bitmap) {
-			for (id = 0; id < res_defs->num_dfm_ids; id++) {
-				ret = ipu_psys_allocate_one_dfm
-					(dev, process,
-					 &pool->dfms[id], &pm, id, alloc);
-				if (ret && ret != -ENXIO)
-					goto free_out;
-			}
-		}
-
-		if (pm.ext_mem_size) {
-			for (mem_type_id = 0;
-			     mem_type_id < res_defs->num_ext_mem_types;
-			     mem_type_id++) {
-				u32 bank = res_defs->num_ext_mem_ids;
-
-				if (cell != res_defs->num_cells) {
-					idx = res_defs->cell_mem_row * cell +
-						mem_type_id;
-					bank = res_defs->cell_mem[idx];
-				}
-
-				if (bank == res_defs->num_ext_mem_ids)
-					continue;
-
-				ret = __alloc_mem_resrc(dev, process,
-							&pool->ext_memory[bank],
-							&pm, mem_type_id, bank,
-							alloc);
-				if (ret && ret != -ENXIO)
-					goto free_out;
-			}
-		}
-	}
-	alloc->cells |= cells;
-	pool->cells |= cells;
-
-	kfree(alloc);
-	return 0;
-
-free_out:
-	dev_dbg(dev, "failed to try_allocate resource\n");
-	kfree(alloc);
-	return ret;
-}
-
-/*
- * Allocate resources for pg from `pool'. Mark the allocated
- * resources into `alloc'. Returns 0 on success, -ENOSPC
- * if there are no enough resources, in which cases resources
- * are not allocated at all, or some other error on other conditions.
- */
-int ipu_psys_allocate_resources(const struct device *dev,
-				struct ipu_fw_psys_process_group *pg,
-				void *pg_manifest,
-				struct ipu_psys_resource_alloc
-				*alloc, struct ipu_psys_resource_pool
-				*pool)
-{
-	u32 id;
-	u32 mem_type_id;
-	int ret, i;
-	u16 *process_offset_table;
-	u8 processes;
-	u32 cells = 0;
-	int p, idx;
-	u32 bmp, a_bmp;
-	const struct ipu_fw_resource_definitions *res_defs;
-
-	if (!pg)
-		return -EINVAL;
-
-	res_defs = get_res();
-	process_offset_table = (u16 *)((u8 *)pg + pg->processes_offset);
-	processes = pg->process_count;
-
-	for (i = 0; i < processes; i++) {
-		u32 cell;
-		struct ipu_fw_psys_process *process =
-		    (struct ipu_fw_psys_process *)
-		    ((char *)pg + process_offset_table[i]);
-		struct ipu_fw_generic_program_manifest pm;
-
-		memset(&pm, 0, sizeof(pm));
-		if (!process) {
-			dev_err(dev, "can not get process\n");
-			ret = -ENOENT;
-			goto free_out;
-		}
-
-		ret = ipu_fw_psys_get_program_manifest_by_process
-		    (&pm, pg_manifest, process);
-		if (ret < 0) {
-			dev_err(dev, "can not get manifest\n");
-			goto free_out;
-		}
-
-		if (pm.cell_id == res_defs->num_cells &&
-		    pm.cell_type_id == res_defs->num_cells_type) {
-			cell = res_defs->num_cells;
-		} else if ((pm.cell_id != res_defs->num_cells &&
-			    pm.cell_type_id == res_defs->num_cells_type)) {
-			cell = pm.cell_id;
-		} else {
-			/* Find a free cell of desired type */
-			u32 type = pm.cell_type_id;
-
-			for (cell = 0; cell < res_defs->num_cells; cell++)
-				if (res_defs->cells[cell] == type &&
-				    ((pool->cells | cells) & (1 << cell)) == 0)
-					break;
-			if (cell >= res_defs->num_cells) {
-				dev_dbg(dev, "no free cells of right type\n");
-				ret = -ENOSPC;
-				goto free_out;
-			}
-			ret = ipu_fw_psys_set_process_cell_id(process, 0, cell);
-			if (ret)
-				goto free_out;
-		}
-		if (cell < res_defs->num_cells)
-			cells |= 1 << cell;
-		if (pool->cells & cells) {
-			dev_dbg(dev, "out of cell resources\n");
-			ret = -ENOSPC;
-			goto free_out;
-		}
-
-		if (pm.dev_chn_size) {
-			for (id = 0; id < res_defs->num_dev_channels; id++) {
-				ret = __alloc_one_resrc(dev, process,
-							&pool->dev_channels[id],
-							&pm, id, alloc);
-				if (ret == -ENXIO)
-					continue;
-
-				if (ret)
-					goto free_out;
-
-				idx = alloc->resources - 1;
-				p = alloc->resource_alloc[idx].pos;
-				ret = ipu_fw_psys_set_proc_dev_chn(process, id,
-								   p);
-				if (ret)
-					goto free_out;
-			}
-		}
-
-		if (pm.dfm_port_bitmap) {
-			for (id = 0; id < res_defs->num_dfm_ids; id++) {
-				ret = ipu_psys_allocate_one_dfm(dev, process,
-								&pool->dfms[id],
-								&pm, id, alloc);
-				if (ret == -ENXIO)
-					continue;
-
-				if (ret)
-					goto free_out;
-
-				idx = alloc->resources - 1;
-				p = alloc->resource_alloc[idx].pos;
-				bmp = pm.dfm_port_bitmap[id];
-				bmp = bmp << p;
-				a_bmp = pm.dfm_active_port_bitmap[id];
-				a_bmp = a_bmp << p;
-				ret = ipu_fw_psys_set_proc_dfm_bitmap(process,
-								      id, bmp,
-								      a_bmp);
-				if (ret)
-					goto free_out;
-			}
-		}
-
-		if (pm.ext_mem_size) {
-			for (mem_type_id = 0;
-			     mem_type_id < res_defs->num_ext_mem_types;
-			     mem_type_id++) {
-				u32 bank = res_defs->num_ext_mem_ids;
-
-				if (cell != res_defs->num_cells) {
-					idx = res_defs->cell_mem_row * cell +
-						mem_type_id;
-					bank = res_defs->cell_mem[idx];
-				}
-				if (bank == res_defs->num_ext_mem_ids)
-					continue;
-
-				ret = __alloc_mem_resrc(dev, process,
-							&pool->ext_memory[bank],
-							&pm, mem_type_id,
-							bank, alloc);
-				if (ret == -ENXIO)
-					continue;
-
-				if (ret)
-					goto free_out;
-
-				/* no return value check here because fw api
-				 * will do some checks, and would return
-				 * non-zero except mem_type_id == 0.
-				 * This maybe caused by that above flow of
-				 * allocating mem_bank_id is improper.
-				 */
-				idx = alloc->resources - 1;
-				p = alloc->resource_alloc[idx].pos;
-				ipu_fw_psys_set_process_ext_mem(process,
-								mem_type_id,
-								bank, p);
-			}
-		}
-	}
-	alloc->cells |= cells;
-	pool->cells |= cells;
-	return 0;
-
-free_out:
-	dev_err(dev, "failed to allocate resources, ret %d\n", ret);
-	ipu_psys_reset_process_cell(dev, pg, pg_manifest, i + 1);
-	ipu_psys_free_resources(alloc, pool);
-	return ret;
-}
-
-int ipu_psys_move_resources(const struct device *dev,
-			    struct ipu_psys_resource_alloc *alloc,
-			    struct ipu_psys_resource_pool
-			    *source_pool, struct ipu_psys_resource_pool
-			    *target_pool)
-{
-	int i;
-
-	if (target_pool->cells & alloc->cells) {
-		dev_dbg(dev, "out of cell resources\n");
-		return -ENOSPC;
-	}
-
-	for (i = 0; i < alloc->resources; i++) {
-		unsigned long bitmap = 0;
-		unsigned int id = alloc->resource_alloc[i].resource->id;
-		unsigned long fbit, end;
-
-		switch (alloc->resource_alloc[i].type) {
-		case IPU_RESOURCE_DEV_CHN:
-			bitmap_set(&bitmap, alloc->resource_alloc[i].pos,
-				   alloc->resource_alloc[i].elements);
-			if (*target_pool->dev_channels[id].bitmap & bitmap)
-				return -ENOSPC;
-			break;
-		case IPU_RESOURCE_EXT_MEM:
-			end = alloc->resource_alloc[i].elements +
-			    alloc->resource_alloc[i].pos;
-
-			fbit = find_next_bit(target_pool->ext_memory[id].bitmap,
-					     end, alloc->resource_alloc[i].pos);
-			/* if find_next_bit returns "end" it didn't find 1bit */
-			if (end != fbit)
-				return -ENOSPC;
-			break;
-		case IPU_RESOURCE_DFM:
-			bitmap = alloc->resource_alloc[i].elements;
-			if (*target_pool->dfms[id].bitmap & bitmap)
-				return -ENOSPC;
-			break;
-		default:
-			dev_err(dev, "Illegal resource type\n");
-			return -EINVAL;
-		}
-	}
-
-	for (i = 0; i < alloc->resources; i++) {
-		u32 id = alloc->resource_alloc[i].resource->id;
-
-		switch (alloc->resource_alloc[i].type) {
-		case IPU_RESOURCE_DEV_CHN:
-			bitmap_set(target_pool->dev_channels[id].bitmap,
-				   alloc->resource_alloc[i].pos,
-				   alloc->resource_alloc[i].elements);
-			ipu_resource_free(&alloc->resource_alloc[i]);
-			alloc->resource_alloc[i].resource =
-			    &target_pool->dev_channels[id];
-			break;
-		case IPU_RESOURCE_EXT_MEM:
-			bitmap_set(target_pool->ext_memory[id].bitmap,
-				   alloc->resource_alloc[i].pos,
-				   alloc->resource_alloc[i].elements);
-			ipu_resource_free(&alloc->resource_alloc[i]);
-			alloc->resource_alloc[i].resource =
-			    &target_pool->ext_memory[id];
-			break;
-		case IPU_RESOURCE_DFM:
-			*target_pool->dfms[id].bitmap |=
-			    alloc->resource_alloc[i].elements;
-			*alloc->resource_alloc[i].resource->bitmap &=
-			    ~(alloc->resource_alloc[i].elements);
-			alloc->resource_alloc[i].resource =
-			    &target_pool->dfms[id];
-			break;
-		default:
-			/*
-			 * Just keep compiler happy. This case failed already
-			 * in above loop.
-			 */
-			break;
-		}
-	}
-
-	target_pool->cells |= alloc->cells;
-	source_pool->cells &= ~alloc->cells;
-
-	return 0;
-}
-
-void ipu_psys_reset_process_cell(const struct device *dev,
-				 struct ipu_fw_psys_process_group *pg,
-				 void *pg_manifest,
-				 int process_count)
-{
-	int i;
-	u16 *process_offset_table;
-	const struct ipu_fw_resource_definitions *res_defs;
-
-	if (!pg)
-		return;
-
-	res_defs = get_res();
-	process_offset_table = (u16 *)((u8 *)pg + pg->processes_offset);
-	for (i = 0; i < process_count; i++) {
-		struct ipu_fw_psys_process *process =
-		    (struct ipu_fw_psys_process *)
-		    ((char *)pg + process_offset_table[i]);
-		struct ipu_fw_generic_program_manifest pm;
-		int ret;
-
-		if (!process)
-			break;
-
-		ret = ipu_fw_psys_get_program_manifest_by_process(&pm,
-								  pg_manifest,
-								  process);
-		if (ret < 0) {
-			dev_err(dev, "can not get manifest\n");
-			break;
-		}
-		if ((pm.cell_id != res_defs->num_cells &&
-		     pm.cell_type_id == res_defs->num_cells_type))
-			continue;
-		/* no return value check here because if finding free cell
-		 * failed, process cell would not set then calling clear_cell
-		 * will return non-zero.
-		 */
-		ipu_fw_psys_clear_process_cell(process);
-	}
-}
-
-/* Free resources marked in `alloc' from `resources' */
-void ipu_psys_free_resources(struct ipu_psys_resource_alloc
-			     *alloc, struct ipu_psys_resource_pool *pool)
-{
-	unsigned int i;
-
-	pool->cells &= ~alloc->cells;
-	alloc->cells = 0;
-	for (i = 0; i < alloc->resources; i++)
-		ipu_resource_free(&alloc->resource_alloc[i]);
-	alloc->resources = 0;
-}
diff --git a/drivers/media/pci/intel/ipu6/ipu6-fw-resources.c b/drivers/media/pci/intel/ipu6/ipu6-fw-resources.c
deleted file mode 100644
index 338e90d8f29b..000000000000
--- a/drivers/media/pci/intel/ipu6/ipu6-fw-resources.c
+++ /dev/null
@@ -1,608 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0
-// Copyright (C) 2015 - 2021 Intel Corporation
-
-#include <linux/err.h>
-#include <linux/string.h>
-
-#include "ipu-psys.h"
-#include "ipu-fw-psys.h"
-#include "ipu6-platform-resources.h"
-
-/* resources table */
-
-/*
- * Cell types by cell IDs
- */
-static const u8 ipu6_fw_psys_cell_types[IPU6_FW_PSYS_N_CELL_ID] = {
-	IPU6_FW_PSYS_SP_CTRL_TYPE_ID,
-	IPU6_FW_PSYS_VP_TYPE_ID,
-	IPU6_FW_PSYS_ACC_PSA_TYPE_ID,
-	IPU6_FW_PSYS_ACC_PSA_TYPE_ID,
-	IPU6_FW_PSYS_ACC_PSA_TYPE_ID,
-	IPU6_FW_PSYS_ACC_PSA_TYPE_ID,
-	IPU6_FW_PSYS_ACC_OSA_TYPE_ID,
-	IPU6_FW_PSYS_ACC_OSA_TYPE_ID,
-	IPU6_FW_PSYS_ACC_OSA_TYPE_ID,
-	IPU6_FW_PSYS_ACC_PSA_TYPE_ID,
-	IPU6_FW_PSYS_ACC_PSA_TYPE_ID,
-	IPU6_FW_PSYS_ACC_PSA_TYPE_ID,
-	IPU6_FW_PSYS_ACC_PSA_TYPE_ID,
-	IPU6_FW_PSYS_ACC_ISA_TYPE_ID,
-	IPU6_FW_PSYS_ACC_ISA_TYPE_ID,
-	IPU6_FW_PSYS_ACC_ISA_TYPE_ID,
-	IPU6_FW_PSYS_ACC_ISA_TYPE_ID,
-	IPU6_FW_PSYS_ACC_ISA_TYPE_ID,
-	IPU6_FW_PSYS_ACC_ISA_TYPE_ID,
-	IPU6_FW_PSYS_ACC_ISA_TYPE_ID,
-	IPU6_FW_PSYS_ACC_ISA_TYPE_ID,
-	IPU6_FW_PSYS_ACC_ISA_TYPE_ID,
-	IPU6_FW_PSYS_ACC_ISA_TYPE_ID,
-	IPU6_FW_PSYS_ACC_ISA_TYPE_ID,
-	IPU6_FW_PSYS_ACC_ISA_TYPE_ID,
-	IPU6_FW_PSYS_ACC_ISA_TYPE_ID,
-	IPU6_FW_PSYS_ACC_ISA_TYPE_ID, /* X2B_MD */
-	IPU6_FW_PSYS_ACC_ISA_TYPE_ID, /* ICA_MEDIUM */
-	IPU6_FW_PSYS_ACC_ISA_TYPE_ID, /* X2B_SVE_RGBIR */
-	IPU6_FW_PSYS_ACC_ISA_TYPE_ID, /* PAF */
-	IPU6_FW_PSYS_GDC_TYPE_ID,
-	IPU6_FW_PSYS_TNR_TYPE_ID,
-};
-
-static const u16 ipu6_fw_num_dev_channels[IPU6_FW_PSYS_N_DEV_CHN_ID] = {
-	IPU6_FW_PSYS_DEV_CHN_DMA_EXT0_MAX_SIZE,
-	IPU6_FW_PSYS_DEV_CHN_DMA_EXT1_READ_MAX_SIZE,
-	IPU6_FW_PSYS_DEV_CHN_DMA_EXT1_WRITE_MAX_SIZE,
-	IPU6_FW_PSYS_DEV_CHN_DMA_INTERNAL_MAX_SIZE,
-	IPU6_FW_PSYS_DEV_CHN_DMA_ISA_MAX_SIZE,
-};
-
-static const u16 ipu6_fw_psys_mem_size[IPU6_FW_PSYS_N_MEM_ID] = {
-	IPU6_FW_PSYS_VMEM0_MAX_SIZE,
-	IPU6_FW_PSYS_TRANSFER_VMEM0_MAX_SIZE,
-	IPU6_FW_PSYS_TRANSFER_VMEM1_MAX_SIZE,
-	IPU6_FW_PSYS_LB_VMEM_MAX_SIZE,
-	IPU6_FW_PSYS_BAMEM0_MAX_SIZE,
-	IPU6_FW_PSYS_DMEM0_MAX_SIZE,
-	IPU6_FW_PSYS_DMEM1_MAX_SIZE,
-	IPU6_FW_PSYS_DMEM2_MAX_SIZE,
-	IPU6_FW_PSYS_DMEM3_MAX_SIZE,
-	IPU6_FW_PSYS_PMEM0_MAX_SIZE
-};
-
-static const u16 ipu6_fw_psys_dfms[IPU6_FW_PSYS_N_DEV_DFM_ID] = {
-	IPU6_FW_PSYS_DEV_DFM_BB_FULL_PORT_ID_MAX_SIZE,
-	IPU6_FW_PSYS_DEV_DFM_BB_EMPTY_PORT_ID_MAX_SIZE,
-	IPU6_FW_PSYS_DEV_DFM_ISL_FULL_PORT_ID_MAX_SIZE,
-	IPU6_FW_PSYS_DEV_DFM_ISL_EMPTY_PORT_ID_MAX_SIZE,
-	IPU6_FW_PSYS_DEV_DFM_LB_FULL_PORT_ID_MAX_SIZE,
-	IPU6_FW_PSYS_DEV_DFM_LB_EMPTY_PORT_ID_MAX_SIZE,
-};
-
-static const u8
-ipu6_fw_psys_c_mem[IPU6_FW_PSYS_N_CELL_ID][IPU6_FW_PSYS_N_MEM_TYPE_ID] = {
-	{
-		/* IPU6_FW_PSYS_SP0_ID */
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_DMEM0_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-	},
-	{
-		/* IPU6_FW_PSYS_SP1_ID */
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_DMEM1_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-	},
-	{
-		/* IPU6_FW_PSYS_VP0_ID */
-		IPU6_FW_PSYS_TRANSFER_VMEM0_ID,
-		IPU6_FW_PSYS_TRANSFER_VMEM1_ID,
-		IPU6_FW_PSYS_LB_VMEM_ID,
-		IPU6_FW_PSYS_DMEM3_ID,
-		IPU6_FW_PSYS_VMEM0_ID,
-		IPU6_FW_PSYS_BAMEM0_ID,
-		IPU6_FW_PSYS_PMEM0_ID,
-	},
-	{
-		/* IPU6_FW_PSYS_ACC1_ID BNLM */
-		IPU6_FW_PSYS_TRANSFER_VMEM0_ID,
-		IPU6_FW_PSYS_TRANSFER_VMEM1_ID,
-		IPU6_FW_PSYS_LB_VMEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-	},
-	{
-		/* IPU6_FW_PSYS_ACC2_ID DM */
-		IPU6_FW_PSYS_TRANSFER_VMEM0_ID,
-		IPU6_FW_PSYS_TRANSFER_VMEM1_ID,
-		IPU6_FW_PSYS_LB_VMEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-	},
-	{
-		/* IPU6_FW_PSYS_ACC3_ID ACM */
-		IPU6_FW_PSYS_TRANSFER_VMEM0_ID,
-		IPU6_FW_PSYS_TRANSFER_VMEM1_ID,
-		IPU6_FW_PSYS_LB_VMEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-	},
-	{
-		/* IPU6_FW_PSYS_ACC4_ID GTC YUV1 */
-		IPU6_FW_PSYS_TRANSFER_VMEM0_ID,
-		IPU6_FW_PSYS_TRANSFER_VMEM1_ID,
-		IPU6_FW_PSYS_LB_VMEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-	},
-	{
-		/* IPU6_FW_PSYS_ACC5_ID OFS pin main */
-		IPU6_FW_PSYS_TRANSFER_VMEM0_ID,
-		IPU6_FW_PSYS_TRANSFER_VMEM1_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-	},
-	{
-		/* IPU6_FW_PSYS_ACC6_ID OFS pin display */
-		IPU6_FW_PSYS_TRANSFER_VMEM0_ID,
-		IPU6_FW_PSYS_TRANSFER_VMEM1_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-	},
-	{
-		/* IPU6_FW_PSYS_ACC7_ID OFS pin pp */
-		IPU6_FW_PSYS_TRANSFER_VMEM0_ID,
-		IPU6_FW_PSYS_TRANSFER_VMEM1_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-	},
-	{
-		/* IPU6_FW_PSYS_ACC8_ID GAMMASTAR */
-		IPU6_FW_PSYS_TRANSFER_VMEM0_ID,
-		IPU6_FW_PSYS_TRANSFER_VMEM1_ID,
-		IPU6_FW_PSYS_LB_VMEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-	},
-	{
-		/* IPU6_FW_PSYS_ACC9_ID GLTM */
-		IPU6_FW_PSYS_TRANSFER_VMEM0_ID,
-		IPU6_FW_PSYS_TRANSFER_VMEM1_ID,
-		IPU6_FW_PSYS_LB_VMEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-	},
-	{
-		/* IPU6_FW_PSYS_ACC10_ID XNR */
-		IPU6_FW_PSYS_TRANSFER_VMEM0_ID,
-		IPU6_FW_PSYS_TRANSFER_VMEM1_ID,
-		IPU6_FW_PSYS_LB_VMEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-	},
-	{
-		/* IPU6_FW_PSYS_ISA_ICA_ID */
-		IPU6_FW_PSYS_TRANSFER_VMEM0_ID,
-		IPU6_FW_PSYS_TRANSFER_VMEM1_ID,
-		IPU6_FW_PSYS_LB_VMEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-	},
-	{
-		/* IPU6_FW_PSYS_ISA_LSC_ID */
-		IPU6_FW_PSYS_TRANSFER_VMEM0_ID,
-		IPU6_FW_PSYS_TRANSFER_VMEM1_ID,
-		IPU6_FW_PSYS_LB_VMEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-	},
-	{
-		/* IPU6_FW_PSYS_ISA_DPC_ID */
-		IPU6_FW_PSYS_TRANSFER_VMEM0_ID,
-		IPU6_FW_PSYS_TRANSFER_VMEM1_ID,
-		IPU6_FW_PSYS_LB_VMEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-	},
-	{
-		/* IPU6_FW_PSYS_ISA_SIS_A_ID */
-		IPU6_FW_PSYS_TRANSFER_VMEM0_ID,
-		IPU6_FW_PSYS_TRANSFER_VMEM1_ID,
-		IPU6_FW_PSYS_LB_VMEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-	},
-	{
-		/* IPU6_FW_PSYS_ISA_SIS_B_ID */
-		IPU6_FW_PSYS_TRANSFER_VMEM0_ID,
-		IPU6_FW_PSYS_TRANSFER_VMEM1_ID,
-		IPU6_FW_PSYS_LB_VMEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-	},
-	{
-		/* IPU6_FW_PSYS_ISA_B2B_ID */
-		IPU6_FW_PSYS_TRANSFER_VMEM0_ID,
-		IPU6_FW_PSYS_TRANSFER_VMEM1_ID,
-		IPU6_FW_PSYS_LB_VMEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-	},
-	{
-		/* IPU6_FW_PSYS_ISA_B2R_ID and ISA_R2I_SIE */
-		IPU6_FW_PSYS_TRANSFER_VMEM0_ID,
-		IPU6_FW_PSYS_TRANSFER_VMEM1_ID,
-		IPU6_FW_PSYS_LB_VMEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-	},
-	{
-		/* IPU6_FW_PSYS_ISA_R2I_DS_A_ID */
-		IPU6_FW_PSYS_TRANSFER_VMEM0_ID,
-		IPU6_FW_PSYS_TRANSFER_VMEM1_ID,
-		IPU6_FW_PSYS_LB_VMEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-	},
-	{
-		/* IPU6_FW_PSYS_ISA_R2I_DS_B_ID */
-		IPU6_FW_PSYS_TRANSFER_VMEM0_ID,
-		IPU6_FW_PSYS_TRANSFER_VMEM1_ID,
-		IPU6_FW_PSYS_LB_VMEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-	},
-	{
-		/* IPU6_FW_PSYS_ISA_AWB_ID */
-		IPU6_FW_PSYS_TRANSFER_VMEM0_ID,
-		IPU6_FW_PSYS_TRANSFER_VMEM1_ID,
-		IPU6_FW_PSYS_LB_VMEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-	},
-	{
-		/* IPU6_FW_PSYS_ISA_AE_ID */
-		IPU6_FW_PSYS_TRANSFER_VMEM0_ID,
-		IPU6_FW_PSYS_TRANSFER_VMEM1_ID,
-		IPU6_FW_PSYS_LB_VMEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-	},
-	{
-		/* IPU6_FW_PSYS_ISA_AF_ID */
-		IPU6_FW_PSYS_TRANSFER_VMEM0_ID,
-		IPU6_FW_PSYS_TRANSFER_VMEM1_ID,
-		IPU6_FW_PSYS_LB_VMEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-	},
-	{
-		/* IPU6_FW_PSYS_ISA_DOL_ID */
-		IPU6_FW_PSYS_TRANSFER_VMEM0_ID,
-		IPU6_FW_PSYS_TRANSFER_VMEM1_ID,
-		IPU6_FW_PSYS_LB_VMEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-	},
-	{
-		/* IPU6_FW_PSYS_ISA_X2B_MD_ID */
-		IPU6_FW_PSYS_TRANSFER_VMEM0_ID,
-		IPU6_FW_PSYS_TRANSFER_VMEM1_ID,
-		IPU6_FW_PSYS_LB_VMEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-	},
-	{
-		/* IPU6_FW_PSYS_ISA_ICA_MEDIUM_ID */
-		IPU6_FW_PSYS_TRANSFER_VMEM0_ID,
-		IPU6_FW_PSYS_TRANSFER_VMEM1_ID,
-		IPU6_FW_PSYS_LB_VMEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-	},
-	{
-		/* IPU6_FW_PSYS_ISA_X2B_SVE_RGBIR_ID */
-		IPU6_FW_PSYS_TRANSFER_VMEM0_ID,
-		IPU6_FW_PSYS_TRANSFER_VMEM1_ID,
-		IPU6_FW_PSYS_LB_VMEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-	},
-	{
-		/* IPU6_FW_PSYS_ISA_PAF_ID */
-		IPU6_FW_PSYS_TRANSFER_VMEM0_ID,
-		IPU6_FW_PSYS_TRANSFER_VMEM1_ID,
-		IPU6_FW_PSYS_LB_VMEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-	},
-	{
-		/* IPU6_FW_PSYS_BB_ACC_GDC0_ID */
-		IPU6_FW_PSYS_TRANSFER_VMEM0_ID,
-		IPU6_FW_PSYS_TRANSFER_VMEM1_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-	},
-	{
-		/* IPU6_FW_PSYS_BB_ACC_TNR_ID */
-		IPU6_FW_PSYS_TRANSFER_VMEM0_ID,
-		IPU6_FW_PSYS_TRANSFER_VMEM1_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-	}
-};
-
-static const struct ipu_fw_resource_definitions ipu6_defs = {
-	.cells = ipu6_fw_psys_cell_types,
-	.num_cells = IPU6_FW_PSYS_N_CELL_ID,
-	.num_cells_type = IPU6_FW_PSYS_N_CELL_TYPE_ID,
-
-	.dev_channels = ipu6_fw_num_dev_channels,
-	.num_dev_channels = IPU6_FW_PSYS_N_DEV_CHN_ID,
-
-	.num_ext_mem_types = IPU6_FW_PSYS_N_DATA_MEM_TYPE_ID,
-	.num_ext_mem_ids = IPU6_FW_PSYS_N_MEM_ID,
-	.ext_mem_ids = ipu6_fw_psys_mem_size,
-
-	.num_dfm_ids = IPU6_FW_PSYS_N_DEV_DFM_ID,
-
-	.dfms = ipu6_fw_psys_dfms,
-
-	.cell_mem_row = IPU6_FW_PSYS_N_MEM_TYPE_ID,
-	.cell_mem = &ipu6_fw_psys_c_mem[0][0],
-};
-
-const struct ipu_fw_resource_definitions *ipu6_res_defs = &ipu6_defs;
-
-/********** Generic resource handling **********/
-
-int ipu6_fw_psys_set_proc_dev_chn(struct ipu_fw_psys_process *ptr, u16 offset,
-				  u16 value)
-{
-	struct ipu6_fw_psys_process_ext *pm_ext;
-	u8 ps_ext_offset;
-
-	ps_ext_offset = ptr->process_extension_offset;
-	if (!ps_ext_offset)
-		return -EINVAL;
-
-	pm_ext = (struct ipu6_fw_psys_process_ext *)((u8 *)ptr + ps_ext_offset);
-
-	pm_ext->dev_chn_offset[offset] = value;
-
-	return 0;
-}
-
-int ipu6_fw_psys_set_proc_dfm_bitmap(struct ipu_fw_psys_process *ptr,
-				     u16 id, u32 bitmap,
-				     u32 active_bitmap)
-{
-	struct ipu6_fw_psys_process_ext *pm_ext;
-	u8 ps_ext_offset;
-
-	ps_ext_offset = ptr->process_extension_offset;
-	if (!ps_ext_offset)
-		return -EINVAL;
-
-	pm_ext = (struct ipu6_fw_psys_process_ext *)((u8 *)ptr + ps_ext_offset);
-
-	pm_ext->dfm_port_bitmap[id] = bitmap;
-	pm_ext->dfm_active_port_bitmap[id] = active_bitmap;
-
-	return 0;
-}
-
-int ipu6_fw_psys_set_process_ext_mem(struct ipu_fw_psys_process *ptr,
-				     u16 type_id, u16 mem_id, u16 offset)
-{
-	struct ipu6_fw_psys_process_ext *pm_ext;
-	u8 ps_ext_offset;
-
-	ps_ext_offset = ptr->process_extension_offset;
-	if (!ps_ext_offset)
-		return -EINVAL;
-
-	pm_ext = (struct ipu6_fw_psys_process_ext *)((u8 *)ptr + ps_ext_offset);
-
-	pm_ext->ext_mem_offset[type_id] = offset;
-	pm_ext->ext_mem_id[type_id] = mem_id;
-
-	return 0;
-}
-
-static struct ipu_fw_psys_program_manifest *
-get_program_manifest(const struct ipu_fw_psys_program_group_manifest *manifest,
-		     const unsigned int program_index)
-{
-	struct ipu_fw_psys_program_manifest *prg_manifest_base;
-	u8 *program_manifest = NULL;
-	u8 program_count;
-	unsigned int i;
-
-	program_count = manifest->program_count;
-
-	prg_manifest_base = (struct ipu_fw_psys_program_manifest *)
-		((char *)manifest + manifest->program_manifest_offset);
-	if (program_index < program_count) {
-		program_manifest = (u8 *)prg_manifest_base;
-		for (i = 0; i < program_index; i++)
-			program_manifest +=
-				((struct ipu_fw_psys_program_manifest *)
-				 program_manifest)->size;
-	}
-
-	return (struct ipu_fw_psys_program_manifest *)program_manifest;
-}
-
-int ipu6_fw_psys_get_program_manifest_by_process(
-	struct ipu_fw_generic_program_manifest *gen_pm,
-	const struct ipu_fw_psys_program_group_manifest *pg_manifest,
-	struct ipu_fw_psys_process *process)
-{
-	u32 program_id = process->program_idx;
-	struct ipu_fw_psys_program_manifest *pm;
-	struct ipu6_fw_psys_program_manifest_ext *pm_ext;
-
-	pm = get_program_manifest(pg_manifest, program_id);
-
-	if (!pm)
-		return -ENOENT;
-
-	if (pm->program_extension_offset) {
-		pm_ext = (struct ipu6_fw_psys_program_manifest_ext *)
-			((u8 *)pm + pm->program_extension_offset);
-
-		gen_pm->dev_chn_size = pm_ext->dev_chn_size;
-		gen_pm->dev_chn_offset = pm_ext->dev_chn_offset;
-		gen_pm->ext_mem_size = pm_ext->ext_mem_size;
-		gen_pm->ext_mem_offset = (u16 *)pm_ext->ext_mem_offset;
-		gen_pm->is_dfm_relocatable = pm_ext->is_dfm_relocatable;
-		gen_pm->dfm_port_bitmap = pm_ext->dfm_port_bitmap;
-		gen_pm->dfm_active_port_bitmap =
-			pm_ext->dfm_active_port_bitmap;
-	}
-
-	memcpy(gen_pm->cells, pm->cells, sizeof(pm->cells));
-	gen_pm->cell_id = pm->cells[0];
-	gen_pm->cell_type_id = pm->cell_type_id;
-
-	return 0;
-}
-
-#if defined(DEBUG) || defined(CONFIG_DYNAMIC_DEBUG) || \
-	(defined(CONFIG_DYNAMIC_DEBUG_CORE) && defined(DYNAMIC_DEBUG_MODULE))
-void ipu6_fw_psys_pg_dump(struct ipu_psys *psys,
-			  struct ipu_psys_kcmd *kcmd, const char *note)
-{
-	struct ipu_fw_psys_process_group *pg = kcmd->kpg->pg;
-	u32 pgid = pg->ID;
-	u8 processes = pg->process_count;
-	u16 *process_offset_table = (u16 *)((char *)pg + pg->processes_offset);
-	unsigned int p, chn, mem, mem_id;
-	unsigned int mem_type, max_mem_id, dev_chn;
-
-	if (ipu_ver == IPU_VER_6SE) {
-		mem_type = IPU6SE_FW_PSYS_N_DATA_MEM_TYPE_ID;
-		max_mem_id = IPU6SE_FW_PSYS_N_MEM_ID;
-		dev_chn = IPU6SE_FW_PSYS_N_DEV_CHN_ID;
-	} else if (ipu_ver == IPU_VER_6 || ipu_ver == IPU_VER_6EP) {
-		mem_type = IPU6_FW_PSYS_N_DATA_MEM_TYPE_ID;
-		max_mem_id = IPU6_FW_PSYS_N_MEM_ID;
-		dev_chn = IPU6_FW_PSYS_N_DEV_CHN_ID;
-	} else {
-		WARN(1, "%s ipu_ver:[%u] is unsupported!\n", __func__, ipu_ver);
-		return;
-	}
-
-	dev_dbg(&psys->adev->dev, "%s %s pgid %i has %i processes:\n",
-		__func__, note, pgid, processes);
-
-	for (p = 0; p < processes; p++) {
-		struct ipu_fw_psys_process *process =
-		    (struct ipu_fw_psys_process *)
-		    ((char *)pg + process_offset_table[p]);
-		struct ipu6_fw_psys_process_ext *pm_ext =
-		    (struct ipu6_fw_psys_process_ext *)((u8 *)process
-		    + process->process_extension_offset);
-		dev_dbg(&psys->adev->dev, "\t process %i size=%u",
-			p, process->size);
-		if (!process->process_extension_offset)
-			continue;
-
-		for (mem = 0; mem < mem_type; mem++) {
-			mem_id = pm_ext->ext_mem_id[mem];
-			if (mem_id != max_mem_id)
-				dev_dbg(&psys->adev->dev,
-					"\t mem type %u id %d offset=0x%x",
-					mem, mem_id,
-					pm_ext->ext_mem_offset[mem]);
-		}
-		for (chn = 0; chn < dev_chn; chn++) {
-			if (pm_ext->dev_chn_offset[chn] != (u16)(-1))
-				dev_dbg(&psys->adev->dev,
-					"\t dev_chn[%u]=0x%x\n",
-					chn, pm_ext->dev_chn_offset[chn]);
-		}
-	}
-}
-#else
-void ipu6_fw_psys_pg_dump(struct ipu_psys *psys,
-			  struct ipu_psys_kcmd *kcmd, const char *note)
-{
-	if (ipu_ver == IPU_VER_6SE || ipu_ver == IPU_VER_6 ||
-	    ipu_ver == IPU_VER_6EP)
-		return;
-
-	WARN(1, "%s ipu_ver:[%u] is unsupported!\n", __func__, ipu_ver);
-}
-#endif
diff --git a/drivers/media/pci/intel/ipu6/ipu6-isys-csi2.c b/drivers/media/pci/intel/ipu6/ipu6-isys-csi2.c
deleted file mode 100644
index b0f39586256b..000000000000
--- a/drivers/media/pci/intel/ipu6/ipu6-isys-csi2.c
+++ /dev/null
@@ -1,513 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0
-// Copyright (C) 2020 Intel Corporation
-
-#include <linux/delay.h>
-#include <linux/spinlock.h>
-#include <media/ipu-isys.h>
-#include "ipu.h"
-#include "ipu-buttress.h"
-#include "ipu-isys.h"
-#include "ipu-platform-buttress-regs.h"
-#include "ipu-platform-regs.h"
-#include "ipu-platform-isys-csi2-reg.h"
-#include "ipu6-isys-csi2.h"
-#include "ipu6-isys-phy.h"
-#include "ipu-isys-csi2.h"
-
-struct ipu6_csi2_error {
-	const char *error_string;
-	bool is_info_only;
-};
-
-struct ipu6_csi_irq_info_map {
-	u32 irq_error_mask;
-	u32 irq_num;
-	unsigned int irq_base;
-	unsigned int irq_base_ctrl2;
-	struct ipu6_csi2_error *errors;
-};
-
-/*
- * Strings corresponding to CSI-2 receiver errors are here.
- * Corresponding macros are defined in the header file.
- */
-static struct ipu6_csi2_error dphy_rx_errors[] = {
-	{"Single packet header error corrected", true},
-	{"Multiple packet header errors detected", true},
-	{"Payload checksum (CRC) error", true},
-	{"Transfer FIFO overflow", false},
-	{"Reserved short packet data type detected", true},
-	{"Reserved long packet data type detected", true},
-	{"Incomplete long packet detected", false},
-	{"Frame sync error", false},
-	{"Line sync error", false},
-	{"DPHY recoverable synchronization error", true},
-	{"DPHY fatal error", false},
-	{"DPHY elastic FIFO overflow", false},
-	{"Inter-frame short packet discarded", true},
-	{"Inter-frame long packet discarded", true},
-	{"MIPI pktgen overflow", false},
-	{"MIPI pktgen data loss", false},
-	{"FIFO overflow", false},
-	{"Lane deskew", false},
-	{"SOT sync error", false},
-	{"HSIDLE detected", false}
-};
-
-static refcount_t phy_power_ref_count[IPU_ISYS_CSI_PHY_NUM];
-
-static int ipu6_csi2_phy_power_set(struct ipu_isys *isys,
-				   struct ipu_isys_csi2_config *cfg, bool on)
-{
-	int ret = 0;
-	unsigned int port, phy_id;
-	refcount_t *ref;
-	void __iomem *isys_base = isys->pdata->base;
-	unsigned int nr;
-
-	port = cfg->port;
-	phy_id = port / 4;
-	ref = &phy_power_ref_count[phy_id];
-	dev_dbg(&isys->adev->dev, "for phy %d port %d, lanes: %d\n",
-		phy_id, port, cfg->nlanes);
-
-	nr = (ipu_ver == IPU_VER_6 || ipu_ver == IPU_VER_6EP) ?
-		IPU6_ISYS_CSI_PORT_NUM : IPU6SE_ISYS_CSI_PORT_NUM;
-
-	if (!isys_base || port >= nr) {
-		dev_warn(&isys->adev->dev, "invalid port ID %d\n", port);
-		return -EINVAL;
-	}
-
-	if (on) {
-		if (refcount_read(ref)) {
-			/* already up */
-			dev_warn(&isys->adev->dev, "for phy %d is already UP",
-				 phy_id);
-			refcount_inc(ref);
-			return 0;
-		}
-
-		ret = ipu6_isys_phy_powerup_ack(isys, phy_id);
-		if (ret)
-			return ret;
-
-		ipu6_isys_phy_reset(isys, phy_id, 0);
-		ipu6_isys_phy_common_init(isys);
-
-		ret = ipu6_isys_phy_config(isys);
-		if (ret)
-			return ret;
-
-		ipu6_isys_phy_reset(isys, phy_id, 1);
-		ret = ipu6_isys_phy_ready(isys, phy_id);
-		if (ret)
-			return ret;
-
-		refcount_set(ref, 1);
-		return 0;
-	}
-
-	/* power off process */
-	if (refcount_dec_and_test(ref))
-		ret = ipu6_isys_phy_powerdown_ack(isys, phy_id);
-	if (ret)
-		dev_err(&isys->adev->dev, "phy poweroff failed!");
-
-	return ret;
-}
-
-static void ipu6_isys_register_errors(struct ipu_isys_csi2 *csi2)
-{
-	u32 mask = 0;
-	u32 irq = readl(csi2->base + CSI_PORT_REG_BASE_IRQ_CSI +
-			CSI_PORT_REG_BASE_IRQ_STATUS_OFFSET);
-
-	mask = (ipu_ver == IPU_VER_6 || ipu_ver == IPU_VER_6EP) ?
-		IPU6_CSI_RX_ERROR_IRQ_MASK : IPU6SE_CSI_RX_ERROR_IRQ_MASK;
-
-	writel(irq & mask,
-	       csi2->base + CSI_PORT_REG_BASE_IRQ_CSI +
-	       CSI_PORT_REG_BASE_IRQ_CLEAR_OFFSET);
-	csi2->receiver_errors |= irq & mask;
-}
-
-void ipu_isys_csi2_error(struct ipu_isys_csi2 *csi2)
-{
-	struct ipu6_csi2_error *errors;
-	u32 status;
-	unsigned int i;
-
-	/* Register errors once more in case of error interrupts are disabled */
-	ipu6_isys_register_errors(csi2);
-	status = csi2->receiver_errors;
-	csi2->receiver_errors = 0;
-	errors = dphy_rx_errors;
-
-	for (i = 0; i < CSI_RX_NUM_ERRORS_IN_IRQ; i++) {
-		if (status & BIT(i))
-			dev_err_ratelimited(&csi2->isys->adev->dev,
-					    "csi2-%i error: %s\n",
-					    csi2->index,
-					    errors[i].error_string);
-	}
-}
-
-const unsigned int csi2_port_cfg[][3] = {
-	{0, 0, 0x1f}, /* no link */
-	{4, 0, 0x10}, /* x4 + x4 config */
-	{2, 0, 0x12}, /* x2 + x2 config */
-	{1, 0, 0x13}, /* x1 + x1 config */
-	{2, 1, 0x15}, /* x2x1 + x2x1 config */
-	{1, 1, 0x16}, /* x1x1 + x1x1 config */
-	{2, 2, 0x18}, /* x2x2 + x2x2 config */
-	{1, 2, 0x19}, /* x1x2 + x1x2 config */
-};
-
-const unsigned int phy_port_cfg[][4] = {
-	/* port, nlanes, bbindex, portcfg */
-	/* sip0 */
-	{0, 1, 0, 0x15},
-	{0, 2, 0, 0x15},
-	{0, 4, 0, 0x15},
-	{0, 4, 2, 0x22},
-	/* sip1 */
-	{2, 1, 4, 0x15},
-	{2, 2, 4, 0x15},
-	{2, 4, 4, 0x15},
-	{2, 4, 6, 0x22},
-};
-
-static int ipu_isys_csi2_phy_config_by_port(struct ipu_isys *isys,
-					    unsigned int port,
-					    unsigned int nlanes)
-{
-	void __iomem *base = isys->adev->isp->base;
-	u32 val, reg, i;
-	unsigned int bbnum;
-
-	dev_dbg(&isys->adev->dev, "%s port %u with %u lanes", __func__,
-		port, nlanes);
-
-	/* hard code for x2x2 + x2x2 with <1.5Gbps */
-	for (i = 0; i < IPU6SE_ISYS_PHY_BB_NUM; i++) {
-		/* cphy_dll_ovrd.crcdc_fsm_dlane0 = 13 */
-		reg = IPU6SE_ISYS_PHY_0_BASE + PHY_CPHY_DLL_OVRD(i);
-		val = readl(base + reg);
-		val |= 13 << 1;
-		/* val &= ~0x1; */
-		writel(val, base + reg);
-
-		/* cphy_rx_control1.en_crc1 = 1 */
-		reg = IPU6SE_ISYS_PHY_0_BASE + PHY_CPHY_RX_CONTROL1(i);
-		val = readl(base + reg);
-		val |= 0x1 << 31;
-		writel(val, base + reg);
-
-		/* dphy_cfg.reserved = 1
-		 * dphy_cfg.lden_from_dll_ovrd_0 = 1
-		 */
-		reg = IPU6SE_ISYS_PHY_0_BASE + PHY_DPHY_CFG(i);
-		val = readl(base + reg);
-		val |= 0x1 << 25;
-		val |= 0x1 << 26;
-		writel(val, base + reg);
-
-		/* cphy_dll_ovrd.lden_crcdc_fsm_dlane0 = 1 */
-		reg = IPU6SE_ISYS_PHY_0_BASE + PHY_CPHY_DLL_OVRD(i);
-		val = readl(base + reg);
-		val |= 1;
-		writel(val, base + reg);
-	}
-
-	/* bb afe config, use minimal channel loss */
-	for (i = 0; i < ARRAY_SIZE(phy_port_cfg); i++) {
-		if (phy_port_cfg[i][0] == port &&
-		    phy_port_cfg[i][1] == nlanes) {
-			bbnum = phy_port_cfg[i][2] / 2;
-			reg = IPU6SE_ISYS_PHY_0_BASE + PHY_BB_AFE_CONFIG(bbnum);
-			val = readl(base + reg);
-			val |= phy_port_cfg[i][3];
-			writel(val, base + reg);
-		}
-	}
-
-	return 0;
-}
-
-static void ipu_isys_csi2_rx_control(struct ipu_isys *isys)
-{
-	void __iomem *base = isys->adev->isp->base;
-	u32 val, reg;
-
-	/* lp11 release */
-	reg = CSI2_HUB_GPREG_SIP0_CSI_RX_A_CONTROL;
-	val = readl(base + reg);
-	val |= 0x1;
-	writel(0x1, base + CSI2_HUB_GPREG_SIP0_CSI_RX_A_CONTROL);
-
-	reg = CSI2_HUB_GPREG_SIP0_CSI_RX_B_CONTROL;
-	val = readl(base + reg);
-	val |= 0x1;
-	writel(0x1, base + CSI2_HUB_GPREG_SIP0_CSI_RX_B_CONTROL);
-
-	reg = CSI2_HUB_GPREG_SIP1_CSI_RX_A_CONTROL;
-	val = readl(base + reg);
-	val |= 0x1;
-	writel(0x1, base + CSI2_HUB_GPREG_SIP1_CSI_RX_A_CONTROL);
-
-	reg = CSI2_HUB_GPREG_SIP1_CSI_RX_B_CONTROL;
-	val = readl(base + reg);
-	val |= 0x1;
-	writel(0x1, base + CSI2_HUB_GPREG_SIP1_CSI_RX_B_CONTROL);
-}
-
-static int ipu_isys_csi2_set_port_cfg(struct v4l2_subdev *sd, unsigned int port,
-				      unsigned int nlanes)
-{
-	struct ipu_isys_csi2 *csi2 = to_ipu_isys_csi2(sd);
-	struct ipu_isys *isys = csi2->isys;
-	unsigned int sip = port / 2;
-	unsigned int index;
-
-	switch (nlanes) {
-	case 1:
-		index = 5;
-		break;
-	case 2:
-		index = 6;
-		break;
-	case 4:
-		index = 1;
-		break;
-	default:
-		dev_err(&isys->adev->dev, "lanes nr %u is unsupported\n",
-			nlanes);
-		return -EINVAL;
-	}
-
-	dev_dbg(&isys->adev->dev, "port config for port %u with %u lanes\n",
-		port, nlanes);
-	writel(csi2_port_cfg[index][2],
-	       isys->pdata->base + CSI2_HUB_GPREG_SIP_FB_PORT_CFG(sip));
-
-	return 0;
-}
-
-static void ipu_isys_csi2_set_timing(struct v4l2_subdev *sd,
-				     struct ipu_isys_csi2_timing timing,
-				     unsigned int port,
-				     unsigned int nlanes)
-{
-	u32 port_base;
-	void __iomem *reg;
-	struct ipu_isys_csi2 *csi2 = to_ipu_isys_csi2(sd);
-	struct ipu_isys *isys = csi2->isys;
-	unsigned int i;
-
-	port_base = (port % 2) ? CSI2_SIP_TOP_CSI_RX_PORT_BASE_1(port) :
-		CSI2_SIP_TOP_CSI_RX_PORT_BASE_0(port);
-
-	dev_dbg(&isys->adev->dev,
-		"set timing for port %u base 0x%x with %u lanes\n",
-		port, port_base, nlanes);
-
-	reg = isys->pdata->base + port_base;
-	reg += CSI2_SIP_TOP_CSI_RX_DLY_CNT_TERMEN_CLANE;
-
-	writel(timing.ctermen, reg);
-
-	reg = isys->pdata->base + port_base;
-	reg += CSI2_SIP_TOP_CSI_RX_DLY_CNT_SETTLE_CLANE;
-	writel(timing.csettle, reg);
-
-	for (i = 0; i < nlanes; i++) {
-		reg = isys->pdata->base + port_base;
-		reg += CSI2_SIP_TOP_CSI_RX_DLY_CNT_TERMEN_DLANE(i);
-		writel(timing.dtermen, reg);
-
-		reg = isys->pdata->base + port_base;
-		reg += CSI2_SIP_TOP_CSI_RX_DLY_CNT_SETTLE_DLANE(i);
-		writel(timing.dsettle, reg);
-	}
-}
-
-int ipu_isys_csi2_set_stream(struct v4l2_subdev *sd,
-			     struct ipu_isys_csi2_timing timing,
-			     unsigned int nlanes, int enable)
-{
-	struct ipu_isys_csi2 *csi2 = to_ipu_isys_csi2(sd);
-	struct ipu_isys *isys = csi2->isys;
-	struct ipu_isys_pipeline *ip = container_of(sd->entity.pipe,
-						    struct ipu_isys_pipeline,
-						    pipe);
-	struct ipu_isys_csi2_config *cfg =
-		v4l2_get_subdev_hostdata(media_entity_to_v4l2_subdev
-					 (ip->external->entity));
-	unsigned int port;
-	int ret;
-	u32 mask = 0;
-
-	port = cfg->port;
-	dev_dbg(&isys->adev->dev, "for port %u\n", port);
-
-	mask = (ipu_ver == IPU_VER_6 || ipu_ver == IPU_VER_6EP) ?
-		IPU6_CSI_RX_ERROR_IRQ_MASK : IPU6SE_CSI_RX_ERROR_IRQ_MASK;
-
-	if (!enable) {
-
-		writel(0, csi2->base + CSI_REG_CSI_FE_ENABLE);
-		writel(0, csi2->base + CSI_REG_PPI2CSI_ENABLE);
-
-		/* Disable interrupts */
-		writel(0,
-		       csi2->base + CSI_PORT_REG_BASE_IRQ_CSI +
-		       CSI_PORT_REG_BASE_IRQ_ENABLE_OFFSET);
-		writel(mask,
-		       csi2->base + CSI_PORT_REG_BASE_IRQ_CSI +
-		       CSI_PORT_REG_BASE_IRQ_CLEAR_OFFSET);
-		writel(0,
-		       csi2->base + CSI_PORT_REG_BASE_IRQ_CSI_SYNC +
-		       CSI_PORT_REG_BASE_IRQ_ENABLE_OFFSET);
-		writel(0xffffffff,
-		       csi2->base + CSI_PORT_REG_BASE_IRQ_CSI_SYNC +
-		       CSI_PORT_REG_BASE_IRQ_CLEAR_OFFSET);
-
-		/* Disable clock */
-		writel(0, isys->pdata->base +
-		       CSI_REG_HUB_FW_ACCESS_PORT(port));
-		writel(0, isys->pdata->base +
-		       CSI_REG_HUB_DRV_ACCESS_PORT(port));
-
-		if (ipu_ver == IPU_VER_6SE)
-			return 0;
-
-		/* power down */
-		return ipu6_csi2_phy_power_set(isys, cfg, false);
-	}
-
-	if (ipu_ver == IPU_VER_6 || ipu_ver == IPU_VER_6EP) {
-		/* Enable DPHY power */
-		ret = ipu6_csi2_phy_power_set(isys, cfg, true);
-		if (ret) {
-			dev_err(&isys->adev->dev,
-				"CSI-%d PHY power up failed %d\n",
-				cfg->port, ret);
-			return ret;
-		}
-	}
-
-	/* reset port reset */
-	writel(0x1, csi2->base + CSI_REG_PORT_GPREG_SRST);
-	usleep_range(100, 200);
-	writel(0x0, csi2->base + CSI_REG_PORT_GPREG_SRST);
-
-	/* Enable port clock */
-	writel(1, isys->pdata->base + CSI_REG_HUB_DRV_ACCESS_PORT(port));
-	writel(1, isys->pdata->base + CSI_REG_HUB_FW_ACCESS_PORT(port));
-
-	if (ipu_ver == IPU_VER_6SE) {
-		ipu_isys_csi2_phy_config_by_port(isys, port, nlanes);
-
-		/* 9'b00010.1000 for 400Mhz isys freqency */
-		writel(0x28,
-		       isys->pdata->base + CSI2_HUB_GPREG_DPHY_TIMER_INCR);
-		/* set port cfg and rx timing */
-		ipu_isys_csi2_set_timing(sd, timing, port, nlanes);
-
-		ret = ipu_isys_csi2_set_port_cfg(sd, port, nlanes);
-		if (ret)
-			return ret;
-
-		ipu_isys_csi2_rx_control(isys);
-	}
-
-	/* enable all error related irq */
-	writel(mask,
-	       csi2->base + CSI_PORT_REG_BASE_IRQ_CSI +
-	       CSI_PORT_REG_BASE_IRQ_STATUS_OFFSET);
-	writel(mask,
-	       csi2->base + CSI_PORT_REG_BASE_IRQ_CSI +
-	       CSI_PORT_REG_BASE_IRQ_MASK_OFFSET);
-	writel(mask,
-	       csi2->base + CSI_PORT_REG_BASE_IRQ_CSI +
-	       CSI_PORT_REG_BASE_IRQ_CLEAR_OFFSET);
-	writel(mask,
-	       csi2->base + CSI_PORT_REG_BASE_IRQ_CSI +
-	       CSI_PORT_REG_BASE_IRQ_LEVEL_NOT_PULSE_OFFSET);
-	writel(mask,
-	       csi2->base + CSI_PORT_REG_BASE_IRQ_CSI +
-	       CSI_PORT_REG_BASE_IRQ_ENABLE_OFFSET);
-
-	/* To save CPU wakeups, disable CSI SOF/EOF irq */
-	writel(0xffffffff, csi2->base + CSI_PORT_REG_BASE_IRQ_CSI_SYNC +
-	       CSI_PORT_REG_BASE_IRQ_STATUS_OFFSET);
-	writel(0, csi2->base + CSI_PORT_REG_BASE_IRQ_CSI_SYNC +
-	       CSI_PORT_REG_BASE_IRQ_MASK_OFFSET);
-	writel(0xffffffff, csi2->base + CSI_PORT_REG_BASE_IRQ_CSI_SYNC +
-	       CSI_PORT_REG_BASE_IRQ_CLEAR_OFFSET);
-	writel(0, csi2->base + CSI_PORT_REG_BASE_IRQ_CSI_SYNC +
-	       CSI_PORT_REG_BASE_IRQ_LEVEL_NOT_PULSE_OFFSET);
-	writel(0xffffffff, csi2->base + CSI_PORT_REG_BASE_IRQ_CSI_SYNC +
-	       CSI_PORT_REG_BASE_IRQ_ENABLE_OFFSET);
-
-	/* Configure FE/PPI2CSI and enable FE/ PPI2CSI */
-	writel(0, csi2->base + CSI_REG_CSI_FE_MODE);
-	writel(CSI_SENSOR_INPUT, csi2->base + CSI_REG_CSI_FE_MUX_CTRL);
-	writel(CSI_CNTR_SENSOR_LINE_ID | CSI_CNTR_SENSOR_FRAME_ID,
-	       csi2->base + CSI_REG_CSI_FE_SYNC_CNTR_SEL);
-	writel(((nlanes - 1) <<
-		PPI_INTF_CONFIG_NOF_ENABLED_DATALANES_SHIFT) |
-	       (0 << PPI_INTF_CONFIG_RX_AUTO_CLKGATING_SHIFT),
-	       csi2->base + CSI_REG_PPI2CSI_CONFIG_PPI_INTF);
-	writel(0x06, csi2->base + CSI_REG_PPI2CSI_CONFIG_CSI_FEATURE);
-	writel(1, csi2->base + CSI_REG_PPI2CSI_ENABLE);
-	writel(1, csi2->base + CSI_REG_CSI_FE_ENABLE);
-
-	return 0;
-}
-
-void ipu_isys_csi2_isr(struct ipu_isys_csi2 *csi2)
-{
-	u32 status;
-
-	ipu6_isys_register_errors(csi2);
-
-	status = readl(csi2->base + CSI_PORT_REG_BASE_IRQ_CSI_SYNC +
-		       CSI_PORT_REG_BASE_IRQ_STATUS_OFFSET);
-
-	writel(status, csi2->base + CSI_PORT_REG_BASE_IRQ_CSI_SYNC +
-	       CSI_PORT_REG_BASE_IRQ_CLEAR_OFFSET);
-
-	if (status & IPU_CSI_RX_IRQ_FS_VC)
-		ipu_isys_csi2_sof_event(csi2);
-	if (status & IPU_CSI_RX_IRQ_FE_VC)
-		ipu_isys_csi2_eof_event(csi2);
-}
-
-unsigned int ipu_isys_csi2_get_current_field(struct ipu_isys_pipeline *ip,
-					     unsigned int *timestamp)
-{
-	struct ipu_isys_video *av = container_of(ip, struct ipu_isys_video, ip);
-	struct ipu_isys *isys = av->isys;
-	unsigned int field = V4L2_FIELD_TOP;
-
-	struct ipu_isys_buffer *short_packet_ib =
-		list_last_entry(&ip->short_packet_active,
-				struct ipu_isys_buffer, head);
-	struct ipu_isys_private_buffer *pb =
-		ipu_isys_buffer_to_private_buffer(short_packet_ib);
-	struct ipu_isys_mipi_packet_header *ph =
-		(struct ipu_isys_mipi_packet_header *)
-		pb->buffer;
-
-	/* Check if the first SOF packet is received. */
-	if ((ph->dtype & IPU_ISYS_SHORT_PACKET_DTYPE_MASK) != 0)
-		dev_warn(&isys->adev->dev, "First short packet is not SOF.\n");
-	field = (ph->word_count % 2) ? V4L2_FIELD_TOP : V4L2_FIELD_BOTTOM;
-	dev_dbg(&isys->adev->dev,
-		"Interlaced field ready. frame_num = %d field = %d\n",
-		ph->word_count, field);
-
-	return field;
-}
diff --git a/drivers/media/pci/intel/ipu6/ipu6-isys-csi2.h b/drivers/media/pci/intel/ipu6/ipu6-isys-csi2.h
deleted file mode 100644
index 9db3ef6f8869..000000000000
--- a/drivers/media/pci/intel/ipu6/ipu6-isys-csi2.h
+++ /dev/null
@@ -1,14 +0,0 @@
-/* SPDX-License-Identifier: GPL-2.0 */
-/* Copyright (C) 2020 Intel Corporation */
-
-#ifndef IPU6_ISYS_CSI2_H
-#define IPU6_ISYS_CSI2_H
-
-struct ipu_isys_csi2_timing;
-struct ipu_isys_csi2;
-struct ipu_isys_pipeline;
-struct v4l2_subdev;
-
-#define IPU_ISYS_SHORT_PACKET_DTYPE_MASK	0x3f
-
-#endif /* IPU6_ISYS_CSI2_H */
diff --git a/drivers/media/pci/intel/ipu6/ipu6-isys-gpc.c b/drivers/media/pci/intel/ipu6/ipu6-isys-gpc.c
deleted file mode 100644
index a305c0c3e2cf..000000000000
--- a/drivers/media/pci/intel/ipu6/ipu6-isys-gpc.c
+++ /dev/null
@@ -1,203 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0
-// Copyright (C) 2020 Intel Corporation
-
-#ifdef CONFIG_DEBUG_FS
-#include <linux/debugfs.h>
-#include <linux/pm_runtime.h>
-
-#include "ipu-isys.h"
-#include "ipu-platform-regs.h"
-
-#define IPU_ISYS_GPC_NUM		16
-
-#ifndef CONFIG_PM
-#define pm_runtime_get_sync(d)		0
-#define pm_runtime_put(d)		0
-#endif
-
-struct ipu_isys_gpc {
-	bool enable;
-	unsigned int route;
-	unsigned int source;
-	unsigned int sense;
-	unsigned int gpcindex;
-	void *prit;
-};
-
-struct ipu_isys_gpcs {
-	bool gpc_enable;
-	struct ipu_isys_gpc gpc[IPU_ISYS_GPC_NUM];
-	void *prit;
-};
-
-static int ipu6_isys_gpc_global_enable_get(void *data, u64 *val)
-{
-	struct ipu_isys_gpcs *isys_gpcs = data;
-	struct ipu_isys *isys = isys_gpcs->prit;
-
-	mutex_lock(&isys->mutex);
-
-	*val = isys_gpcs->gpc_enable;
-
-	mutex_unlock(&isys->mutex);
-	return 0;
-}
-
-static int ipu6_isys_gpc_global_enable_set(void *data, u64 val)
-{
-	struct ipu_isys_gpcs *isys_gpcs = data;
-	struct ipu_isys *isys = isys_gpcs->prit;
-	void __iomem *base;
-	int i, ret;
-
-	if (val != 0 && val != 1)
-		return -EINVAL;
-
-	if (!isys || !isys->pdata || !isys->pdata->base)
-		return -EINVAL;
-
-	mutex_lock(&isys->mutex);
-
-	base = isys->pdata->base + IPU_ISYS_GPC_BASE;
-
-	ret = pm_runtime_get_sync(&isys->adev->dev);
-	if (ret < 0) {
-		pm_runtime_put(&isys->adev->dev);
-		mutex_unlock(&isys->mutex);
-		return ret;
-	}
-
-	if (!val) {
-		writel(0x0, base + IPU_ISYS_GPREG_TRACE_TIMER_RST);
-		writel(0x0, base + IPU_ISF_CDC_MMU_GPC_OVERALL_ENABLE);
-		writel(0xffff, base + IPU_ISF_CDC_MMU_GPC_SOFT_RESET);
-		isys_gpcs->gpc_enable = false;
-		for (i = 0; i < IPU_ISYS_GPC_NUM; i++) {
-			isys_gpcs->gpc[i].enable = 0;
-			isys_gpcs->gpc[i].sense = 0;
-			isys_gpcs->gpc[i].route = 0;
-			isys_gpcs->gpc[i].source = 0;
-		}
-		pm_runtime_mark_last_busy(&isys->adev->dev);
-		pm_runtime_put_autosuspend(&isys->adev->dev);
-	} else {
-		/*
-		 * Set gpc reg and start all gpc here.
-		 * RST free running local timer.
-		 */
-		writel(0x0, base + IPU_ISYS_GPREG_TRACE_TIMER_RST);
-		writel(0x1, base + IPU_ISYS_GPREG_TRACE_TIMER_RST);
-
-		for (i = 0; i < IPU_ISYS_GPC_NUM; i++) {
-			/* Enable */
-			writel(isys_gpcs->gpc[i].enable,
-			       base + IPU_ISF_CDC_MMU_GPC_ENABLE0 + 4 * i);
-			/* Setting (route/source/sense) */
-			writel((isys_gpcs->gpc[i].sense
-					<< IPU_GPC_SENSE_OFFSET)
-				+ (isys_gpcs->gpc[i].route
-					<< IPU_GPC_ROUTE_OFFSET)
-				+ (isys_gpcs->gpc[i].source
-					<< IPU_GPC_SOURCE_OFFSET),
-				base + IPU_ISF_CDC_MMU_GPC_CNT_SEL0 + 4 * i);
-		}
-
-		/* Soft reset and Overall Enable. */
-		writel(0x0, base + IPU_ISF_CDC_MMU_GPC_OVERALL_ENABLE);
-		writel(0xffff, base + IPU_ISF_CDC_MMU_GPC_SOFT_RESET);
-		writel(0x1, base + IPU_ISF_CDC_MMU_GPC_OVERALL_ENABLE);
-
-		isys_gpcs->gpc_enable = true;
-	}
-
-	mutex_unlock(&isys->mutex);
-	return 0;
-}
-
-DEFINE_SIMPLE_ATTRIBUTE(isys_gpc_globe_enable_fops,
-			ipu6_isys_gpc_global_enable_get,
-			ipu6_isys_gpc_global_enable_set, "%llu\n");
-
-static int ipu6_isys_gpc_count_get(void *data, u64 *val)
-{
-	struct ipu_isys_gpc *isys_gpc = data;
-	struct ipu_isys *isys = isys_gpc->prit;
-	void __iomem *base;
-
-	if (!isys || !isys->pdata || !isys->pdata->base)
-		return -EINVAL;
-
-	spin_lock(&isys->power_lock);
-	if (isys->power) {
-		base = isys->pdata->base + IPU_ISYS_GPC_BASE;
-		*val = readl(base + IPU_ISF_CDC_MMU_GPC_VALUE0
-				 + 4 * isys_gpc->gpcindex);
-	} else {
-		*val = 0;
-	}
-	spin_unlock(&isys->power_lock);
-
-	return 0;
-}
-
-DEFINE_SIMPLE_ATTRIBUTE(isys_gpc_count_fops, ipu6_isys_gpc_count_get,
-			NULL, "%llu\n");
-
-int ipu_isys_gpc_init_debugfs(struct ipu_isys *isys)
-{
-	struct dentry *gpcdir;
-	struct dentry *dir;
-	struct dentry *file;
-	int i;
-	char gpcname[10];
-	struct ipu_isys_gpcs *isys_gpcs;
-
-	isys_gpcs = devm_kzalloc(&isys->adev->dev, sizeof(*isys_gpcs),
-				 GFP_KERNEL);
-	if (!isys_gpcs)
-		return -ENOMEM;
-
-	gpcdir = debugfs_create_dir("gpcs", isys->debugfsdir);
-	if (IS_ERR(gpcdir))
-		return -ENOMEM;
-
-	isys_gpcs->prit = isys;
-	file = debugfs_create_file("enable", 0600, gpcdir, isys_gpcs,
-				   &isys_gpc_globe_enable_fops);
-	if (IS_ERR(file))
-		goto err;
-
-	for (i = 0; i < IPU_ISYS_GPC_NUM; i++) {
-		sprintf(gpcname, "gpc%d", i);
-		dir = debugfs_create_dir(gpcname, gpcdir);
-		if (IS_ERR(dir))
-			goto err;
-
-		debugfs_create_bool("enable", 0600, dir,
-				    &isys_gpcs->gpc[i].enable);
-
-		debugfs_create_u32("source", 0600, dir,
-				   &isys_gpcs->gpc[i].source);
-
-		debugfs_create_u32("route", 0600, dir,
-				   &isys_gpcs->gpc[i].route);
-
-		debugfs_create_u32("sense", 0600, dir,
-				   &isys_gpcs->gpc[i].sense);
-
-		isys_gpcs->gpc[i].gpcindex = i;
-		isys_gpcs->gpc[i].prit = isys;
-		file = debugfs_create_file("count", 0400, dir,
-					   &isys_gpcs->gpc[i],
-					   &isys_gpc_count_fops);
-		if (IS_ERR(file))
-			goto err;
-	}
-
-	return 0;
-
-err:
-	debugfs_remove_recursive(gpcdir);
-	return -ENOMEM;
-}
-#endif
diff --git a/drivers/media/pci/intel/ipu6/ipu6-isys-phy.c b/drivers/media/pci/intel/ipu6/ipu6-isys-phy.c
deleted file mode 100644
index c26780106c78..000000000000
--- a/drivers/media/pci/intel/ipu6/ipu6-isys-phy.c
+++ /dev/null
@@ -1,595 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0
-/*
- * Copyright (C) 2013 - 2020 Intel Corporation
- */
-
-#include <linux/delay.h>
-#include <media/ipu-isys.h>
-#include <media/v4l2-device.h>
-#include "ipu.h"
-#include "ipu-buttress.h"
-#include "ipu-isys.h"
-#include "ipu-isys-csi2.h"
-#include "ipu-platform-regs.h"
-#include "ipu-platform-isys-csi2-reg.h"
-#include "ipu6-isys-csi2.h"
-#include "ipu6-isys-phy.h"
-
-#define LOOP (2000)
-
-#define PHY_REG_INIT_CTL	     0x00000694
-#define PHY_REG_INIT_CTL_PORT_OFFSET 0x00000600
-
-struct phy_reg {
-	u32 reg;
-	u32 val;
-};
-
-static const struct phy_reg common_init_regs[] = {
-	/* for TGL-U, use 0x80000000 */
-	{0x00000040, 0x80000000},
-	{0x00000044, 0x00a80880},
-	{0x00000044, 0x00b80880},
-	{0x00000010, 0x0000078c},
-	{0x00000344, 0x2f4401e2},
-	{0x00000544, 0x924401e2},
-	{0x00000744, 0x594401e2},
-	{0x00000944, 0x624401e2},
-	{0x00000b44, 0xfc4401e2},
-	{0x00000d44, 0xc54401e2},
-	{0x00000f44, 0x034401e2},
-	{0x00001144, 0x8f4401e2},
-	{0x00001344, 0x754401e2},
-	{0x00001544, 0xe94401e2},
-	{0x00001744, 0xcb4401e2},
-	{0x00001944, 0xfa4401e2}
-};
-
-static const struct phy_reg x1_port0_config_regs[] = {
-	{0x00000694, 0xc80060fa},
-	{0x00000680, 0x3d4f78ea},
-	{0x00000690, 0x10a0140b},
-	{0x000006a8, 0xdf04010a},
-	{0x00000700, 0x57050060},
-	{0x00000710, 0x0030001c},
-	{0x00000738, 0x5f004444},
-	{0x0000073c, 0x78464204},
-	{0x00000748, 0x7821f940},
-	{0x0000074c, 0xb2000433},
-	{0x00000494, 0xfe6030fa},
-	{0x00000480, 0x29ef5ed0},
-	{0x00000490, 0x10a0540b},
-	{0x000004a8, 0x7a01010a},
-	{0x00000500, 0xef053460},
-	{0x00000510, 0xe030101c},
-	{0x00000538, 0xdf808444},
-	{0x0000053c, 0xc8422204},
-	{0x00000540, 0x0180088c},
-	{0x00000574, 0x00000000},
-	{0x00000000, 0x00000000}
-};
-
-static const struct phy_reg x1_port1_config_regs[] = {
-	{0x00000c94, 0xc80060fa},
-	{0x00000c80, 0xcf47abea},
-	{0x00000c90, 0x10a0840b},
-	{0x00000ca8, 0xdf04010a},
-	{0x00000d00, 0x57050060},
-	{0x00000d10, 0x0030001c},
-	{0x00000d38, 0x5f004444},
-	{0x00000d3c, 0x78464204},
-	{0x00000d48, 0x7821f940},
-	{0x00000d4c, 0xb2000433},
-	{0x00000a94, 0xc91030fa},
-	{0x00000a80, 0x5a166ed0},
-	{0x00000a90, 0x10a0540b},
-	{0x00000aa8, 0x5d060100},
-	{0x00000b00, 0xef053460},
-	{0x00000b10, 0xa030101c},
-	{0x00000b38, 0xdf808444},
-	{0x00000b3c, 0xc8422204},
-	{0x00000b40, 0x0180088c},
-	{0x00000b74, 0x00000000},
-	{0x00000000, 0x00000000}
-};
-
-static const struct phy_reg x1_port2_config_regs[] = {
-	{0x00001294, 0x28f000fa},
-	{0x00001280, 0x08130cea},
-	{0x00001290, 0x10a0140b},
-	{0x000012a8, 0xd704010a},
-	{0x00001300, 0x8d050060},
-	{0x00001310, 0x0030001c},
-	{0x00001338, 0xdf008444},
-	{0x0000133c, 0x78422204},
-	{0x00001348, 0x7821f940},
-	{0x0000134c, 0x5a000433},
-	{0x00001094, 0x2d20b0fa},
-	{0x00001080, 0xade75dd0},
-	{0x00001090, 0x10a0540b},
-	{0x000010a8, 0xb101010a},
-	{0x00001100, 0x33053460},
-	{0x00001110, 0x0030101c},
-	{0x00001138, 0xdf808444},
-	{0x0000113c, 0xc8422204},
-	{0x00001140, 0x8180088c},
-	{0x00001174, 0x00000000},
-	{0x00000000, 0x00000000}
-};
-
-static const struct phy_reg x1_port3_config_regs[] = {
-	{0x00001894, 0xc80060fa},
-	{0x00001880, 0x0f90fd6a},
-	{0x00001890, 0x10a0840b},
-	{0x000018a8, 0xdf04010a},
-	{0x00001900, 0x57050060},
-	{0x00001910, 0x0030001c},
-	{0x00001938, 0x5f004444},
-	{0x0000193c, 0x78464204},
-	{0x00001948, 0x7821f940},
-	{0x0000194c, 0xb2000433},
-	{0x00001694, 0x3050d0fa},
-	{0x00001680, 0x0ef6d050},
-	{0x00001690, 0x10a0540b},
-	{0x000016a8, 0xe301010a},
-	{0x00001700, 0x69053460},
-	{0x00001710, 0xa030101c},
-	{0x00001738, 0xdf808444},
-	{0x0000173c, 0xc8422204},
-	{0x00001740, 0x0180088c},
-	{0x00001774, 0x00000000},
-	{0x00000000, 0x00000000}
-};
-
-static const struct phy_reg x2_port0_config_regs[] = {
-	{0x00000694, 0xc80060fa},
-	{0x00000680, 0x3d4f78ea},
-	{0x00000690, 0x10a0140b},
-	{0x000006a8, 0xdf04010a},
-	{0x00000700, 0x57050060},
-	{0x00000710, 0x0030001c},
-	{0x00000738, 0x5f004444},
-	{0x0000073c, 0x78464204},
-	{0x00000748, 0x7821f940},
-	{0x0000074c, 0xb2000433},
-	{0x00000494, 0xc80060fa},
-	{0x00000480, 0x29ef5ed8},
-	{0x00000490, 0x10a0540b},
-	{0x000004a8, 0x7a01010a},
-	{0x00000500, 0xef053460},
-	{0x00000510, 0xe030101c},
-	{0x00000538, 0xdf808444},
-	{0x0000053c, 0xc8422204},
-	{0x00000540, 0x0180088c},
-	{0x00000574, 0x00000000},
-	{0x00000294, 0xc80060fa},
-	{0x00000280, 0xcb45b950},
-	{0x00000290, 0x10a0540b},
-	{0x000002a8, 0x8c01010a},
-	{0x00000300, 0xef053460},
-	{0x00000310, 0x8030101c},
-	{0x00000338, 0x41808444},
-	{0x0000033c, 0x32422204},
-	{0x00000340, 0x0180088c},
-	{0x00000374, 0x00000000},
-	{0x00000000, 0x00000000}
-};
-
-static const struct phy_reg x2_port1_config_regs[] = {
-	{0x00000c94, 0xc80060fa},
-	{0x00000c80, 0xcf47abea},
-	{0x00000c90, 0x10a0840b},
-	{0x00000ca8, 0xdf04010a},
-	{0x00000d00, 0x57050060},
-	{0x00000d10, 0x0030001c},
-	{0x00000d38, 0x5f004444},
-	{0x00000d3c, 0x78464204},
-	{0x00000d48, 0x7821f940},
-	{0x00000d4c, 0xb2000433},
-	{0x00000a94, 0xc80060fa},
-	{0x00000a80, 0x5a166ed8},
-	{0x00000a90, 0x10a0540b},
-	{0x00000aa8, 0x7a01010a},
-	{0x00000b00, 0xef053460},
-	{0x00000b10, 0xa030101c},
-	{0x00000b38, 0xdf808444},
-	{0x00000b3c, 0xc8422204},
-	{0x00000b40, 0x0180088c},
-	{0x00000b74, 0x00000000},
-	{0x00000894, 0xc80060fa},
-	{0x00000880, 0x4d4f21d0},
-	{0x00000890, 0x10a0540b},
-	{0x000008a8, 0x5601010a},
-	{0x00000900, 0xef053460},
-	{0x00000910, 0x8030101c},
-	{0x00000938, 0xdf808444},
-	{0x0000093c, 0xc8422204},
-	{0x00000940, 0x0180088c},
-	{0x00000974, 0x00000000},
-	{0x00000000, 0x00000000}
-};
-
-static const struct phy_reg x2_port2_config_regs[] = {
-	{0x00001294, 0xc80060fa},
-	{0x00001280, 0x08130cea},
-	{0x00001290, 0x10a0140b},
-	{0x000012a8, 0xd704010a},
-	{0x00001300, 0x8d050060},
-	{0x00001310, 0x0030001c},
-	{0x00001338, 0xdf008444},
-	{0x0000133c, 0x78422204},
-	{0x00001348, 0x7821f940},
-	{0x0000134c, 0x5a000433},
-	{0x00001094, 0xc80060fa},
-	{0x00001080, 0xade75dd8},
-	{0x00001090, 0x10a0540b},
-	{0x000010a8, 0xb101010a},
-	{0x00001100, 0x33053460},
-	{0x00001110, 0x0030101c},
-	{0x00001138, 0xdf808444},
-	{0x0000113c, 0xc8422204},
-	{0x00001140, 0x8180088c},
-	{0x00001174, 0x00000000},
-	{0x00000e94, 0xc80060fa},
-	{0x00000e80, 0x0fbf16d0},
-	{0x00000e90, 0x10a0540b},
-	{0x00000ea8, 0x7a01010a},
-	{0x00000f00, 0xf5053460},
-	{0x00000f10, 0xc030101c},
-	{0x00000f38, 0xdf808444},
-	{0x00000f3c, 0xc8422204},
-	{0x00000f40, 0x8180088c},
-	{0x00000000, 0x00000000}
-};
-
-static const struct phy_reg x2_port3_config_regs[] = {
-	{0x00001894, 0xc80060fa},
-	{0x00001880, 0x0f90fd6a},
-	{0x00001890, 0x10a0840b},
-	{0x000018a8, 0xdf04010a},
-	{0x00001900, 0x57050060},
-	{0x00001910, 0x0030001c},
-	{0x00001938, 0x5f004444},
-	{0x0000193c, 0x78464204},
-	{0x00001948, 0x7821f940},
-	{0x0000194c, 0xb2000433},
-	{0x00001694, 0xc80060fa},
-	{0x00001680, 0x0ef6d058},
-	{0x00001690, 0x10a0540b},
-	{0x000016a8, 0x7a01010a},
-	{0x00001700, 0x69053460},
-	{0x00001710, 0xa030101c},
-	{0x00001738, 0xdf808444},
-	{0x0000173c, 0xc8422204},
-	{0x00001740, 0x0180088c},
-	{0x00001774, 0x00000000},
-	{0x00001494, 0xc80060fa},
-	{0x00001480, 0xf9d34bd0},
-	{0x00001490, 0x10a0540b},
-	{0x000014a8, 0x7a01010a},
-	{0x00001500, 0x1b053460},
-	{0x00001510, 0x0030101c},
-	{0x00001538, 0xdf808444},
-	{0x0000153c, 0xc8422204},
-	{0x00001540, 0x8180088c},
-	{0x00001574, 0x00000000},
-	{0x00000000, 0x00000000}
-};
-
-static const struct phy_reg x4_port0_config_regs[] = {
-	{0x00000694, 0xc80060fa},
-	{0x00000680, 0x3d4f78fa},
-	{0x00000690, 0x10a0140b},
-	{0x000006a8, 0xdf04010a},
-	{0x00000700, 0x57050060},
-	{0x00000710, 0x0030001c},
-	{0x00000738, 0x5f004444},
-	{0x0000073c, 0x78464204},
-	{0x00000748, 0x7821f940},
-	{0x0000074c, 0xb2000433},
-	{0x00000494, 0xfe6030fa},
-	{0x00000480, 0x29ef5ed8},
-	{0x00000490, 0x10a0540b},
-	{0x000004a8, 0x7a01010a},
-	{0x00000500, 0xef053460},
-	{0x00000510, 0xe030101c},
-	{0x00000538, 0xdf808444},
-	{0x0000053c, 0xc8422204},
-	{0x00000540, 0x0180088c},
-	{0x00000574, 0x00000004},
-	{0x00000294, 0x23e030fa},
-	{0x00000280, 0xcb45b950},
-	{0x00000290, 0x10a0540b},
-	{0x000002a8, 0x8c01010a},
-	{0x00000300, 0xef053460},
-	{0x00000310, 0x8030101c},
-	{0x00000338, 0x41808444},
-	{0x0000033c, 0x32422204},
-	{0x00000340, 0x0180088c},
-	{0x00000374, 0x00000004},
-	{0x00000894, 0x5620b0fa},
-	{0x00000880, 0x4d4f21dc},
-	{0x00000890, 0x10a0540b},
-	{0x000008a8, 0x5601010a},
-	{0x00000900, 0xef053460},
-	{0x00000910, 0x8030101c},
-	{0x00000938, 0xdf808444},
-	{0x0000093c, 0xc8422204},
-	{0x00000940, 0x0180088c},
-	{0x00000974, 0x00000004},
-	{0x00000a94, 0xc91030fa},
-	{0x00000a80, 0x5a166ecc},
-	{0x00000a90, 0x10a0540b},
-	{0x00000aa8, 0x5d01010a},
-	{0x00000b00, 0xef053460},
-	{0x00000b10, 0xa030101c},
-	{0x00000b38, 0xdf808444},
-	{0x00000b3c, 0xc8422204},
-	{0x00000b40, 0x0180088c},
-	{0x00000b74, 0x00000004},
-	{0x00000000, 0x00000000}
-};
-
-static const struct phy_reg x4_port1_config_regs[] = {
-	{0x00000000, 0x00000000}
-};
-
-static const struct phy_reg x4_port2_config_regs[] = {
-	{0x00001294, 0x28f000fa},
-	{0x00001280, 0x08130cfa},
-	{0x00001290, 0x10c0140b},
-	{0x000012a8, 0xd704010a},
-	{0x00001300, 0x8d050060},
-	{0x00001310, 0x0030001c},
-	{0x00001338, 0xdf008444},
-	{0x0000133c, 0x78422204},
-	{0x00001348, 0x7821f940},
-	{0x0000134c, 0x5a000433},
-	{0x00001094, 0x2d20b0fa},
-	{0x00001080, 0xade75dd8},
-	{0x00001090, 0x10a0540b},
-	{0x000010a8, 0xb101010a},
-	{0x00001100, 0x33053460},
-	{0x00001110, 0x0030101c},
-	{0x00001138, 0xdf808444},
-	{0x0000113c, 0xc8422204},
-	{0x00001140, 0x8180088c},
-	{0x00001174, 0x00000004},
-	{0x00000e94, 0xd308d0fa},
-	{0x00000e80, 0x0fbf16d0},
-	{0x00000e90, 0x10a0540b},
-	{0x00000ea8, 0x2c01010a},
-	{0x00000f00, 0xf5053460},
-	{0x00000f10, 0xc030101c},
-	{0x00000f38, 0xdf808444},
-	{0x00000f3c, 0xc8422204},
-	{0x00000f40, 0x8180088c},
-	{0x00000f74, 0x00000004},
-	{0x00001494, 0x136850fa},
-	{0x00001480, 0xf9d34bdc},
-	{0x00001490, 0x10a0540b},
-	{0x000014a8, 0x5a01010a},
-	{0x00001500, 0x1b053460},
-	{0x00001510, 0x0030101c},
-	{0x00001538, 0xdf808444},
-	{0x0000153c, 0xc8422204},
-	{0x00001540, 0x8180088c},
-	{0x00001574, 0x00000004},
-	{0x00001694, 0x3050d0fa},
-	{0x00001680, 0x0ef6d04c},
-	{0x00001690, 0x10a0540b},
-	{0x000016a8, 0xe301010a},
-	{0x00001700, 0x69053460},
-	{0x00001710, 0xa030101c},
-	{0x00001738, 0xdf808444},
-	{0x0000173c, 0xc8422204},
-	{0x00001740, 0x0180088c},
-	{0x00001774, 0x00000004},
-	{0x00000000, 0x00000000}
-};
-
-static const struct phy_reg x4_port3_config_regs[] = {
-	{0x00000000, 0x00000000}
-};
-
-static const struct phy_reg *x1_config_regs[4] = {
-	x1_port0_config_regs,
-	x1_port1_config_regs,
-	x1_port2_config_regs,
-	x1_port3_config_regs
-};
-
-static const struct phy_reg *x2_config_regs[4] = {
-	x2_port0_config_regs,
-	x2_port1_config_regs,
-	x2_port2_config_regs,
-	x2_port3_config_regs
-};
-
-static const struct phy_reg *x4_config_regs[4] = {
-	x4_port0_config_regs,
-	x4_port1_config_regs,
-	x4_port2_config_regs,
-	x4_port3_config_regs
-};
-
-static const struct phy_reg **config_regs[3] = {
-	x1_config_regs,
-	x2_config_regs,
-	x4_config_regs,
-};
-
-int ipu6_isys_phy_powerup_ack(struct ipu_isys *isys, unsigned int phy_id)
-{
-	unsigned int i;
-	u32 val;
-	void __iomem *isys_base = isys->pdata->base;
-
-	val = readl(isys_base + CSI_REG_HUB_GPREG_PHY_CONTROL(phy_id));
-	val |= CSI_REG_HUB_GPREG_PHY_CONTROL_PWR_EN;
-	writel(val, isys_base + CSI_REG_HUB_GPREG_PHY_CONTROL(phy_id));
-
-	for (i = 0; i < LOOP; i++) {
-		if (readl(isys_base + CSI_REG_HUB_GPREG_PHY_STATUS(phy_id)) &
-		    CSI_REG_HUB_GPREG_PHY_STATUS_POWER_ACK)
-			return 0;
-		usleep_range(100, 200);
-	}
-
-	dev_warn(&isys->adev->dev, "PHY%d powerup ack timeout", phy_id);
-
-	return -ETIMEDOUT;
-}
-
-int ipu6_isys_phy_powerdown_ack(struct ipu_isys *isys, unsigned int phy_id)
-{
-	unsigned int i;
-	u32 val;
-	void __iomem *isys_base = isys->pdata->base;
-
-	writel(0, isys_base + CSI_REG_HUB_GPREG_PHY_CONTROL(phy_id));
-	for (i = 0; i < LOOP; i++) {
-		usleep_range(10, 20);
-		val = readl(isys_base + CSI_REG_HUB_GPREG_PHY_STATUS(phy_id));
-		if (!(val & CSI_REG_HUB_GPREG_PHY_STATUS_POWER_ACK))
-			return 0;
-	}
-
-	dev_warn(&isys->adev->dev, "PHY %d poweroff ack timeout.\n", phy_id);
-
-	return -ETIMEDOUT;
-}
-
-int ipu6_isys_phy_reset(struct ipu_isys *isys, unsigned int phy_id,
-			bool assert)
-{
-	void __iomem *isys_base = isys->pdata->base;
-	u32 val;
-
-	val = readl(isys_base + CSI_REG_HUB_GPREG_PHY_CONTROL(phy_id));
-	if (assert)
-		val |= CSI_REG_HUB_GPREG_PHY_CONTROL_RESET;
-	else
-		val &= ~(CSI_REG_HUB_GPREG_PHY_CONTROL_RESET);
-
-	writel(val, isys_base + CSI_REG_HUB_GPREG_PHY_CONTROL(phy_id));
-
-	return 0;
-}
-
-int ipu6_isys_phy_ready(struct ipu_isys *isys, unsigned int phy_id)
-{
-	unsigned int i;
-	u32 val;
-	void __iomem *isys_base = isys->pdata->base;
-
-	for (i = 0; i < LOOP; i++) {
-		val = readl(isys_base + CSI_REG_HUB_GPREG_PHY_STATUS(phy_id));
-		dev_dbg(&isys->adev->dev, "PHY%d ready status 0x%x\n",
-			phy_id, val);
-		if (val & CSI_REG_HUB_GPREG_PHY_STATUS_PHY_READY)
-			return 0;
-		usleep_range(10, 20);
-	}
-
-	dev_warn(&isys->adev->dev, "PHY%d ready timeout\n", phy_id);
-
-	return -ETIMEDOUT;
-}
-
-int ipu6_isys_phy_common_init(struct ipu_isys *isys)
-{
-	unsigned int phy_id;
-	void __iomem *phy_base;
-	struct ipu_bus_device *adev = to_ipu_bus_device(&isys->adev->dev);
-	struct ipu_device *isp = adev->isp;
-	void __iomem *isp_base = isp->base;
-	struct v4l2_async_subdev *asd;
-	struct sensor_async_subdev *s_asd;
-	unsigned int i;
-
-	list_for_each_entry(asd, &isys->notifier.asd_list, asd_list) {
-		s_asd = container_of(asd, struct sensor_async_subdev, asd);
-		phy_id = s_asd->csi2.port / 4;
-		phy_base = isp_base + IPU6_ISYS_PHY_BASE(phy_id);
-
-		for (i = 0 ; i < ARRAY_SIZE(common_init_regs); i++) {
-			writel(common_init_regs[i].val,
-				phy_base + common_init_regs[i].reg);
-		}
-	}
-
-	return 0;
-}
-
-static int ipu6_isys_driver_port_to_phy_port(struct ipu_isys_csi2_config *cfg)
-{
-	int phy_port;
-	int ret;
-
-	if (!(cfg->nlanes == 4 || cfg->nlanes == 2 || cfg->nlanes == 1))
-		return -EINVAL;
-
-	/* B,F -> C0 A,E -> C1 C,G -> C2 D,H -> C4 */
-	/* normalize driver port number */
-	phy_port = cfg->port % 4;
-
-	/* swap port number only for A and B */
-	if (phy_port == 0)
-		phy_port = 1;
-	else if (phy_port == 1)
-		phy_port = 0;
-
-	ret = phy_port;
-
-	/* check validity per lane configuration */
-	if ((cfg->nlanes == 4) &&
-		 !(phy_port == 0 || phy_port == 2))
-		ret = -EINVAL;
-	else if ((cfg->nlanes == 2 || cfg->nlanes == 1) &&
-		 !(phy_port >= 0 && phy_port <= 3))
-		ret = -EINVAL;
-
-	return ret;
-}
-
-int ipu6_isys_phy_config(struct ipu_isys *isys)
-{
-	int phy_port;
-	unsigned int phy_id;
-	void __iomem *phy_base;
-	struct ipu_bus_device *adev = to_ipu_bus_device(&isys->adev->dev);
-	struct ipu_device *isp = adev->isp;
-	void __iomem *isp_base = isp->base;
-	const struct phy_reg **phy_config_regs;
-	struct v4l2_async_subdev *asd;
-	struct sensor_async_subdev *s_asd;
-	struct ipu_isys_csi2_config cfg;
-	int i;
-
-	list_for_each_entry(asd, &isys->notifier.asd_list, asd_list) {
-		s_asd = container_of(asd, struct sensor_async_subdev, asd);
-		cfg.port = s_asd->csi2.port;
-		cfg.nlanes = s_asd->csi2.nlanes;
-		phy_port = ipu6_isys_driver_port_to_phy_port(&cfg);
-		if (phy_port < 0) {
-			dev_err(&isys->adev->dev, "invalid port %d for lane %d",
-				cfg.port, cfg.nlanes);
-			return -ENXIO;
-		}
-
-		phy_id = cfg.port / 4;
-		phy_base = isp_base + IPU6_ISYS_PHY_BASE(phy_id);
-		dev_dbg(&isys->adev->dev, "port%d PHY%u lanes %u\n",
-			cfg.port, phy_id, cfg.nlanes);
-
-		phy_config_regs = config_regs[cfg.nlanes/2];
-		cfg.port = phy_port;
-		for (i = 0; phy_config_regs[cfg.port][i].reg; i++) {
-			writel(phy_config_regs[cfg.port][i].val,
-				phy_base + phy_config_regs[cfg.port][i].reg);
-		}
-	}
-
-	return 0;
-}
diff --git a/drivers/media/pci/intel/ipu6/ipu6-isys-phy.h b/drivers/media/pci/intel/ipu6/ipu6-isys-phy.h
deleted file mode 100644
index 10a1d88c3088..000000000000
--- a/drivers/media/pci/intel/ipu6/ipu6-isys-phy.h
+++ /dev/null
@@ -1,159 +0,0 @@
-/* SPDX-License-Identifier: GPL-2.0 */
-/*
- * Copyright (C) 2013 - 2020 Intel Corporation
- */
-
-#ifndef IPU6_ISYS_PHY_H
-#define IPU6_ISYS_PHY_H
-
-/* bridge to phy in buttress reg map, each phy has 16 kbytes
- * for tgl u/y, only 2 phys
- */
-#define IPU6_ISYS_PHY_0_BASE			0x10000
-#define IPU6_ISYS_PHY_1_BASE			0x14000
-#define IPU6_ISYS_PHY_2_BASE			0x18000
-#define IPU6_ISYS_PHY_BASE(i)			(0x10000 + (i) * 0x4000)
-
-/* ppi mapping per phy :
- *
- * x4x4:
- * port0 - PPI range {0, 1, 2, 3, 4}
- * port2 - PPI range {6, 7, 8, 9, 10}
- *
- * x4x2:
- * port0 - PPI range {0, 1, 2, 3, 4}
- * port2 - PPI range {6, 7, 8}
- *
- * x2x4:
- * port0 - PPI range {0, 1, 2}
- * port2 - PPI range {6, 7, 8, 9, 10}
- *
- * x2x2:
- * port0 - PPI range {0, 1, 2}
- * port1 - PPI range {3, 4, 5}
- * port2 - PPI range {6, 7, 8}
- * port3 - PPI range {9, 10, 11}
- */
-
-/* cbbs config regs */
-#define PHY_CBBS1_BASE				0x0
-/* register offset */
-#define PHY_CBBS1_DFX_VMISCCTL			0x0
-#define PHY_CBBS1_DFX_VBYTESEL0			0x4
-#define PHY_CBBS1_DFX_VBYTESEL1			0x8
-#define PHY_CBBS1_VISA2OBS_CTRL_REG		0xc
-#define PHY_CBBS1_PGL_CTRL_REG			0x10
-#define PHY_CBBS1_RCOMP_CTRL_REG_1		0x14
-#define PHY_CBBS1_RCOMP_CTRL_REG_2		0x18
-#define PHY_CBBS1_RCOMP_CTRL_REG_3		0x1c
-#define PHY_CBBS1_RCOMP_CTRL_REG_4		0x20
-#define PHY_CBBS1_RCOMP_CTRL_REG_5		0x24
-#define PHY_CBBS1_RCOMP_STATUS_REG_1		0x28
-#define PHY_CBBS1_RCOMP_STATUS_REG_2		0x2c
-#define PHY_CBBS1_CLOCK_CTRL_REG		0x30
-#define PHY_CBBS1_CBB_ISOLATION_REG		0x34
-#define PHY_CBBS1_CBB_PLL_CONTROL		0x38
-#define PHY_CBBS1_CBB_STATUS_REG		0x3c
-#define PHY_CBBS1_AFE_CONTROL_REG_1		0x40
-#define PHY_CBBS1_AFE_CONTROL_REG_2		0x44
-#define PHY_CBBS1_CBB_SPARE			0x48
-#define PHY_CBBS1_CRI_CLK_CONTROL		0x4c
-
-/* dbbs shared, i = [0..11] */
-#define PHY_DBBS_SHARED(ppi)			((ppi) * 0x200 + 0x200)
-/* register offset */
-#define PHY_DBBDFE_DFX_V1MISCCTL		0x0
-#define PHY_DBBDFE_DFX_V1BYTESEL0		0x4
-#define PHY_DBBDFE_DFX_V1BYTESEL1		0x8
-#define PHY_DBBDFE_DFX_V2MISCCTL		0xc
-#define PHY_DBBDFE_DFX_V2BYTESEL0		0x10
-#define PHY_DBBDFE_DFX_V2BYTESEL1		0x14
-#define PHY_DBBDFE_GBLCTL			0x18
-#define PHY_DBBDFE_GBL_STATUS			0x1c
-
-/* dbbs udln, i = [0..11] */
-#define IPU6_ISYS_PHY_DBBS_UDLN(ppi)		((ppi) * 0x200 + 0x280)
-/* register offset */
-#define PHY_DBBUDLN_CTL				0x0
-#define PHY_DBBUDLN_CLK_CTL			0x4
-#define PHY_DBBUDLN_SOFT_RST_CTL		0x8
-#define PHY_DBBUDLN_STRAP_VALUES		0xc
-#define PHY_DBBUDLN_TXRX_CTL			0x10
-#define PHY_DBBUDLN_MST_SLV_INIT_CTL		0x14
-#define PHY_DBBUDLN_TX_TIMING_CTL0		0x18
-#define PHY_DBBUDLN_TX_TIMING_CTL1		0x1c
-#define PHY_DBBUDLN_TX_TIMING_CTL2		0x20
-#define PHY_DBBUDLN_TX_TIMING_CTL3		0x24
-#define PHY_DBBUDLN_RX_TIMING_CTL		0x28
-#define PHY_DBBUDLN_PPI_STATUS_CTL		0x2c
-#define PHY_DBBUDLN_PPI_STATUS			0x30
-#define PHY_DBBUDLN_ERR_CTL			0x34
-#define PHY_DBBUDLN_ERR_STATUS			0x38
-#define PHY_DBBUDLN_DFX_LPBK_CTL		0x3c
-#define PHY_DBBUDLN_DFX_PPI_CTL			0x40
-#define PHY_DBBUDLN_DFX_TX_DPHY_CTL		0x44
-#define PHY_DBBUDLN_DFX_TXRX_PRBSPAT_CTL	0x48
-#define PHY_DBBUDLN_DFX_TXRX_PRBSPAT_SEED	0x4c
-#define PHY_DBBUDLN_DFX_PRBSPAT_MAX_WRD_CNT	0x50
-#define PHY_DBBUDLN_DFX_PRBSPAT_STATUS		0x54
-#define PHY_DBBUDLN_DFX_PRBSPAT_WRD_CNT0_STATUS	0x58
-#define PHY_DBBUDLN_DFX_PRBSPAT_WRD_CNT1_STATUS	0x5c
-#define PHY_DBBUDLN_DFX_PRBSPAT_FF_ERR_STATUS	0x60
-#define PHY_DBBUDLN_DFX_PRBSPAT_FF_REF_STATUS		0x64
-#define PHY_DBBUDLN_DFX_PRBSPAT_FF_WRD_CNT0_STATUS	0x68
-#define PHY_DBBUDLN_DFX_PRBSPAT_FF_WRD_CNT1_STATUS	0x6c
-#define PHY_DBBUDLN_RSVD_CTL				0x70
-#define PHY_DBBUDLN_TINIT_DONE				BIT(27)
-
-/* dbbs supar, i = [0..11] */
-#define IPU6_ISYS_PHY_DBBS_SUPAR(ppi)		((ppi) * 0x200 + 0x300)
-/* register offset */
-#define PHY_DBBSUPAR_TXRX_FUPAR_CTL		0x0
-#define PHY_DBBSUPAR_TXHS_AFE_CTL		0x4
-#define PHY_DBBSUPAR_TXHS_AFE_LEGDIS_CTL	0x8
-#define PHY_DBBSUPAR_TXHS_AFE_EQ_CTL		0xc
-#define PHY_DBBSUPAR_RXHS_AFE_CTL1		0x10
-#define PHY_DBBSUPAR_RXHS_AFE_PICTL1		0x14
-#define PHY_DBBSUPAR_TXRXLP_AFE_CTL		0x18
-#define PHY_DBBSUPAR_DFX_TXRX_STATUS		0x1c
-#define PHY_DBBSUPAR_DFX_TXRX_CTL		0x20
-#define PHY_DBBSUPAR_DFX_DIGMON_CTL		0x24
-#define PHY_DBBSUPAR_DFX_LOCMON_CTL		0x28
-#define PHY_DBBSUPAR_DFX_RCOMP_CTL1		0x2c
-#define PHY_DBBSUPAR_DFX_RCOMP_CTL2		0x30
-#define PHY_DBBSUPAR_CAL_TOP1			0x34
-#define PHY_DBBSUPAR_CAL_SHARED1		0x38
-#define PHY_DBBSUPAR_CAL_SHARED2		0x3c
-#define PHY_DBBSUPAR_CAL_CDR1			0x40
-#define PHY_DBBSUPAR_CAL_OCAL1			0x44
-#define PHY_DBBSUPAR_CAL_DCC_DLL1		0x48
-#define PHY_DBBSUPAR_CAL_DLL2			0x4c
-#define PHY_DBBSUPAR_CAL_DFX1			0x50
-#define PHY_DBBSUPAR_CAL_DFX2			0x54
-#define PHY_DBBSUPAR_CAL_DFX3			0x58
-#define PHY_BBSUPAR_CAL_DFX4			0x5c
-#define PHY_DBBSUPAR_CAL_DFX5			0x60
-#define PHY_DBBSUPAR_CAL_DFX6			0x64
-#define PHY_DBBSUPAR_CAL_DFX7			0x68
-#define PHY_DBBSUPAR_DFX_AFE_SPARE_CTL1		0x6c
-#define PHY_DBBSUPAR_DFX_AFE_SPARE_CTL2		0x70
-#define	PHY_DBBSUPAR_SPARE			0x74
-
-/* sai, i = [0..11] */
-#define	IPU6_ISYS_PHY_SAI			0xf800
-/* register offset */
-#define PHY_SAI_CTRL_REG0                       0x40
-#define PHY_SAI_CTRL_REG0_1                     0x44
-#define PHY_SAI_WR_REG0                         0x48
-#define PHY_SAI_WR_REG0_1                       0x4c
-#define PHY_SAI_RD_REG0                         0x50
-#define PHY_SAI_RD_REG0_1                       0x54
-
-int ipu6_isys_phy_powerup_ack(struct ipu_isys *isys, unsigned int phy_id);
-int ipu6_isys_phy_powerdown_ack(struct ipu_isys *isys, unsigned int phy_id);
-int ipu6_isys_phy_reset(struct ipu_isys *isys, unsigned int phy_id,
-			bool assert);
-int ipu6_isys_phy_ready(struct ipu_isys *isys, unsigned int phy_id);
-int ipu6_isys_phy_common_init(struct ipu_isys *isys);
-int ipu6_isys_phy_config(struct ipu_isys *isys);
-#endif
diff --git a/drivers/media/pci/intel/ipu6/ipu6-isys.c b/drivers/media/pci/intel/ipu6/ipu6-isys.c
deleted file mode 100644
index b5a9e81db108..000000000000
--- a/drivers/media/pci/intel/ipu6/ipu6-isys.c
+++ /dev/null
@@ -1,174 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0
-// Copyright (C) 2020 Intel Corporation
-
-#include <linux/module.h>
-#include <media/v4l2-event.h>
-
-#include "ipu.h"
-#include "ipu-platform-regs.h"
-#include "ipu-trace.h"
-#include "ipu-isys.h"
-#include "ipu-platform-isys-csi2-reg.h"
-
-const struct ipu_isys_pixelformat ipu_isys_pfmts[] = {
-	{V4L2_PIX_FMT_SBGGR12, 16, 12, 0, MEDIA_BUS_FMT_SBGGR12_1X12,
-	 IPU_FW_ISYS_FRAME_FORMAT_RAW16},
-	{V4L2_PIX_FMT_SGBRG12, 16, 12, 0, MEDIA_BUS_FMT_SGBRG12_1X12,
-	 IPU_FW_ISYS_FRAME_FORMAT_RAW16},
-	{V4L2_PIX_FMT_SGRBG12, 16, 12, 0, MEDIA_BUS_FMT_SGRBG12_1X12,
-	 IPU_FW_ISYS_FRAME_FORMAT_RAW16},
-	{V4L2_PIX_FMT_SRGGB12, 16, 12, 0, MEDIA_BUS_FMT_SRGGB12_1X12,
-	 IPU_FW_ISYS_FRAME_FORMAT_RAW16},
-	{V4L2_PIX_FMT_SBGGR10, 16, 10, 0, MEDIA_BUS_FMT_SBGGR10_1X10,
-	 IPU_FW_ISYS_FRAME_FORMAT_RAW16},
-	{V4L2_PIX_FMT_SGBRG10, 16, 10, 0, MEDIA_BUS_FMT_SGBRG10_1X10,
-	 IPU_FW_ISYS_FRAME_FORMAT_RAW16},
-	{V4L2_PIX_FMT_SGRBG10, 16, 10, 0, MEDIA_BUS_FMT_SGRBG10_1X10,
-	 IPU_FW_ISYS_FRAME_FORMAT_RAW16},
-	{V4L2_PIX_FMT_SRGGB10, 16, 10, 0, MEDIA_BUS_FMT_SRGGB10_1X10,
-	 IPU_FW_ISYS_FRAME_FORMAT_RAW16},
-	{V4L2_PIX_FMT_SBGGR8, 8, 8, 0, MEDIA_BUS_FMT_SBGGR8_1X8,
-	 IPU_FW_ISYS_FRAME_FORMAT_RAW8},
-	{V4L2_PIX_FMT_SGBRG8, 8, 8, 0, MEDIA_BUS_FMT_SGBRG8_1X8,
-	 IPU_FW_ISYS_FRAME_FORMAT_RAW8},
-	{V4L2_PIX_FMT_SGRBG8, 8, 8, 0, MEDIA_BUS_FMT_SGRBG8_1X8,
-	 IPU_FW_ISYS_FRAME_FORMAT_RAW8},
-	{V4L2_PIX_FMT_SRGGB8, 8, 8, 0, MEDIA_BUS_FMT_SRGGB8_1X8,
-	 IPU_FW_ISYS_FRAME_FORMAT_RAW8},
-	{}
-};
-
-struct ipu_trace_block isys_trace_blocks[] = {
-	{
-		.offset = IPU_TRACE_REG_IS_TRACE_UNIT_BASE,
-		.type = IPU_TRACE_BLOCK_TUN,
-	},
-	{
-		.offset = IPU_TRACE_REG_IS_SP_EVQ_BASE,
-		.type = IPU_TRACE_BLOCK_TM,
-	},
-	{
-		.offset = IPU_TRACE_REG_IS_SP_GPC_BASE,
-		.type = IPU_TRACE_BLOCK_GPC,
-	},
-	{
-		.offset = IPU_TRACE_REG_IS_ISL_GPC_BASE,
-		.type = IPU_TRACE_BLOCK_GPC,
-	},
-	{
-		.offset = IPU_TRACE_REG_IS_MMU_GPC_BASE,
-		.type = IPU_TRACE_BLOCK_GPC,
-	},
-	{
-		/* Note! this covers all 8 blocks */
-		.offset = IPU_TRACE_REG_CSI2_TM_BASE(0),
-		.type = IPU_TRACE_CSI2,
-	},
-	{
-		/* Note! this covers all 11 blocks */
-		.offset = IPU_TRACE_REG_CSI2_PORT_SIG2SIO_GR_BASE(0),
-		.type = IPU_TRACE_SIG2CIOS,
-	},
-	{
-		.offset = IPU_TRACE_REG_IS_GPREG_TRACE_TIMER_RST_N,
-		.type = IPU_TRACE_TIMER_RST,
-	},
-	{
-		.type = IPU_TRACE_BLOCK_END,
-	}
-};
-
-void isys_setup_hw(struct ipu_isys *isys)
-{
-	void __iomem *base = isys->pdata->base;
-	const u8 *thd = isys->pdata->ipdata->hw_variant.cdc_fifo_threshold;
-	u32 irqs = 0;
-	unsigned int i, nr;
-
-	nr = (ipu_ver == IPU_VER_6 || ipu_ver == IPU_VER_6EP) ?
-		IPU6_ISYS_CSI_PORT_NUM : IPU6SE_ISYS_CSI_PORT_NUM;
-
-	/* Enable irqs for all MIPI ports */
-	for (i = 0; i < nr; i++)
-		irqs |= IPU_ISYS_UNISPART_IRQ_CSI2(i);
-
-	writel(irqs, base + IPU_REG_ISYS_CSI_TOP_CTRL0_IRQ_EDGE);
-	writel(irqs, base + IPU_REG_ISYS_CSI_TOP_CTRL0_IRQ_LEVEL_NOT_PULSE);
-	writel(0xffffffff, base + IPU_REG_ISYS_CSI_TOP_CTRL0_IRQ_CLEAR);
-	writel(irqs, base + IPU_REG_ISYS_CSI_TOP_CTRL0_IRQ_MASK);
-	writel(irqs, base + IPU_REG_ISYS_CSI_TOP_CTRL0_IRQ_ENABLE);
-
-	irqs = ISYS_UNISPART_IRQS;
-	writel(irqs, base + IPU_REG_ISYS_UNISPART_IRQ_EDGE);
-	writel(irqs, base + IPU_REG_ISYS_UNISPART_IRQ_LEVEL_NOT_PULSE);
-	writel(0xffffffff, base + IPU_REG_ISYS_UNISPART_IRQ_CLEAR);
-	writel(irqs, base + IPU_REG_ISYS_UNISPART_IRQ_MASK);
-	writel(irqs, base + IPU_REG_ISYS_UNISPART_IRQ_ENABLE);
-
-	writel(0, base + IPU_REG_ISYS_UNISPART_SW_IRQ_REG);
-	writel(0, base + IPU_REG_ISYS_UNISPART_SW_IRQ_MUX_REG);
-
-	/* Write CDC FIFO threshold values for isys */
-	for (i = 0; i < isys->pdata->ipdata->hw_variant.cdc_fifos; i++)
-		writel(thd[i], base + IPU_REG_ISYS_CDC_THRESHOLD(i));
-}
-
-irqreturn_t isys_isr(struct ipu_bus_device *adev)
-{
-	struct ipu_isys *isys = ipu_bus_get_drvdata(adev);
-	void __iomem *base = isys->pdata->base;
-	u32 status_sw, status_csi;
-
-	spin_lock(&isys->power_lock);
-	if (!isys->power) {
-		spin_unlock(&isys->power_lock);
-		return IRQ_NONE;
-	}
-
-	status_csi = readl(isys->pdata->base +
-			   IPU_REG_ISYS_CSI_TOP_CTRL0_IRQ_STATUS);
-	status_sw = readl(isys->pdata->base + IPU_REG_ISYS_UNISPART_IRQ_STATUS);
-
-	writel(ISYS_UNISPART_IRQS & ~IPU_ISYS_UNISPART_IRQ_SW,
-	       base + IPU_REG_ISYS_UNISPART_IRQ_MASK);
-
-	do {
-		writel(status_csi, isys->pdata->base +
-			   IPU_REG_ISYS_CSI_TOP_CTRL0_IRQ_CLEAR);
-		writel(status_sw, isys->pdata->base +
-			   IPU_REG_ISYS_UNISPART_IRQ_CLEAR);
-
-		if (isys->isr_csi2_bits & status_csi) {
-			unsigned int i;
-
-			for (i = 0; i < isys->pdata->ipdata->csi2.nports; i++) {
-				/* irq from not enabled port */
-				if (!isys->csi2[i].base)
-					continue;
-				if (status_csi & IPU_ISYS_UNISPART_IRQ_CSI2(i))
-					ipu_isys_csi2_isr(&isys->csi2[i]);
-			}
-		}
-
-		writel(0, base + IPU_REG_ISYS_UNISPART_SW_IRQ_REG);
-
-		if (!isys_isr_one(adev))
-			status_sw = IPU_ISYS_UNISPART_IRQ_SW;
-		else
-			status_sw = 0;
-
-		status_csi = readl(isys->pdata->base +
-				       IPU_REG_ISYS_CSI_TOP_CTRL0_IRQ_STATUS);
-		status_sw |= readl(isys->pdata->base +
-				       IPU_REG_ISYS_UNISPART_IRQ_STATUS);
-	} while (((status_csi & isys->isr_csi2_bits) ||
-		  (status_sw & IPU_ISYS_UNISPART_IRQ_SW)) &&
-		 !isys->adev->isp->flr_done);
-
-	writel(ISYS_UNISPART_IRQS, base + IPU_REG_ISYS_UNISPART_IRQ_MASK);
-
-	spin_unlock(&isys->power_lock);
-
-	return IRQ_HANDLED;
-}
-
diff --git a/drivers/media/pci/intel/ipu6/ipu6-l-scheduler.c b/drivers/media/pci/intel/ipu6/ipu6-l-scheduler.c
deleted file mode 100644
index 77677ef75ae7..000000000000
--- a/drivers/media/pci/intel/ipu6/ipu6-l-scheduler.c
+++ /dev/null
@@ -1,615 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0
-// Copyright (C) 2020 Intel Corporation
-
-#include "ipu-psys.h"
-#include "ipu6-ppg.h"
-
-extern bool enable_power_gating;
-
-struct sched_list {
-	struct list_head list;
-	/* to protect the list */
-	struct mutex lock;
-};
-
-static struct sched_list start_list = {
-	.list	= LIST_HEAD_INIT(start_list.list),
-	.lock	= __MUTEX_INITIALIZER(start_list.lock),
-};
-
-static struct sched_list stop_list = {
-	.list	= LIST_HEAD_INIT(stop_list.list),
-	.lock	= __MUTEX_INITIALIZER(stop_list.lock),
-};
-
-static struct sched_list *get_sc_list(enum SCHED_LIST type)
-{
-	/* for debug purposes */
-	WARN_ON(type != SCHED_START_LIST && type != SCHED_STOP_LIST);
-
-	if (type == SCHED_START_LIST)
-		return &start_list;
-	return &stop_list;
-}
-
-static bool is_kppg_in_list(struct ipu_psys_ppg *kppg, struct list_head *head)
-{
-	struct ipu_psys_ppg *tmp;
-
-	list_for_each_entry(tmp, head, sched_list) {
-		if (kppg == tmp)
-			return true;
-	}
-
-	return false;
-}
-
-void ipu_psys_scheduler_remove_kppg(struct ipu_psys_ppg *kppg,
-				    enum SCHED_LIST type)
-{
-	struct sched_list *sc_list = get_sc_list(type);
-	struct ipu_psys_ppg *tmp0, *tmp1;
-	struct ipu_psys *psys = kppg->fh->psys;
-
-	mutex_lock(&sc_list->lock);
-	list_for_each_entry_safe(tmp0, tmp1, &sc_list->list, sched_list) {
-		if (tmp0 == kppg) {
-			dev_dbg(&psys->adev->dev,
-				 "remove from %s list, kppg(%d 0x%p) state %d\n",
-				 type == SCHED_START_LIST ? "start" : "stop",
-				 kppg->kpg->pg->ID, kppg, kppg->state);
-			list_del_init(&kppg->sched_list);
-		}
-	}
-	mutex_unlock(&sc_list->lock);
-}
-
-void ipu_psys_scheduler_add_kppg(struct ipu_psys_ppg *kppg,
-				 enum SCHED_LIST type)
-{
-	int cur_pri = kppg->pri_base + kppg->pri_dynamic;
-	struct sched_list *sc_list = get_sc_list(type);
-	struct ipu_psys *psys = kppg->fh->psys;
-	struct ipu_psys_ppg *tmp0, *tmp1;
-
-	dev_dbg(&psys->adev->dev,
-		"add to %s list, kppg(%d 0x%p) state %d prio(%d %d) fh 0x%p\n",
-		type == SCHED_START_LIST ? "start" : "stop",
-		kppg->kpg->pg->ID, kppg, kppg->state,
-		kppg->pri_base, kppg->pri_dynamic, kppg->fh);
-
-	mutex_lock(&sc_list->lock);
-	if (list_empty(&sc_list->list)) {
-		list_add(&kppg->sched_list, &sc_list->list);
-		goto out;
-	}
-
-	if (is_kppg_in_list(kppg, &sc_list->list)) {
-		dev_dbg(&psys->adev->dev, "kppg already in list\n");
-		goto out;
-	}
-
-	list_for_each_entry_safe(tmp0, tmp1, &sc_list->list, sched_list) {
-		int tmp_pri = tmp0->pri_base + tmp0->pri_dynamic;
-
-		dev_dbg(&psys->adev->dev,
-			"found kppg(%d 0x%p), state %d pri(%d %d) fh 0x%p\n",
-			tmp0->kpg->pg->ID, tmp0, tmp0->state,
-			tmp0->pri_base, tmp0->pri_dynamic, tmp0->fh);
-
-		if (type == SCHED_START_LIST && tmp_pri > cur_pri) {
-			list_add(&kppg->sched_list, tmp0->sched_list.prev);
-			goto out;
-		} else if (type == SCHED_STOP_LIST && tmp_pri < cur_pri) {
-			list_add(&kppg->sched_list, tmp0->sched_list.prev);
-			goto out;
-		}
-	}
-
-	list_add_tail(&kppg->sched_list, &sc_list->list);
-out:
-	mutex_unlock(&sc_list->lock);
-}
-
-static int ipu_psys_detect_resource_contention(struct ipu_psys_ppg *kppg)
-{
-	struct ipu_psys_resource_pool *try_res_pool;
-	struct ipu_psys *psys = kppg->fh->psys;
-	int ret = 0;
-	int state;
-
-	try_res_pool = kzalloc(sizeof(*try_res_pool), GFP_KERNEL);
-	if (IS_ERR_OR_NULL(try_res_pool))
-		return -ENOMEM;
-
-	mutex_lock(&kppg->mutex);
-	state = kppg->state;
-	mutex_unlock(&kppg->mutex);
-	if (state == PPG_STATE_STARTED || state == PPG_STATE_RUNNING ||
-	    state == PPG_STATE_RESUMED)
-		goto exit;
-
-	ret = ipu_psys_resource_pool_init(try_res_pool);
-	if (ret < 0) {
-		dev_err(&psys->adev->dev, "unable to alloc pg resources\n");
-		WARN_ON(1);
-		goto exit;
-	}
-
-	ipu_psys_resource_copy(&psys->resource_pool_running, try_res_pool);
-	ret = ipu_psys_try_allocate_resources(&psys->adev->dev,
-					      kppg->kpg->pg,
-					      kppg->manifest,
-					      try_res_pool);
-
-	ipu_psys_resource_pool_cleanup(try_res_pool);
-exit:
-	kfree(try_res_pool);
-
-	return ret;
-}
-
-static void ipu_psys_scheduler_ppg_sort(struct ipu_psys *psys, bool *stopping)
-{
-	struct ipu_psys_ppg *kppg, *tmp;
-	struct ipu_psys_scheduler *sched;
-	struct ipu_psys_fh *fh;
-
-	list_for_each_entry(fh, &psys->fhs, list) {
-		mutex_lock(&fh->mutex);
-		sched = &fh->sched;
-
-		if (list_empty(&sched->ppgs)) {
-			mutex_unlock(&fh->mutex);
-			continue;
-		}
-
-		list_for_each_entry_safe(kppg, tmp, &sched->ppgs, list) {
-			mutex_lock(&kppg->mutex);
-			if (kppg->state == PPG_STATE_START ||
-			    kppg->state == PPG_STATE_RESUME) {
-				ipu_psys_scheduler_add_kppg(kppg,
-							    SCHED_START_LIST);
-			} else if (kppg->state == PPG_STATE_RUNNING) {
-				ipu_psys_scheduler_add_kppg(kppg,
-							    SCHED_STOP_LIST);
-			} else if (kppg->state == PPG_STATE_SUSPENDING ||
-				   kppg->state == PPG_STATE_STOPPING) {
-				/* there are some suspending/stopping ppgs */
-				*stopping = true;
-			} else if (kppg->state == PPG_STATE_RESUMING ||
-				   kppg->state == PPG_STATE_STARTING) {
-				   /* how about kppg are resuming/starting? */
-			}
-			mutex_unlock(&kppg->mutex);
-		}
-		mutex_unlock(&fh->mutex);
-	}
-}
-
-static void ipu_psys_scheduler_update_start_ppg_priority(void)
-{
-	struct sched_list *sc_list = get_sc_list(SCHED_START_LIST);
-	struct ipu_psys_ppg *kppg, *tmp;
-
-	mutex_lock(&sc_list->lock);
-	if (!list_empty(&sc_list->list))
-		list_for_each_entry_safe(kppg, tmp, &sc_list->list, sched_list)
-			kppg->pri_dynamic--;
-	mutex_unlock(&sc_list->lock);
-}
-
-static bool ipu_psys_scheduler_switch_ppg(struct ipu_psys *psys)
-{
-	struct sched_list *sc_list = get_sc_list(SCHED_STOP_LIST);
-	struct ipu_psys_ppg *kppg;
-	bool resched = false;
-
-	mutex_lock(&sc_list->lock);
-	if (list_empty(&sc_list->list)) {
-		/* some ppgs are RESUMING/STARTING */
-		dev_dbg(&psys->adev->dev, "no candidated stop ppg\n");
-		mutex_unlock(&sc_list->lock);
-		return false;
-	}
-	kppg = list_first_entry(&sc_list->list, struct ipu_psys_ppg,
-				sched_list);
-	mutex_unlock(&sc_list->lock);
-
-	mutex_lock(&kppg->mutex);
-	if (!(kppg->state & PPG_STATE_STOP)) {
-		dev_dbg(&psys->adev->dev, "s_change:%s: %p %d -> %d\n",
-			__func__, kppg, kppg->state, PPG_STATE_SUSPEND);
-		kppg->state = PPG_STATE_SUSPEND;
-		resched = true;
-	}
-	mutex_unlock(&kppg->mutex);
-
-	return resched;
-}
-
-/*
- * search all kppgs and sort them into start_list and stop_list, alway start
- * first kppg(high priority) in start_list;
- * if there is resource contention, it would switch kppgs in stop_list
- * to suspend state one by one
- */
-static bool ipu_psys_scheduler_ppg_start(struct ipu_psys *psys)
-{
-	struct sched_list *sc_list = get_sc_list(SCHED_START_LIST);
-	struct ipu_psys_ppg *kppg, *kppg0;
-	bool stopping_existed = false;
-	int ret;
-
-	ipu_psys_scheduler_ppg_sort(psys, &stopping_existed);
-
-	mutex_lock(&sc_list->lock);
-	if (list_empty(&sc_list->list)) {
-		dev_dbg(&psys->adev->dev, "no ppg to start\n");
-		mutex_unlock(&sc_list->lock);
-		return false;
-	}
-
-	list_for_each_entry_safe(kppg, kppg0,
-				 &sc_list->list, sched_list) {
-		mutex_unlock(&sc_list->lock);
-
-		ret = ipu_psys_detect_resource_contention(kppg);
-		if (ret < 0) {
-			dev_dbg(&psys->adev->dev,
-				"ppg %d resource detect failed(%d)\n",
-				kppg->kpg->pg->ID, ret);
-			/*
-			 * switch out other ppg in 2 cases:
-			 * 1. resource contention
-			 * 2. no suspending/stopping ppg
-			 */
-			if (ret == -ENOSPC) {
-				if (!stopping_existed &&
-				    ipu_psys_scheduler_switch_ppg(psys)) {
-					return true;
-				}
-				dev_dbg(&psys->adev->dev,
-					"ppg is suspending/stopping\n");
-			} else {
-				dev_err(&psys->adev->dev,
-					"detect resource error %d\n", ret);
-			}
-		} else {
-			kppg->pri_dynamic = 0;
-
-			mutex_lock(&kppg->mutex);
-			if (kppg->state == PPG_STATE_START)
-				ipu_psys_ppg_start(kppg);
-			else
-				ipu_psys_ppg_resume(kppg);
-			mutex_unlock(&kppg->mutex);
-
-			ipu_psys_scheduler_remove_kppg(kppg,
-						       SCHED_START_LIST);
-			ipu_psys_scheduler_update_start_ppg_priority();
-		}
-		mutex_lock(&sc_list->lock);
-	}
-	mutex_unlock(&sc_list->lock);
-
-	return false;
-}
-
-static bool ipu_psys_scheduler_ppg_enqueue_bufset(struct ipu_psys *psys)
-{
-	struct ipu_psys_scheduler *sched;
-	struct ipu_psys_ppg *kppg;
-	struct ipu_psys_fh *fh;
-	bool resched = false;
-
-	list_for_each_entry(fh, &psys->fhs, list) {
-		mutex_lock(&fh->mutex);
-		sched = &fh->sched;
-		if (list_empty(&sched->ppgs)) {
-			mutex_unlock(&fh->mutex);
-			continue;
-		}
-
-		list_for_each_entry(kppg, &sched->ppgs, list) {
-			if (ipu_psys_ppg_enqueue_bufsets(kppg))
-				resched = true;
-		}
-		mutex_unlock(&fh->mutex);
-	}
-
-	return resched;
-}
-
-/*
- * This function will check all kppgs within fhs, and if kppg state
- * is STOP or SUSPEND, l-scheduler will call ppg function to stop
- * or suspend it and update stop list
- */
-
-static bool ipu_psys_scheduler_ppg_halt(struct ipu_psys *psys)
-{
-	struct ipu_psys_scheduler *sched;
-	struct ipu_psys_ppg *kppg, *tmp;
-	struct ipu_psys_fh *fh;
-	bool stopping_exit = false;
-
-	list_for_each_entry(fh, &psys->fhs, list) {
-		mutex_lock(&fh->mutex);
-		sched = &fh->sched;
-		if (list_empty(&sched->ppgs)) {
-			mutex_unlock(&fh->mutex);
-			continue;
-		}
-
-		list_for_each_entry_safe(kppg, tmp, &sched->ppgs, list) {
-			mutex_lock(&kppg->mutex);
-			if (kppg->state & PPG_STATE_STOP) {
-				ipu_psys_ppg_stop(kppg);
-				ipu_psys_scheduler_remove_kppg(kppg,
-							       SCHED_STOP_LIST);
-			} else if (kppg->state == PPG_STATE_SUSPEND) {
-				ipu_psys_ppg_suspend(kppg);
-				ipu_psys_scheduler_remove_kppg(kppg,
-							       SCHED_STOP_LIST);
-			} else if (kppg->state == PPG_STATE_SUSPENDING ||
-				   kppg->state == PPG_STATE_STOPPING) {
-				stopping_exit = true;
-			}
-			mutex_unlock(&kppg->mutex);
-		}
-		mutex_unlock(&fh->mutex);
-	}
-	return stopping_exit;
-}
-
-static void ipu_psys_update_ppg_state_by_kcmd(struct ipu_psys *psys,
-					      struct ipu_psys_ppg *kppg,
-					      struct ipu_psys_kcmd *kcmd)
-{
-	int old_ppg_state = kppg->state;
-
-	/*
-	 * Respond kcmd when ppg is in stable state:
-	 * STARTED/RESUMED/RUNNING/SUSPENDED/STOPPED
-	 */
-	if (kppg->state == PPG_STATE_STARTED ||
-	    kppg->state == PPG_STATE_RESUMED ||
-	    kppg->state == PPG_STATE_RUNNING) {
-		if (kcmd->state == KCMD_STATE_PPG_START)
-			ipu_psys_kcmd_complete(kppg, kcmd, 0);
-		else if (kcmd->state == KCMD_STATE_PPG_STOP)
-			kppg->state = PPG_STATE_STOP;
-	} else if (kppg->state == PPG_STATE_SUSPENDED) {
-		if (kcmd->state == KCMD_STATE_PPG_START)
-			ipu_psys_kcmd_complete(kppg, kcmd, 0);
-		else if (kcmd->state == KCMD_STATE_PPG_STOP)
-			/*
-			 * Record the previous state
-			 * because here need resume at first
-			 */
-			kppg->state |= PPG_STATE_STOP;
-		else if (kcmd->state == KCMD_STATE_PPG_ENQUEUE)
-			kppg->state = PPG_STATE_RESUME;
-	} else if (kppg->state == PPG_STATE_STOPPED) {
-		if (kcmd->state == KCMD_STATE_PPG_START)
-			kppg->state = PPG_STATE_START;
-		else if (kcmd->state == KCMD_STATE_PPG_STOP)
-			ipu_psys_kcmd_complete(kppg, kcmd, 0);
-		else if (kcmd->state == KCMD_STATE_PPG_ENQUEUE) {
-			dev_err(&psys->adev->dev, "ppg %p stopped!\n", kppg);
-			ipu_psys_kcmd_complete(kppg, kcmd, -EIO);
-		}
-	}
-
-	if (old_ppg_state != kppg->state)
-		dev_dbg(&psys->adev->dev, "s_change:%s: %p %d -> %d\n",
-			__func__, kppg, old_ppg_state, kppg->state);
-}
-
-static void ipu_psys_scheduler_kcmd_set(struct ipu_psys *psys)
-{
-	struct ipu_psys_kcmd *kcmd;
-	struct ipu_psys_scheduler *sched;
-	struct ipu_psys_ppg *kppg, *tmp;
-	struct ipu_psys_fh *fh;
-
-	list_for_each_entry(fh, &psys->fhs, list) {
-		mutex_lock(&fh->mutex);
-		sched = &fh->sched;
-		if (list_empty(&sched->ppgs)) {
-			mutex_unlock(&fh->mutex);
-			continue;
-		}
-
-		list_for_each_entry_safe(kppg, tmp, &sched->ppgs, list) {
-			mutex_lock(&kppg->mutex);
-			if (list_empty(&kppg->kcmds_new_list)) {
-				mutex_unlock(&kppg->mutex);
-				continue;
-			};
-
-			kcmd = list_first_entry(&kppg->kcmds_new_list,
-						struct ipu_psys_kcmd, list);
-			ipu_psys_update_ppg_state_by_kcmd(psys, kppg, kcmd);
-			mutex_unlock(&kppg->mutex);
-		}
-		mutex_unlock(&fh->mutex);
-	}
-}
-
-static bool is_ready_to_enter_power_gating(struct ipu_psys *psys)
-{
-	struct ipu_psys_scheduler *sched;
-	struct ipu_psys_ppg *kppg, *tmp;
-	struct ipu_psys_fh *fh;
-
-	list_for_each_entry(fh, &psys->fhs, list) {
-		mutex_lock(&fh->mutex);
-		sched = &fh->sched;
-		if (list_empty(&sched->ppgs)) {
-			mutex_unlock(&fh->mutex);
-			continue;
-		}
-
-		list_for_each_entry_safe(kppg, tmp, &sched->ppgs, list) {
-			mutex_lock(&kppg->mutex);
-			if (!list_empty(&kppg->kcmds_new_list) ||
-			    !list_empty(&kppg->kcmds_processing_list)) {
-				mutex_unlock(&kppg->mutex);
-				mutex_unlock(&fh->mutex);
-				return false;
-			}
-			if (!(kppg->state == PPG_STATE_RUNNING ||
-			      kppg->state == PPG_STATE_STOPPED ||
-			      kppg->state == PPG_STATE_SUSPENDED)) {
-				mutex_unlock(&kppg->mutex);
-				mutex_unlock(&fh->mutex);
-				return false;
-			}
-			mutex_unlock(&kppg->mutex);
-		}
-		mutex_unlock(&fh->mutex);
-	}
-
-	return true;
-}
-
-static bool has_pending_kcmd(struct ipu_psys *psys)
-{
-	struct ipu_psys_scheduler *sched;
-	struct ipu_psys_ppg *kppg, *tmp;
-	struct ipu_psys_fh *fh;
-
-	list_for_each_entry(fh, &psys->fhs, list) {
-		mutex_lock(&fh->mutex);
-		sched = &fh->sched;
-		if (list_empty(&sched->ppgs)) {
-			mutex_unlock(&fh->mutex);
-			continue;
-		}
-
-		list_for_each_entry_safe(kppg, tmp, &sched->ppgs, list) {
-			mutex_lock(&kppg->mutex);
-			if (!list_empty(&kppg->kcmds_new_list) ||
-			    !list_empty(&kppg->kcmds_processing_list)) {
-				mutex_unlock(&kppg->mutex);
-				mutex_unlock(&fh->mutex);
-				return true;
-			}
-			mutex_unlock(&kppg->mutex);
-		}
-		mutex_unlock(&fh->mutex);
-	}
-
-	return false;
-}
-
-static bool ipu_psys_scheduler_exit_power_gating(struct ipu_psys *psys)
-{
-	/* Assume power gating process can be aborted directly during START */
-	if (psys->power_gating == PSYS_POWER_GATED) {
-		dev_dbg(&psys->adev->dev, "powergating: exit ---\n");
-		ipu_psys_exit_power_gating(psys);
-	}
-	psys->power_gating = PSYS_POWER_NORMAL;
-	return false;
-}
-
-static bool ipu_psys_scheduler_enter_power_gating(struct ipu_psys *psys)
-{
-	struct ipu_psys_scheduler *sched;
-	struct ipu_psys_ppg *kppg, *tmp;
-	struct ipu_psys_fh *fh;
-
-	if (!enable_power_gating)
-		return false;
-
-	if (psys->power_gating == PSYS_POWER_NORMAL &&
-	    is_ready_to_enter_power_gating(psys)) {
-		/* Enter power gating */
-		dev_dbg(&psys->adev->dev, "powergating: enter +++\n");
-		psys->power_gating = PSYS_POWER_GATING;
-	}
-
-	if (psys->power_gating != PSYS_POWER_GATING)
-		return false;
-
-	/* Suspend ppgs one by one */
-	list_for_each_entry(fh, &psys->fhs, list) {
-		mutex_lock(&fh->mutex);
-		sched = &fh->sched;
-		if (list_empty(&sched->ppgs)) {
-			mutex_unlock(&fh->mutex);
-			continue;
-		}
-
-		list_for_each_entry_safe(kppg, tmp, &sched->ppgs, list) {
-			mutex_lock(&kppg->mutex);
-			if (kppg->state == PPG_STATE_RUNNING) {
-				kppg->state = PPG_STATE_SUSPEND;
-				mutex_unlock(&kppg->mutex);
-				mutex_unlock(&fh->mutex);
-				return true;
-			}
-
-			if (kppg->state != PPG_STATE_SUSPENDED &&
-			    kppg->state != PPG_STATE_STOPPED) {
-				/* Can't enter power gating */
-				mutex_unlock(&kppg->mutex);
-				mutex_unlock(&fh->mutex);
-				/* Need re-run l-scheduler to suspend ppg? */
-				return (kppg->state & PPG_STATE_STOP ||
-					kppg->state == PPG_STATE_SUSPEND);
-			}
-			mutex_unlock(&kppg->mutex);
-		}
-		mutex_unlock(&fh->mutex);
-	}
-
-	psys->power_gating = PSYS_POWER_GATED;
-	ipu_psys_enter_power_gating(psys);
-
-	return false;
-}
-
-void ipu_psys_run_next(struct ipu_psys *psys)
-{
-	/* Wake up scheduler due to unfinished work */
-	bool need_trigger = false;
-	/* Wait FW callback if there are stopping/suspending/running ppg */
-	bool wait_fw_finish = false;
-	/*
-	 * Code below will crash if fhs is empty. Normally this
-	 * shouldn't happen.
-	 */
-	if (list_empty(&psys->fhs)) {
-		WARN_ON(1);
-		return;
-	}
-
-	/* Abort power gating process */
-	if (psys->power_gating != PSYS_POWER_NORMAL &&
-	    has_pending_kcmd(psys))
-		need_trigger = ipu_psys_scheduler_exit_power_gating(psys);
-
-	/* Handle kcmd and related ppg switch */
-	if (psys->power_gating == PSYS_POWER_NORMAL) {
-		ipu_psys_scheduler_kcmd_set(psys);
-		wait_fw_finish = ipu_psys_scheduler_ppg_halt(psys);
-		need_trigger |= ipu_psys_scheduler_ppg_start(psys);
-		need_trigger |= ipu_psys_scheduler_ppg_enqueue_bufset(psys);
-	}
-	if (!(need_trigger || wait_fw_finish)) {
-		/* Nothing to do, enter power gating */
-		need_trigger = ipu_psys_scheduler_enter_power_gating(psys);
-		if (psys->power_gating == PSYS_POWER_GATING)
-			wait_fw_finish = ipu_psys_scheduler_ppg_halt(psys);
-	}
-
-	if (need_trigger && !wait_fw_finish) {
-		dev_dbg(&psys->adev->dev, "scheduler: wake up\n");
-		atomic_set(&psys->wakeup_count, 1);
-		wake_up_interruptible(&psys->sched_cmd_wq);
-	}
-}
diff --git a/drivers/media/pci/intel/ipu6/ipu6-platform-resources.h b/drivers/media/pci/intel/ipu6/ipu6-platform-resources.h
deleted file mode 100644
index 329901ac3acb..000000000000
--- a/drivers/media/pci/intel/ipu6/ipu6-platform-resources.h
+++ /dev/null
@@ -1,196 +0,0 @@
-/* SPDX-License-Identifier: GPL-2.0 */
-/* Copyright (C) 2018 - 2020 Intel Corporation */
-
-#ifndef IPU6_PLATFORM_RESOURCES_H
-#define IPU6_PLATFORM_RESOURCES_H
-
-#include <linux/kernel.h>
-#include <linux/device.h>
-#include "ipu-platform-resources.h"
-
-#define	IPU6_FW_PSYS_N_PADDING_UINT8_IN_PROCESS_EXT_STRUCT		0
-
-enum {
-	IPU6_FW_PSYS_CMD_QUEUE_COMMAND_ID = 0,
-	IPU6_FW_PSYS_CMD_QUEUE_DEVICE_ID,
-	IPU6_FW_PSYS_CMD_QUEUE_PPG0_COMMAND_ID,
-	IPU6_FW_PSYS_CMD_QUEUE_PPG1_COMMAND_ID,
-	IPU6_FW_PSYS_CMD_QUEUE_PPG2_COMMAND_ID,
-	IPU6_FW_PSYS_CMD_QUEUE_PPG3_COMMAND_ID,
-	IPU6_FW_PSYS_CMD_QUEUE_PPG4_COMMAND_ID,
-	IPU6_FW_PSYS_CMD_QUEUE_PPG5_COMMAND_ID,
-	IPU6_FW_PSYS_CMD_QUEUE_PPG6_COMMAND_ID,
-	IPU6_FW_PSYS_CMD_QUEUE_PPG7_COMMAND_ID,
-	IPU6_FW_PSYS_CMD_QUEUE_PPG8_COMMAND_ID,
-	IPU6_FW_PSYS_CMD_QUEUE_PPG9_COMMAND_ID,
-	IPU6_FW_PSYS_CMD_QUEUE_PPG10_COMMAND_ID,
-	IPU6_FW_PSYS_CMD_QUEUE_PPG11_COMMAND_ID,
-	IPU6_FW_PSYS_CMD_QUEUE_PPG12_COMMAND_ID,
-	IPU6_FW_PSYS_CMD_QUEUE_PPG13_COMMAND_ID,
-	IPU6_FW_PSYS_CMD_QUEUE_PPG14_COMMAND_ID,
-	IPU6_FW_PSYS_CMD_QUEUE_PPG15_COMMAND_ID,
-	IPU6_FW_PSYS_CMD_QUEUE_PPG16_COMMAND_ID,
-	IPU6_FW_PSYS_CMD_QUEUE_PPG17_COMMAND_ID,
-	IPU6_FW_PSYS_CMD_QUEUE_PPG18_COMMAND_ID,
-	IPU6_FW_PSYS_CMD_QUEUE_PPG19_COMMAND_ID,
-	IPU6_FW_PSYS_CMD_QUEUE_PPG20_COMMAND_ID,
-	IPU6_FW_PSYS_CMD_QUEUE_PPG21_COMMAND_ID,
-	IPU6_FW_PSYS_CMD_QUEUE_PPG22_COMMAND_ID,
-	IPU6_FW_PSYS_CMD_QUEUE_PPG23_COMMAND_ID,
-	IPU6_FW_PSYS_CMD_QUEUE_PPG24_COMMAND_ID,
-	IPU6_FW_PSYS_CMD_QUEUE_PPG25_COMMAND_ID,
-	IPU6_FW_PSYS_CMD_QUEUE_PPG26_COMMAND_ID,
-	IPU6_FW_PSYS_CMD_QUEUE_PPG27_COMMAND_ID,
-	IPU6_FW_PSYS_CMD_QUEUE_PPG28_COMMAND_ID,
-	IPU6_FW_PSYS_CMD_QUEUE_PPG29_COMMAND_ID,
-	IPU6_FW_PSYS_N_PSYS_CMD_QUEUE_ID
-};
-
-enum {
-	IPU6_FW_PSYS_TRANSFER_VMEM0_TYPE_ID = 0,
-	IPU6_FW_PSYS_TRANSFER_VMEM1_TYPE_ID,
-	IPU6_FW_PSYS_LB_VMEM_TYPE_ID,
-	IPU6_FW_PSYS_DMEM_TYPE_ID,
-	IPU6_FW_PSYS_VMEM_TYPE_ID,
-	IPU6_FW_PSYS_BAMEM_TYPE_ID,
-	IPU6_FW_PSYS_PMEM_TYPE_ID,
-	IPU6_FW_PSYS_N_MEM_TYPE_ID
-};
-
-enum ipu6_mem_id {
-	IPU6_FW_PSYS_VMEM0_ID = 0,	/* ISP0 VMEM */
-	IPU6_FW_PSYS_TRANSFER_VMEM0_ID,	/* TRANSFER VMEM 0 */
-	IPU6_FW_PSYS_TRANSFER_VMEM1_ID,	/* TRANSFER VMEM 1 */
-	IPU6_FW_PSYS_LB_VMEM_ID,	/* LB VMEM */
-	IPU6_FW_PSYS_BAMEM0_ID,	/* ISP0 BAMEM */
-	IPU6_FW_PSYS_DMEM0_ID,	/* SPC0 Dmem */
-	IPU6_FW_PSYS_DMEM1_ID,	/* SPP0 Dmem */
-	IPU6_FW_PSYS_DMEM2_ID,	/* SPP1 Dmem */
-	IPU6_FW_PSYS_DMEM3_ID,	/* ISP0 Dmem */
-	IPU6_FW_PSYS_PMEM0_ID,	/* ISP0 PMEM */
-	IPU6_FW_PSYS_N_MEM_ID
-};
-
-enum {
-	IPU6_FW_PSYS_DEV_CHN_DMA_EXT0_ID = 0,
-	IPU6_FW_PSYS_DEV_CHN_DMA_EXT1_READ_ID,
-	IPU6_FW_PSYS_DEV_CHN_DMA_EXT1_WRITE_ID,
-	IPU6_FW_PSYS_DEV_CHN_DMA_INTERNAL_ID,
-	IPU6_FW_PSYS_DEV_CHN_DMA_ISA_ID,
-	IPU6_FW_PSYS_N_DEV_CHN_ID
-};
-
-enum {
-	IPU6_FW_PSYS_SP_CTRL_TYPE_ID = 0,
-	IPU6_FW_PSYS_SP_SERVER_TYPE_ID,
-	IPU6_FW_PSYS_VP_TYPE_ID,
-	IPU6_FW_PSYS_ACC_PSA_TYPE_ID,
-	IPU6_FW_PSYS_ACC_ISA_TYPE_ID,
-	IPU6_FW_PSYS_ACC_OSA_TYPE_ID,
-	IPU6_FW_PSYS_GDC_TYPE_ID,
-	IPU6_FW_PSYS_TNR_TYPE_ID,
-	IPU6_FW_PSYS_N_CELL_TYPE_ID
-};
-
-enum {
-	IPU6_FW_PSYS_SP0_ID = 0,
-	IPU6_FW_PSYS_VP0_ID,
-	IPU6_FW_PSYS_PSA_ACC_BNLM_ID,
-	IPU6_FW_PSYS_PSA_ACC_DM_ID,
-	IPU6_FW_PSYS_PSA_ACC_ACM_ID,
-	IPU6_FW_PSYS_PSA_ACC_GTC_YUV1_ID,
-	IPU6_FW_PSYS_BB_ACC_OFS_PIN_MAIN_ID,
-	IPU6_FW_PSYS_BB_ACC_OFS_PIN_DISPLAY_ID,
-	IPU6_FW_PSYS_BB_ACC_OFS_PIN_PP_ID,
-	IPU6_FW_PSYS_PSA_ACC_GAMMASTAR_ID,
-	IPU6_FW_PSYS_PSA_ACC_GLTM_ID,
-	IPU6_FW_PSYS_PSA_ACC_XNR_ID,
-	IPU6_FW_PSYS_PSA_VCSC_ID,	/* VCSC */
-	IPU6_FW_PSYS_ISA_ICA_ID,
-	IPU6_FW_PSYS_ISA_LSC_ID,
-	IPU6_FW_PSYS_ISA_DPC_ID,
-	IPU6_FW_PSYS_ISA_SIS_A_ID,
-	IPU6_FW_PSYS_ISA_SIS_B_ID,
-	IPU6_FW_PSYS_ISA_B2B_ID,
-	IPU6_FW_PSYS_ISA_B2R_R2I_SIE_ID,
-	IPU6_FW_PSYS_ISA_R2I_DS_A_ID,
-	IPU6_FW_PSYS_ISA_R2I_DS_B_ID,
-	IPU6_FW_PSYS_ISA_AWB_ID,
-	IPU6_FW_PSYS_ISA_AE_ID,
-	IPU6_FW_PSYS_ISA_AF_ID,
-	IPU6_FW_PSYS_ISA_DOL_ID,
-	IPU6_FW_PSYS_ISA_ICA_MEDIUM_ID,
-	IPU6_FW_PSYS_ISA_X2B_MD_ID,
-	IPU6_FW_PSYS_ISA_X2B_SVE_RGBIR_ID,
-	IPU6_FW_PSYS_ISA_PAF_ID,
-	IPU6_FW_PSYS_BB_ACC_GDC0_ID,
-	IPU6_FW_PSYS_BB_ACC_TNR_ID,
-	IPU6_FW_PSYS_N_CELL_ID
-};
-
-enum {
-	IPU6_FW_PSYS_DEV_DFM_BB_FULL_PORT_ID = 0,
-	IPU6_FW_PSYS_DEV_DFM_BB_EMPTY_PORT_ID,
-	IPU6_FW_PSYS_DEV_DFM_ISL_FULL_PORT_ID,
-	IPU6_FW_PSYS_DEV_DFM_ISL_EMPTY_PORT_ID,
-	IPU6_FW_PSYS_DEV_DFM_LB_FULL_PORT_ID,
-	IPU6_FW_PSYS_DEV_DFM_LB_EMPTY_PORT_ID,
-};
-
-/* Excluding PMEM */
-#define IPU6_FW_PSYS_N_DATA_MEM_TYPE_ID	(IPU6_FW_PSYS_N_MEM_TYPE_ID - 1)
-#define IPU6_FW_PSYS_N_DEV_DFM_ID	\
-	(IPU6_FW_PSYS_DEV_DFM_LB_EMPTY_PORT_ID + 1)
-
-#define IPU6_FW_PSYS_VMEM0_MAX_SIZE		0x0800
-/* Transfer VMEM0 words, ref HAS Transfer*/
-#define IPU6_FW_PSYS_TRANSFER_VMEM0_MAX_SIZE	0x0800
-/* Transfer VMEM1 words, ref HAS Transfer*/
-#define IPU6_FW_PSYS_TRANSFER_VMEM1_MAX_SIZE	0x0800
-#define IPU6_FW_PSYS_LB_VMEM_MAX_SIZE		0x0400	/* LB VMEM words */
-#define IPU6_FW_PSYS_BAMEM0_MAX_SIZE		0x0800
-#define IPU6_FW_PSYS_DMEM0_MAX_SIZE		0x4000
-#define IPU6_FW_PSYS_DMEM1_MAX_SIZE		0x1000
-#define IPU6_FW_PSYS_DMEM2_MAX_SIZE		0x1000
-#define IPU6_FW_PSYS_DMEM3_MAX_SIZE		0x1000
-#define IPU6_FW_PSYS_PMEM0_MAX_SIZE		0x0500
-
-#define IPU6_FW_PSYS_DEV_CHN_DMA_EXT0_MAX_SIZE		30
-#define IPU6_FW_PSYS_DEV_CHN_GDC_MAX_SIZE		0
-#define IPU6_FW_PSYS_DEV_CHN_DMA_EXT1_READ_MAX_SIZE	30
-#define IPU6_FW_PSYS_DEV_CHN_DMA_EXT1_WRITE_MAX_SIZE	43
-#define IPU6_FW_PSYS_DEV_CHN_DMA_INTERNAL_MAX_SIZE	8
-#define IPU6_FW_PSYS_DEV_CHN_DMA_IPFD_MAX_SIZE		0
-#define IPU6_FW_PSYS_DEV_CHN_DMA_ISA_MAX_SIZE		2
-
-#define IPU6_FW_PSYS_DEV_DFM_BB_FULL_PORT_ID_MAX_SIZE		32
-#define IPU6_FW_PSYS_DEV_DFM_ISL_FULL_PORT_ID_MAX_SIZE		32
-#define IPU6_FW_PSYS_DEV_DFM_LB_FULL_PORT_ID_MAX_SIZE		32
-#define IPU6_FW_PSYS_DEV_DFM_BB_EMPTY_PORT_ID_MAX_SIZE		32
-#define IPU6_FW_PSYS_DEV_DFM_ISL_EMPTY_PORT_ID_MAX_SIZE		32
-#define IPU6_FW_PSYS_DEV_DFM_LB_EMPTY_PORT_ID_MAX_SIZE		32
-
-struct ipu6_fw_psys_program_manifest_ext {
-	u32 dfm_port_bitmap[IPU6_FW_PSYS_N_DEV_DFM_ID];
-	u32 dfm_active_port_bitmap[IPU6_FW_PSYS_N_DEV_DFM_ID];
-	u16 ext_mem_size[IPU6_FW_PSYS_N_DATA_MEM_TYPE_ID];
-	u16 ext_mem_offset[IPU6_FW_PSYS_N_DATA_MEM_TYPE_ID];
-	u16 dev_chn_size[IPU6_FW_PSYS_N_DEV_CHN_ID];
-	u16 dev_chn_offset[IPU6_FW_PSYS_N_DEV_CHN_ID];
-	u8 is_dfm_relocatable[IPU6_FW_PSYS_N_DEV_DFM_ID];
-	u8 dec_resources_input[IPU_FW_PSYS_MAX_INPUT_DEC_RESOURCES];
-	u8 dec_resources_input_terminal[IPU_FW_PSYS_MAX_INPUT_DEC_RESOURCES];
-	u8 dec_resources_output[IPU_FW_PSYS_MAX_OUTPUT_DEC_RESOURCES];
-	u8 dec_resources_output_terminal[IPU_FW_PSYS_MAX_OUTPUT_DEC_RESOURCES];
-	u8 padding[IPU_FW_PSYS_N_PADDING_UINT8_IN_PROGRAM_MANIFEST_EXT];
-};
-
-struct ipu6_fw_psys_process_ext {
-	u32 dfm_port_bitmap[IPU6_FW_PSYS_N_DEV_DFM_ID];
-	u32 dfm_active_port_bitmap[IPU6_FW_PSYS_N_DEV_DFM_ID];
-	u16 ext_mem_offset[IPU6_FW_PSYS_N_DATA_MEM_TYPE_ID];
-	u16 dev_chn_offset[IPU6_FW_PSYS_N_DEV_CHN_ID];
-	u8 ext_mem_id[IPU6_FW_PSYS_N_DATA_MEM_TYPE_ID];
-};
-
-#endif /* IPU6_PLATFORM_RESOURCES_H */
diff --git a/drivers/media/pci/intel/ipu6/ipu6-ppg.c b/drivers/media/pci/intel/ipu6/ipu6-ppg.c
deleted file mode 100644
index 8f6f413c0393..000000000000
--- a/drivers/media/pci/intel/ipu6/ipu6-ppg.c
+++ /dev/null
@@ -1,560 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0
-// Copyright (C) 2020 Intel Corporation
-
-#include <linux/module.h>
-#include <linux/pm_runtime.h>
-
-#include <asm/cacheflush.h>
-
-#include "ipu6-ppg.h"
-
-static bool enable_suspend_resume;
-module_param(enable_suspend_resume, bool, 0664);
-MODULE_PARM_DESC(enable_suspend_resume, "enable fw ppg suspend/resume api");
-
-static struct ipu_psys_kcmd *
-ipu_psys_ppg_get_kcmd(struct ipu_psys_ppg *kppg, enum ipu_psys_cmd_state state)
-{
-	struct ipu_psys_kcmd *kcmd;
-
-	if (list_empty(&kppg->kcmds_new_list))
-		return NULL;
-
-	list_for_each_entry(kcmd, &kppg->kcmds_new_list, list) {
-		if (kcmd->state == state)
-			return kcmd;
-	}
-
-	return NULL;
-}
-
-struct ipu_psys_kcmd *ipu_psys_ppg_get_stop_kcmd(struct ipu_psys_ppg *kppg)
-{
-	struct ipu_psys_kcmd *kcmd;
-
-	WARN(!mutex_is_locked(&kppg->mutex), "ppg locking error");
-
-	if (list_empty(&kppg->kcmds_processing_list))
-		return NULL;
-
-	list_for_each_entry(kcmd, &kppg->kcmds_processing_list, list) {
-		if (kcmd->state == KCMD_STATE_PPG_STOP)
-			return kcmd;
-	}
-
-	return NULL;
-}
-
-static struct ipu_psys_buffer_set *
-__get_buf_set(struct ipu_psys_fh *fh, size_t buf_set_size)
-{
-	struct ipu_psys_buffer_set *kbuf_set;
-	struct ipu_psys_scheduler *sched = &fh->sched;
-
-	mutex_lock(&sched->bs_mutex);
-	list_for_each_entry(kbuf_set, &sched->buf_sets, list) {
-		if (!kbuf_set->buf_set_size &&
-		    kbuf_set->size >= buf_set_size) {
-			kbuf_set->buf_set_size = buf_set_size;
-			mutex_unlock(&sched->bs_mutex);
-			return kbuf_set;
-		}
-	}
-
-	mutex_unlock(&sched->bs_mutex);
-	/* no suitable buffer available, allocate new one */
-	kbuf_set = kzalloc(sizeof(*kbuf_set), GFP_KERNEL);
-	if (!kbuf_set)
-		return NULL;
-
-	kbuf_set->kaddr = dma_alloc_attrs(&fh->psys->adev->dev,
-					  buf_set_size, &kbuf_set->dma_addr,
-					  GFP_KERNEL, 0);
-	if (!kbuf_set->kaddr) {
-		kfree(kbuf_set);
-		return NULL;
-	}
-
-	kbuf_set->buf_set_size = buf_set_size;
-	kbuf_set->size = buf_set_size;
-	mutex_lock(&sched->bs_mutex);
-	list_add(&kbuf_set->list, &sched->buf_sets);
-	mutex_unlock(&sched->bs_mutex);
-
-	return kbuf_set;
-}
-
-static struct ipu_psys_buffer_set *
-ipu_psys_create_buffer_set(struct ipu_psys_kcmd *kcmd,
-			   struct ipu_psys_ppg *kppg)
-{
-	struct ipu_psys_fh *fh = kcmd->fh;
-	struct ipu_psys *psys = fh->psys;
-	struct ipu_psys_buffer_set *kbuf_set;
-	size_t buf_set_size;
-	u32 *keb;
-
-	buf_set_size = ipu_fw_psys_ppg_get_buffer_set_size(kcmd);
-
-	kbuf_set = __get_buf_set(fh, buf_set_size);
-	if (!kbuf_set) {
-		dev_err(&psys->adev->dev, "failed to create buffer set\n");
-		return NULL;
-	}
-
-	kbuf_set->buf_set = ipu_fw_psys_ppg_create_buffer_set(kcmd,
-							      kbuf_set->kaddr,
-							      0);
-
-	ipu_fw_psys_ppg_buffer_set_vaddress(kbuf_set->buf_set,
-					    kbuf_set->dma_addr);
-	keb = kcmd->kernel_enable_bitmap;
-	ipu_fw_psys_ppg_buffer_set_set_kernel_enable_bitmap(kbuf_set->buf_set,
-							    keb);
-
-	return kbuf_set;
-}
-
-int ipu_psys_ppg_get_bufset(struct ipu_psys_kcmd *kcmd,
-			    struct ipu_psys_ppg *kppg)
-{
-	struct ipu_psys *psys = kppg->fh->psys;
-	struct ipu_psys_buffer_set *kbuf_set;
-	unsigned int i;
-	int ret;
-
-	kbuf_set = ipu_psys_create_buffer_set(kcmd, kppg);
-	if (!kbuf_set) {
-		ret = -EINVAL;
-		goto error;
-	}
-	kcmd->kbuf_set = kbuf_set;
-	kbuf_set->kcmd = kcmd;
-
-	for (i = 0; i < kcmd->nbuffers; i++) {
-		struct ipu_fw_psys_terminal *terminal;
-		u32 buffer;
-
-		terminal = ipu_fw_psys_pg_get_terminal(kcmd, i);
-		if (!terminal)
-			continue;
-
-		buffer = (u32)kcmd->kbufs[i]->dma_addr +
-				    kcmd->buffers[i].data_offset;
-
-		ret = ipu_fw_psys_ppg_set_buffer_set(kcmd, terminal, i, buffer);
-		if (ret) {
-			dev_err(&psys->adev->dev, "Unable to set bufset\n");
-			goto error;
-		}
-	}
-
-	return 0;
-
-error:
-	dev_err(&psys->adev->dev, "failed to get buffer set\n");
-	return ret;
-}
-
-void ipu_psys_ppg_complete(struct ipu_psys *psys, struct ipu_psys_ppg *kppg)
-{
-	u8 queue_id;
-	int old_ppg_state;
-
-	if (!psys || !kppg)
-		return;
-
-	mutex_lock(&kppg->mutex);
-	old_ppg_state = kppg->state;
-	if (kppg->state == PPG_STATE_STOPPING) {
-		struct ipu_psys_kcmd tmp_kcmd = {
-			.kpg = kppg->kpg,
-		};
-
-		kppg->state = PPG_STATE_STOPPED;
-		ipu_psys_free_resources(&kppg->kpg->resource_alloc,
-					&psys->resource_pool_running);
-		queue_id = ipu_fw_psys_ppg_get_base_queue_id(&tmp_kcmd);
-		ipu_psys_free_cmd_queue_resource(&psys->resource_pool_running,
-						 queue_id);
-		pm_runtime_put(&psys->adev->dev);
-	} else {
-		if (kppg->state == PPG_STATE_SUSPENDING) {
-			kppg->state = PPG_STATE_SUSPENDED;
-			ipu_psys_free_resources(&kppg->kpg->resource_alloc,
-						&psys->resource_pool_running);
-		} else if (kppg->state == PPG_STATE_STARTED ||
-			   kppg->state == PPG_STATE_RESUMED) {
-			kppg->state = PPG_STATE_RUNNING;
-		}
-
-		/* Kick l-scheduler thread for FW callback,
-		 * also for checking if need to enter power gating
-		 */
-		atomic_set(&psys->wakeup_count, 1);
-		wake_up_interruptible(&psys->sched_cmd_wq);
-	}
-	if (old_ppg_state != kppg->state)
-		dev_dbg(&psys->adev->dev, "s_change:%s: %p %d -> %d\n",
-			__func__, kppg, old_ppg_state, kppg->state);
-
-	mutex_unlock(&kppg->mutex);
-}
-
-int ipu_psys_ppg_start(struct ipu_psys_ppg *kppg)
-{
-	struct ipu_psys *psys = kppg->fh->psys;
-	struct ipu_psys_kcmd *kcmd = ipu_psys_ppg_get_kcmd(kppg,
-						KCMD_STATE_PPG_START);
-	unsigned int i;
-	int ret;
-
-	if (!kcmd) {
-		dev_err(&psys->adev->dev, "failed to find start kcmd!\n");
-		return -EINVAL;
-	}
-
-	dev_dbg(&psys->adev->dev, "start ppg id %d, addr 0x%p\n",
-		ipu_fw_psys_pg_get_id(kcmd), kppg);
-
-	kppg->state = PPG_STATE_STARTING;
-	for (i = 0; i < kcmd->nbuffers; i++) {
-		struct ipu_fw_psys_terminal *terminal;
-
-		terminal = ipu_fw_psys_pg_get_terminal(kcmd, i);
-		if (!terminal)
-			continue;
-
-		ret = ipu_fw_psys_terminal_set(terminal, i, kcmd, 0,
-					       kcmd->buffers[i].len);
-		if (ret) {
-			dev_err(&psys->adev->dev, "Unable to set terminal\n");
-			return ret;
-		}
-	}
-
-	ret = ipu_fw_psys_pg_submit(kcmd);
-	if (ret) {
-		dev_err(&psys->adev->dev, "failed to submit kcmd!\n");
-		return ret;
-	}
-
-	ret = ipu_psys_allocate_resources(&psys->adev->dev,
-					  kcmd->kpg->pg,
-					  kcmd->pg_manifest,
-					  &kcmd->kpg->resource_alloc,
-					  &psys->resource_pool_running);
-	if (ret) {
-		dev_err(&psys->adev->dev, "alloc resources failed!\n");
-		return ret;
-	}
-
-	ret = pm_runtime_get_sync(&psys->adev->dev);
-	if (ret < 0) {
-		dev_err(&psys->adev->dev, "failed to power on psys\n");
-		goto error;
-	}
-
-	ret = ipu_psys_kcmd_start(psys, kcmd);
-	if (ret) {
-		ipu_psys_kcmd_complete(kppg, kcmd, -EIO);
-		goto error;
-	}
-
-	dev_dbg(&psys->adev->dev, "s_change:%s: %p %d -> %d\n",
-		__func__, kppg, kppg->state, PPG_STATE_STARTED);
-	kppg->state = PPG_STATE_STARTED;
-	ipu_psys_kcmd_complete(kppg, kcmd, 0);
-
-	return 0;
-
-error:
-	pm_runtime_put_noidle(&psys->adev->dev);
-	ipu_psys_reset_process_cell(&psys->adev->dev,
-				    kcmd->kpg->pg,
-				    kcmd->pg_manifest,
-				    kcmd->kpg->pg->process_count);
-	ipu_psys_free_resources(&kppg->kpg->resource_alloc,
-				&psys->resource_pool_running);
-
-	dev_err(&psys->adev->dev, "failed to start ppg\n");
-	return ret;
-}
-
-int ipu_psys_ppg_resume(struct ipu_psys_ppg *kppg)
-{
-	struct ipu_psys *psys = kppg->fh->psys;
-	struct ipu_psys_kcmd tmp_kcmd = {
-		.kpg = kppg->kpg,
-		.fh = kppg->fh,
-	};
-	int ret;
-
-	dev_dbg(&psys->adev->dev, "resume ppg id %d, addr 0x%p\n",
-		ipu_fw_psys_pg_get_id(&tmp_kcmd), kppg);
-
-	kppg->state = PPG_STATE_RESUMING;
-	if (enable_suspend_resume) {
-		ret = ipu_psys_allocate_resources(&psys->adev->dev,
-						  kppg->kpg->pg,
-						  kppg->manifest,
-						  &kppg->kpg->resource_alloc,
-						  &psys->resource_pool_running);
-		if (ret) {
-			dev_err(&psys->adev->dev, "failed to allocate res\n");
-			return -EIO;
-		}
-
-		ret = ipu_fw_psys_ppg_resume(&tmp_kcmd);
-		if (ret) {
-			dev_err(&psys->adev->dev, "failed to resume ppg\n");
-			goto error;
-		}
-	} else {
-		kppg->kpg->pg->state = IPU_FW_PSYS_PROCESS_GROUP_READY;
-		ret = ipu_fw_psys_pg_submit(&tmp_kcmd);
-		if (ret) {
-			dev_err(&psys->adev->dev, "failed to submit kcmd!\n");
-			return ret;
-		}
-
-		ret = ipu_psys_allocate_resources(&psys->adev->dev,
-						  kppg->kpg->pg,
-						  kppg->manifest,
-						  &kppg->kpg->resource_alloc,
-						  &psys->resource_pool_running);
-		if (ret) {
-			dev_err(&psys->adev->dev, "failed to allocate res\n");
-			return ret;
-		}
-
-		ret = ipu_psys_kcmd_start(psys, &tmp_kcmd);
-		if (ret) {
-			dev_err(&psys->adev->dev, "failed to start kcmd!\n");
-			goto error;
-		}
-	}
-	dev_dbg(&psys->adev->dev, "s_change:%s: %p %d -> %d\n",
-		__func__, kppg, kppg->state, PPG_STATE_RESUMED);
-	kppg->state = PPG_STATE_RESUMED;
-
-	return 0;
-
-error:
-	ipu_psys_reset_process_cell(&psys->adev->dev,
-				    kppg->kpg->pg,
-				    kppg->manifest,
-				    kppg->kpg->pg->process_count);
-	ipu_psys_free_resources(&kppg->kpg->resource_alloc,
-				&psys->resource_pool_running);
-
-	return ret;
-}
-
-int ipu_psys_ppg_stop(struct ipu_psys_ppg *kppg)
-{
-	struct ipu_psys_kcmd *kcmd = ipu_psys_ppg_get_kcmd(kppg,
-							   KCMD_STATE_PPG_STOP);
-	struct ipu_psys *psys = kppg->fh->psys;
-	struct ipu_psys_kcmd kcmd_temp;
-	int ppg_id, ret = 0;
-
-	if (kcmd) {
-		list_move_tail(&kcmd->list, &kppg->kcmds_processing_list);
-	} else {
-		dev_dbg(&psys->adev->dev, "Exceptional stop happened!\n");
-		kcmd_temp.kpg = kppg->kpg;
-		kcmd_temp.fh = kppg->fh;
-		kcmd = &kcmd_temp;
-		/* delete kppg in stop list to avoid this ppg resuming */
-		ipu_psys_scheduler_remove_kppg(kppg, SCHED_STOP_LIST);
-	}
-
-	ppg_id = ipu_fw_psys_pg_get_id(kcmd);
-	dev_dbg(&psys->adev->dev, "stop ppg(%d, addr 0x%p)\n", ppg_id, kppg);
-
-	if (kppg->state & PPG_STATE_SUSPENDED) {
-		if (enable_suspend_resume) {
-			dev_dbg(&psys->adev->dev, "need resume before stop!\n");
-			kcmd_temp.kpg = kppg->kpg;
-			kcmd_temp.fh = kppg->fh;
-			ret = ipu_fw_psys_ppg_resume(&kcmd_temp);
-			if (ret)
-				dev_err(&psys->adev->dev,
-					"ppg(%d) failed to resume\n", ppg_id);
-		} else if (kcmd != &kcmd_temp) {
-			ipu_psys_free_cmd_queue_resource(
-				&psys->resource_pool_running,
-				ipu_fw_psys_ppg_get_base_queue_id(kcmd));
-			ipu_psys_kcmd_complete(kppg, kcmd, 0);
-			dev_dbg(&psys->adev->dev,
-				"s_change:%s %p %d -> %d\n", __func__,
-				kppg, kppg->state, PPG_STATE_STOPPED);
-			pm_runtime_put(&psys->adev->dev);
-			kppg->state = PPG_STATE_STOPPED;
-			return 0;
-		} else {
-			return 0;
-		}
-	}
-	dev_dbg(&psys->adev->dev, "s_change:%s %p %d -> %d\n",
-		__func__, kppg, kppg->state, PPG_STATE_STOPPING);
-	kppg->state = PPG_STATE_STOPPING;
-	ret = ipu_fw_psys_pg_abort(kcmd);
-	if (ret)
-		dev_err(&psys->adev->dev, "ppg(%d) failed to abort\n", ppg_id);
-
-	return ret;
-}
-
-int ipu_psys_ppg_suspend(struct ipu_psys_ppg *kppg)
-{
-	struct ipu_psys *psys = kppg->fh->psys;
-	struct ipu_psys_kcmd tmp_kcmd = {
-		.kpg = kppg->kpg,
-		.fh = kppg->fh,
-	};
-	int ppg_id = ipu_fw_psys_pg_get_id(&tmp_kcmd);
-	int ret = 0;
-
-	dev_dbg(&psys->adev->dev, "suspend ppg(%d, addr 0x%p)\n", ppg_id, kppg);
-
-	dev_dbg(&psys->adev->dev, "s_change:%s %p %d -> %d\n",
-		__func__, kppg, kppg->state, PPG_STATE_SUSPENDING);
-	kppg->state = PPG_STATE_SUSPENDING;
-	if (enable_suspend_resume)
-		ret = ipu_fw_psys_ppg_suspend(&tmp_kcmd);
-	else
-		ret = ipu_fw_psys_pg_abort(&tmp_kcmd);
-	if (ret)
-		dev_err(&psys->adev->dev, "failed to %s ppg(%d)\n",
-			enable_suspend_resume ? "suspend" : "stop", ret);
-
-	return ret;
-}
-
-static bool ipu_psys_ppg_is_bufset_existing(struct ipu_psys_ppg *kppg)
-{
-	return !list_empty(&kppg->kcmds_new_list);
-}
-
-/*
- * ipu_psys_ppg_enqueue_bufsets - enqueue buffer sets to firmware
- * Sometimes, if the ppg is at suspended state, this function will return true
- * to reschedule and let the resume command scheduled before the buffer sets
- * enqueuing.
- */
-bool ipu_psys_ppg_enqueue_bufsets(struct ipu_psys_ppg *kppg)
-{
-	struct ipu_psys_kcmd *kcmd, *kcmd0;
-	struct ipu_psys *psys = kppg->fh->psys;
-	bool need_resume = false;
-
-	mutex_lock(&kppg->mutex);
-
-	if (kppg->state & (PPG_STATE_STARTED | PPG_STATE_RESUMED |
-			   PPG_STATE_RUNNING)) {
-		if (ipu_psys_ppg_is_bufset_existing(kppg)) {
-			list_for_each_entry_safe(kcmd, kcmd0,
-						 &kppg->kcmds_new_list, list) {
-				int ret;
-
-				if (kcmd->state != KCMD_STATE_PPG_ENQUEUE) {
-					need_resume = true;
-					break;
-				}
-
-				ret = ipu_fw_psys_ppg_enqueue_bufs(kcmd);
-				if (ret) {
-					dev_err(&psys->adev->dev,
-						"kppg 0x%p fail to qbufset %d",
-						kppg, ret);
-					break;
-				}
-				list_move_tail(&kcmd->list,
-					       &kppg->kcmds_processing_list);
-				dev_dbg(&psys->adev->dev,
-					"kppg %d %p queue kcmd 0x%p fh 0x%p\n",
-					ipu_fw_psys_pg_get_id(kcmd),
-					kppg, kcmd, kcmd->fh);
-			}
-		}
-	}
-
-	mutex_unlock(&kppg->mutex);
-	return need_resume;
-}
-
-void ipu_psys_enter_power_gating(struct ipu_psys *psys)
-{
-	struct ipu_psys_scheduler *sched;
-	struct ipu_psys_ppg *kppg, *tmp;
-	struct ipu_psys_fh *fh;
-	int ret = 0;
-
-	list_for_each_entry(fh, &psys->fhs, list) {
-		mutex_lock(&fh->mutex);
-		sched = &fh->sched;
-		if (list_empty(&sched->ppgs)) {
-			mutex_unlock(&fh->mutex);
-			continue;
-		}
-
-		list_for_each_entry_safe(kppg, tmp, &sched->ppgs, list) {
-			mutex_lock(&kppg->mutex);
-			/*
-			 * Only for SUSPENDED kppgs, STOPPED kppgs has already
-			 * power down and new kppgs might come now.
-			 */
-			if (kppg->state != PPG_STATE_SUSPENDED) {
-				mutex_unlock(&kppg->mutex);
-				continue;
-			}
-
-			ret = pm_runtime_put_autosuspend(&psys->adev->dev);
-			if (ret < 0) {
-				dev_err(&psys->adev->dev,
-					"failed to power gating off\n");
-				pm_runtime_get_sync(&psys->adev->dev);
-
-			}
-			mutex_unlock(&kppg->mutex);
-		}
-		mutex_unlock(&fh->mutex);
-	}
-}
-
-void ipu_psys_exit_power_gating(struct ipu_psys *psys)
-{
-	struct ipu_psys_scheduler *sched;
-	struct ipu_psys_ppg *kppg, *tmp;
-	struct ipu_psys_fh *fh;
-	int ret = 0;
-
-	list_for_each_entry(fh, &psys->fhs, list) {
-		mutex_lock(&fh->mutex);
-		sched = &fh->sched;
-		if (list_empty(&sched->ppgs)) {
-			mutex_unlock(&fh->mutex);
-			continue;
-		}
-
-		list_for_each_entry_safe(kppg, tmp, &sched->ppgs, list) {
-			mutex_lock(&kppg->mutex);
-			/* Only for SUSPENDED kppgs */
-			if (kppg->state != PPG_STATE_SUSPENDED) {
-				mutex_unlock(&kppg->mutex);
-				continue;
-			}
-
-			ret = pm_runtime_get_sync(&psys->adev->dev);
-			if (ret < 0) {
-				dev_err(&psys->adev->dev,
-					"failed to power gating\n");
-				pm_runtime_put_noidle(&psys->adev->dev);
-			}
-			mutex_unlock(&kppg->mutex);
-		}
-		mutex_unlock(&fh->mutex);
-	}
-}
diff --git a/drivers/media/pci/intel/ipu6/ipu6-ppg.h b/drivers/media/pci/intel/ipu6/ipu6-ppg.h
deleted file mode 100644
index 9ec1baf78631..000000000000
--- a/drivers/media/pci/intel/ipu6/ipu6-ppg.h
+++ /dev/null
@@ -1,38 +0,0 @@
-/* SPDX-License-Identifier: GPL-2.0 */
-/*
- * Copyright (C) 2020 Intel Corporation
- */
-
-#ifndef IPU6_PPG_H
-#define IPU6_PPG_H
-
-#include "ipu-psys.h"
-/* starting from '2' in case of someone passes true or false */
-enum SCHED_LIST {
-	SCHED_START_LIST = 2,
-	SCHED_STOP_LIST
-};
-
-enum ipu_psys_power_gating_state {
-	PSYS_POWER_NORMAL = 0,
-	PSYS_POWER_GATING,
-	PSYS_POWER_GATED
-};
-
-int ipu_psys_ppg_get_bufset(struct ipu_psys_kcmd *kcmd,
-			    struct ipu_psys_ppg *kppg);
-struct ipu_psys_kcmd *ipu_psys_ppg_get_stop_kcmd(struct ipu_psys_ppg *kppg);
-void ipu_psys_scheduler_remove_kppg(struct ipu_psys_ppg *kppg,
-				    enum SCHED_LIST type);
-void ipu_psys_scheduler_add_kppg(struct ipu_psys_ppg *kppg,
-				 enum SCHED_LIST type);
-int ipu_psys_ppg_start(struct ipu_psys_ppg *kppg);
-int ipu_psys_ppg_resume(struct ipu_psys_ppg *kppg);
-int ipu_psys_ppg_stop(struct ipu_psys_ppg *kppg);
-int ipu_psys_ppg_suspend(struct ipu_psys_ppg *kppg);
-void ipu_psys_ppg_complete(struct ipu_psys *psys, struct ipu_psys_ppg *kppg);
-bool ipu_psys_ppg_enqueue_bufsets(struct ipu_psys_ppg *kppg);
-void ipu_psys_enter_power_gating(struct ipu_psys *psys);
-void ipu_psys_exit_power_gating(struct ipu_psys *psys);
-
-#endif /* IPU6_PPG_H */
diff --git a/drivers/media/pci/intel/ipu6/ipu6-psys-gpc.c b/drivers/media/pci/intel/ipu6/ipu6-psys-gpc.c
deleted file mode 100644
index b6b850a68398..000000000000
--- a/drivers/media/pci/intel/ipu6/ipu6-psys-gpc.c
+++ /dev/null
@@ -1,210 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0
-// Copyright (C) 2020 Intel Corporation
-
-#ifdef CONFIG_DEBUG_FS
-#include <linux/debugfs.h>
-#include <linux/pm_runtime.h>
-
-#include "ipu-psys.h"
-#include "ipu-platform-regs.h"
-
-/*
- * GPC (Gerneral Performance Counters)
- */
-#define IPU_PSYS_GPC_NUM 16
-
-#ifndef CONFIG_PM
-#define pm_runtime_get_sync(d)			0
-#define pm_runtime_put(d)			0
-#endif
-
-struct ipu_psys_gpc {
-	bool enable;
-	unsigned int route;
-	unsigned int source;
-	unsigned int sense;
-	unsigned int gpcindex;
-	void *prit;
-};
-
-struct ipu_psys_gpcs {
-	bool gpc_enable;
-	struct ipu_psys_gpc gpc[IPU_PSYS_GPC_NUM];
-	void *prit;
-};
-
-static int ipu6_psys_gpc_global_enable_get(void *data, u64 *val)
-{
-	struct ipu_psys_gpcs *psys_gpcs = data;
-	struct ipu_psys *psys = psys_gpcs->prit;
-
-	mutex_lock(&psys->mutex);
-
-	*val = psys_gpcs->gpc_enable;
-
-	mutex_unlock(&psys->mutex);
-	return 0;
-}
-
-static int ipu6_psys_gpc_global_enable_set(void *data, u64 val)
-{
-	struct ipu_psys_gpcs *psys_gpcs = data;
-	struct ipu_psys *psys = psys_gpcs->prit;
-	void __iomem *base;
-	int idx, res;
-
-	if (val != 0 && val != 1)
-		return -EINVAL;
-
-	if (!psys || !psys->pdata || !psys->pdata->base)
-		return -EINVAL;
-
-	mutex_lock(&psys->mutex);
-
-	base = psys->pdata->base + IPU_GPC_BASE;
-
-	res = pm_runtime_get_sync(&psys->adev->dev);
-	if (res < 0) {
-		pm_runtime_put(&psys->adev->dev);
-		mutex_unlock(&psys->mutex);
-		return res;
-	}
-
-	if (val == 0) {
-		writel(0x0, base + IPU_GPREG_TRACE_TIMER_RST);
-		writel(0x0, base + IPU_CDC_MMU_GPC_OVERALL_ENABLE);
-		writel(0xffff, base + IPU_CDC_MMU_GPC_SOFT_RESET);
-		psys_gpcs->gpc_enable = false;
-		for (idx = 0; idx < IPU_PSYS_GPC_NUM; idx++) {
-			psys_gpcs->gpc[idx].enable = 0;
-			psys_gpcs->gpc[idx].sense = 0;
-			psys_gpcs->gpc[idx].route = 0;
-			psys_gpcs->gpc[idx].source = 0;
-		}
-		pm_runtime_mark_last_busy(&psys->adev->dev);
-		pm_runtime_put_autosuspend(&psys->adev->dev);
-	} else {
-		/* Set gpc reg and start all gpc here.
-		 * RST free running local timer.
-		 */
-		writel(0x0, base + IPU_GPREG_TRACE_TIMER_RST);
-		writel(0x1, base + IPU_GPREG_TRACE_TIMER_RST);
-
-		for (idx = 0; idx < IPU_PSYS_GPC_NUM; idx++) {
-			/* Enable */
-			writel(psys_gpcs->gpc[idx].enable,
-			       base + IPU_CDC_MMU_GPC_ENABLE0 + 4 * idx);
-			/* Setting (route/source/sense) */
-			writel((psys_gpcs->gpc[idx].sense
-					<< IPU_GPC_SENSE_OFFSET)
-				+ (psys_gpcs->gpc[idx].route
-					<< IPU_GPC_ROUTE_OFFSET)
-				+ (psys_gpcs->gpc[idx].source
-					<< IPU_GPC_SOURCE_OFFSET),
-				base + IPU_CDC_MMU_GPC_CNT_SEL0 + 4 * idx);
-		}
-
-		/* Soft reset and Overall Enable. */
-		writel(0x0, base + IPU_CDC_MMU_GPC_OVERALL_ENABLE);
-		writel(0xffff, base + IPU_CDC_MMU_GPC_SOFT_RESET);
-		writel(0x1, base + IPU_CDC_MMU_GPC_OVERALL_ENABLE);
-
-		psys_gpcs->gpc_enable = true;
-	}
-
-	mutex_unlock(&psys->mutex);
-	return 0;
-}
-
-DEFINE_SIMPLE_ATTRIBUTE(psys_gpc_globe_enable_fops,
-			ipu6_psys_gpc_global_enable_get,
-			ipu6_psys_gpc_global_enable_set, "%llu\n");
-
-static int ipu6_psys_gpc_count_get(void *data, u64 *val)
-{
-	struct ipu_psys_gpc *psys_gpc = data;
-	struct ipu_psys *psys = psys_gpc->prit;
-	void __iomem *base;
-	int res;
-
-	if (!psys || !psys->pdata || !psys->pdata->base)
-		return -EINVAL;
-
-	mutex_lock(&psys->mutex);
-
-	base = psys->pdata->base + IPU_GPC_BASE;
-
-	res = pm_runtime_get_sync(&psys->adev->dev);
-	if (res < 0) {
-		pm_runtime_put(&psys->adev->dev);
-		mutex_unlock(&psys->mutex);
-		return res;
-	}
-
-	*val = readl(base + IPU_CDC_MMU_GPC_VALUE0 + 4 * psys_gpc->gpcindex);
-
-	mutex_unlock(&psys->mutex);
-	return 0;
-}
-
-DEFINE_SIMPLE_ATTRIBUTE(psys_gpc_count_fops,
-			ipu6_psys_gpc_count_get,
-			NULL, "%llu\n");
-
-int ipu_psys_gpc_init_debugfs(struct ipu_psys *psys)
-{
-	struct dentry *gpcdir;
-	struct dentry *dir;
-	struct dentry *file;
-	int idx;
-	char gpcname[10];
-	struct ipu_psys_gpcs *psys_gpcs;
-
-	psys_gpcs = devm_kzalloc(&psys->dev, sizeof(*psys_gpcs), GFP_KERNEL);
-	if (!psys_gpcs)
-		return -ENOMEM;
-
-	gpcdir = debugfs_create_dir("gpc", psys->debugfsdir);
-	if (IS_ERR(gpcdir))
-		return -ENOMEM;
-
-	psys_gpcs->prit = psys;
-	file = debugfs_create_file("enable", 0600, gpcdir, psys_gpcs,
-				   &psys_gpc_globe_enable_fops);
-	if (IS_ERR(file))
-		goto err;
-
-	for (idx = 0; idx < IPU_PSYS_GPC_NUM; idx++) {
-		sprintf(gpcname, "gpc%d", idx);
-		dir = debugfs_create_dir(gpcname, gpcdir);
-		if (IS_ERR(dir))
-			goto err;
-
-		debugfs_create_bool("enable", 0600, dir,
-				    &psys_gpcs->gpc[idx].enable);
-
-		debugfs_create_u32("source", 0600, dir,
-				   &psys_gpcs->gpc[idx].source);
-
-		debugfs_create_u32("route", 0600, dir,
-				   &psys_gpcs->gpc[idx].route);
-
-		debugfs_create_u32("sense", 0600, dir,
-				   &psys_gpcs->gpc[idx].sense);
-
-		psys_gpcs->gpc[idx].gpcindex = idx;
-		psys_gpcs->gpc[idx].prit = psys;
-		file = debugfs_create_file("count", 0400, dir,
-					   &psys_gpcs->gpc[idx],
-					   &psys_gpc_count_fops);
-		if (IS_ERR(file))
-			goto err;
-	}
-
-	return 0;
-
-err:
-	debugfs_remove_recursive(gpcdir);
-	return -ENOMEM;
-}
-#endif
diff --git a/drivers/media/pci/intel/ipu6/ipu6-psys.c b/drivers/media/pci/intel/ipu6/ipu6-psys.c
deleted file mode 100644
index 294a6f1638e5..000000000000
--- a/drivers/media/pci/intel/ipu6/ipu6-psys.c
+++ /dev/null
@@ -1,1032 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0
-// Copyright (C) 2020 Intel Corporation
-
-#include <linux/uaccess.h>
-#include <linux/device.h>
-#include <linux/delay.h>
-#include <linux/highmem.h>
-#include <linux/mm.h>
-#include <linux/pm_runtime.h>
-#include <linux/kthread.h>
-#include <linux/init_task.h>
-#include <linux/version.h>
-#include <uapi/linux/sched/types.h>
-#include <linux/module.h>
-#include <linux/fs.h>
-
-#include "ipu.h"
-#include "ipu-psys.h"
-#include "ipu6-ppg.h"
-#include "ipu-platform-regs.h"
-#include "ipu-trace.h"
-
-static bool early_pg_transfer;
-module_param(early_pg_transfer, bool, 0664);
-MODULE_PARM_DESC(early_pg_transfer,
-		 "Copy PGs back to user after resource allocation");
-
-bool enable_power_gating = true;
-module_param(enable_power_gating, bool, 0664);
-MODULE_PARM_DESC(enable_power_gating, "enable power gating");
-
-struct ipu_trace_block psys_trace_blocks[] = {
-	{
-		.offset = IPU_TRACE_REG_PS_TRACE_UNIT_BASE,
-		.type = IPU_TRACE_BLOCK_TUN,
-	},
-	{
-		.offset = IPU_TRACE_REG_PS_SPC_EVQ_BASE,
-		.type = IPU_TRACE_BLOCK_TM,
-	},
-	{
-		.offset = IPU_TRACE_REG_PS_SPP0_EVQ_BASE,
-		.type = IPU_TRACE_BLOCK_TM,
-	},
-	{
-		.offset = IPU_TRACE_REG_PS_SPC_GPC_BASE,
-		.type = IPU_TRACE_BLOCK_GPC,
-	},
-	{
-		.offset = IPU_TRACE_REG_PS_SPP0_GPC_BASE,
-		.type = IPU_TRACE_BLOCK_GPC,
-	},
-	{
-		.offset = IPU_TRACE_REG_PS_MMU_GPC_BASE,
-		.type = IPU_TRACE_BLOCK_GPC,
-	},
-	{
-		.offset = IPU_TRACE_REG_PS_GPREG_TRACE_TIMER_RST_N,
-		.type = IPU_TRACE_TIMER_RST,
-	},
-	{
-		.type = IPU_TRACE_BLOCK_END,
-	}
-};
-
-static void ipu6_set_sp_info_bits(void *base)
-{
-	int i;
-
-	writel(IPU_INFO_REQUEST_DESTINATION_IOSF,
-	       base + IPU_REG_PSYS_INFO_SEG_0_CONFIG_ICACHE_MASTER);
-
-	for (i = 0; i < 4; i++)
-		writel(IPU_INFO_REQUEST_DESTINATION_IOSF,
-		       base + IPU_REG_PSYS_INFO_SEG_CMEM_MASTER(i));
-	for (i = 0; i < 4; i++)
-		writel(IPU_INFO_REQUEST_DESTINATION_IOSF,
-		       base + IPU_REG_PSYS_INFO_SEG_XMEM_MASTER(i));
-}
-
-#define PSYS_SUBDOMAINS_STATUS_WAIT_COUNT        1000
-void ipu_psys_subdomains_power(struct ipu_psys *psys, bool on)
-{
-	unsigned int i;
-	u32 val;
-
-	/* power domain req */
-	dev_dbg(&psys->adev->dev, "power %s psys sub-domains",
-		on ? "UP" : "DOWN");
-	if (on)
-		writel(IPU_PSYS_SUBDOMAINS_POWER_MASK,
-		       psys->adev->isp->base + IPU_PSYS_SUBDOMAINS_POWER_REQ);
-	else
-		writel(0x0,
-		       psys->adev->isp->base + IPU_PSYS_SUBDOMAINS_POWER_REQ);
-
-	i = 0;
-	do {
-		usleep_range(10, 20);
-		val = readl(psys->adev->isp->base +
-			    IPU_PSYS_SUBDOMAINS_POWER_STATUS);
-		if (!(val & BIT(31))) {
-			dev_dbg(&psys->adev->dev,
-				"PS sub-domains req done with status 0x%x",
-				val);
-			break;
-		}
-		i++;
-	} while (i < PSYS_SUBDOMAINS_STATUS_WAIT_COUNT);
-
-	if (i == PSYS_SUBDOMAINS_STATUS_WAIT_COUNT)
-		dev_warn(&psys->adev->dev, "Psys sub-domains %s req timeout!",
-			 on ? "UP" : "DOWN");
-}
-
-void ipu_psys_setup_hw(struct ipu_psys *psys)
-{
-	void __iomem *base = psys->pdata->base;
-	void __iomem *spc_regs_base =
-	    base + psys->pdata->ipdata->hw_variant.spc_offset;
-	void *psys_iommu0_ctrl;
-	u32 irqs;
-	const u8 r3 = IPU_DEVICE_AB_GROUP1_TARGET_ID_R3_SPC_STATUS_REG;
-	const u8 r4 = IPU_DEVICE_AB_GROUP1_TARGET_ID_R4_SPC_MASTER_BASE_ADDR;
-	const u8 r5 = IPU_DEVICE_AB_GROUP1_TARGET_ID_R5_SPC_PC_STALL;
-
-	if (!psys->adev->isp->secure_mode) {
-		/* configure access blocker for non-secure mode */
-		writel(NCI_AB_ACCESS_MODE_RW,
-		       base + IPU_REG_DMA_TOP_AB_GROUP1_BASE_ADDR +
-		       IPU_REG_DMA_TOP_AB_RING_ACCESS_OFFSET(r3));
-		writel(NCI_AB_ACCESS_MODE_RW,
-		       base + IPU_REG_DMA_TOP_AB_GROUP1_BASE_ADDR +
-		       IPU_REG_DMA_TOP_AB_RING_ACCESS_OFFSET(r4));
-		writel(NCI_AB_ACCESS_MODE_RW,
-		       base + IPU_REG_DMA_TOP_AB_GROUP1_BASE_ADDR +
-		       IPU_REG_DMA_TOP_AB_RING_ACCESS_OFFSET(r5));
-	}
-	psys_iommu0_ctrl = base +
-		psys->pdata->ipdata->hw_variant.mmu_hw[0].offset +
-		IPU_MMU_INFO_OFFSET;
-	writel(IPU_INFO_REQUEST_DESTINATION_IOSF, psys_iommu0_ctrl);
-
-	ipu6_set_sp_info_bits(spc_regs_base + IPU_PSYS_REG_SPC_STATUS_CTRL);
-	ipu6_set_sp_info_bits(spc_regs_base + IPU_PSYS_REG_SPP0_STATUS_CTRL);
-
-	/* Enable FW interrupt #0 */
-	writel(0, base + IPU_REG_PSYS_GPDEV_FWIRQ(0));
-	irqs = IPU_PSYS_GPDEV_IRQ_FWIRQ(IPU_PSYS_GPDEV_FWIRQ0);
-	writel(irqs, base + IPU_REG_PSYS_GPDEV_IRQ_EDGE);
-	writel(irqs, base + IPU_REG_PSYS_GPDEV_IRQ_LEVEL_NOT_PULSE);
-	writel(0xffffffff, base + IPU_REG_PSYS_GPDEV_IRQ_CLEAR);
-	writel(irqs, base + IPU_REG_PSYS_GPDEV_IRQ_MASK);
-	writel(irqs, base + IPU_REG_PSYS_GPDEV_IRQ_ENABLE);
-}
-
-static struct ipu_psys_ppg *ipu_psys_identify_kppg(struct ipu_psys_kcmd *kcmd)
-{
-	struct ipu_psys_scheduler *sched = &kcmd->fh->sched;
-	struct ipu_psys_ppg *kppg, *tmp;
-
-	mutex_lock(&kcmd->fh->mutex);
-	if (list_empty(&sched->ppgs))
-		goto not_found;
-
-	list_for_each_entry_safe(kppg, tmp, &sched->ppgs, list) {
-		if (ipu_fw_psys_pg_get_token(kcmd)
-		    != kppg->token)
-			continue;
-		mutex_unlock(&kcmd->fh->mutex);
-		return kppg;
-	}
-
-not_found:
-	mutex_unlock(&kcmd->fh->mutex);
-	return NULL;
-}
-
-/*
- * Called to free up all resources associated with a kcmd.
- * After this the kcmd doesn't anymore exist in the driver.
- */
-static void ipu_psys_kcmd_free(struct ipu_psys_kcmd *kcmd)
-{
-	struct ipu_psys_ppg *kppg;
-	struct ipu_psys_scheduler *sched;
-
-	if (!kcmd)
-		return;
-
-	kppg = ipu_psys_identify_kppg(kcmd);
-	sched = &kcmd->fh->sched;
-
-	if (kcmd->kbuf_set) {
-		mutex_lock(&sched->bs_mutex);
-		kcmd->kbuf_set->buf_set_size = 0;
-		mutex_unlock(&sched->bs_mutex);
-		kcmd->kbuf_set = NULL;
-	}
-
-	if (kppg) {
-		mutex_lock(&kppg->mutex);
-		if (!list_empty(&kcmd->list))
-			list_del(&kcmd->list);
-		mutex_unlock(&kppg->mutex);
-	}
-
-	kfree(kcmd->pg_manifest);
-	kfree(kcmd->kbufs);
-	kfree(kcmd->buffers);
-	kfree(kcmd);
-}
-
-static struct ipu_psys_kcmd *ipu_psys_copy_cmd(struct ipu_psys_command *cmd,
-					       struct ipu_psys_fh *fh)
-{
-	struct ipu_psys *psys = fh->psys;
-	struct ipu_psys_kcmd *kcmd;
-	struct ipu_psys_kbuffer *kpgbuf;
-	unsigned int i;
-	int ret, prevfd, fd;
-
-	fd = prevfd = -1;
-
-	if (cmd->bufcount > IPU_MAX_PSYS_CMD_BUFFERS)
-		return NULL;
-
-	if (!cmd->pg_manifest_size)
-		return NULL;
-
-	kcmd = kzalloc(sizeof(*kcmd), GFP_KERNEL);
-	if (!kcmd)
-		return NULL;
-
-	kcmd->state = KCMD_STATE_PPG_NEW;
-	kcmd->fh = fh;
-	INIT_LIST_HEAD(&kcmd->list);
-
-	mutex_lock(&fh->mutex);
-	fd = cmd->pg;
-	kpgbuf = ipu_psys_lookup_kbuffer(fh, fd);
-	if (!kpgbuf || !kpgbuf->sgt) {
-		dev_err(&psys->adev->dev, "%s kbuf %p with fd %d not found.\n",
-			__func__, kpgbuf, fd);
-		mutex_unlock(&fh->mutex);
-		goto error;
-	}
-
-	/* check and remap if possibe */
-	ret = ipu_psys_mapbuf_locked(fd, fh, kpgbuf);
-	if (ret) {
-		dev_err(&psys->adev->dev, "%s remap failed\n", __func__);
-		mutex_unlock(&fh->mutex);
-		goto error;
-	}
-
-	kpgbuf = ipu_psys_lookup_kbuffer(fh, fd);
-	if (!kpgbuf || !kpgbuf->sgt) {
-		WARN(1, "kbuf not found or unmapped.\n");
-		mutex_unlock(&fh->mutex);
-		goto error;
-	}
-	mutex_unlock(&fh->mutex);
-
-	kcmd->pg_user = kpgbuf->kaddr;
-	kcmd->kpg = __get_pg_buf(psys, kpgbuf->len);
-	if (!kcmd->kpg)
-		goto error;
-
-	memcpy(kcmd->kpg->pg, kcmd->pg_user, kcmd->kpg->pg_size);
-
-	kcmd->pg_manifest = kzalloc(cmd->pg_manifest_size, GFP_KERNEL);
-	if (!kcmd->pg_manifest)
-		goto error;
-
-	ret = copy_from_user(kcmd->pg_manifest, cmd->pg_manifest,
-			     cmd->pg_manifest_size);
-	if (ret)
-		goto error;
-
-	kcmd->pg_manifest_size = cmd->pg_manifest_size;
-
-	kcmd->user_token = cmd->user_token;
-	kcmd->issue_id = cmd->issue_id;
-	kcmd->priority = cmd->priority;
-	if (kcmd->priority >= IPU_PSYS_CMD_PRIORITY_NUM)
-		goto error;
-
-	/*
-	 * Kenel enable bitmap be used only.
-	 */
-	memcpy(kcmd->kernel_enable_bitmap, cmd->kernel_enable_bitmap,
-	       sizeof(cmd->kernel_enable_bitmap));
-
-	kcmd->nbuffers = ipu_fw_psys_pg_get_terminal_count(kcmd);
-	kcmd->buffers = kcalloc(kcmd->nbuffers, sizeof(*kcmd->buffers),
-				GFP_KERNEL);
-	if (!kcmd->buffers)
-		goto error;
-
-	kcmd->kbufs = kcalloc(kcmd->nbuffers, sizeof(kcmd->kbufs[0]),
-			      GFP_KERNEL);
-	if (!kcmd->kbufs)
-		goto error;
-
-	/* should be stop cmd for ppg */
-	if (!cmd->buffers) {
-		kcmd->state = KCMD_STATE_PPG_STOP;
-		return kcmd;
-	}
-
-	if (!cmd->bufcount || kcmd->nbuffers > cmd->bufcount)
-		goto error;
-
-	ret = copy_from_user(kcmd->buffers, cmd->buffers,
-			     kcmd->nbuffers * sizeof(*kcmd->buffers));
-	if (ret)
-		goto error;
-
-	for (i = 0; i < kcmd->nbuffers; i++) {
-		struct ipu_fw_psys_terminal *terminal;
-
-		terminal = ipu_fw_psys_pg_get_terminal(kcmd, i);
-		if (!terminal)
-			continue;
-
-		if (!(kcmd->buffers[i].flags & IPU_BUFFER_FLAG_DMA_HANDLE)) {
-			kcmd->state = KCMD_STATE_PPG_START;
-			continue;
-		}
-		if (kcmd->state == KCMD_STATE_PPG_START) {
-			dev_err(&psys->adev->dev,
-				"err: all buffer.flags&DMA_HANDLE must 0\n");
-			goto error;
-		}
-
-		mutex_lock(&fh->mutex);
-		fd = kcmd->buffers[i].base.fd;
-		kpgbuf = ipu_psys_lookup_kbuffer(fh, fd);
-		if (!kpgbuf || !kpgbuf->sgt) {
-			dev_err(&psys->adev->dev,
-				"%s kcmd->buffers[%d] %p fd %d not found.\n",
-				__func__, i, kpgbuf, fd);
-			mutex_unlock(&fh->mutex);
-			goto error;
-		}
-
-		ret = ipu_psys_mapbuf_locked(fd, fh, kpgbuf);
-		if (ret) {
-			dev_err(&psys->adev->dev, "%s remap failed\n",
-				__func__);
-			mutex_unlock(&fh->mutex);
-			goto error;
-		}
-
-		kpgbuf = ipu_psys_lookup_kbuffer(fh, fd);
-		if (!kpgbuf || !kpgbuf->sgt) {
-			WARN(1, "kbuf not found or unmapped.\n");
-			mutex_unlock(&fh->mutex);
-			goto error;
-		}
-		mutex_unlock(&fh->mutex);
-		kcmd->kbufs[i] = kpgbuf;
-		if (!kcmd->kbufs[i] || !kcmd->kbufs[i]->sgt ||
-		    kcmd->kbufs[i]->len < kcmd->buffers[i].bytes_used)
-			goto error;
-		if ((kcmd->kbufs[i]->flags &
-		     IPU_BUFFER_FLAG_NO_FLUSH) ||
-		    (kcmd->buffers[i].flags &
-		     IPU_BUFFER_FLAG_NO_FLUSH) ||
-		    prevfd == kcmd->buffers[i].base.fd)
-			continue;
-
-		prevfd = kcmd->buffers[i].base.fd;
-		dma_sync_sg_for_device(&psys->adev->dev,
-				       kcmd->kbufs[i]->sgt->sgl,
-				       kcmd->kbufs[i]->sgt->orig_nents,
-				       DMA_BIDIRECTIONAL);
-	}
-
-	if (kcmd->state != KCMD_STATE_PPG_START)
-		kcmd->state = KCMD_STATE_PPG_ENQUEUE;
-
-	return kcmd;
-error:
-	ipu_psys_kcmd_free(kcmd);
-
-	dev_dbg(&psys->adev->dev, "failed to copy cmd\n");
-
-	return NULL;
-}
-
-static struct ipu_psys_buffer_set *
-ipu_psys_lookup_kbuffer_set(struct ipu_psys *psys, u32 addr)
-{
-	struct ipu_psys_fh *fh;
-	struct ipu_psys_buffer_set *kbuf_set;
-	struct ipu_psys_scheduler *sched;
-
-	list_for_each_entry(fh, &psys->fhs, list) {
-		sched = &fh->sched;
-		mutex_lock(&sched->bs_mutex);
-		list_for_each_entry(kbuf_set, &sched->buf_sets, list) {
-			if (kbuf_set->buf_set &&
-			    kbuf_set->buf_set->ipu_virtual_address == addr) {
-				mutex_unlock(&sched->bs_mutex);
-				return kbuf_set;
-			}
-		}
-		mutex_unlock(&sched->bs_mutex);
-	}
-
-	return NULL;
-}
-
-static struct ipu_psys_ppg *ipu_psys_lookup_ppg(struct ipu_psys *psys,
-						dma_addr_t pg_addr)
-{
-	struct ipu_psys_scheduler *sched;
-	struct ipu_psys_ppg *kppg, *tmp;
-	struct ipu_psys_fh *fh;
-
-	list_for_each_entry(fh, &psys->fhs, list) {
-		sched = &fh->sched;
-		mutex_lock(&fh->mutex);
-		if (list_empty(&sched->ppgs)) {
-			mutex_unlock(&fh->mutex);
-			continue;
-		}
-
-		list_for_each_entry_safe(kppg, tmp, &sched->ppgs, list) {
-			if (pg_addr != kppg->kpg->pg_dma_addr)
-				continue;
-			mutex_unlock(&fh->mutex);
-			return kppg;
-		}
-		mutex_unlock(&fh->mutex);
-	}
-
-	return NULL;
-}
-
-/*
- * Move kcmd into completed state (due to running finished or failure).
- * Fill up the event struct and notify waiters.
- */
-void ipu_psys_kcmd_complete(struct ipu_psys_ppg *kppg,
-			    struct ipu_psys_kcmd *kcmd, int error)
-{
-	struct ipu_psys_fh *fh = kcmd->fh;
-	struct ipu_psys *psys = fh->psys;
-
-	kcmd->ev.type = IPU_PSYS_EVENT_TYPE_CMD_COMPLETE;
-	kcmd->ev.user_token = kcmd->user_token;
-	kcmd->ev.issue_id = kcmd->issue_id;
-	kcmd->ev.error = error;
-	list_move_tail(&kcmd->list, &kppg->kcmds_finished_list);
-
-	if (kcmd->constraint.min_freq)
-		ipu_buttress_remove_psys_constraint(psys->adev->isp,
-						    &kcmd->constraint);
-
-	if (!early_pg_transfer && kcmd->pg_user && kcmd->kpg->pg) {
-		struct ipu_psys_kbuffer *kbuf;
-
-		kbuf = ipu_psys_lookup_kbuffer_by_kaddr(kcmd->fh,
-							kcmd->pg_user);
-		if (kbuf && kbuf->valid)
-			memcpy(kcmd->pg_user,
-			       kcmd->kpg->pg, kcmd->kpg->pg_size);
-		else
-			dev_dbg(&psys->adev->dev, "Skipping unmapped buffer\n");
-	}
-
-	kcmd->state = KCMD_STATE_PPG_COMPLETE;
-	wake_up_interruptible(&fh->wait);
-}
-
-/*
- * Submit kcmd into psys queue. If running fails, complete the kcmd
- * with an error.
- *
- * Found a runnable PG. Move queue to the list tail for round-robin
- * scheduling and run the PG. Start the watchdog timer if the PG was
- * started successfully. Enable PSYS power if requested.
- */
-int ipu_psys_kcmd_start(struct ipu_psys *psys, struct ipu_psys_kcmd *kcmd)
-{
-	int ret;
-
-	if (psys->adev->isp->flr_done)
-		return -EIO;
-
-	if (early_pg_transfer && kcmd->pg_user && kcmd->kpg->pg)
-		memcpy(kcmd->pg_user, kcmd->kpg->pg, kcmd->kpg->pg_size);
-
-	ret = ipu_fw_psys_pg_start(kcmd);
-	if (ret) {
-		dev_err(&psys->adev->dev, "failed to start kcmd!\n");
-		return ret;
-	}
-
-	ipu_fw_psys_pg_dump(psys, kcmd, "run");
-
-	ret = ipu_fw_psys_pg_disown(kcmd);
-	if (ret) {
-		dev_err(&psys->adev->dev, "failed to start kcmd!\n");
-		return ret;
-	}
-
-	return 0;
-}
-
-static int ipu_psys_kcmd_send_to_ppg_start(struct ipu_psys_kcmd *kcmd)
-{
-	struct ipu_psys_fh *fh = kcmd->fh;
-	struct ipu_psys_scheduler *sched = &fh->sched;
-	struct ipu_psys *psys = fh->psys;
-	struct ipu_psys_ppg *kppg;
-	struct ipu_psys_resource_pool *rpr;
-	int queue_id;
-	int ret;
-
-	rpr = &psys->resource_pool_running;
-
-	kppg = kzalloc(sizeof(*kppg), GFP_KERNEL);
-	if (!kppg)
-		return -ENOMEM;
-
-	kppg->fh = fh;
-	kppg->kpg = kcmd->kpg;
-	kppg->state = PPG_STATE_START;
-	kppg->pri_base = kcmd->priority;
-	kppg->pri_dynamic = 0;
-	INIT_LIST_HEAD(&kppg->list);
-
-	mutex_init(&kppg->mutex);
-	INIT_LIST_HEAD(&kppg->kcmds_new_list);
-	INIT_LIST_HEAD(&kppg->kcmds_processing_list);
-	INIT_LIST_HEAD(&kppg->kcmds_finished_list);
-	INIT_LIST_HEAD(&kppg->sched_list);
-
-	kppg->manifest = kzalloc(kcmd->pg_manifest_size, GFP_KERNEL);
-	if (!kppg->manifest) {
-		kfree(kppg);
-		return -ENOMEM;
-	}
-	memcpy(kppg->manifest, kcmd->pg_manifest,
-	       kcmd->pg_manifest_size);
-
-	queue_id = ipu_psys_allocate_cmd_queue_resource(rpr);
-	if (queue_id == -ENOSPC) {
-		dev_err(&psys->adev->dev, "no available queue\n");
-		kfree(kppg->manifest);
-		kfree(kppg);
-		mutex_unlock(&psys->mutex);
-		return -ENOMEM;
-	}
-
-	/*
-	 * set token as start cmd will immediately be followed by a
-	 * enqueue cmd so that kppg could be retrieved.
-	 */
-	kppg->token = (u64)kcmd->kpg;
-	ipu_fw_psys_pg_set_token(kcmd, kppg->token);
-	ipu_fw_psys_ppg_set_base_queue_id(kcmd, queue_id);
-	ret = ipu_fw_psys_pg_set_ipu_vaddress(kcmd,
-					      kcmd->kpg->pg_dma_addr);
-	if (ret) {
-		ipu_psys_free_cmd_queue_resource(rpr, queue_id);
-		kfree(kppg->manifest);
-		kfree(kppg);
-		return -EIO;
-	}
-	memcpy(kcmd->pg_user, kcmd->kpg->pg, kcmd->kpg->pg_size);
-
-	mutex_lock(&fh->mutex);
-	list_add_tail(&kppg->list, &sched->ppgs);
-	mutex_unlock(&fh->mutex);
-
-	mutex_lock(&kppg->mutex);
-	list_add(&kcmd->list, &kppg->kcmds_new_list);
-	mutex_unlock(&kppg->mutex);
-
-	dev_dbg(&psys->adev->dev,
-		"START ppg(%d, 0x%p) kcmd 0x%p, queue %d\n",
-		ipu_fw_psys_pg_get_id(kcmd), kppg, kcmd, queue_id);
-
-	/* Kick l-scheduler thread */
-	atomic_set(&psys->wakeup_count, 1);
-	wake_up_interruptible(&psys->sched_cmd_wq);
-
-	return 0;
-}
-
-static int ipu_psys_kcmd_send_to_ppg(struct ipu_psys_kcmd *kcmd)
-{
-	struct ipu_psys_fh *fh = kcmd->fh;
-	struct ipu_psys *psys = fh->psys;
-	struct ipu_psys_ppg *kppg;
-	struct ipu_psys_resource_pool *rpr;
-	unsigned long flags;
-	u8 id;
-	bool resche = true;
-
-	rpr = &psys->resource_pool_running;
-	if (kcmd->state == KCMD_STATE_PPG_START)
-		return ipu_psys_kcmd_send_to_ppg_start(kcmd);
-
-	kppg = ipu_psys_identify_kppg(kcmd);
-	spin_lock_irqsave(&psys->pgs_lock, flags);
-	kcmd->kpg->pg_size = 0;
-	spin_unlock_irqrestore(&psys->pgs_lock, flags);
-	if (!kppg) {
-		dev_err(&psys->adev->dev, "token not match\n");
-		return -EINVAL;
-	}
-
-	kcmd->kpg = kppg->kpg;
-
-	dev_dbg(&psys->adev->dev, "%s ppg(%d, 0x%p) kcmd %p\n",
-		(kcmd->state == KCMD_STATE_PPG_STOP) ?
-		"STOP" : "ENQUEUE",
-		ipu_fw_psys_pg_get_id(kcmd), kppg, kcmd);
-
-	if (kcmd->state == KCMD_STATE_PPG_STOP) {
-		mutex_lock(&kppg->mutex);
-		if (kppg->state == PPG_STATE_STOPPED) {
-			dev_dbg(&psys->adev->dev,
-				"kppg 0x%p  stopped!\n", kppg);
-			id = ipu_fw_psys_ppg_get_base_queue_id(kcmd);
-			ipu_psys_free_cmd_queue_resource(rpr, id);
-			ipu_psys_kcmd_complete(kppg, kcmd, 0);
-			pm_runtime_put(&psys->adev->dev);
-			resche = false;
-		} else {
-			list_add(&kcmd->list, &kppg->kcmds_new_list);
-		}
-		mutex_unlock(&kppg->mutex);
-	} else {
-		int ret;
-
-		ret = ipu_psys_ppg_get_bufset(kcmd, kppg);
-		if (ret)
-			return ret;
-
-		mutex_lock(&kppg->mutex);
-		list_add_tail(&kcmd->list, &kppg->kcmds_new_list);
-		mutex_unlock(&kppg->mutex);
-	}
-
-	if (resche) {
-		/* Kick l-scheduler thread */
-		atomic_set(&psys->wakeup_count, 1);
-		wake_up_interruptible(&psys->sched_cmd_wq);
-	}
-	return 0;
-}
-
-int ipu_psys_kcmd_new(struct ipu_psys_command *cmd, struct ipu_psys_fh *fh)
-{
-	struct ipu_psys *psys = fh->psys;
-	struct ipu_psys_kcmd *kcmd;
-	size_t pg_size;
-	int ret;
-
-	if (psys->adev->isp->flr_done)
-		return -EIO;
-
-	kcmd = ipu_psys_copy_cmd(cmd, fh);
-	if (!kcmd)
-		return -EINVAL;
-
-	pg_size = ipu_fw_psys_pg_get_size(kcmd);
-	if (pg_size > kcmd->kpg->pg_size) {
-		dev_dbg(&psys->adev->dev, "pg size mismatch %lu %lu\n",
-			pg_size, kcmd->kpg->pg_size);
-		ret = -EINVAL;
-		goto error;
-	}
-
-	if (ipu_fw_psys_pg_get_protocol(kcmd) !=
-			IPU_FW_PSYS_PROCESS_GROUP_PROTOCOL_PPG) {
-		dev_err(&psys->adev->dev, "No support legacy pg now\n");
-		ret = -EINVAL;
-		goto error;
-	}
-
-	if (cmd->min_psys_freq) {
-		kcmd->constraint.min_freq = cmd->min_psys_freq;
-		ipu_buttress_add_psys_constraint(psys->adev->isp,
-						 &kcmd->constraint);
-	}
-
-	ret = ipu_psys_kcmd_send_to_ppg(kcmd);
-	if (ret)
-		goto error;
-
-	dev_dbg(&psys->adev->dev,
-		"IOC_QCMD: user_token:%llx issue_id:0x%llx pri:%d\n",
-		cmd->user_token, cmd->issue_id, cmd->priority);
-
-	return 0;
-
-error:
-	ipu_psys_kcmd_free(kcmd);
-
-	return ret;
-}
-
-static bool ipu_psys_kcmd_is_valid(struct ipu_psys *psys,
-				   struct ipu_psys_kcmd *kcmd)
-{
-	struct ipu_psys_fh *fh;
-	struct ipu_psys_kcmd *kcmd0;
-	struct ipu_psys_ppg *kppg, *tmp;
-	struct ipu_psys_scheduler *sched;
-
-	list_for_each_entry(fh, &psys->fhs, list) {
-		sched = &fh->sched;
-		mutex_lock(&fh->mutex);
-		if (list_empty(&sched->ppgs)) {
-			mutex_unlock(&fh->mutex);
-			continue;
-		}
-		list_for_each_entry_safe(kppg, tmp, &sched->ppgs, list) {
-			mutex_lock(&kppg->mutex);
-			list_for_each_entry(kcmd0,
-					    &kppg->kcmds_processing_list,
-					    list) {
-				if (kcmd0 == kcmd) {
-					mutex_unlock(&kppg->mutex);
-					mutex_unlock(&fh->mutex);
-					return true;
-				}
-			}
-			mutex_unlock(&kppg->mutex);
-		}
-		mutex_unlock(&fh->mutex);
-	}
-
-	return false;
-}
-
-void ipu_psys_handle_events(struct ipu_psys *psys)
-{
-	struct ipu_psys_kcmd *kcmd;
-	struct ipu_fw_psys_event event;
-	struct ipu_psys_ppg *kppg;
-	bool error;
-	u32 hdl;
-	u16 cmd, status;
-	int res;
-
-	do {
-		memset(&event, 0, sizeof(event));
-		if (!ipu_fw_psys_rcv_event(psys, &event))
-			break;
-
-		if (!event.context_handle)
-			break;
-
-		dev_dbg(&psys->adev->dev, "ppg event: 0x%x, %d, status %d\n",
-			event.context_handle, event.command, event.status);
-
-		error = false;
-		/*
-		 * event.command == CMD_RUN shows this is fw processing frame
-		 * done as pPG mode, and event.context_handle should be pointer
-		 * of buffer set; so we make use of this pointer to lookup
-		 * kbuffer_set and kcmd
-		 */
-		hdl = event.context_handle;
-		cmd = event.command;
-		status = event.status;
-
-		kppg = NULL;
-		kcmd = NULL;
-		if (cmd == IPU_FW_PSYS_PROCESS_GROUP_CMD_RUN) {
-			struct ipu_psys_buffer_set *kbuf_set;
-			/*
-			 * Need change ppg state when the 1st running is done
-			 * (after PPG started/resumed)
-			 */
-			kbuf_set = ipu_psys_lookup_kbuffer_set(psys, hdl);
-			if (kbuf_set)
-				kcmd = kbuf_set->kcmd;
-			if (!kbuf_set || !kcmd)
-				error = true;
-			else
-				kppg = ipu_psys_identify_kppg(kcmd);
-		} else if (cmd == IPU_FW_PSYS_PROCESS_GROUP_CMD_STOP ||
-			   cmd == IPU_FW_PSYS_PROCESS_GROUP_CMD_SUSPEND ||
-			   cmd == IPU_FW_PSYS_PROCESS_GROUP_CMD_RESUME) {
-			/*
-			 * STOP/SUSPEND/RESUME cmd event would run this branch;
-			 * only stop cmd queued by user has stop_kcmd and need
-			 * to notify user to dequeue.
-			 */
-			kppg = ipu_psys_lookup_ppg(psys, hdl);
-			if (kppg) {
-				mutex_lock(&kppg->mutex);
-				if (kppg->state == PPG_STATE_STOPPING) {
-					kcmd = ipu_psys_ppg_get_stop_kcmd(kppg);
-					if (!kcmd)
-						error = true;
-				}
-				mutex_unlock(&kppg->mutex);
-			}
-		} else {
-			dev_err(&psys->adev->dev, "invalid event\n");
-			continue;
-		}
-
-		if (error || !kppg) {
-			dev_err(&psys->adev->dev, "event error, command %d\n",
-				cmd);
-			break;
-		}
-
-		dev_dbg(&psys->adev->dev, "event to kppg 0x%p, kcmd 0x%p\n",
-			kppg, kcmd);
-
-		ipu_psys_ppg_complete(psys, kppg);
-
-		if (kcmd && ipu_psys_kcmd_is_valid(psys, kcmd)) {
-			res = (status == IPU_PSYS_EVENT_CMD_COMPLETE ||
-			       status == IPU_PSYS_EVENT_FRAGMENT_COMPLETE) ?
-				0 : -EIO;
-			mutex_lock(&kppg->mutex);
-			ipu_psys_kcmd_complete(kppg, kcmd, res);
-			mutex_unlock(&kppg->mutex);
-		}
-	} while (1);
-}
-
-int ipu_psys_fh_init(struct ipu_psys_fh *fh)
-{
-	struct ipu_psys *psys = fh->psys;
-	struct ipu_psys_buffer_set *kbuf_set, *kbuf_set_tmp;
-	struct ipu_psys_scheduler *sched = &fh->sched;
-	int i;
-
-	mutex_init(&sched->bs_mutex);
-	INIT_LIST_HEAD(&sched->buf_sets);
-	INIT_LIST_HEAD(&sched->ppgs);
-	pm_runtime_dont_use_autosuspend(&psys->adev->dev);
-	/* allocate and map memory for buf_sets */
-	for (i = 0; i < IPU_PSYS_BUF_SET_POOL_SIZE; i++) {
-		kbuf_set = kzalloc(sizeof(*kbuf_set), GFP_KERNEL);
-		if (!kbuf_set)
-			goto out_free_buf_sets;
-		kbuf_set->kaddr = dma_alloc_attrs(&psys->adev->dev,
-						  IPU_PSYS_BUF_SET_MAX_SIZE,
-						  &kbuf_set->dma_addr,
-						  GFP_KERNEL,
-						  0);
-		if (!kbuf_set->kaddr) {
-			kfree(kbuf_set);
-			goto out_free_buf_sets;
-		}
-		kbuf_set->size = IPU_PSYS_BUF_SET_MAX_SIZE;
-		list_add(&kbuf_set->list, &sched->buf_sets);
-	}
-
-	return 0;
-
-out_free_buf_sets:
-	list_for_each_entry_safe(kbuf_set, kbuf_set_tmp,
-				 &sched->buf_sets, list) {
-		dma_free_attrs(&psys->adev->dev,
-			       kbuf_set->size, kbuf_set->kaddr,
-			       kbuf_set->dma_addr, 0);
-		list_del(&kbuf_set->list);
-		kfree(kbuf_set);
-	}
-	mutex_destroy(&sched->bs_mutex);
-
-	return -ENOMEM;
-}
-
-int ipu_psys_fh_deinit(struct ipu_psys_fh *fh)
-{
-	struct ipu_psys *psys = fh->psys;
-	struct ipu_psys_ppg *kppg, *kppg0;
-	struct ipu_psys_kcmd *kcmd, *kcmd0;
-	struct ipu_psys_buffer_set *kbuf_set, *kbuf_set0;
-	struct ipu_psys_scheduler *sched = &fh->sched;
-	struct ipu_psys_resource_pool *rpr;
-	struct ipu_psys_resource_alloc *alloc;
-	u8 id;
-
-	mutex_lock(&fh->mutex);
-	if (!list_empty(&sched->ppgs)) {
-		list_for_each_entry_safe(kppg, kppg0, &sched->ppgs, list) {
-			unsigned long flags;
-
-			mutex_lock(&kppg->mutex);
-			if (!(kppg->state &
-			      (PPG_STATE_STOPPED |
-			       PPG_STATE_STOPPING))) {
-				struct ipu_psys_kcmd tmp = {
-					.kpg = kppg->kpg,
-				};
-
-				rpr = &psys->resource_pool_running;
-				alloc = &kppg->kpg->resource_alloc;
-				id = ipu_fw_psys_ppg_get_base_queue_id(&tmp);
-				ipu_psys_ppg_stop(kppg);
-				ipu_psys_free_resources(alloc, rpr);
-				ipu_psys_free_cmd_queue_resource(rpr, id);
-				dev_dbg(&psys->adev->dev,
-				    "s_change:%s %p %d -> %d\n", __func__,
-				    kppg, kppg->state, PPG_STATE_STOPPED);
-				kppg->state = PPG_STATE_STOPPED;
-				if (psys->power_gating != PSYS_POWER_GATED)
-					pm_runtime_put(&psys->adev->dev);
-			}
-			list_del(&kppg->list);
-			mutex_unlock(&kppg->mutex);
-
-			list_for_each_entry_safe(kcmd, kcmd0,
-						 &kppg->kcmds_new_list, list) {
-				kcmd->pg_user = NULL;
-				mutex_unlock(&fh->mutex);
-				ipu_psys_kcmd_free(kcmd);
-				mutex_lock(&fh->mutex);
-			}
-
-			list_for_each_entry_safe(kcmd, kcmd0,
-						 &kppg->kcmds_processing_list,
-						 list) {
-				kcmd->pg_user = NULL;
-				mutex_unlock(&fh->mutex);
-				ipu_psys_kcmd_free(kcmd);
-				mutex_lock(&fh->mutex);
-			}
-
-			list_for_each_entry_safe(kcmd, kcmd0,
-						 &kppg->kcmds_finished_list,
-						 list) {
-				kcmd->pg_user = NULL;
-				mutex_unlock(&fh->mutex);
-				ipu_psys_kcmd_free(kcmd);
-				mutex_lock(&fh->mutex);
-			}
-
-			spin_lock_irqsave(&psys->pgs_lock, flags);
-			kppg->kpg->pg_size = 0;
-			spin_unlock_irqrestore(&psys->pgs_lock, flags);
-
-			mutex_destroy(&kppg->mutex);
-			kfree(kppg->manifest);
-			kfree(kppg);
-		}
-	}
-	mutex_unlock(&fh->mutex);
-
-	mutex_lock(&sched->bs_mutex);
-	list_for_each_entry_safe(kbuf_set, kbuf_set0, &sched->buf_sets, list) {
-		dma_free_attrs(&psys->adev->dev,
-			       kbuf_set->size, kbuf_set->kaddr,
-			       kbuf_set->dma_addr, 0);
-		list_del(&kbuf_set->list);
-		kfree(kbuf_set);
-	}
-	mutex_unlock(&sched->bs_mutex);
-	mutex_destroy(&sched->bs_mutex);
-
-	return 0;
-}
-
-struct ipu_psys_kcmd *ipu_get_completed_kcmd(struct ipu_psys_fh *fh)
-{
-	struct ipu_psys_scheduler *sched = &fh->sched;
-	struct ipu_psys_kcmd *kcmd;
-	struct ipu_psys_ppg *kppg;
-
-	mutex_lock(&fh->mutex);
-	if (list_empty(&sched->ppgs)) {
-		mutex_unlock(&fh->mutex);
-		return NULL;
-	}
-
-	list_for_each_entry(kppg, &sched->ppgs, list) {
-		mutex_lock(&kppg->mutex);
-		if (list_empty(&kppg->kcmds_finished_list)) {
-			mutex_unlock(&kppg->mutex);
-			continue;
-		}
-
-		kcmd = list_first_entry(&kppg->kcmds_finished_list,
-					struct ipu_psys_kcmd, list);
-		mutex_unlock(&fh->mutex);
-		mutex_unlock(&kppg->mutex);
-		dev_dbg(&fh->psys->adev->dev,
-			"get completed kcmd 0x%p\n", kcmd);
-		return kcmd;
-	}
-	mutex_unlock(&fh->mutex);
-
-	return NULL;
-}
-
-long ipu_ioctl_dqevent(struct ipu_psys_event *event,
-		       struct ipu_psys_fh *fh, unsigned int f_flags)
-{
-	struct ipu_psys *psys = fh->psys;
-	struct ipu_psys_kcmd *kcmd = NULL;
-	int rval;
-
-	dev_dbg(&psys->adev->dev, "IOC_DQEVENT\n");
-
-	if (!(f_flags & O_NONBLOCK)) {
-		rval = wait_event_interruptible(fh->wait,
-						(kcmd =
-						 ipu_get_completed_kcmd(fh)));
-		if (rval == -ERESTARTSYS)
-			return rval;
-	}
-
-	if (!kcmd) {
-		kcmd = ipu_get_completed_kcmd(fh);
-		if (!kcmd)
-			return -ENODATA;
-	}
-
-	*event = kcmd->ev;
-	ipu_psys_kcmd_free(kcmd);
-
-	return 0;
-}
diff --git a/drivers/media/pci/intel/ipu6/ipu6.c b/drivers/media/pci/intel/ipu6/ipu6.c
deleted file mode 100644
index ad89abd8bd2e..000000000000
--- a/drivers/media/pci/intel/ipu6/ipu6.c
+++ /dev/null
@@ -1,333 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0
-// Copyright (C) 2018 - 2021 Intel Corporation
-
-#include <linux/device.h>
-#include <linux/delay.h>
-#include <linux/firmware.h>
-#include <linux/module.h>
-#include <linux/pm_runtime.h>
-
-#include "ipu.h"
-#include "ipu-cpd.h"
-#include "ipu-isys.h"
-#include "ipu-psys.h"
-#include "ipu-platform.h"
-#include "ipu-platform-regs.h"
-#include "ipu-platform-buttress-regs.h"
-#include "ipu-platform-isys-csi2-reg.h"
-
-struct ipu_cell_program_t {
-	unsigned int magic_number;
-
-	unsigned int blob_offset;
-	unsigned int blob_size;
-
-	unsigned int start[3];
-
-	unsigned int icache_source;
-	unsigned int icache_target;
-	unsigned int icache_size;
-
-	unsigned int pmem_source;
-	unsigned int pmem_target;
-	unsigned int pmem_size;
-
-	unsigned int data_source;
-	unsigned int data_target;
-	unsigned int data_size;
-
-	unsigned int bss_target;
-	unsigned int bss_size;
-
-	unsigned int cell_id;
-	unsigned int regs_addr;
-
-	unsigned int cell_pmem_data_bus_address;
-	unsigned int cell_dmem_data_bus_address;
-	unsigned int cell_pmem_control_bus_address;
-	unsigned int cell_dmem_control_bus_address;
-
-	unsigned int next;
-	unsigned int dummy[2];
-};
-
-static unsigned int ipu6se_csi_offsets[] = {
-	IPU_CSI_PORT_A_ADDR_OFFSET,
-	IPU_CSI_PORT_B_ADDR_OFFSET,
-	IPU_CSI_PORT_C_ADDR_OFFSET,
-	IPU_CSI_PORT_D_ADDR_OFFSET,
-};
-
-static unsigned int ipu6_csi_offsets[] = {
-	IPU_CSI_PORT_A_ADDR_OFFSET,
-	IPU_CSI_PORT_B_ADDR_OFFSET,
-	IPU_CSI_PORT_C_ADDR_OFFSET,
-	IPU_CSI_PORT_D_ADDR_OFFSET,
-	IPU_CSI_PORT_E_ADDR_OFFSET,
-	IPU_CSI_PORT_F_ADDR_OFFSET,
-	IPU_CSI_PORT_G_ADDR_OFFSET,
-	IPU_CSI_PORT_H_ADDR_OFFSET
-};
-
-struct ipu_isys_internal_pdata isys_ipdata = {
-	.hw_variant = {
-		       .offset = IPU_UNIFIED_OFFSET,
-		       .nr_mmus = 3,
-		       .mmu_hw = {
-				{
-				   .offset = IPU_ISYS_IOMMU0_OFFSET,
-				   .info_bits =
-				   IPU_INFO_REQUEST_DESTINATION_IOSF,
-				   .nr_l1streams = 16,
-				   .l1_block_sz = {
-						   3, 8, 2, 2, 2, 2, 2, 2, 1, 1,
-						   1, 1, 1, 1, 1, 1
-				   },
-				   .nr_l2streams = 16,
-				   .l2_block_sz = {
-						   2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
-						   2, 2, 2, 2, 2, 2
-				   },
-				   .insert_read_before_invalidate = false,
-				   .l1_stream_id_reg_offset =
-				   IPU_MMU_L1_STREAM_ID_REG_OFFSET,
-				   .l2_stream_id_reg_offset =
-				   IPU_MMU_L2_STREAM_ID_REG_OFFSET,
-				},
-				{
-				   .offset = IPU_ISYS_IOMMU1_OFFSET,
-				   .info_bits = IPU_INFO_STREAM_ID_SET(0),
-				   .nr_l1streams = 16,
-				   .l1_block_sz = {
-						   2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
-						   2, 2, 2, 1, 1, 4
-				   },
-				   .nr_l2streams = 16,
-				   .l2_block_sz = {
-						   2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
-						   2, 2, 2, 2, 2, 2
-				   },
-				   .insert_read_before_invalidate = false,
-				   .l1_stream_id_reg_offset =
-				   IPU_MMU_L1_STREAM_ID_REG_OFFSET,
-				   .l2_stream_id_reg_offset =
-				   IPU_MMU_L2_STREAM_ID_REG_OFFSET,
-				},
-				{
-				   .offset = IPU_ISYS_IOMMUI_OFFSET,
-				   .info_bits = IPU_INFO_STREAM_ID_SET(0),
-				   .nr_l1streams = 0,
-				   .nr_l2streams = 0,
-				   .insert_read_before_invalidate = false,
-				},
-			},
-		       .cdc_fifos = 3,
-		       .cdc_fifo_threshold = {6, 8, 2},
-		       .dmem_offset = IPU_ISYS_DMEM_OFFSET,
-		       .spc_offset = IPU_ISYS_SPC_OFFSET,
-	},
-	.isys_dma_overshoot = IPU_ISYS_OVERALLOC_MIN,
-};
-
-struct ipu_psys_internal_pdata psys_ipdata = {
-	.hw_variant = {
-		       .offset = IPU_UNIFIED_OFFSET,
-		       .nr_mmus = 4,
-		       .mmu_hw = {
-				{
-				   .offset = IPU_PSYS_IOMMU0_OFFSET,
-				   .info_bits =
-				   IPU_INFO_REQUEST_DESTINATION_IOSF,
-				   .nr_l1streams = 16,
-				   .l1_block_sz = {
-						   2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
-						   2, 2, 2, 2, 2, 2
-				   },
-				   .nr_l2streams = 16,
-				   .l2_block_sz = {
-						   2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
-						   2, 2, 2, 2, 2, 2
-				   },
-				   .insert_read_before_invalidate = false,
-				   .l1_stream_id_reg_offset =
-				   IPU_MMU_L1_STREAM_ID_REG_OFFSET,
-				   .l2_stream_id_reg_offset =
-				   IPU_MMU_L2_STREAM_ID_REG_OFFSET,
-				},
-				{
-				   .offset = IPU_PSYS_IOMMU1_OFFSET,
-				   .info_bits = IPU_INFO_STREAM_ID_SET(0),
-				   .nr_l1streams = 32,
-				   .l1_block_sz = {
-						   1, 2, 2, 2, 2, 2, 2, 2, 2, 2,
-						   2, 2, 2, 2, 2, 10,
-						   5, 4, 14, 6, 4, 14, 6, 4, 8,
-						   4, 2, 1, 1, 1, 1, 14
-				   },
-				   .nr_l2streams = 32,
-				   .l2_block_sz = {
-						   2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
-						   2, 2, 2, 2, 2, 2,
-						   2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
-						   2, 2, 2, 2, 2, 2
-				   },
-				   .insert_read_before_invalidate = false,
-				   .l1_stream_id_reg_offset =
-				   IPU_MMU_L1_STREAM_ID_REG_OFFSET,
-				   .l2_stream_id_reg_offset =
-				   IPU_PSYS_MMU1W_L2_STREAM_ID_REG_OFFSET,
-				},
-				{
-				   .offset = IPU_PSYS_IOMMU1R_OFFSET,
-				   .info_bits = IPU_INFO_STREAM_ID_SET(0),
-				   .nr_l1streams = 16,
-				   .l1_block_sz = {
-						   1, 4, 4, 4, 4, 16, 8, 4, 32,
-						   16, 16, 2, 2, 2, 1, 12
-				   },
-				   .nr_l2streams = 16,
-				   .l2_block_sz = {
-						   2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
-						   2, 2, 2, 2, 2, 2
-				   },
-				   .insert_read_before_invalidate = false,
-				   .l1_stream_id_reg_offset =
-				   IPU_MMU_L1_STREAM_ID_REG_OFFSET,
-				   .l2_stream_id_reg_offset =
-				   IPU_MMU_L2_STREAM_ID_REG_OFFSET,
-				},
-				{
-				   .offset = IPU_PSYS_IOMMUI_OFFSET,
-				   .info_bits = IPU_INFO_STREAM_ID_SET(0),
-				   .nr_l1streams = 0,
-				   .nr_l2streams = 0,
-				   .insert_read_before_invalidate = false,
-				},
-		},
-	       .dmem_offset = IPU_PSYS_DMEM_OFFSET,
-	},
-};
-
-const struct ipu_buttress_ctrl isys_buttress_ctrl = {
-	.ratio = IPU_IS_FREQ_CTL_DEFAULT_RATIO,
-	.qos_floor = IPU_IS_FREQ_CTL_DEFAULT_QOS_FLOOR_RATIO,
-	.freq_ctl = IPU_BUTTRESS_REG_IS_FREQ_CTL,
-	.pwr_sts_shift = IPU_BUTTRESS_PWR_STATE_IS_PWR_SHIFT,
-	.pwr_sts_mask = IPU_BUTTRESS_PWR_STATE_IS_PWR_MASK,
-	.pwr_sts_on = IPU_BUTTRESS_PWR_STATE_UP_DONE,
-	.pwr_sts_off = IPU_BUTTRESS_PWR_STATE_DN_DONE,
-};
-
-const struct ipu_buttress_ctrl psys_buttress_ctrl = {
-	.ratio = IPU_PS_FREQ_CTL_DEFAULT_RATIO,
-	.qos_floor = IPU_PS_FREQ_CTL_DEFAULT_QOS_FLOOR_RATIO,
-	.freq_ctl = IPU_BUTTRESS_REG_PS_FREQ_CTL,
-	.pwr_sts_shift = IPU_BUTTRESS_PWR_STATE_PS_PWR_SHIFT,
-	.pwr_sts_mask = IPU_BUTTRESS_PWR_STATE_PS_PWR_MASK,
-	.pwr_sts_on = IPU_BUTTRESS_PWR_STATE_UP_DONE,
-	.pwr_sts_off = IPU_BUTTRESS_PWR_STATE_DN_DONE,
-};
-
-static void ipu6_pkg_dir_configure_spc(struct ipu_device *isp,
-				       const struct ipu_hw_variants *hw_variant,
-				       int pkg_dir_idx, void __iomem *base,
-				       u64 *pkg_dir,
-				       dma_addr_t pkg_dir_vied_address)
-{
-	struct ipu_psys *psys = ipu_bus_get_drvdata(isp->psys);
-	struct ipu_isys *isys = ipu_bus_get_drvdata(isp->isys);
-	unsigned int server_fw_virtaddr;
-	struct ipu_cell_program_t *prog;
-	void __iomem *spc_base;
-	dma_addr_t dma_addr;
-
-	if (!pkg_dir || !isp->cpd_fw) {
-		dev_err(&isp->pdev->dev, "invalid addr\n");
-		return;
-	}
-
-	server_fw_virtaddr = *(pkg_dir + (pkg_dir_idx + 1) * 2);
-	if (pkg_dir_idx == IPU_CPD_PKG_DIR_ISYS_SERVER_IDX) {
-		dma_addr = sg_dma_address(isys->fw_sgt.sgl);
-		prog = (struct ipu_cell_program_t *)((u64)isp->cpd_fw->data +
-							(server_fw_virtaddr -
-							 dma_addr));
-	} else {
-		dma_addr = sg_dma_address(psys->fw_sgt.sgl);
-		prog = (struct ipu_cell_program_t *)((u64)isp->cpd_fw->data +
-							(server_fw_virtaddr -
-							 dma_addr));
-	}
-
-	spc_base = base + prog->regs_addr;
-	if (spc_base != (base + hw_variant->spc_offset))
-		dev_warn(&isp->pdev->dev,
-			 "SPC reg addr 0x%p not matching value from CPD 0x%p\n",
-			 base + hw_variant->spc_offset, spc_base);
-	writel(server_fw_virtaddr + prog->blob_offset +
-	       prog->icache_source, spc_base + IPU_PSYS_REG_SPC_ICACHE_BASE);
-	writel(IPU_INFO_REQUEST_DESTINATION_IOSF,
-	       spc_base + IPU_REG_PSYS_INFO_SEG_0_CONFIG_ICACHE_MASTER);
-	writel(prog->start[1], spc_base + IPU_PSYS_REG_SPC_START_PC);
-	writel(pkg_dir_vied_address, base + hw_variant->dmem_offset);
-}
-
-void ipu_configure_spc(struct ipu_device *isp,
-		       const struct ipu_hw_variants *hw_variant,
-		       int pkg_dir_idx, void __iomem *base, u64 *pkg_dir,
-		       dma_addr_t pkg_dir_dma_addr)
-{
-	u32 val;
-	void __iomem *dmem_base = base + hw_variant->dmem_offset;
-	void __iomem *spc_regs_base = base + hw_variant->spc_offset;
-
-	val = readl(spc_regs_base + IPU_PSYS_REG_SPC_STATUS_CTRL);
-	val |= IPU_PSYS_SPC_STATUS_CTRL_ICACHE_INVALIDATE;
-	writel(val, spc_regs_base + IPU_PSYS_REG_SPC_STATUS_CTRL);
-
-	if (isp->secure_mode)
-		writel(IPU_PKG_DIR_IMR_OFFSET, dmem_base);
-	else
-		ipu6_pkg_dir_configure_spc(isp, hw_variant, pkg_dir_idx, base,
-					   pkg_dir, pkg_dir_dma_addr);
-}
-EXPORT_SYMBOL(ipu_configure_spc);
-
-int ipu_buttress_psys_freq_get(void *data, u64 *val)
-{
-	struct ipu_device *isp = data;
-	u32 reg_val;
-	int rval;
-
-	rval = pm_runtime_get_sync(&isp->psys->dev);
-	if (rval < 0) {
-		pm_runtime_put(&isp->psys->dev);
-		dev_err(&isp->pdev->dev, "Runtime PM failed (%d)\n", rval);
-		return rval;
-	}
-
-	reg_val = readl(isp->base + BUTTRESS_REG_PS_FREQ_CTL);
-
-	pm_runtime_put(&isp->psys->dev);
-
-	*val = IPU_PS_FREQ_RATIO_BASE *
-	    (reg_val & IPU_BUTTRESS_PS_FREQ_CTL_DIVISOR_MASK);
-
-	return 0;
-}
-
-void ipu_internal_pdata_init(void)
-{
-	if (ipu_ver == IPU_VER_6 || ipu_ver == IPU_VER_6EP) {
-		isys_ipdata.csi2.nports = ARRAY_SIZE(ipu6_csi_offsets);
-		isys_ipdata.csi2.offsets = ipu6_csi_offsets;
-		isys_ipdata.num_parallel_streams = IPU6_ISYS_NUM_STREAMS;
-		psys_ipdata.hw_variant.spc_offset = IPU6_PSYS_SPC_OFFSET;
-
-	} else if (ipu_ver == IPU_VER_6SE) {
-		isys_ipdata.csi2.nports = ARRAY_SIZE(ipu6se_csi_offsets);
-		isys_ipdata.csi2.offsets = ipu6se_csi_offsets;
-		isys_ipdata.num_parallel_streams = IPU6SE_ISYS_NUM_STREAMS;
-		psys_ipdata.hw_variant.spc_offset = IPU6SE_PSYS_SPC_OFFSET;
-	}
-}
diff --git a/drivers/media/pci/intel/ipu6/ipu6ep-fw-resources.c b/drivers/media/pci/intel/ipu6/ipu6ep-fw-resources.c
deleted file mode 100644
index 7b1ee7c6dc4e..000000000000
--- a/drivers/media/pci/intel/ipu6/ipu6ep-fw-resources.c
+++ /dev/null
@@ -1,393 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0
-// Copyright (C) 2020 Intel Corporation
-
-#include <linux/err.h>
-#include <linux/string.h>
-
-#include "ipu-psys.h"
-#include "ipu-fw-psys.h"
-#include "ipu6-platform-resources.h"
-#include "ipu6ep-platform-resources.h"
-
-/* resources table */
-
-/*
- * Cell types by cell IDs
- */
-static const u8 ipu6ep_fw_psys_cell_types[IPU6EP_FW_PSYS_N_CELL_ID] = {
-	IPU6_FW_PSYS_SP_CTRL_TYPE_ID,
-	IPU6_FW_PSYS_VP_TYPE_ID,
-	IPU6_FW_PSYS_ACC_PSA_TYPE_ID,
-	IPU6_FW_PSYS_ACC_PSA_TYPE_ID,
-	IPU6_FW_PSYS_ACC_PSA_TYPE_ID,
-	IPU6_FW_PSYS_ACC_PSA_TYPE_ID,
-	IPU6_FW_PSYS_ACC_OSA_TYPE_ID,
-	IPU6_FW_PSYS_ACC_OSA_TYPE_ID,
-	IPU6_FW_PSYS_ACC_OSA_TYPE_ID,
-	IPU6_FW_PSYS_ACC_PSA_TYPE_ID,
-	IPU6_FW_PSYS_ACC_PSA_TYPE_ID,
-	IPU6_FW_PSYS_ACC_PSA_TYPE_ID,
-	IPU6_FW_PSYS_ACC_PSA_TYPE_ID,
-	IPU6_FW_PSYS_ACC_ISA_TYPE_ID,
-	IPU6_FW_PSYS_ACC_ISA_TYPE_ID,
-	IPU6_FW_PSYS_ACC_ISA_TYPE_ID,
-	IPU6_FW_PSYS_ACC_ISA_TYPE_ID,
-	IPU6_FW_PSYS_ACC_ISA_TYPE_ID,
-	IPU6_FW_PSYS_ACC_ISA_TYPE_ID,
-	IPU6_FW_PSYS_ACC_ISA_TYPE_ID,
-	IPU6_FW_PSYS_ACC_ISA_TYPE_ID,
-	IPU6_FW_PSYS_ACC_ISA_TYPE_ID,
-	IPU6_FW_PSYS_ACC_ISA_TYPE_ID,
-	IPU6_FW_PSYS_ACC_ISA_TYPE_ID, /* AF */
-	IPU6_FW_PSYS_ACC_ISA_TYPE_ID, /* X2B_MD */
-	IPU6_FW_PSYS_ACC_ISA_TYPE_ID, /* X2B_SVE_RGBIR */
-	IPU6_FW_PSYS_ACC_ISA_TYPE_ID, /* PAF */
-	IPU6_FW_PSYS_GDC_TYPE_ID,
-	IPU6_FW_PSYS_TNR_TYPE_ID,
-};
-
-static const u16 ipu6ep_fw_num_dev_channels[IPU6_FW_PSYS_N_DEV_CHN_ID] = {
-	IPU6_FW_PSYS_DEV_CHN_DMA_EXT0_MAX_SIZE,
-	IPU6_FW_PSYS_DEV_CHN_DMA_EXT1_READ_MAX_SIZE,
-	IPU6_FW_PSYS_DEV_CHN_DMA_EXT1_WRITE_MAX_SIZE,
-	IPU6_FW_PSYS_DEV_CHN_DMA_INTERNAL_MAX_SIZE,
-	IPU6_FW_PSYS_DEV_CHN_DMA_ISA_MAX_SIZE,
-};
-
-static const u16 ipu6ep_fw_psys_mem_size[IPU6_FW_PSYS_N_MEM_ID] = {
-	IPU6_FW_PSYS_VMEM0_MAX_SIZE,
-	IPU6_FW_PSYS_TRANSFER_VMEM0_MAX_SIZE,
-	IPU6_FW_PSYS_TRANSFER_VMEM1_MAX_SIZE,
-	IPU6_FW_PSYS_LB_VMEM_MAX_SIZE,
-	IPU6_FW_PSYS_BAMEM0_MAX_SIZE,
-	IPU6_FW_PSYS_DMEM0_MAX_SIZE,
-	IPU6_FW_PSYS_DMEM1_MAX_SIZE,
-	IPU6_FW_PSYS_DMEM2_MAX_SIZE,
-	IPU6_FW_PSYS_DMEM3_MAX_SIZE,
-	IPU6_FW_PSYS_PMEM0_MAX_SIZE
-};
-
-static const u16 ipu6ep_fw_psys_dfms[IPU6_FW_PSYS_N_DEV_DFM_ID] = {
-	IPU6_FW_PSYS_DEV_DFM_BB_FULL_PORT_ID_MAX_SIZE,
-	IPU6_FW_PSYS_DEV_DFM_BB_EMPTY_PORT_ID_MAX_SIZE,
-	IPU6_FW_PSYS_DEV_DFM_ISL_FULL_PORT_ID_MAX_SIZE,
-	IPU6_FW_PSYS_DEV_DFM_ISL_EMPTY_PORT_ID_MAX_SIZE,
-	IPU6_FW_PSYS_DEV_DFM_LB_FULL_PORT_ID_MAX_SIZE,
-	IPU6_FW_PSYS_DEV_DFM_LB_EMPTY_PORT_ID_MAX_SIZE,
-};
-
-static const u8
-ipu6ep_fw_psys_c_mem[IPU6EP_FW_PSYS_N_CELL_ID][IPU6_FW_PSYS_N_MEM_TYPE_ID] = {
-	{
-		/* IPU6_FW_PSYS_SP0_ID */
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_DMEM0_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-	},
-	{
-		/* IPU6_FW_PSYS_SP1_ID */
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_DMEM1_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-	},
-	{
-		/* IPU6_FW_PSYS_VP0_ID */
-		IPU6_FW_PSYS_TRANSFER_VMEM0_ID,
-		IPU6_FW_PSYS_TRANSFER_VMEM1_ID,
-		IPU6_FW_PSYS_LB_VMEM_ID,
-		IPU6_FW_PSYS_DMEM3_ID,
-		IPU6_FW_PSYS_VMEM0_ID,
-		IPU6_FW_PSYS_BAMEM0_ID,
-		IPU6_FW_PSYS_PMEM0_ID,
-	},
-	{
-		/* IPU6_FW_PSYS_ACC1_ID BNLM */
-		IPU6_FW_PSYS_TRANSFER_VMEM0_ID,
-		IPU6_FW_PSYS_TRANSFER_VMEM1_ID,
-		IPU6_FW_PSYS_LB_VMEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-	},
-	{
-		/* IPU6_FW_PSYS_ACC2_ID DM */
-		IPU6_FW_PSYS_TRANSFER_VMEM0_ID,
-		IPU6_FW_PSYS_TRANSFER_VMEM1_ID,
-		IPU6_FW_PSYS_LB_VMEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-	},
-	{
-		/* IPU6_FW_PSYS_ACC3_ID ACM */
-		IPU6_FW_PSYS_TRANSFER_VMEM0_ID,
-		IPU6_FW_PSYS_TRANSFER_VMEM1_ID,
-		IPU6_FW_PSYS_LB_VMEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-	},
-	{
-		/* IPU6_FW_PSYS_ACC4_ID GTC YUV1 */
-		IPU6_FW_PSYS_TRANSFER_VMEM0_ID,
-		IPU6_FW_PSYS_TRANSFER_VMEM1_ID,
-		IPU6_FW_PSYS_LB_VMEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-	},
-	{
-		/* IPU6_FW_PSYS_ACC5_ID OFS pin main */
-		IPU6_FW_PSYS_TRANSFER_VMEM0_ID,
-		IPU6_FW_PSYS_TRANSFER_VMEM1_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-	},
-	{
-		/* IPU6_FW_PSYS_ACC6_ID OFS pin display */
-		IPU6_FW_PSYS_TRANSFER_VMEM0_ID,
-		IPU6_FW_PSYS_TRANSFER_VMEM1_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-	},
-	{
-		/* IPU6_FW_PSYS_ACC7_ID OFS pin pp */
-		IPU6_FW_PSYS_TRANSFER_VMEM0_ID,
-		IPU6_FW_PSYS_TRANSFER_VMEM1_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-	},
-	{
-		/* IPU6_FW_PSYS_ACC8_ID GAMMASTAR */
-		IPU6_FW_PSYS_TRANSFER_VMEM0_ID,
-		IPU6_FW_PSYS_TRANSFER_VMEM1_ID,
-		IPU6_FW_PSYS_LB_VMEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-	},
-	{
-		/* IPU6_FW_PSYS_ACC9_ID GLTM */
-		IPU6_FW_PSYS_TRANSFER_VMEM0_ID,
-		IPU6_FW_PSYS_TRANSFER_VMEM1_ID,
-		IPU6_FW_PSYS_LB_VMEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-	},
-	{
-		/* IPU6_FW_PSYS_ACC10_ID XNR */
-		IPU6_FW_PSYS_TRANSFER_VMEM0_ID,
-		IPU6_FW_PSYS_TRANSFER_VMEM1_ID,
-		IPU6_FW_PSYS_LB_VMEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-	},
-	{
-		/* IPU6_FW_PSYS_ISA_ICA_ID */
-		IPU6_FW_PSYS_TRANSFER_VMEM0_ID,
-		IPU6_FW_PSYS_TRANSFER_VMEM1_ID,
-		IPU6_FW_PSYS_LB_VMEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-	},
-	{
-		/* IPU6_FW_PSYS_ISA_LSC_ID */
-		IPU6_FW_PSYS_TRANSFER_VMEM0_ID,
-		IPU6_FW_PSYS_TRANSFER_VMEM1_ID,
-		IPU6_FW_PSYS_LB_VMEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-	},
-	{
-		/* IPU6_FW_PSYS_ISA_DPC_ID */
-		IPU6_FW_PSYS_TRANSFER_VMEM0_ID,
-		IPU6_FW_PSYS_TRANSFER_VMEM1_ID,
-		IPU6_FW_PSYS_LB_VMEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-	},
-	{
-		/* IPU6_FW_PSYS_ISA_SIS_A_ID */
-		IPU6_FW_PSYS_TRANSFER_VMEM0_ID,
-		IPU6_FW_PSYS_TRANSFER_VMEM1_ID,
-		IPU6_FW_PSYS_LB_VMEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-	},
-	{
-		/* IPU6_FW_PSYS_ISA_SIS_B_ID */
-		IPU6_FW_PSYS_TRANSFER_VMEM0_ID,
-		IPU6_FW_PSYS_TRANSFER_VMEM1_ID,
-		IPU6_FW_PSYS_LB_VMEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-	},
-	{
-		/* IPU6_FW_PSYS_ISA_B2B_ID */
-		IPU6_FW_PSYS_TRANSFER_VMEM0_ID,
-		IPU6_FW_PSYS_TRANSFER_VMEM1_ID,
-		IPU6_FW_PSYS_LB_VMEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-	},
-	{
-		/* IPU6_FW_PSYS_ISA_B2R_ID and ISA_R2I_SIE */
-		IPU6_FW_PSYS_TRANSFER_VMEM0_ID,
-		IPU6_FW_PSYS_TRANSFER_VMEM1_ID,
-		IPU6_FW_PSYS_LB_VMEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-	},
-	{
-		/* IPU6_FW_PSYS_ISA_R2I_DS_A_ID */
-		IPU6_FW_PSYS_TRANSFER_VMEM0_ID,
-		IPU6_FW_PSYS_TRANSFER_VMEM1_ID,
-		IPU6_FW_PSYS_LB_VMEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-	},
-	{
-		/* IPU6_FW_PSYS_ISA_AWB_ID */
-		IPU6_FW_PSYS_TRANSFER_VMEM0_ID,
-		IPU6_FW_PSYS_TRANSFER_VMEM1_ID,
-		IPU6_FW_PSYS_LB_VMEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-	},
-	{
-		/* IPU6_FW_PSYS_ISA_AE_ID */
-		IPU6_FW_PSYS_TRANSFER_VMEM0_ID,
-		IPU6_FW_PSYS_TRANSFER_VMEM1_ID,
-		IPU6_FW_PSYS_LB_VMEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-	},
-	{
-		/* IPU6_FW_PSYS_ISA_AF_ID */
-		IPU6_FW_PSYS_TRANSFER_VMEM0_ID,
-		IPU6_FW_PSYS_TRANSFER_VMEM1_ID,
-		IPU6_FW_PSYS_LB_VMEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-	},
-	{
-		/* IPU6_FW_PSYS_ISA_X2B_MD_ID */
-		IPU6_FW_PSYS_TRANSFER_VMEM0_ID,
-		IPU6_FW_PSYS_TRANSFER_VMEM1_ID,
-		IPU6_FW_PSYS_LB_VMEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-	},
-	{
-		/* IPU6_FW_PSYS_ISA_X2B_SVE_RGBIR_ID */
-		IPU6_FW_PSYS_TRANSFER_VMEM0_ID,
-		IPU6_FW_PSYS_TRANSFER_VMEM1_ID,
-		IPU6_FW_PSYS_LB_VMEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-	},
-	{
-		/* IPU6_FW_PSYS_ISA_PAF_ID */
-		IPU6_FW_PSYS_TRANSFER_VMEM0_ID,
-		IPU6_FW_PSYS_TRANSFER_VMEM1_ID,
-		IPU6_FW_PSYS_LB_VMEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-	},
-	{
-		/* IPU6_FW_PSYS_BB_ACC_GDC0_ID */
-		IPU6_FW_PSYS_TRANSFER_VMEM0_ID,
-		IPU6_FW_PSYS_TRANSFER_VMEM1_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-	},
-	{
-		/* IPU6_FW_PSYS_BB_ACC_TNR_ID */
-		IPU6_FW_PSYS_TRANSFER_VMEM0_ID,
-		IPU6_FW_PSYS_TRANSFER_VMEM1_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-		IPU6_FW_PSYS_N_MEM_ID,
-	}
-};
-
-static const struct ipu_fw_resource_definitions ipu6ep_defs = {
-	.cells = ipu6ep_fw_psys_cell_types,
-	.num_cells = IPU6EP_FW_PSYS_N_CELL_ID,
-	.num_cells_type = IPU6_FW_PSYS_N_CELL_TYPE_ID,
-
-	.dev_channels = ipu6ep_fw_num_dev_channels,
-	.num_dev_channels = IPU6_FW_PSYS_N_DEV_CHN_ID,
-
-	.num_ext_mem_types = IPU6_FW_PSYS_N_DATA_MEM_TYPE_ID,
-	.num_ext_mem_ids = IPU6_FW_PSYS_N_MEM_ID,
-	.ext_mem_ids = ipu6ep_fw_psys_mem_size,
-
-	.num_dfm_ids = IPU6_FW_PSYS_N_DEV_DFM_ID,
-
-	.dfms = ipu6ep_fw_psys_dfms,
-
-	.cell_mem_row = IPU6_FW_PSYS_N_MEM_TYPE_ID,
-	.cell_mem = &ipu6ep_fw_psys_c_mem[0][0],
-};
-
-const struct ipu_fw_resource_definitions *ipu6ep_res_defs = &ipu6ep_defs;
diff --git a/drivers/media/pci/intel/ipu6/ipu6ep-platform-resources.h b/drivers/media/pci/intel/ipu6/ipu6ep-platform-resources.h
deleted file mode 100644
index 7776ea986940..000000000000
--- a/drivers/media/pci/intel/ipu6/ipu6ep-platform-resources.h
+++ /dev/null
@@ -1,42 +0,0 @@
-/* SPDX-License-Identifier: GPL-2.0 */
-/* Copyright (C) 2020 Intel Corporation */
-
-#ifndef IPU6EP_PLATFORM_RESOURCES_H
-#define IPU6EP_PLATFORM_RESOURCES_H
-
-#include <linux/kernel.h>
-#include <linux/device.h>
-
-enum {
-	IPU6EP_FW_PSYS_SP0_ID = 0,
-	IPU6EP_FW_PSYS_VP0_ID,
-	IPU6EP_FW_PSYS_PSA_ACC_BNLM_ID,
-	IPU6EP_FW_PSYS_PSA_ACC_DM_ID,
-	IPU6EP_FW_PSYS_PSA_ACC_ACM_ID,
-	IPU6EP_FW_PSYS_PSA_ACC_GTC_YUV1_ID,
-	IPU6EP_FW_PSYS_BB_ACC_OFS_PIN_MAIN_ID,
-	IPU6EP_FW_PSYS_BB_ACC_OFS_PIN_DISPLAY_ID,
-	IPU6EP_FW_PSYS_BB_ACC_OFS_PIN_PP_ID,
-	IPU6EP_FW_PSYS_PSA_ACC_GAMMASTAR_ID,
-	IPU6EP_FW_PSYS_PSA_ACC_GLTM_ID,
-	IPU6EP_FW_PSYS_PSA_ACC_XNR_ID,
-	IPU6EP_FW_PSYS_PSA_VCSC_ID,	/* VCSC */
-	IPU6EP_FW_PSYS_ISA_ICA_ID,
-	IPU6EP_FW_PSYS_ISA_LSC_ID,
-	IPU6EP_FW_PSYS_ISA_DPC_ID,
-	IPU6EP_FW_PSYS_ISA_SIS_A_ID,
-	IPU6EP_FW_PSYS_ISA_SIS_B_ID,
-	IPU6EP_FW_PSYS_ISA_B2B_ID,
-	IPU6EP_FW_PSYS_ISA_B2R_R2I_SIE_ID,
-	IPU6EP_FW_PSYS_ISA_R2I_DS_A_ID,
-	IPU6EP_FW_PSYS_ISA_AWB_ID,
-	IPU6EP_FW_PSYS_ISA_AE_ID,
-	IPU6EP_FW_PSYS_ISA_AF_ID,
-	IPU6EP_FW_PSYS_ISA_X2B_MD_ID,
-	IPU6EP_FW_PSYS_ISA_X2B_SVE_RGBIR_ID,
-	IPU6EP_FW_PSYS_ISA_PAF_ID,
-	IPU6EP_FW_PSYS_BB_ACC_GDC0_ID,
-	IPU6EP_FW_PSYS_BB_ACC_TNR_ID,
-	IPU6EP_FW_PSYS_N_CELL_ID
-};
-#endif /* IPU6EP_PLATFORM_RESOURCES_H */
diff --git a/drivers/media/pci/intel/ipu6/ipu6se-fw-resources.c b/drivers/media/pci/intel/ipu6/ipu6se-fw-resources.c
deleted file mode 100644
index f94df275b37c..000000000000
--- a/drivers/media/pci/intel/ipu6/ipu6se-fw-resources.c
+++ /dev/null
@@ -1,194 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0
-// Copyright (C) 2015 - 2019 Intel Corporation
-
-#include <linux/err.h>
-#include <linux/string.h>
-
-#include "ipu-psys.h"
-#include "ipu-fw-psys.h"
-#include "ipu6se-platform-resources.h"
-
-/* resources table */
-
-/*
- * Cell types by cell IDs
- */
-/* resources table */
-
-/*
- * Cell types by cell IDs
- */
-const u8 ipu6se_fw_psys_cell_types[IPU6SE_FW_PSYS_N_CELL_ID] = {
-	IPU6SE_FW_PSYS_SP_CTRL_TYPE_ID,
-	IPU6SE_FW_PSYS_ACC_ISA_TYPE_ID, /* IPU6SE_FW_PSYS_ISA_ICA_ID */
-	IPU6SE_FW_PSYS_ACC_ISA_TYPE_ID, /* IPU6SE_FW_PSYS_ISA_LSC_ID */
-	IPU6SE_FW_PSYS_ACC_ISA_TYPE_ID, /* IPU6SE_FW_PSYS_ISA_DPC_ID */
-	IPU6SE_FW_PSYS_ACC_ISA_TYPE_ID, /* IPU6SE_FW_PSYS_ISA_B2B_ID */
-	IPU6SE_FW_PSYS_ACC_ISA_TYPE_ID, /* IPU6SE_FW_PSYS_ISA_BNLM_ID */
-	IPU6SE_FW_PSYS_ACC_ISA_TYPE_ID, /* IPU6SE_FW_PSYS_ISA_DM_ID */
-	IPU6SE_FW_PSYS_ACC_ISA_TYPE_ID, /* IPU6SE_FW_PSYS_ISA_R2I_SIE_ID */
-	IPU6SE_FW_PSYS_ACC_ISA_TYPE_ID, /* IPU6SE_FW_PSYS_ISA_R2I_DS_A_ID */
-	IPU6SE_FW_PSYS_ACC_ISA_TYPE_ID, /* IPU6SE_FW_PSYS_ISA_R2I_DS_B_ID */
-	IPU6SE_FW_PSYS_ACC_ISA_TYPE_ID, /* IPU6SE_FW_PSYS_ISA_AWB_ID */
-	IPU6SE_FW_PSYS_ACC_ISA_TYPE_ID, /* IPU6SE_FW_PSYS_ISA_AE_ID */
-	IPU6SE_FW_PSYS_ACC_ISA_TYPE_ID, /* IPU6SE_FW_PSYS_ISA_AF_ID*/
-	IPU6SE_FW_PSYS_ACC_ISA_TYPE_ID  /* PAF */
-};
-
-const u16 ipu6se_fw_num_dev_channels[IPU6SE_FW_PSYS_N_DEV_CHN_ID] = {
-	IPU6SE_FW_PSYS_DEV_CHN_DMA_EXT0_MAX_SIZE,
-	IPU6SE_FW_PSYS_DEV_CHN_DMA_EXT1_READ_MAX_SIZE,
-	IPU6SE_FW_PSYS_DEV_CHN_DMA_EXT1_WRITE_MAX_SIZE,
-	IPU6SE_FW_PSYS_DEV_CHN_DMA_ISA_MAX_SIZE,
-};
-
-const u16 ipu6se_fw_psys_mem_size[IPU6SE_FW_PSYS_N_MEM_ID] = {
-	IPU6SE_FW_PSYS_TRANSFER_VMEM0_MAX_SIZE,
-	IPU6SE_FW_PSYS_LB_VMEM_MAX_SIZE,
-	IPU6SE_FW_PSYS_DMEM0_MAX_SIZE,
-	IPU6SE_FW_PSYS_DMEM1_MAX_SIZE
-};
-
-const u16 ipu6se_fw_psys_dfms[IPU6SE_FW_PSYS_N_DEV_DFM_ID] = {
-	IPU6SE_FW_PSYS_DEV_DFM_ISL_FULL_PORT_ID_MAX_SIZE,
-	IPU6SE_FW_PSYS_DEV_DFM_ISL_EMPTY_PORT_ID_MAX_SIZE
-};
-
-const u8
-ipu6se_fw_psys_c_mem[IPU6SE_FW_PSYS_N_CELL_ID][IPU6SE_FW_PSYS_N_MEM_TYPE_ID] = {
-	{ /* IPU6SE_FW_PSYS_SP0_ID */
-		IPU6SE_FW_PSYS_N_MEM_ID,
-		IPU6SE_FW_PSYS_N_MEM_ID,
-		IPU6SE_FW_PSYS_DMEM0_ID,
-		IPU6SE_FW_PSYS_N_MEM_ID,
-		IPU6SE_FW_PSYS_N_MEM_ID,
-		IPU6SE_FW_PSYS_N_MEM_ID,
-	},
-	{ /* IPU6SE_FW_PSYS_ISA_ICA_ID */
-		IPU6SE_FW_PSYS_TRANSFER_VMEM0_ID,
-		IPU6SE_FW_PSYS_LB_VMEM_ID,
-		IPU6SE_FW_PSYS_N_MEM_ID,
-		IPU6SE_FW_PSYS_N_MEM_ID,
-		IPU6SE_FW_PSYS_N_MEM_ID,
-		IPU6SE_FW_PSYS_N_MEM_ID,
-	},
-	{ /* IPU6SE_FW_PSYS_ISA_LSC_ID */
-		IPU6SE_FW_PSYS_TRANSFER_VMEM0_ID,
-		IPU6SE_FW_PSYS_LB_VMEM_ID,
-		IPU6SE_FW_PSYS_N_MEM_ID,
-		IPU6SE_FW_PSYS_N_MEM_ID,
-		IPU6SE_FW_PSYS_N_MEM_ID,
-		IPU6SE_FW_PSYS_N_MEM_ID,
-	},
-	{ /* IPU6SE_FW_PSYS_ISA_DPC_ID */
-		IPU6SE_FW_PSYS_TRANSFER_VMEM0_ID,
-		IPU6SE_FW_PSYS_LB_VMEM_ID,
-		IPU6SE_FW_PSYS_N_MEM_ID,
-		IPU6SE_FW_PSYS_N_MEM_ID,
-		IPU6SE_FW_PSYS_N_MEM_ID,
-		IPU6SE_FW_PSYS_N_MEM_ID,
-	},
-	{ /* IPU6SE_FW_PSYS_ISA_B2B_ID */
-		IPU6SE_FW_PSYS_TRANSFER_VMEM0_ID,
-		IPU6SE_FW_PSYS_LB_VMEM_ID,
-		IPU6SE_FW_PSYS_N_MEM_ID,
-		IPU6SE_FW_PSYS_N_MEM_ID,
-		IPU6SE_FW_PSYS_N_MEM_ID,
-		IPU6SE_FW_PSYS_N_MEM_ID,
-	},
-
-	{ /* IPU6SE_FW_PSYS_ISA_BNLM_ID */
-		IPU6SE_FW_PSYS_TRANSFER_VMEM0_ID,
-		IPU6SE_FW_PSYS_LB_VMEM_ID,
-		IPU6SE_FW_PSYS_N_MEM_ID,
-		IPU6SE_FW_PSYS_N_MEM_ID,
-		IPU6SE_FW_PSYS_N_MEM_ID,
-		IPU6SE_FW_PSYS_N_MEM_ID,
-	},
-	{ /* IPU6SE_FW_PSYS_ISA_DM_ID */
-		IPU6SE_FW_PSYS_TRANSFER_VMEM0_ID,
-		IPU6SE_FW_PSYS_LB_VMEM_ID,
-		IPU6SE_FW_PSYS_N_MEM_ID,
-		IPU6SE_FW_PSYS_N_MEM_ID,
-		IPU6SE_FW_PSYS_N_MEM_ID,
-		IPU6SE_FW_PSYS_N_MEM_ID,
-	},
-	{ /* IPU6SE_FW_PSYS_ISA_R2I_SIE_ID */
-		IPU6SE_FW_PSYS_TRANSFER_VMEM0_ID,
-		IPU6SE_FW_PSYS_LB_VMEM_ID,
-		IPU6SE_FW_PSYS_N_MEM_ID,
-		IPU6SE_FW_PSYS_N_MEM_ID,
-		IPU6SE_FW_PSYS_N_MEM_ID,
-		IPU6SE_FW_PSYS_N_MEM_ID,
-	},
-	{ /* IPU6SE_FW_PSYS_ISA_R2I_DS_A_ID */
-		IPU6SE_FW_PSYS_TRANSFER_VMEM0_ID,
-		IPU6SE_FW_PSYS_LB_VMEM_ID,
-		IPU6SE_FW_PSYS_N_MEM_ID,
-		IPU6SE_FW_PSYS_N_MEM_ID,
-		IPU6SE_FW_PSYS_N_MEM_ID,
-		IPU6SE_FW_PSYS_N_MEM_ID,
-	},
-	{ /* IPU6SE_FW_PSYS_ISA_R2I_DS_B_ID */
-		IPU6SE_FW_PSYS_TRANSFER_VMEM0_ID,
-		IPU6SE_FW_PSYS_LB_VMEM_ID,
-		IPU6SE_FW_PSYS_N_MEM_ID,
-		IPU6SE_FW_PSYS_N_MEM_ID,
-		IPU6SE_FW_PSYS_N_MEM_ID,
-		IPU6SE_FW_PSYS_N_MEM_ID,
-	},
-	{ /* IPU6SE_FW_PSYS_ISA_AWB_ID */
-		IPU6SE_FW_PSYS_TRANSFER_VMEM0_ID,
-		IPU6SE_FW_PSYS_LB_VMEM_ID,
-		IPU6SE_FW_PSYS_N_MEM_ID,
-		IPU6SE_FW_PSYS_N_MEM_ID,
-		IPU6SE_FW_PSYS_N_MEM_ID,
-		IPU6SE_FW_PSYS_N_MEM_ID,
-	},
-	{ /* IPU6SE_FW_PSYS_ISA_AE_ID */
-		IPU6SE_FW_PSYS_TRANSFER_VMEM0_ID,
-		IPU6SE_FW_PSYS_LB_VMEM_ID,
-		IPU6SE_FW_PSYS_N_MEM_ID,
-		IPU6SE_FW_PSYS_N_MEM_ID,
-		IPU6SE_FW_PSYS_N_MEM_ID,
-		IPU6SE_FW_PSYS_N_MEM_ID,
-	},
-	{ /* IPU6SE_FW_PSYS_ISA_AF_ID */
-		IPU6SE_FW_PSYS_TRANSFER_VMEM0_ID,
-		IPU6SE_FW_PSYS_LB_VMEM_ID,
-		IPU6SE_FW_PSYS_N_MEM_ID,
-		IPU6SE_FW_PSYS_N_MEM_ID,
-		IPU6SE_FW_PSYS_N_MEM_ID,
-		IPU6SE_FW_PSYS_N_MEM_ID,
-	},
-	{ /* IPU6SE_FW_PSYS_ISA_PAF_ID */
-		IPU6SE_FW_PSYS_TRANSFER_VMEM0_ID,
-		IPU6SE_FW_PSYS_LB_VMEM_ID,
-		IPU6SE_FW_PSYS_N_MEM_ID,
-		IPU6SE_FW_PSYS_N_MEM_ID,
-		IPU6SE_FW_PSYS_N_MEM_ID,
-		IPU6SE_FW_PSYS_N_MEM_ID,
-	}
-};
-
-static const struct ipu_fw_resource_definitions ipu6se_defs = {
-	.cells = ipu6se_fw_psys_cell_types,
-	.num_cells = IPU6SE_FW_PSYS_N_CELL_ID,
-	.num_cells_type = IPU6SE_FW_PSYS_N_CELL_TYPE_ID,
-
-	.dev_channels = ipu6se_fw_num_dev_channels,
-	.num_dev_channels = IPU6SE_FW_PSYS_N_DEV_CHN_ID,
-
-	.num_ext_mem_types = IPU6SE_FW_PSYS_N_DATA_MEM_TYPE_ID,
-	.num_ext_mem_ids = IPU6SE_FW_PSYS_N_MEM_ID,
-	.ext_mem_ids = ipu6se_fw_psys_mem_size,
-
-	.num_dfm_ids = IPU6SE_FW_PSYS_N_DEV_DFM_ID,
-
-	.dfms = ipu6se_fw_psys_dfms,
-
-	.cell_mem_row = IPU6SE_FW_PSYS_N_MEM_TYPE_ID,
-	.cell_mem = &ipu6se_fw_psys_c_mem[0][0],
-};
-
-const struct ipu_fw_resource_definitions *ipu6se_res_defs = &ipu6se_defs;
diff --git a/drivers/media/pci/intel/ipu6/ipu6se-platform-resources.h b/drivers/media/pci/intel/ipu6/ipu6se-platform-resources.h
deleted file mode 100644
index fcb52da3d65b..000000000000
--- a/drivers/media/pci/intel/ipu6/ipu6se-platform-resources.h
+++ /dev/null
@@ -1,103 +0,0 @@
-/* SPDX-License-Identifier: GPL-2.0 */
-/* Copyright (C) 2018 - 2020 Intel Corporation */
-
-#ifndef IPU6SE_PLATFORM_RESOURCES_H
-#define IPU6SE_PLATFORM_RESOURCES_H
-
-#include <linux/kernel.h>
-#include <linux/device.h>
-#include "ipu-platform-resources.h"
-
-#define	IPU6SE_FW_PSYS_N_PADDING_UINT8_IN_PROCESS_EXT_STRUCT		1
-
-enum {
-	IPU6SE_FW_PSYS_CMD_QUEUE_COMMAND_ID = 0,
-	IPU6SE_FW_PSYS_CMD_QUEUE_DEVICE_ID,
-	IPU6SE_FW_PSYS_CMD_QUEUE_PPG0_COMMAND_ID,
-	IPU6SE_FW_PSYS_CMD_QUEUE_PPG1_COMMAND_ID,
-	IPU6SE_FW_PSYS_CMD_QUEUE_PPG2_COMMAND_ID,
-	IPU6SE_FW_PSYS_CMD_QUEUE_PPG3_COMMAND_ID,
-	IPU6SE_FW_PSYS_CMD_QUEUE_PPG4_COMMAND_ID,
-	IPU6SE_FW_PSYS_CMD_QUEUE_PPG5_COMMAND_ID,
-	IPU6SE_FW_PSYS_N_PSYS_CMD_QUEUE_ID
-};
-
-enum {
-	IPU6SE_FW_PSYS_TRANSFER_VMEM0_TYPE_ID = 0,
-	IPU6SE_FW_PSYS_LB_VMEM_TYPE_ID,
-	IPU6SE_FW_PSYS_DMEM_TYPE_ID,
-	IPU6SE_FW_PSYS_VMEM_TYPE_ID,
-	IPU6SE_FW_PSYS_BAMEM_TYPE_ID,
-	IPU6SE_FW_PSYS_PMEM_TYPE_ID,
-	IPU6SE_FW_PSYS_N_MEM_TYPE_ID
-};
-
-enum ipu6se_mem_id {
-	IPU6SE_FW_PSYS_TRANSFER_VMEM0_ID = 0,	/* TRANSFER VMEM 0 */
-	IPU6SE_FW_PSYS_LB_VMEM_ID,	/* LB VMEM */
-	IPU6SE_FW_PSYS_DMEM0_ID,	/* SPC0 Dmem */
-	IPU6SE_FW_PSYS_DMEM1_ID,	/* SPP0 Dmem */
-	IPU6SE_FW_PSYS_N_MEM_ID
-};
-
-enum {
-	IPU6SE_FW_PSYS_DEV_CHN_DMA_EXT0_ID = 0,
-	IPU6SE_FW_PSYS_DEV_CHN_DMA_EXT1_READ_ID,
-	IPU6SE_FW_PSYS_DEV_CHN_DMA_EXT1_WRITE_ID,
-	IPU6SE_FW_PSYS_DEV_CHN_DMA_ISA_ID,
-	IPU6SE_FW_PSYS_N_DEV_CHN_ID
-};
-
-enum {
-	IPU6SE_FW_PSYS_SP_CTRL_TYPE_ID = 0,
-	IPU6SE_FW_PSYS_SP_SERVER_TYPE_ID,
-	IPU6SE_FW_PSYS_ACC_ISA_TYPE_ID,
-	IPU6SE_FW_PSYS_N_CELL_TYPE_ID
-};
-
-enum {
-	IPU6SE_FW_PSYS_SP0_ID = 0,
-	IPU6SE_FW_PSYS_ISA_ICA_ID,
-	IPU6SE_FW_PSYS_ISA_LSC_ID,
-	IPU6SE_FW_PSYS_ISA_DPC_ID,
-	IPU6SE_FW_PSYS_ISA_B2B_ID,
-	IPU6SE_FW_PSYS_ISA_BNLM_ID,
-	IPU6SE_FW_PSYS_ISA_DM_ID,
-	IPU6SE_FW_PSYS_ISA_R2I_SIE_ID,
-	IPU6SE_FW_PSYS_ISA_R2I_DS_A_ID,
-	IPU6SE_FW_PSYS_ISA_R2I_DS_B_ID,
-	IPU6SE_FW_PSYS_ISA_AWB_ID,
-	IPU6SE_FW_PSYS_ISA_AE_ID,
-	IPU6SE_FW_PSYS_ISA_AF_ID,
-	IPU6SE_FW_PSYS_ISA_PAF_ID,
-	IPU6SE_FW_PSYS_N_CELL_ID
-};
-
-enum {
-	IPU6SE_FW_PSYS_DEV_DFM_ISL_FULL_PORT_ID = 0,
-	IPU6SE_FW_PSYS_DEV_DFM_ISL_EMPTY_PORT_ID,
-};
-
-/* Excluding PMEM */
-#define IPU6SE_FW_PSYS_N_DATA_MEM_TYPE_ID (IPU6SE_FW_PSYS_N_MEM_TYPE_ID - 1)
-#define IPU6SE_FW_PSYS_N_DEV_DFM_ID	\
-	(IPU6SE_FW_PSYS_DEV_DFM_ISL_EMPTY_PORT_ID + 1)
-#define IPU6SE_FW_PSYS_VMEM0_MAX_SIZE		0x0800
-/* Transfer VMEM0 words, ref HAS Transfer*/
-#define IPU6SE_FW_PSYS_TRANSFER_VMEM0_MAX_SIZE	0x0800
-#define IPU6SE_FW_PSYS_LB_VMEM_MAX_SIZE		0x0400	/* LB VMEM words */
-#define IPU6SE_FW_PSYS_DMEM0_MAX_SIZE		0x4000
-#define IPU6SE_FW_PSYS_DMEM1_MAX_SIZE		0x1000
-
-#define IPU6SE_FW_PSYS_DEV_CHN_DMA_EXT0_MAX_SIZE		22
-#define IPU6SE_FW_PSYS_DEV_CHN_DMA_EXT1_READ_MAX_SIZE	22
-#define IPU6SE_FW_PSYS_DEV_CHN_DMA_EXT1_WRITE_MAX_SIZE	22
-#define IPU6SE_FW_PSYS_DEV_CHN_DMA_IPFD_MAX_SIZE		0
-#define IPU6SE_FW_PSYS_DEV_CHN_DMA_ISA_MAX_SIZE		2
-
-#define IPU6SE_FW_PSYS_DEV_DFM_ISL_FULL_PORT_ID_MAX_SIZE		32
-#define IPU6SE_FW_PSYS_DEV_DFM_LB_FULL_PORT_ID_MAX_SIZE		32
-#define IPU6SE_FW_PSYS_DEV_DFM_ISL_EMPTY_PORT_ID_MAX_SIZE		32
-#define IPU6SE_FW_PSYS_DEV_DFM_LB_EMPTY_PORT_ID_MAX_SIZE		32
-
-#endif /* IPU6SE_PLATFORM_RESOURCES_H */
-- 
2.34.1

